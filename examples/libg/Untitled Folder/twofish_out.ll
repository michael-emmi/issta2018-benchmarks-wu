; ModuleID = '<stdin>'
source_filename = "libg/twofish.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.TWOFISH_context = type { [4 x [256 x i32]], [8 x i32], [32 x i32] }

@in_key = internal constant [16 x i8] c"\00\11\223DUfw\88\99\AA\BB\CC\DD\EE\FF", align 16
@out = internal global [16 x i8] zeroinitializer, align 16
@in = internal global [16 x i8] c"\C8#\B8\B7k\FE\91\13/\A7^\E6\94wok", align 16
@do_twofish_setkey.initialized = internal global i32 0, align 4
@do_twofish_setkey.selftest_failed = internal global i8* null, align 8
@poly_to_exp = internal constant [256 x i16] [i16 492, i16 0, i16 1, i16 23, i16 2, i16 46, i16 24, i16 83, i16 3, i16 106, i16 47, i16 147, i16 25, i16 52, i16 84, i16 69, i16 4, i16 92, i16 107, i16 182, i16 48, i16 166, i16 148, i16 75, i16 26, i16 140, i16 53, i16 129, i16 85, i16 170, i16 70, i16 13, i16 5, i16 36, i16 93, i16 135, i16 108, i16 155, i16 183, i16 193, i16 49, i16 43, i16 167, i16 163, i16 149, i16 152, i16 76, i16 202, i16 27, i16 230, i16 141, i16 115, i16 54, i16 205, i16 130, i16 18, i16 86, i16 98, i16 171, i16 240, i16 71, i16 79, i16 14, i16 189, i16 6, i16 212, i16 37, i16 210, i16 94, i16 39, i16 136, i16 102, i16 109, i16 214, i16 156, i16 121, i16 184, i16 8, i16 194, i16 223, i16 50, i16 104, i16 44, i16 253, i16 168, i16 138, i16 164, i16 90, i16 150, i16 41, i16 153, i16 34, i16 77, i16 96, i16 203, i16 228, i16 28, i16 123, i16 231, i16 59, i16 142, i16 158, i16 116, i16 244, i16 55, i16 216, i16 206, i16 249, i16 131, i16 111, i16 19, i16 178, i16 87, i16 225, i16 99, i16 220, i16 172, i16 196, i16 241, i16 175, i16 72, i16 10, i16 80, i16 66, i16 15, i16 186, i16 190, i16 199, i16 7, i16 222, i16 213, i16 120, i16 38, i16 101, i16 211, i16 209, i16 95, i16 227, i16 40, i16 33, i16 137, i16 89, i16 103, i16 252, i16 110, i16 177, i16 215, i16 248, i16 157, i16 243, i16 122, i16 58, i16 185, i16 198, i16 9, i16 65, i16 195, i16 174, i16 224, i16 219, i16 51, i16 68, i16 105, i16 146, i16 45, i16 82, i16 254, i16 22, i16 169, i16 12, i16 139, i16 128, i16 165, i16 74, i16 91, i16 181, i16 151, i16 201, i16 42, i16 162, i16 154, i16 192, i16 35, i16 134, i16 78, i16 188, i16 97, i16 239, i16 204, i16 17, i16 229, i16 114, i16 29, i16 61, i16 124, i16 235, i16 232, i16 233, i16 60, i16 234, i16 143, i16 125, i16 159, i16 236, i16 117, i16 30, i16 245, i16 62, i16 56, i16 246, i16 217, i16 63, i16 207, i16 118, i16 250, i16 31, i16 132, i16 160, i16 112, i16 237, i16 20, i16 144, i16 179, i16 126, i16 88, i16 251, i16 226, i16 32, i16 100, i16 208, i16 221, i16 119, i16 173, i16 218, i16 197, i16 64, i16 242, i16 57, i16 176, i16 247, i16 73, i16 180, i16 11, i16 127, i16 81, i16 21, i16 67, i16 145, i16 16, i16 113, i16 187, i16 238, i16 191, i16 133, i16 200, i16 161], align 16
@exp_to_poly = internal constant [748 x i8] c"\01\02\04\08\10 @\80M\9Ay\F2\A9\1F>|\F8\BD7n\DC\F5\A7\03\06\0C\180`\C0\CD\D7\E3\8B[\B6!B\84E\8AY\B2)R\A4\05\0A\14(P\A0\0D\1A4h\D0\ED\97c\C6\C1\CF\D3\EB\9B{\F6\A1\0F\1E<x\F0\AD\17.\5C\B8=z\F4\A5\07\0E\1C8p\E0\8DW\AE\11\22D\88]\BA9r\E4\85G\8EQ\A2\09\12$H\90m\DA\F9\BF3f\CC\D5\E7\83K\96a\C2\C9\DF\F3\AB\1B6l\D8\FD\B7#F\8CU\AA\192d\C8\DD\F7\A3\0B\16,X\B0-Z\B4%J\94e\CA\D9\FF\B3+V\AC\15*T\A8\1D:t\E8\9Dw\EE\91o\DE\F1\AF\13&L\98}\FA\B9?~\FC\B5'N\9Cu\EA\99\7F\FE\B1/^\BC5j\D4\E5\87C\86A\82I\92i\D2\E9\9Fs\E6\81O\9Eq\E2\89_\BE1b\C4\C5\C7\C3\CB\DB\FB\BB;v\EC\95g\CE\D1\EF\93k\D6\E1\8FS\A6\01\02\04\08\10 @\80M\9Ay\F2\A9\1F>|\F8\BD7n\DC\F5\A7\03\06\0C\180`\C0\CD\D7\E3\8B[\B6!B\84E\8AY\B2)R\A4\05\0A\14(P\A0\0D\1A4h\D0\ED\97c\C6\C1\CF\D3\EB\9B{\F6\A1\0F\1E<x\F0\AD\17.\5C\B8=z\F4\A5\07\0E\1C8p\E0\8DW\AE\11\22D\88]\BA9r\E4\85G\8EQ\A2\09\12$H\90m\DA\F9\BF3f\CC\D5\E7\83K\96a\C2\C9\DF\F3\AB\1B6l\D8\FD\B7#F\8CU\AA\192d\C8\DD\F7\A3\0B\16,X\B0-Z\B4%J\94e\CA\D9\FF\B3+V\AC\15*T\A8\1D:t\E8\9Dw\EE\91o\DE\F1\AF\13&L\98}\FA\B9?~\FC\B5'N\9Cu\EA\99\7F\FE\B1/^\BC5j\D4\E5\87C\86A\82I\92i\D2\E9\9Fs\E6\81O\9Eq\E2\89_\BE1b\C4\C5\C7\C3\CB\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00", align 16
@calc_sb_tbl = internal global [512 x i8] c"\A9ug\F3\B3\C6\E8\F4\04\DB\FD{\A3\FBv\C8\9AJ\92\D3\80\E6xk\E4E\DD}\D1\E88K\0D\D6\C625\D8\98\FD\187\F7q\EC\F1l\E1C0u\0F7\F8&\1B\FA\87\13\FA\94\06H?\F2^\D0\BA\8B\AE0[\84\8AT\00\DF\BC#\9D\19m[\C1=\B1Y\0E\F3\80\AE]\A2\D2\82\D5c\A0\01\84\83\07.\14\D9\B5Q\90\9B,|\A3\A6\B2\EBs\A5L\BET\16\92\0Ct\E36aQ\C08\8C\B0:\BD\F5Zs\FC,`%b\0B\96\BBlNB\89\F7k\10S|j(\B4'\F1\8C\E1\13\E6\95\BD\9CE\C7\E2$\F4F\B6;fp\CC\CA\95\E3\03\85V\CB\D4\11\1C\D0\1E\93\D7\B8\FB\A6\C3\83\8E \B5\FF\E9\9F\CFw\BF\C3\BA\CC\EA\03wo9\08\AF\BF3@\C9\E7b+q\E2\81yy\0C\09\AA\AD\82$A\CD:\F9\EA\D8\B9\E5\E4\C5\9A\B9\A4M\97D~\08\DA\86z\E7\17\A1f\1D\94\AA\A1\ED\1D\06=p\F0\B2\DE\D2\B3A\0B{r\A0\A7\11\1C1\EF\C2\D1'S\90> \8F\F63`&\FF_\96\EC\5Cv\B1*\ABI\9E\81\9C\88R\EE\1B!_\C4\93\1A\0A\EB\EF\D9\91\C5\859I\99\EE\CD-\ADO1\8F\8B;\01G\18\87#m\DDF\1F\D6N>-i\F9dH*O\CE\F2\CBe/\8E\FCx\97\5C\05Xz\19\AC\8D\7F\E5\D5\98\1AWKg\0E\7F\A7\05Zd(\AF\14c?\B6)\FE\88\F5<\B7L<\02\A5\B8\CE\DA\E9\B0h\17DU\E0\1FM\8AC}iW)\C7.\8D\ACt\15\B7Y\C4\A8\9F\0Ar\9E~n\15G\22\DF\124X5\07j\99\CF4\DCn\22P\C9\DE\C0h\9Be\89\BC\D4\DB\ED\F8\AB\C8\12\A8\A2+\0D@R\DC\BB\FE\022/\A4\A9\CA\D7\10a!\1E\F0\B4\D3P]\04\0F\F6\00\C2o\16\9D%6\86BVJU^\09\C1\BE\E0\91", align 16
@q0 = internal constant [256 x i8] c"\A9g\B3\E8\04\FD\A3v\9A\92\80x\E4\DD\D18\0D\C65\98\18\F7\EClCu7&\FA\13\94H\F2\D0\8B0\84T\DF#\19[=Y\F3\AE\A2\82c\01\83.\D9Q\9B|\A6\EB\A5\BE\16\0C\E3a\C0\8C:\F5s,%\0B\BBN\89kSj\B4\F1\E1\E6\BDE\E2\F4\B6f\CC\95\03V\D4\1C\1E\D7\FB\C3\8E\B5\E9\CF\BF\BA\EAw9\AF3\C9bq\81y\09\AD$\CD\F9\D8\E5\C5\B9MD\08\86\E7\A1\1D\AA\ED\06p\B2\D2A{\A0\111\C2'\90 \F6`\FF\96\5C\B1\AB\9E\9CR\1B_\93\0A\EF\91\85I\EE-O\8F;G\87mF\D6>id*\CE\CB/\FC\97\05z\AC\7F\D5\1AK\0E\A7Z(\14?)\88<L\02\B8\DA\B0\17U\1F\8A}W\C7\8Dt\B7\C4\9Fr~\15\22\12X\07\994nP\DEhe\BC\DB\F8\C8\A8+@\DC\FE2\A4\CA\10!\F0\D3]\0F\00o\9D6BJ^\C1\E0", align 16
@mds = internal constant [4 x [256 x i32]] [[256 x i32] [i32 -1128517003, i32 -320069133, i32 538985414, i32 -1280062988, i32 -623246373, i32 33721211, i32 -488494085, i32 -1633748280, i32 -909513654, i32 -724301357, i32 404253670, i32 505323371, i32 -1734865339, i32 -1296942979, i32 -1499016472, i32 640071499, i32 1010587606, i32 -1819047374, i32 -2105348392, i32 1381144829, i32 2071712823, i32 -1145358479, i32 1532729329, i32 1195869153, i32 606354480, i32 1364320783, i32 -1162164488, i32 1246425883, i32 -1077983097, i32 218984698, i32 -1330597114, i32 1970658879, i32 -757924514, i32 2105352378, i32 1717973422, i32 976921435, i32 1499012234, i32 0, i32 -842165316, i32 437969053, i32 -1364317075, i32 2139073473, i32 724289457, i32 -1094797042, i32 -522149760, i32 -1970663331, i32 993743570, i32 1684323029, i32 -656897888, i32 -404249212, i32 1600120839, i32 454758676, i32 741130933, i32 -50547568, i32 825304876, i32 -2139069021, i32 1936927410, i32 202146163, i32 2037997388, i32 1802191188, i32 1263207058, i32 1397975412, i32 -1802203338, i32 -2088558767, i32 707409464, i32 -993747792, i32 572704957, i32 -707397542, i32 -1111636996, i32 1212708960, i32 -12702, i32 1280051094, i32 1094809452, i32 -943200702, i32 -336911113, i32 471602192, i32 1566401404, i32 909517352, i32 1734852647, i32 -370561140, i32 1145370899, i32 336915093, i32 -168445028, i32 -808511289, i32 1061104932, i32 -1061100730, i32 1920129851, i32 1414818928, i32 690572490, i32 -252693021, i32 134807173, i32 -960096309, i32 -202158319, i32 -1936923440, i32 -1532733037, i32 -892692808, i32 1751661478, i32 -1195881085, i32 943204384, i32 -437965057, i32 -1381149025, i32 185304183, i32 -926409277, i32 -1717960756, i32 1482222851, i32 421108335, i32 235801096, i32 -1785364801, i32 1886408768, i32 -134795033, i32 1852755755, i32 522153698, i32 -1246413447, i32 151588620, i32 1633760426, i32 1465325186, i32 -1616966847, i32 -1650622406, i32 286352618, i32 623234489, i32 -1347428892, i32 1162152090, i32 -538997340, i32 -1549575017, i32 -353708674, i32 892688602, i32 -303181702, i32 1128528919, i32 -117912730, i32 -67391084, i32 926405537, i32 -84262883, i32 -1027446723, i32 -1263219472, i32 842161630, i32 -1667468877, i32 1448535819, i32 -471606670, i32 -2021171033, i32 353704732, i32 -101106961, i32 1667481553, i32 875866451, i32 -1701149378, i32 -1313783153, i32 2088554803, i32 -2004313306, i32 1027450463, i32 -1583228948, i32 -454762634, i32 -2122214358, i32 -1852767927, i32 252705665, i32 -286348664, i32 370565614, i32 -673746143, i32 -1751648828, i32 -1515870182, i32 -16891925, i32 1835906521, i32 2021174981, i32 -976917191, i32 488498585, i32 1987486925, i32 1044307117, i32 -875862223, i32 -1229568117, i32 -269526271, i32 303177240, i32 1616954659, i32 1785376989, i32 1296954911, i32 -825300658, i32 -555844563, i32 1431674361, i32 2122209864, i32 555856463, i32 50559730, i32 -1600117147, i32 1583225230, i32 1515873912, i32 1701137244, i32 1650609752, i32 -33733351, i32 101119117, i32 1077970661, i32 -218972520, i32 859024471, i32 387420263, i32 84250239, i32 -387424763, i32 1330609508, i32 -1987482961, i32 269522275, i32 1953771446, i32 168457726, i32 1549570805, i32 -1684310857, i32 757936956, i32 808507045, i32 774785486, i32 1229556201, i32 1179021928, i32 2004309316, i32 -1465329440, i32 -1768553395, i32 673758531, i32 -1448531607, i32 -640059095, i32 -2038001362, i32 -774797396, i32 -185316843, i32 -1920133799, i32 -690584920, i32 -1179010038, i32 1111625118, i32 -151600786, i32 791656519, i32 -572717345, i32 589510964, i32 -859020747, i32 -235813782, i32 -1044311345, i32 -2054820900, i32 -1886413278, i32 1903272393, i32 -1869549376, i32 -1431678053, i32 16904585, i32 -1953766956, i32 1313770733, i32 -1903267925, i32 -1414815214, i32 1869561506, i32 -421112819, i32 -606342574, i32 -1835893829, i32 -1212697086, i32 1768540719, i32 960092585, i32 -741143337, i32 -1482218655, i32 -1566397154, i32 -1010591308, i32 1819034704, i32 117900548, i32 67403766, i32 656885442, i32 -1397971178, i32 -791644635, i32 1347425158, i32 -589498538, i32 -2071717291, i32 -505327351, i32 2054825406, i32 320073617], [256 x i32] [i32 -1445381831, i32 1737496343, i32 -1284399972, i32 -388847962, i32 67438343, i32 -40349102, i32 -1553629056, i32 1994384612, i32 -1710734011, i32 -1845343413, i32 -2136940320, i32 2019973722, i32 -455233617, i32 -575640982, i32 -775986333, i32 943073834, i32 223667942, i32 -968679392, i32 895667404, i32 -1732316430, i32 404623890, i32 -148575253, i32 -321412703, i32 1819754817, i32 1136470056, i32 1966259388, i32 936672123, i32 647727240, i32 -93319923, i32 335103044, i32 -1800274949, i32 1213890174, i32 -226884861, i32 -790328180, i32 -1958234442, i32 809247780, i32 -2069501977, i32 1413573483, i32 -553198115, i32 600137824, i32 424017405, i32 1537423930, i32 1030275778, i32 1494584717, i32 -215880468, i32 -1372494234, i32 -1572966545, i32 -2112465065, i32 1670713360, i32 22802415, i32 -2092058440, i32 781289094, i32 -642421395, i32 1361019779, i32 -1689015638, i32 2086886749, i32 -1506056088, i32 -348127490, i32 -1512689616, i32 -1104840070, i32 380087468, i32 202311945, i32 -483004176, i32 1629726631, i32 -1057976176, i32 -1934628375, i32 981507485, i32 -174957476, i32 1937837068, i32 740766001, i32 628543696, i32 199710294, i32 -1149529454, i32 1323945678, i32 -1980694271, i32 1805590046, i32 1403597876, i32 1791291889, i32 -1264991293, i32 -241738917, i32 -511490233, i32 -429189096, i32 -1110957534, i32 1158584472, i32 -496099553, i32 -188107853, i32 -1238403980, i32 1724643576, i32 -855664231, i32 -1779821548, i32 65886296, i32 1459084508, i32 -723416181, i32 471536917, i32 514695842, i32 -687025197, i32 -81009950, i32 -1021458232, i32 -1910940066, i32 -1245565908, i32 -376878775, i32 -820854335, i32 -1082223211, i32 -1172275843, i32 -362540783, i32 2005142283, i32 963495365, i32 -1351972471, i32 869366908, i32 -912166543, i32 1657733119, i32 1899477947, i32 -2114253041, i32 2034087349, i32 156361185, i32 -1378075074, i32 606945087, i32 -844859786, i32 -107129515, i32 -655457662, i32 -444186560, i32 -978421640, i32 -1177737947, i32 1292146326, i32 1146451831, i32 134876686, i32 -2045554608, i32 -416221193, i32 -1579993289, i32 490797818, i32 -1439407775, i32 -309572018, i32 112439472, i32 1886147668, i32 -1305840781, i32 -766362821, i32 1091280799, i32 2072707586, i32 -1601644328, i32 290452467, i32 828885963, i32 -1035589849, i32 666920807, i32 -1867186948, i32 539506744, i32 -159448060, i32 1618495560, i32 -13703707, i32 -1777906612, i32 1548445029, i32 -1312347349, i32 -1418752370, i32 -1643298238, i32 -1665403403, i32 1391647707, i32 468929098, i32 1604730173, i32 -1822841692, i32 180140473, i32 -281347591, i32 -1846602989, i32 -2046949368, i32 1224839569, i32 -295627242, i32 763158238, i32 1337073953, i32 -1891454543, i32 1004237426, i32 1203253039, i32 -2025275457, i32 1831644846, i32 1189331136, i32 -698926020, i32 1048943258, i32 1764338089, i32 1685933903, i32 714375553, i32 -834064850, i32 -887634234, i32 801794409, i32 -54280771, i32 -1755536477, i32 90106088, i32 2060512749, i32 -1400385071, i32 2140013829, i32 -709204892, i32 447260069, i32 1270294054, i32 247054014, i32 -1486846073, i32 1526257109, i32 673330742, i32 336665371, i32 1071543669, i32 695851481, i32 -2002063634, i32 1009986861, i32 1281325433, i32 45529015, i32 -1198077238, i32 -631753419, i32 -1331903292, i32 402408259, i32 1427801220, i32 536235341, i32 -1977853607, i32 2100867762, i32 1470903091, i32 -954675249, i32 -1913387514, i32 1953059667, i32 -1217094757, i32 -990537833, i32 -1621709395, i32 1926947811, i32 2127948522, i32 357233908, i32 580816783, i32 312650667, i32 1481532002, i32 132669279, i32 -1713038051, i32 876159779, i32 1858205430, i32 1346661484, i32 -564317646, i32 1752319558, i32 1697030304, i32 -1131164211, i32 -620504358, i32 -121193798, i32 -923099490, i32 -1467820330, i32 735014510, i32 1079013488, i32 -588544635, i32 -25884150, i32 847942547, i32 -1534205985, i32 -900978391, i32 269753372, i32 561240023, i32 -255019852, i32 -754330412, i32 1561365130, i32 266490193, i32 0, i32 1872369945, i32 -1646257638, i32 915379348, i32 1122420679, i32 1257032137, i32 1593692882, i32 -1045725313, i32 -522671960], [256 x i32] [i32 -1133134798, i32 -319558623, i32 549855299, i32 -1275808823, i32 -623126013, i32 41616011, i32 -486809045, i32 -1631019270, i32 -917845524, i32 -724315127, i32 417732715, i32 510336671, i32 -1740269554, i32 -1300385224, i32 -1494702382, i32 642459319, i32 1020673111, i32 -1825401974, i32 -2099739922, i32 1392333464, i32 2067233748, i32 -1150174409, i32 1542544279, i32 1205946243, i32 607134780, i32 1359958498, i32 -1158104378, i32 1243302643, i32 -1081622712, i32 234491248, i32 -1341738829, i32 1967093214, i32 -765537539, i32 2109373728, i32 1722705457, i32 979057315, i32 1502239004, i32 0, i32 -843264621, i32 446503648, i32 -1368543700, i32 2143387563, i32 733031367, i32 -1106329927, i32 -528424800, i32 -1973581296, i32 1003633490, i32 1691706554, i32 -660547448, i32 -410720347, i32 1594318824, i32 454302481, i32 750070978, i32 -57606988, i32 824979751, i32 -2136768411, i32 1941074730, i32 208866433, i32 2035054943, i32 1800694593, i32 1267878658, i32 1400132457, i32 -1808362353, i32 -2091810017, i32 708323894, i32 -995048292, i32 582820552, i32 -715467272, i32 -1107509821, i32 1214269560, i32 -10289202, i32 1284918279, i32 1097613687, i32 -951924762, i32 -336073948, i32 470817812, i32 1568431459, i32 908604962, i32 1730635712, i32 -376641105, i32 1142113529, i32 345314538, i32 -174262853, i32 -808988904, i32 1059340077, i32 -1069104925, i32 1916498651, i32 1416647788, i32 701114700, i32 -253497291, i32 142936318, i32 -959724009, i32 -216927409, i32 -1932489500, i32 -1533828007, i32 -893859178, i32 1755736123, i32 -1199327155, i32 941635624, i32 -436214482, i32 -1382044330, i32 192351108, i32 -926693347, i32 -1714644481, i32 1476614381, i32 426711450, i32 235408906, i32 -1782606466, i32 1883271248, i32 -135792848, i32 1848340175, i32 534912878, i32 -1250314947, i32 151783695, i32 1638555956, i32 1468159766, i32 -1623089397, i32 -1657102976, i32 300552548, i32 632890829, i32 -1343967267, i32 1167738120, i32 -542842995, i32 -1550343332, i32 -360781099, i32 903492952, i32 -310710832, i32 1125598204, i32 -127469365, i32 -74122319, i32 933312467, i32 -98698688, i32 -1036139928, i32 -1259293492, i32 853422685, i32 -1665950607, i32 1443583719, i32 -479009830, i32 -2019063968, i32 354161947, i32 -101713606, i32 1674666943, i32 877868201, i32 -1707173243, i32 -1315983038, i32 2083749073, i32 -2010740581, i32 1029651878, i32 -1578327593, i32 -461970209, i32 -2127920748, i32 -1857449727, i32 260116475, i32 -293015894, i32 384702049, i32 -685648013, i32 -1748723723, i32 -1524980312, i32 -18088385, i32 1842965941, i32 2026207406, i32 -986069651, i32 496573925, i32 1993176740, i32 1051541212, i32 -885929113, i32 -1232357817, i32 -285085861, i32 303567390, i32 1612931269, i32 1792895664, i32 1293897206, i32 -833696023, i32 -567419268, i32 1442403741, i32 2118680154, i32 558834098, i32 66192250, i32 -1603952602, i32 1586388505, i32 1517836902, i32 1700554059, i32 1649959502, i32 -48628411, i32 109905652, i32 1088766086, i32 -224857410, i32 861352876, i32 392632208, i32 92210574, i32 -402266018, i32 1331974013, i32 -1984984726, i32 274927765, i32 1958114351, i32 184420981, i32 1559583890, i32 -1682465932, i32 758918451, i32 816132310, i32 785264201, i32 1240025481, i32 1181238898, i32 2000975701, i32 -1461671720, i32 -1773300220, i32 675489981, i32 -1452693207, i32 -651568775, i32 -2043771247, i32 -777203321, i32 -199887798, i32 -1923511019, i32 -693578110, i32 -1190479428, i32 1117667853, i32 -160500031, i32 793194424, i32 -572531450, i32 590619449, i32 -868889502, i32 -244649532, i32 -1043349230, i32 -2049145365, i32 -1893560418, i32 1909027233, i32 -1866428176, i32 -1432638893, i32 25756145, i32 -1949004831, i32 1324174988, i32 -1901359505, i32 -1424839774, i32 1872916286, i32 -435296684, i32 -615326734, i32 -1833201029, i32 -1224558666, i32 1764714954, i32 967391705, i32 -740830452, i32 -1486772445, i32 -1575050579, i32 -1011563623, i32 1817209924, i32 117704453, i32 83231871, i32 667035462, i32 -1407800153, i32 -802828170, i32 1350979603, i32 -598287113, i32 -2074770406, i32 -519446191, i32 2059303461, i32 328274927], [256 x i32] [i32 -650532391, i32 -1877514352, i32 1906094961, i32 -760813358, i32 84345861, i32 -1739391592, i32 1702929253, i32 -538675489, i32 138779144, i32 38507010, i32 -1595899744, i32 1717205094, i32 -575675171, i32 -1335173712, i32 -1083977281, i32 908736566, i32 1424362836, i32 1126221379, i32 1657550178, i32 -1091397442, i32 504502302, i32 619444004, i32 -677253929, i32 2000776311, i32 -1121434691, i32 851211570, i32 -730122284, i32 -1685576037, i32 1879964272, i32 -112978951, i32 -1308912463, i32 1518225498, i32 2047079034, i32 -460533532, i32 1203145543, i32 1009004604, i32 -1511553883, i32 1097552961, i32 115203846, i32 -983555131, i32 1174214981, i32 -1556456541, i32 1757560168, i32 361584917, i32 569176865, i32 828812849, i32 1047503422, i32 374833686, i32 -1794088043, i32 1542390107, i32 1303937869, i32 -1853477231, i32 -1251092043, i32 528699679, i32 1403689811, i32 1667071075, i32 996714043, i32 1073670975, i32 -701454890, i32 628801061, i32 -1481894233, i32 252251151, i32 904979253, i32 598171939, i32 -258948880, i32 -1343648593, i32 -2137179520, i32 -1839401582, i32 -2129890431, i32 657533991, i32 1993352566, i32 -413791257, i32 2073213819, i32 -372355351, i32 -251557391, i32 -1625396321, i32 -1456188503, i32 -990811452, i32 -1715227495, i32 -1755582057, i32 -2092441213, i32 1796793963, i32 -937247288, i32 244860174, i32 1847583342, i32 -910953271, i32 796177967, i32 -872913205, i32 -6697729, i32 -367749654, i32 -312998931, i32 -136554761, i32 -510929695, i32 454368283, i32 -1381884243, i32 215209740, i32 736295723, i32 499696413, i32 425627161, i32 -1037257278, i32 -1991644791, i32 314691346, i32 2123743102, i32 545110560, i32 1678895716, i32 -2079623292, i32 1841641837, i32 1787408234, i32 -780389423, i32 -1586378335, i32 -822123826, i32 935031095, i32 -82869765, i32 1035303229, i32 1373702481, i32 -599872036, i32 759112749, i32 -1535717980, i32 -1655309923, i32 -293414674, i32 -2042567290, i32 -1367816786, i32 -853165619, i32 76958980, i32 1433879637, i32 168691722, i32 324044307, i32 821552944, i32 -751328813, i32 1090133312, i32 878815796, i32 -1940984436, i32 -1280309581, i32 1817473132, i32 712225322, i32 1379652178, i32 194986251, i32 -1962771573, i32 -1999069048, i32 1341329743, i32 1741369703, i32 1177010758, i32 -1066981440, i32 -1258516300, i32 674766888, i32 2131031679, i32 2018009208, i32 786825006, i32 122459655, i32 1264933963, i32 -953437753, i32 1871620975, i32 222469645, i32 -1141531461, i32 -220507406, i32 -213246989, i32 -1505927258, i32 1503957849, i32 -1128723780, i32 989458234, i32 -283930129, i32 -32995842, i32 26298625, i32 1628892769, i32 2094935420, i32 -1306439758, i32 1118932802, i32 -613270565, i32 -1204861000, i32 1220511560, i32 749628716, i32 -473938205, i32 1463604823, i32 -2053489019, i32 698968361, i32 2102355069, i32 -1803474284, i32 1227804233, i32 398904087, i32 -899076150, i32 -1010959165, i32 1554224988, i32 1592264030, i32 -789742896, i32 -2016301945, i32 -1912242290, i32 -1167796806, i32 -1465574744, i32 -1222227017, i32 -1178726727, i32 1619502944, i32 -120235272, i32 573974562, i32 286987281, i32 -562741282, i32 2044275065, i32 -1427208022, i32 858602547, i32 1601784927, i32 -1229520202, i32 -1765099370, i32 1479924312, i32 -1664831332, i32 -62711812, i32 444880154, i32 -162717706, i32 475630108, i32 951221560, i32 -1405921364, i32 416270104, i32 -200897036, i32 1767076969, i32 1956362100, i32 -174603019, i32 1454219094, i32 -622628134, i32 -706052395, i32 1257510218, i32 -1634786658, i32 -1565846878, i32 1315067982, i32 -396425240, i32 -451044891, i32 958608441, i32 -1040814399, i32 1147949124, i32 1563614813, i32 1917216882, i32 648045862, i32 -1815233389, i32 64674563, i32 -960825146, i32 -90257158, i32 -2099861374, i32 -814863409, i32 1349533776, i32 -343548693, i32 1963654773, i32 -1970064758, i32 -1914723187, i32 1277807180, i32 337383444, i32 1943478643, i32 -860557108, i32 164942601, i32 277503248, i32 -498003998, i32 0, i32 -1709609062, i32 -535126560, i32 -1886112113, i32 -423148826, i32 -322352404, i32 -36544771, i32 -1417690709, i32 -660021032]], align 16
@q1 = internal constant [256 x i8] c"u\F3\C6\F4\DB{\FB\C8J\D3\E6kE}\E8K\D62\D8\FD7q\F1\E10\0F\F8\1B\87\FA\06?^\BA\AE[\8A\00\BC\9Dm\C1\B1\0E\80]\D2\D5\A0\84\07\14\B5\90,\A3\B2sLT\92t6Q8\B0\BDZ\FC`b\96lB\F7\10|('\8C\13\95\9C\C7$F;p\CA\E3\85\CB\11\D0\93\B8\A6\83 \FF\9Fw\C3\CC\03o\08\BF@\E7+\E2y\0C\AA\82A:\EA\B9\E4\9A\A4\97~\DAz\17f\94\A1\1D=\F0\DE\B3\0Br\A7\1C\EF\D1S>\8F3&_\ECv*I\81\88\EE!\C4\1A\EB\D9\C59\99\CD\AD1\8B\01\18#\DD\1FN-\F9HO\F2e\8Ex\5CX\19\8D\E5\98Wg\7F\05d\AFc\B6\FE\F5\B7<\A5\CE\E9hD\E0MCi).\AC\15Y\A8\0A\9EnG\DF45j\CF\DC\22\C9\C0\9B\89\D4\ED\AB\12\A2\0DR\BB\02/\A9\D7a\1E\B4P\04\F6\C2\16%\86VU\09\BE\91", align 16

; Function Attrs: nounwind uwtable
define i32 @main() #0 {
  %1 = alloca %struct.TWOFISH_context, align 4
  %2 = call i32 @do_twofish_setkey(i8* getelementptr inbounds ([16 x i8], [16 x i8]* @in_key, i32 0, i32 0), %struct.TWOFISH_context* %1, i32 16)
  call void @do_twofish_encrypt(%struct.TWOFISH_context* %1, i8* getelementptr inbounds ([16 x i8], [16 x i8]* @out, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @in, i32 0, i32 0))
  ret i32 0
}

; Function Attrs: nounwind uwtable
define internal i32 @do_twofish_setkey(i8*, %struct.TWOFISH_context*, i32) #0 {
  %4 = sub i32 %2, 16
  %5 = or i32 %4, 16
  %6 = icmp ne i32 %5, 16
  br i1 %6, label %12746, label %7

; <label>:7:                                      ; preds = %3
  %8 = getelementptr inbounds i8, i8* %0, i64 0
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i64
  %11 = srem i64 %10, 32
  %12 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %11
  %13 = load i16, i16* %12, align 2
  %14 = icmp eq i64 %10, %11
  %15 = sext i1 %14 to i16
  %16 = xor i16 %15, -1
  %17 = and i16 %16, 0
  %18 = and i16 %15, %13
  %19 = or i16 %18, %17
  %20 = add i64 %11, 32
  %21 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = icmp eq i64 %10, %20
  %24 = sext i1 %23 to i16
  %25 = xor i16 %24, -1
  %26 = and i16 %25, %19
  %27 = and i16 %24, %22
  %28 = or i16 %27, %26
  %29 = add i64 %20, 32
  %30 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = icmp eq i64 %10, %29
  %33 = sext i1 %32 to i16
  %34 = xor i16 %33, -1
  %35 = and i16 %34, %28
  %36 = and i16 %33, %31
  %37 = or i16 %36, %35
  %38 = add i64 %29, 32
  %39 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i64 %10, %38
  %42 = sext i1 %41 to i16
  %43 = xor i16 %42, -1
  %44 = and i16 %43, %37
  %45 = and i16 %42, %40
  %46 = or i16 %45, %44
  %47 = add i64 %38, 32
  %48 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %47
  %49 = load i16, i16* %48, align 2
  %50 = icmp eq i64 %10, %47
  %51 = sext i1 %50 to i16
  %52 = xor i16 %51, -1
  %53 = and i16 %52, %46
  %54 = and i16 %51, %49
  %55 = or i16 %54, %53
  %56 = add i64 %47, 32
  %57 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %56
  %58 = load i16, i16* %57, align 2
  %59 = icmp eq i64 %10, %56
  %60 = sext i1 %59 to i16
  %61 = xor i16 %60, -1
  %62 = and i16 %61, %55
  %63 = and i16 %60, %58
  %64 = or i16 %63, %62
  %65 = add i64 %56, 32
  %66 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = icmp eq i64 %10, %65
  %69 = sext i1 %68 to i16
  %70 = xor i16 %69, -1
  %71 = and i16 %70, %64
  %72 = and i16 %69, %67
  %73 = or i16 %72, %71
  %74 = add i64 %65, 32
  %75 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = icmp eq i64 %10, %74
  %78 = sext i1 %77 to i16
  %79 = xor i16 %78, -1
  %80 = and i16 %79, %73
  %81 = and i16 %78, %76
  %Mitigated = or i16 %81, %80
  %82 = zext i16 %Mitigated to i32
  %83 = add i32 %82, 0
  %84 = zext i32 %83 to i64
  %85 = srem i64 %84, 64
  %86 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %85
  %87 = load i8, i8* %86, align 1
  %88 = icmp eq i64 %84, %85
  %89 = sext i1 %88 to i8
  %90 = xor i8 %89, -1
  %91 = and i8 %90, 0
  %92 = and i8 %89, %87
  %93 = or i8 %92, %91
  %94 = add i64 %85, 64
  %95 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %94
  %96 = load i8, i8* %95, align 1
  %97 = icmp eq i64 %84, %94
  %98 = sext i1 %97 to i8
  %99 = xor i8 %98, -1
  %100 = and i8 %99, %93
  %101 = and i8 %98, %96
  %102 = or i8 %101, %100
  %103 = add i64 %94, 64
  %104 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %103
  %105 = load i8, i8* %104, align 1
  %106 = icmp eq i64 %84, %103
  %107 = sext i1 %106 to i8
  %108 = xor i8 %107, -1
  %109 = and i8 %108, %102
  %110 = and i8 %107, %105
  %111 = or i8 %110, %109
  %112 = add i64 %103, 64
  %113 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %112
  %114 = load i8, i8* %113, align 1
  %115 = icmp eq i64 %84, %112
  %116 = sext i1 %115 to i8
  %117 = xor i8 %116, -1
  %118 = and i8 %117, %111
  %119 = and i8 %116, %114
  %120 = or i8 %119, %118
  %121 = add i64 %112, 64
  %122 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %121
  %123 = load i8, i8* %122, align 1
  %124 = icmp eq i64 %84, %121
  %125 = sext i1 %124 to i8
  %126 = xor i8 %125, -1
  %127 = and i8 %126, %120
  %128 = and i8 %125, %123
  %129 = or i8 %128, %127
  %130 = add i64 %121, 64
  %131 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = icmp eq i64 %84, %130
  %134 = sext i1 %133 to i8
  %135 = xor i8 %134, -1
  %136 = and i8 %135, %129
  %137 = and i8 %134, %132
  %138 = or i8 %137, %136
  %139 = add i64 %130, 64
  %140 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %139
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i64 %84, %139
  %143 = sext i1 %142 to i8
  %144 = xor i8 %143, -1
  %145 = and i8 %144, %138
  %146 = and i8 %143, %141
  %147 = or i8 %146, %145
  %148 = add i64 %139, 64
  %149 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %148
  %150 = load i8, i8* %149, align 1
  %151 = icmp eq i64 %84, %148
  %152 = sext i1 %151 to i8
  %153 = xor i8 %152, -1
  %154 = and i8 %153, %147
  %155 = and i8 %152, %150
  %156 = or i8 %155, %154
  %157 = add i64 %148, 64
  %158 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %157
  %159 = load i8, i8* %158, align 1
  %160 = icmp eq i64 %84, %157
  %161 = sext i1 %160 to i8
  %162 = xor i8 %161, -1
  %163 = and i8 %162, %156
  %164 = and i8 %161, %159
  %165 = or i8 %164, %163
  %166 = add i64 %157, 64
  %167 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %166
  %168 = load i8, i8* %167, align 1
  %169 = icmp eq i64 %84, %166
  %170 = sext i1 %169 to i8
  %171 = xor i8 %170, -1
  %172 = and i8 %171, %165
  %173 = and i8 %170, %168
  %174 = or i8 %173, %172
  %175 = add i64 %166, 64
  %176 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %175
  %177 = load i8, i8* %176, align 1
  %178 = icmp eq i64 %84, %175
  %179 = sext i1 %178 to i8
  %180 = xor i8 %179, -1
  %181 = and i8 %180, %174
  %182 = and i8 %179, %177
  %183 = or i8 %182, %181
  %184 = add i64 %175, 64
  %185 = icmp sge i64 %184, 748
  %186 = sext i1 %185 to i64
  %187 = xor i64 %186, -1
  %188 = and i64 %186, 747
  %189 = and i64 %187, %184
  %190 = or i64 %188, %189
  %191 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %190
  %192 = load i8, i8* %191, align 1
  %193 = icmp eq i64 %84, %190
  %194 = sext i1 %193 to i8
  %195 = xor i8 %194, -1
  %196 = and i8 %195, %183
  %197 = and i8 %194, %192
  %Mitigated1 = or i8 %197, %196
  %198 = zext i8 %Mitigated1 to i32
  %199 = zext i8 0 to i32
  %200 = xor i32 %199, %198
  %201 = trunc i32 %200 to i8
  %202 = add i32 %82, 45
  %203 = zext i32 %202 to i64
  %204 = srem i64 %203, 64
  %205 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %204
  %206 = load i8, i8* %205, align 1
  %207 = icmp eq i64 %203, %204
  %208 = sext i1 %207 to i8
  %209 = xor i8 %208, -1
  %210 = and i8 %209, 0
  %211 = and i8 %208, %206
  %212 = or i8 %211, %210
  %213 = add i64 %204, 64
  %214 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %213
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i64 %203, %213
  %217 = sext i1 %216 to i8
  %218 = xor i8 %217, -1
  %219 = and i8 %218, %212
  %220 = and i8 %217, %215
  %221 = or i8 %220, %219
  %222 = add i64 %213, 64
  %223 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %222
  %224 = load i8, i8* %223, align 1
  %225 = icmp eq i64 %203, %222
  %226 = sext i1 %225 to i8
  %227 = xor i8 %226, -1
  %228 = and i8 %227, %221
  %229 = and i8 %226, %224
  %230 = or i8 %229, %228
  %231 = add i64 %222, 64
  %232 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %231
  %233 = load i8, i8* %232, align 1
  %234 = icmp eq i64 %203, %231
  %235 = sext i1 %234 to i8
  %236 = xor i8 %235, -1
  %237 = and i8 %236, %230
  %238 = and i8 %235, %233
  %239 = or i8 %238, %237
  %240 = add i64 %231, 64
  %241 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %240
  %242 = load i8, i8* %241, align 1
  %243 = icmp eq i64 %203, %240
  %244 = sext i1 %243 to i8
  %245 = xor i8 %244, -1
  %246 = and i8 %245, %239
  %247 = and i8 %244, %242
  %248 = or i8 %247, %246
  %249 = add i64 %240, 64
  %250 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %249
  %251 = load i8, i8* %250, align 1
  %252 = icmp eq i64 %203, %249
  %253 = sext i1 %252 to i8
  %254 = xor i8 %253, -1
  %255 = and i8 %254, %248
  %256 = and i8 %253, %251
  %257 = or i8 %256, %255
  %258 = add i64 %249, 64
  %259 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %258
  %260 = load i8, i8* %259, align 1
  %261 = icmp eq i64 %203, %258
  %262 = sext i1 %261 to i8
  %263 = xor i8 %262, -1
  %264 = and i8 %263, %257
  %265 = and i8 %262, %260
  %266 = or i8 %265, %264
  %267 = add i64 %258, 64
  %268 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %267
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i64 %203, %267
  %271 = sext i1 %270 to i8
  %272 = xor i8 %271, -1
  %273 = and i8 %272, %266
  %274 = and i8 %271, %269
  %275 = or i8 %274, %273
  %276 = add i64 %267, 64
  %277 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %276
  %278 = load i8, i8* %277, align 1
  %279 = icmp eq i64 %203, %276
  %280 = sext i1 %279 to i8
  %281 = xor i8 %280, -1
  %282 = and i8 %281, %275
  %283 = and i8 %280, %278
  %284 = or i8 %283, %282
  %285 = add i64 %276, 64
  %286 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %285
  %287 = load i8, i8* %286, align 1
  %288 = icmp eq i64 %203, %285
  %289 = sext i1 %288 to i8
  %290 = xor i8 %289, -1
  %291 = and i8 %290, %284
  %292 = and i8 %289, %287
  %293 = or i8 %292, %291
  %294 = add i64 %285, 64
  %295 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %294
  %296 = load i8, i8* %295, align 1
  %297 = icmp eq i64 %203, %294
  %298 = sext i1 %297 to i8
  %299 = xor i8 %298, -1
  %300 = and i8 %299, %293
  %301 = and i8 %298, %296
  %302 = or i8 %301, %300
  %303 = add i64 %294, 64
  %304 = icmp sge i64 %303, 748
  %305 = sext i1 %304 to i64
  %306 = xor i64 %305, -1
  %307 = and i64 %305, 747
  %308 = and i64 %306, %303
  %309 = or i64 %307, %308
  %310 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %309
  %311 = load i8, i8* %310, align 1
  %312 = icmp eq i64 %203, %309
  %313 = sext i1 %312 to i8
  %314 = xor i8 %313, -1
  %315 = and i8 %314, %302
  %316 = and i8 %313, %311
  %Mitigated2 = or i8 %316, %315
  %317 = zext i8 %Mitigated2 to i32
  %318 = zext i8 0 to i32
  %319 = xor i32 %318, %317
  %320 = trunc i32 %319 to i8
  %321 = add i32 %82, 1
  %322 = zext i32 %321 to i64
  %323 = srem i64 %322, 64
  %324 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %323
  %325 = load i8, i8* %324, align 1
  %326 = icmp eq i64 %322, %323
  %327 = sext i1 %326 to i8
  %328 = xor i8 %327, -1
  %329 = and i8 %328, 0
  %330 = and i8 %327, %325
  %331 = or i8 %330, %329
  %332 = add i64 %323, 64
  %333 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %332
  %334 = load i8, i8* %333, align 1
  %335 = icmp eq i64 %322, %332
  %336 = sext i1 %335 to i8
  %337 = xor i8 %336, -1
  %338 = and i8 %337, %331
  %339 = and i8 %336, %334
  %340 = or i8 %339, %338
  %341 = add i64 %332, 64
  %342 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %341
  %343 = load i8, i8* %342, align 1
  %344 = icmp eq i64 %322, %341
  %345 = sext i1 %344 to i8
  %346 = xor i8 %345, -1
  %347 = and i8 %346, %340
  %348 = and i8 %345, %343
  %349 = or i8 %348, %347
  %350 = add i64 %341, 64
  %351 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %350
  %352 = load i8, i8* %351, align 1
  %353 = icmp eq i64 %322, %350
  %354 = sext i1 %353 to i8
  %355 = xor i8 %354, -1
  %356 = and i8 %355, %349
  %357 = and i8 %354, %352
  %358 = or i8 %357, %356
  %359 = add i64 %350, 64
  %360 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %359
  %361 = load i8, i8* %360, align 1
  %362 = icmp eq i64 %322, %359
  %363 = sext i1 %362 to i8
  %364 = xor i8 %363, -1
  %365 = and i8 %364, %358
  %366 = and i8 %363, %361
  %367 = or i8 %366, %365
  %368 = add i64 %359, 64
  %369 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %368
  %370 = load i8, i8* %369, align 1
  %371 = icmp eq i64 %322, %368
  %372 = sext i1 %371 to i8
  %373 = xor i8 %372, -1
  %374 = and i8 %373, %367
  %375 = and i8 %372, %370
  %376 = or i8 %375, %374
  %377 = add i64 %368, 64
  %378 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %377
  %379 = load i8, i8* %378, align 1
  %380 = icmp eq i64 %322, %377
  %381 = sext i1 %380 to i8
  %382 = xor i8 %381, -1
  %383 = and i8 %382, %376
  %384 = and i8 %381, %379
  %385 = or i8 %384, %383
  %386 = add i64 %377, 64
  %387 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %386
  %388 = load i8, i8* %387, align 1
  %389 = icmp eq i64 %322, %386
  %390 = sext i1 %389 to i8
  %391 = xor i8 %390, -1
  %392 = and i8 %391, %385
  %393 = and i8 %390, %388
  %394 = or i8 %393, %392
  %395 = add i64 %386, 64
  %396 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %395
  %397 = load i8, i8* %396, align 1
  %398 = icmp eq i64 %322, %395
  %399 = sext i1 %398 to i8
  %400 = xor i8 %399, -1
  %401 = and i8 %400, %394
  %402 = and i8 %399, %397
  %403 = or i8 %402, %401
  %404 = add i64 %395, 64
  %405 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %404
  %406 = load i8, i8* %405, align 1
  %407 = icmp eq i64 %322, %404
  %408 = sext i1 %407 to i8
  %409 = xor i8 %408, -1
  %410 = and i8 %409, %403
  %411 = and i8 %408, %406
  %412 = or i8 %411, %410
  %413 = add i64 %404, 64
  %414 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %413
  %415 = load i8, i8* %414, align 1
  %416 = icmp eq i64 %322, %413
  %417 = sext i1 %416 to i8
  %418 = xor i8 %417, -1
  %419 = and i8 %418, %412
  %420 = and i8 %417, %415
  %421 = or i8 %420, %419
  %422 = add i64 %413, 64
  %423 = icmp sge i64 %422, 748
  %424 = sext i1 %423 to i64
  %425 = xor i64 %424, -1
  %426 = and i64 %424, 747
  %427 = and i64 %425, %422
  %428 = or i64 %426, %427
  %429 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %428
  %430 = load i8, i8* %429, align 1
  %431 = icmp eq i64 %322, %428
  %432 = sext i1 %431 to i8
  %433 = xor i8 %432, -1
  %434 = and i8 %433, %421
  %435 = and i8 %432, %430
  %Mitigated3 = or i8 %435, %434
  %436 = zext i8 %Mitigated3 to i32
  %437 = zext i8 0 to i32
  %438 = xor i32 %437, %436
  %439 = trunc i32 %438 to i8
  %440 = add i32 %82, 45
  %441 = zext i32 %440 to i64
  %442 = srem i64 %441, 64
  %443 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %442
  %444 = load i8, i8* %443, align 1
  %445 = icmp eq i64 %441, %442
  %446 = sext i1 %445 to i8
  %447 = xor i8 %446, -1
  %448 = and i8 %447, 0
  %449 = and i8 %446, %444
  %450 = or i8 %449, %448
  %451 = add i64 %442, 64
  %452 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %451
  %453 = load i8, i8* %452, align 1
  %454 = icmp eq i64 %441, %451
  %455 = sext i1 %454 to i8
  %456 = xor i8 %455, -1
  %457 = and i8 %456, %450
  %458 = and i8 %455, %453
  %459 = or i8 %458, %457
  %460 = add i64 %451, 64
  %461 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %460
  %462 = load i8, i8* %461, align 1
  %463 = icmp eq i64 %441, %460
  %464 = sext i1 %463 to i8
  %465 = xor i8 %464, -1
  %466 = and i8 %465, %459
  %467 = and i8 %464, %462
  %468 = or i8 %467, %466
  %469 = add i64 %460, 64
  %470 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %469
  %471 = load i8, i8* %470, align 1
  %472 = icmp eq i64 %441, %469
  %473 = sext i1 %472 to i8
  %474 = xor i8 %473, -1
  %475 = and i8 %474, %468
  %476 = and i8 %473, %471
  %477 = or i8 %476, %475
  %478 = add i64 %469, 64
  %479 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %478
  %480 = load i8, i8* %479, align 1
  %481 = icmp eq i64 %441, %478
  %482 = sext i1 %481 to i8
  %483 = xor i8 %482, -1
  %484 = and i8 %483, %477
  %485 = and i8 %482, %480
  %486 = or i8 %485, %484
  %487 = add i64 %478, 64
  %488 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %487
  %489 = load i8, i8* %488, align 1
  %490 = icmp eq i64 %441, %487
  %491 = sext i1 %490 to i8
  %492 = xor i8 %491, -1
  %493 = and i8 %492, %486
  %494 = and i8 %491, %489
  %495 = or i8 %494, %493
  %496 = add i64 %487, 64
  %497 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %496
  %498 = load i8, i8* %497, align 1
  %499 = icmp eq i64 %441, %496
  %500 = sext i1 %499 to i8
  %501 = xor i8 %500, -1
  %502 = and i8 %501, %495
  %503 = and i8 %500, %498
  %504 = or i8 %503, %502
  %505 = add i64 %496, 64
  %506 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %505
  %507 = load i8, i8* %506, align 1
  %508 = icmp eq i64 %441, %505
  %509 = sext i1 %508 to i8
  %510 = xor i8 %509, -1
  %511 = and i8 %510, %504
  %512 = and i8 %509, %507
  %513 = or i8 %512, %511
  %514 = add i64 %505, 64
  %515 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %514
  %516 = load i8, i8* %515, align 1
  %517 = icmp eq i64 %441, %514
  %518 = sext i1 %517 to i8
  %519 = xor i8 %518, -1
  %520 = and i8 %519, %513
  %521 = and i8 %518, %516
  %522 = or i8 %521, %520
  %523 = add i64 %514, 64
  %524 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %523
  %525 = load i8, i8* %524, align 1
  %526 = icmp eq i64 %441, %523
  %527 = sext i1 %526 to i8
  %528 = xor i8 %527, -1
  %529 = and i8 %528, %522
  %530 = and i8 %527, %525
  %531 = or i8 %530, %529
  %532 = add i64 %523, 64
  %533 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %532
  %534 = load i8, i8* %533, align 1
  %535 = icmp eq i64 %441, %532
  %536 = sext i1 %535 to i8
  %537 = xor i8 %536, -1
  %538 = and i8 %537, %531
  %539 = and i8 %536, %534
  %540 = or i8 %539, %538
  %541 = add i64 %532, 64
  %542 = icmp sge i64 %541, 748
  %543 = sext i1 %542 to i64
  %544 = xor i64 %543, -1
  %545 = and i64 %543, 747
  %546 = and i64 %544, %541
  %547 = or i64 %545, %546
  %548 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %547
  %549 = load i8, i8* %548, align 1
  %550 = icmp eq i64 %441, %547
  %551 = sext i1 %550 to i8
  %552 = xor i8 %551, -1
  %553 = and i8 %552, %540
  %554 = and i8 %551, %549
  %Mitigated4 = or i8 %554, %553
  %555 = zext i8 %Mitigated4 to i32
  %556 = zext i8 0 to i32
  %557 = xor i32 %556, %555
  %558 = trunc i32 %557 to i8
  %559 = getelementptr inbounds i8, i8* %0, i64 1
  %560 = load i8, i8* %559, align 1
  %561 = zext i8 %560 to i64
  %562 = srem i64 %561, 32
  %563 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %562
  %564 = load i16, i16* %563, align 2
  %565 = icmp eq i64 %561, %562
  %566 = sext i1 %565 to i16
  %567 = xor i16 %566, -1
  %568 = and i16 %567, 0
  %569 = and i16 %566, %564
  %570 = or i16 %569, %568
  %571 = add i64 %562, 32
  %572 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %571
  %573 = load i16, i16* %572, align 2
  %574 = icmp eq i64 %561, %571
  %575 = sext i1 %574 to i16
  %576 = xor i16 %575, -1
  %577 = and i16 %576, %570
  %578 = and i16 %575, %573
  %579 = or i16 %578, %577
  %580 = add i64 %571, 32
  %581 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %580
  %582 = load i16, i16* %581, align 2
  %583 = icmp eq i64 %561, %580
  %584 = sext i1 %583 to i16
  %585 = xor i16 %584, -1
  %586 = and i16 %585, %579
  %587 = and i16 %584, %582
  %588 = or i16 %587, %586
  %589 = add i64 %580, 32
  %590 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %589
  %591 = load i16, i16* %590, align 2
  %592 = icmp eq i64 %561, %589
  %593 = sext i1 %592 to i16
  %594 = xor i16 %593, -1
  %595 = and i16 %594, %588
  %596 = and i16 %593, %591
  %597 = or i16 %596, %595
  %598 = add i64 %589, 32
  %599 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %598
  %600 = load i16, i16* %599, align 2
  %601 = icmp eq i64 %561, %598
  %602 = sext i1 %601 to i16
  %603 = xor i16 %602, -1
  %604 = and i16 %603, %597
  %605 = and i16 %602, %600
  %606 = or i16 %605, %604
  %607 = add i64 %598, 32
  %608 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %607
  %609 = load i16, i16* %608, align 2
  %610 = icmp eq i64 %561, %607
  %611 = sext i1 %610 to i16
  %612 = xor i16 %611, -1
  %613 = and i16 %612, %606
  %614 = and i16 %611, %609
  %615 = or i16 %614, %613
  %616 = add i64 %607, 32
  %617 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %616
  %618 = load i16, i16* %617, align 2
  %619 = icmp eq i64 %561, %616
  %620 = sext i1 %619 to i16
  %621 = xor i16 %620, -1
  %622 = and i16 %621, %615
  %623 = and i16 %620, %618
  %624 = or i16 %623, %622
  %625 = add i64 %616, 32
  %626 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %625
  %627 = load i16, i16* %626, align 2
  %628 = icmp eq i64 %561, %625
  %629 = sext i1 %628 to i16
  %630 = xor i16 %629, -1
  %631 = and i16 %630, %624
  %632 = and i16 %629, %627
  %Mitigated5 = or i16 %632, %631
  %633 = zext i16 %Mitigated5 to i32
  %634 = add i32 %633, 45
  %635 = zext i32 %634 to i64
  %636 = srem i64 %635, 64
  %637 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %636
  %638 = load i8, i8* %637, align 1
  %639 = icmp eq i64 %635, %636
  %640 = sext i1 %639 to i8
  %641 = xor i8 %640, -1
  %642 = and i8 %641, 0
  %643 = and i8 %640, %638
  %644 = or i8 %643, %642
  %645 = add i64 %636, 64
  %646 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %645
  %647 = load i8, i8* %646, align 1
  %648 = icmp eq i64 %635, %645
  %649 = sext i1 %648 to i8
  %650 = xor i8 %649, -1
  %651 = and i8 %650, %644
  %652 = and i8 %649, %647
  %653 = or i8 %652, %651
  %654 = add i64 %645, 64
  %655 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %654
  %656 = load i8, i8* %655, align 1
  %657 = icmp eq i64 %635, %654
  %658 = sext i1 %657 to i8
  %659 = xor i8 %658, -1
  %660 = and i8 %659, %653
  %661 = and i8 %658, %656
  %662 = or i8 %661, %660
  %663 = add i64 %654, 64
  %664 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %663
  %665 = load i8, i8* %664, align 1
  %666 = icmp eq i64 %635, %663
  %667 = sext i1 %666 to i8
  %668 = xor i8 %667, -1
  %669 = and i8 %668, %662
  %670 = and i8 %667, %665
  %671 = or i8 %670, %669
  %672 = add i64 %663, 64
  %673 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %672
  %674 = load i8, i8* %673, align 1
  %675 = icmp eq i64 %635, %672
  %676 = sext i1 %675 to i8
  %677 = xor i8 %676, -1
  %678 = and i8 %677, %671
  %679 = and i8 %676, %674
  %680 = or i8 %679, %678
  %681 = add i64 %672, 64
  %682 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %681
  %683 = load i8, i8* %682, align 1
  %684 = icmp eq i64 %635, %681
  %685 = sext i1 %684 to i8
  %686 = xor i8 %685, -1
  %687 = and i8 %686, %680
  %688 = and i8 %685, %683
  %689 = or i8 %688, %687
  %690 = add i64 %681, 64
  %691 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %690
  %692 = load i8, i8* %691, align 1
  %693 = icmp eq i64 %635, %690
  %694 = sext i1 %693 to i8
  %695 = xor i8 %694, -1
  %696 = and i8 %695, %689
  %697 = and i8 %694, %692
  %698 = or i8 %697, %696
  %699 = add i64 %690, 64
  %700 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %699
  %701 = load i8, i8* %700, align 1
  %702 = icmp eq i64 %635, %699
  %703 = sext i1 %702 to i8
  %704 = xor i8 %703, -1
  %705 = and i8 %704, %698
  %706 = and i8 %703, %701
  %707 = or i8 %706, %705
  %708 = add i64 %699, 64
  %709 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %708
  %710 = load i8, i8* %709, align 1
  %711 = icmp eq i64 %635, %708
  %712 = sext i1 %711 to i8
  %713 = xor i8 %712, -1
  %714 = and i8 %713, %707
  %715 = and i8 %712, %710
  %716 = or i8 %715, %714
  %717 = add i64 %708, 64
  %718 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %717
  %719 = load i8, i8* %718, align 1
  %720 = icmp eq i64 %635, %717
  %721 = sext i1 %720 to i8
  %722 = xor i8 %721, -1
  %723 = and i8 %722, %716
  %724 = and i8 %721, %719
  %725 = or i8 %724, %723
  %726 = add i64 %717, 64
  %727 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %726
  %728 = load i8, i8* %727, align 1
  %729 = icmp eq i64 %635, %726
  %730 = sext i1 %729 to i8
  %731 = xor i8 %730, -1
  %732 = and i8 %731, %725
  %733 = and i8 %730, %728
  %734 = or i8 %733, %732
  %735 = add i64 %726, 64
  %736 = icmp sge i64 %735, 748
  %737 = sext i1 %736 to i64
  %738 = xor i64 %737, -1
  %739 = and i64 %737, 747
  %740 = and i64 %738, %735
  %741 = or i64 %739, %740
  %742 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %741
  %743 = load i8, i8* %742, align 1
  %744 = icmp eq i64 %635, %741
  %745 = sext i1 %744 to i8
  %746 = xor i8 %745, -1
  %747 = and i8 %746, %734
  %748 = and i8 %745, %743
  %Mitigated6 = or i8 %748, %747
  %749 = zext i8 %Mitigated6 to i32
  %750 = zext i8 %201 to i32
  %751 = xor i32 %750, %749
  %752 = trunc i32 %751 to i8
  %753 = add i32 %633, 164
  %754 = zext i32 %753 to i64
  %755 = srem i64 %754, 64
  %756 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %755
  %757 = load i8, i8* %756, align 1
  %758 = icmp eq i64 %754, %755
  %759 = sext i1 %758 to i8
  %760 = xor i8 %759, -1
  %761 = and i8 %760, 0
  %762 = and i8 %759, %757
  %763 = or i8 %762, %761
  %764 = add i64 %755, 64
  %765 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %764
  %766 = load i8, i8* %765, align 1
  %767 = icmp eq i64 %754, %764
  %768 = sext i1 %767 to i8
  %769 = xor i8 %768, -1
  %770 = and i8 %769, %763
  %771 = and i8 %768, %766
  %772 = or i8 %771, %770
  %773 = add i64 %764, 64
  %774 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %773
  %775 = load i8, i8* %774, align 1
  %776 = icmp eq i64 %754, %773
  %777 = sext i1 %776 to i8
  %778 = xor i8 %777, -1
  %779 = and i8 %778, %772
  %780 = and i8 %777, %775
  %781 = or i8 %780, %779
  %782 = add i64 %773, 64
  %783 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %782
  %784 = load i8, i8* %783, align 1
  %785 = icmp eq i64 %754, %782
  %786 = sext i1 %785 to i8
  %787 = xor i8 %786, -1
  %788 = and i8 %787, %781
  %789 = and i8 %786, %784
  %790 = or i8 %789, %788
  %791 = add i64 %782, 64
  %792 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %791
  %793 = load i8, i8* %792, align 1
  %794 = icmp eq i64 %754, %791
  %795 = sext i1 %794 to i8
  %796 = xor i8 %795, -1
  %797 = and i8 %796, %790
  %798 = and i8 %795, %793
  %799 = or i8 %798, %797
  %800 = add i64 %791, 64
  %801 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %800
  %802 = load i8, i8* %801, align 1
  %803 = icmp eq i64 %754, %800
  %804 = sext i1 %803 to i8
  %805 = xor i8 %804, -1
  %806 = and i8 %805, %799
  %807 = and i8 %804, %802
  %808 = or i8 %807, %806
  %809 = add i64 %800, 64
  %810 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %809
  %811 = load i8, i8* %810, align 1
  %812 = icmp eq i64 %754, %809
  %813 = sext i1 %812 to i8
  %814 = xor i8 %813, -1
  %815 = and i8 %814, %808
  %816 = and i8 %813, %811
  %817 = or i8 %816, %815
  %818 = add i64 %809, 64
  %819 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %818
  %820 = load i8, i8* %819, align 1
  %821 = icmp eq i64 %754, %818
  %822 = sext i1 %821 to i8
  %823 = xor i8 %822, -1
  %824 = and i8 %823, %817
  %825 = and i8 %822, %820
  %826 = or i8 %825, %824
  %827 = add i64 %818, 64
  %828 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %827
  %829 = load i8, i8* %828, align 1
  %830 = icmp eq i64 %754, %827
  %831 = sext i1 %830 to i8
  %832 = xor i8 %831, -1
  %833 = and i8 %832, %826
  %834 = and i8 %831, %829
  %835 = or i8 %834, %833
  %836 = add i64 %827, 64
  %837 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %836
  %838 = load i8, i8* %837, align 1
  %839 = icmp eq i64 %754, %836
  %840 = sext i1 %839 to i8
  %841 = xor i8 %840, -1
  %842 = and i8 %841, %835
  %843 = and i8 %840, %838
  %844 = or i8 %843, %842
  %845 = add i64 %836, 64
  %846 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %845
  %847 = load i8, i8* %846, align 1
  %848 = icmp eq i64 %754, %845
  %849 = sext i1 %848 to i8
  %850 = xor i8 %849, -1
  %851 = and i8 %850, %844
  %852 = and i8 %849, %847
  %853 = or i8 %852, %851
  %854 = add i64 %845, 64
  %855 = icmp sge i64 %854, 748
  %856 = sext i1 %855 to i64
  %857 = xor i64 %856, -1
  %858 = and i64 %856, 747
  %859 = and i64 %857, %854
  %860 = or i64 %858, %859
  %861 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %860
  %862 = load i8, i8* %861, align 1
  %863 = icmp eq i64 %754, %860
  %864 = sext i1 %863 to i8
  %865 = xor i8 %864, -1
  %866 = and i8 %865, %853
  %867 = and i8 %864, %862
  %Mitigated7 = or i8 %867, %866
  %868 = zext i8 %Mitigated7 to i32
  %869 = zext i8 %320 to i32
  %870 = xor i32 %869, %868
  %871 = trunc i32 %870 to i8
  %872 = add i32 %633, 68
  %873 = zext i32 %872 to i64
  %874 = srem i64 %873, 64
  %875 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %874
  %876 = load i8, i8* %875, align 1
  %877 = icmp eq i64 %873, %874
  %878 = sext i1 %877 to i8
  %879 = xor i8 %878, -1
  %880 = and i8 %879, 0
  %881 = and i8 %878, %876
  %882 = or i8 %881, %880
  %883 = add i64 %874, 64
  %884 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %883
  %885 = load i8, i8* %884, align 1
  %886 = icmp eq i64 %873, %883
  %887 = sext i1 %886 to i8
  %888 = xor i8 %887, -1
  %889 = and i8 %888, %882
  %890 = and i8 %887, %885
  %891 = or i8 %890, %889
  %892 = add i64 %883, 64
  %893 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %892
  %894 = load i8, i8* %893, align 1
  %895 = icmp eq i64 %873, %892
  %896 = sext i1 %895 to i8
  %897 = xor i8 %896, -1
  %898 = and i8 %897, %891
  %899 = and i8 %896, %894
  %900 = or i8 %899, %898
  %901 = add i64 %892, 64
  %902 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %901
  %903 = load i8, i8* %902, align 1
  %904 = icmp eq i64 %873, %901
  %905 = sext i1 %904 to i8
  %906 = xor i8 %905, -1
  %907 = and i8 %906, %900
  %908 = and i8 %905, %903
  %909 = or i8 %908, %907
  %910 = add i64 %901, 64
  %911 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %910
  %912 = load i8, i8* %911, align 1
  %913 = icmp eq i64 %873, %910
  %914 = sext i1 %913 to i8
  %915 = xor i8 %914, -1
  %916 = and i8 %915, %909
  %917 = and i8 %914, %912
  %918 = or i8 %917, %916
  %919 = add i64 %910, 64
  %920 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %919
  %921 = load i8, i8* %920, align 1
  %922 = icmp eq i64 %873, %919
  %923 = sext i1 %922 to i8
  %924 = xor i8 %923, -1
  %925 = and i8 %924, %918
  %926 = and i8 %923, %921
  %927 = or i8 %926, %925
  %928 = add i64 %919, 64
  %929 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %928
  %930 = load i8, i8* %929, align 1
  %931 = icmp eq i64 %873, %928
  %932 = sext i1 %931 to i8
  %933 = xor i8 %932, -1
  %934 = and i8 %933, %927
  %935 = and i8 %932, %930
  %936 = or i8 %935, %934
  %937 = add i64 %928, 64
  %938 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %937
  %939 = load i8, i8* %938, align 1
  %940 = icmp eq i64 %873, %937
  %941 = sext i1 %940 to i8
  %942 = xor i8 %941, -1
  %943 = and i8 %942, %936
  %944 = and i8 %941, %939
  %945 = or i8 %944, %943
  %946 = add i64 %937, 64
  %947 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %946
  %948 = load i8, i8* %947, align 1
  %949 = icmp eq i64 %873, %946
  %950 = sext i1 %949 to i8
  %951 = xor i8 %950, -1
  %952 = and i8 %951, %945
  %953 = and i8 %950, %948
  %954 = or i8 %953, %952
  %955 = add i64 %946, 64
  %956 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %955
  %957 = load i8, i8* %956, align 1
  %958 = icmp eq i64 %873, %955
  %959 = sext i1 %958 to i8
  %960 = xor i8 %959, -1
  %961 = and i8 %960, %954
  %962 = and i8 %959, %957
  %963 = or i8 %962, %961
  %964 = add i64 %955, 64
  %965 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %964
  %966 = load i8, i8* %965, align 1
  %967 = icmp eq i64 %873, %964
  %968 = sext i1 %967 to i8
  %969 = xor i8 %968, -1
  %970 = and i8 %969, %963
  %971 = and i8 %968, %966
  %972 = or i8 %971, %970
  %973 = add i64 %964, 64
  %974 = icmp sge i64 %973, 748
  %975 = sext i1 %974 to i64
  %976 = xor i64 %975, -1
  %977 = and i64 %975, 747
  %978 = and i64 %976, %973
  %979 = or i64 %977, %978
  %980 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %979
  %981 = load i8, i8* %980, align 1
  %982 = icmp eq i64 %873, %979
  %983 = sext i1 %982 to i8
  %984 = xor i8 %983, -1
  %985 = and i8 %984, %972
  %986 = and i8 %983, %981
  %Mitigated8 = or i8 %986, %985
  %987 = zext i8 %Mitigated8 to i32
  %988 = zext i8 %439 to i32
  %989 = xor i32 %988, %987
  %990 = trunc i32 %989 to i8
  %991 = add i32 %633, 138
  %992 = zext i32 %991 to i64
  %993 = srem i64 %992, 64
  %994 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %993
  %995 = load i8, i8* %994, align 1
  %996 = icmp eq i64 %992, %993
  %997 = sext i1 %996 to i8
  %998 = xor i8 %997, -1
  %999 = and i8 %998, 0
  %1000 = and i8 %997, %995
  %1001 = or i8 %1000, %999
  %1002 = add i64 %993, 64
  %1003 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1002
  %1004 = load i8, i8* %1003, align 1
  %1005 = icmp eq i64 %992, %1002
  %1006 = sext i1 %1005 to i8
  %1007 = xor i8 %1006, -1
  %1008 = and i8 %1007, %1001
  %1009 = and i8 %1006, %1004
  %1010 = or i8 %1009, %1008
  %1011 = add i64 %1002, 64
  %1012 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1011
  %1013 = load i8, i8* %1012, align 1
  %1014 = icmp eq i64 %992, %1011
  %1015 = sext i1 %1014 to i8
  %1016 = xor i8 %1015, -1
  %1017 = and i8 %1016, %1010
  %1018 = and i8 %1015, %1013
  %1019 = or i8 %1018, %1017
  %1020 = add i64 %1011, 64
  %1021 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1020
  %1022 = load i8, i8* %1021, align 1
  %1023 = icmp eq i64 %992, %1020
  %1024 = sext i1 %1023 to i8
  %1025 = xor i8 %1024, -1
  %1026 = and i8 %1025, %1019
  %1027 = and i8 %1024, %1022
  %1028 = or i8 %1027, %1026
  %1029 = add i64 %1020, 64
  %1030 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1029
  %1031 = load i8, i8* %1030, align 1
  %1032 = icmp eq i64 %992, %1029
  %1033 = sext i1 %1032 to i8
  %1034 = xor i8 %1033, -1
  %1035 = and i8 %1034, %1028
  %1036 = and i8 %1033, %1031
  %1037 = or i8 %1036, %1035
  %1038 = add i64 %1029, 64
  %1039 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1038
  %1040 = load i8, i8* %1039, align 1
  %1041 = icmp eq i64 %992, %1038
  %1042 = sext i1 %1041 to i8
  %1043 = xor i8 %1042, -1
  %1044 = and i8 %1043, %1037
  %1045 = and i8 %1042, %1040
  %1046 = or i8 %1045, %1044
  %1047 = add i64 %1038, 64
  %1048 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1047
  %1049 = load i8, i8* %1048, align 1
  %1050 = icmp eq i64 %992, %1047
  %1051 = sext i1 %1050 to i8
  %1052 = xor i8 %1051, -1
  %1053 = and i8 %1052, %1046
  %1054 = and i8 %1051, %1049
  %1055 = or i8 %1054, %1053
  %1056 = add i64 %1047, 64
  %1057 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1056
  %1058 = load i8, i8* %1057, align 1
  %1059 = icmp eq i64 %992, %1056
  %1060 = sext i1 %1059 to i8
  %1061 = xor i8 %1060, -1
  %1062 = and i8 %1061, %1055
  %1063 = and i8 %1060, %1058
  %1064 = or i8 %1063, %1062
  %1065 = add i64 %1056, 64
  %1066 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1065
  %1067 = load i8, i8* %1066, align 1
  %1068 = icmp eq i64 %992, %1065
  %1069 = sext i1 %1068 to i8
  %1070 = xor i8 %1069, -1
  %1071 = and i8 %1070, %1064
  %1072 = and i8 %1069, %1067
  %1073 = or i8 %1072, %1071
  %1074 = add i64 %1065, 64
  %1075 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1074
  %1076 = load i8, i8* %1075, align 1
  %1077 = icmp eq i64 %992, %1074
  %1078 = sext i1 %1077 to i8
  %1079 = xor i8 %1078, -1
  %1080 = and i8 %1079, %1073
  %1081 = and i8 %1078, %1076
  %1082 = or i8 %1081, %1080
  %1083 = add i64 %1074, 64
  %1084 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1083
  %1085 = load i8, i8* %1084, align 1
  %1086 = icmp eq i64 %992, %1083
  %1087 = sext i1 %1086 to i8
  %1088 = xor i8 %1087, -1
  %1089 = and i8 %1088, %1082
  %1090 = and i8 %1087, %1085
  %1091 = or i8 %1090, %1089
  %1092 = add i64 %1083, 64
  %1093 = icmp sge i64 %1092, 748
  %1094 = sext i1 %1093 to i64
  %1095 = xor i64 %1094, -1
  %1096 = and i64 %1094, 747
  %1097 = and i64 %1095, %1092
  %1098 = or i64 %1096, %1097
  %1099 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1098
  %1100 = load i8, i8* %1099, align 1
  %1101 = icmp eq i64 %992, %1098
  %1102 = sext i1 %1101 to i8
  %1103 = xor i8 %1102, -1
  %1104 = and i8 %1103, %1091
  %1105 = and i8 %1102, %1100
  %Mitigated9 = or i8 %1105, %1104
  %1106 = zext i8 %Mitigated9 to i32
  %1107 = zext i8 %558 to i32
  %1108 = xor i32 %1107, %1106
  %1109 = trunc i32 %1108 to i8
  %1110 = getelementptr inbounds i8, i8* %0, i64 2
  %1111 = load i8, i8* %1110, align 1
  %1112 = zext i8 %1111 to i64
  %1113 = srem i64 %1112, 32
  %1114 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1113
  %1115 = load i16, i16* %1114, align 2
  %1116 = icmp eq i64 %1112, %1113
  %1117 = sext i1 %1116 to i16
  %1118 = xor i16 %1117, -1
  %1119 = and i16 %1118, 0
  %1120 = and i16 %1117, %1115
  %1121 = or i16 %1120, %1119
  %1122 = add i64 %1113, 32
  %1123 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1122
  %1124 = load i16, i16* %1123, align 2
  %1125 = icmp eq i64 %1112, %1122
  %1126 = sext i1 %1125 to i16
  %1127 = xor i16 %1126, -1
  %1128 = and i16 %1127, %1121
  %1129 = and i16 %1126, %1124
  %1130 = or i16 %1129, %1128
  %1131 = add i64 %1122, 32
  %1132 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1131
  %1133 = load i16, i16* %1132, align 2
  %1134 = icmp eq i64 %1112, %1131
  %1135 = sext i1 %1134 to i16
  %1136 = xor i16 %1135, -1
  %1137 = and i16 %1136, %1130
  %1138 = and i16 %1135, %1133
  %1139 = or i16 %1138, %1137
  %1140 = add i64 %1131, 32
  %1141 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1140
  %1142 = load i16, i16* %1141, align 2
  %1143 = icmp eq i64 %1112, %1140
  %1144 = sext i1 %1143 to i16
  %1145 = xor i16 %1144, -1
  %1146 = and i16 %1145, %1139
  %1147 = and i16 %1144, %1142
  %1148 = or i16 %1147, %1146
  %1149 = add i64 %1140, 32
  %1150 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1149
  %1151 = load i16, i16* %1150, align 2
  %1152 = icmp eq i64 %1112, %1149
  %1153 = sext i1 %1152 to i16
  %1154 = xor i16 %1153, -1
  %1155 = and i16 %1154, %1148
  %1156 = and i16 %1153, %1151
  %1157 = or i16 %1156, %1155
  %1158 = add i64 %1149, 32
  %1159 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1158
  %1160 = load i16, i16* %1159, align 2
  %1161 = icmp eq i64 %1112, %1158
  %1162 = sext i1 %1161 to i16
  %1163 = xor i16 %1162, -1
  %1164 = and i16 %1163, %1157
  %1165 = and i16 %1162, %1160
  %1166 = or i16 %1165, %1164
  %1167 = add i64 %1158, 32
  %1168 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1167
  %1169 = load i16, i16* %1168, align 2
  %1170 = icmp eq i64 %1112, %1167
  %1171 = sext i1 %1170 to i16
  %1172 = xor i16 %1171, -1
  %1173 = and i16 %1172, %1166
  %1174 = and i16 %1171, %1169
  %1175 = or i16 %1174, %1173
  %1176 = add i64 %1167, 32
  %1177 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1176
  %1178 = load i16, i16* %1177, align 2
  %1179 = icmp eq i64 %1112, %1176
  %1180 = sext i1 %1179 to i16
  %1181 = xor i16 %1180, -1
  %1182 = and i16 %1181, %1175
  %1183 = and i16 %1180, %1178
  %Mitigated10 = or i16 %1183, %1182
  %1184 = zext i16 %Mitigated10 to i32
  %1185 = add i32 %1184, 138
  %1186 = zext i32 %1185 to i64
  %1187 = srem i64 %1186, 64
  %1188 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1187
  %1189 = load i8, i8* %1188, align 1
  %1190 = icmp eq i64 %1186, %1187
  %1191 = sext i1 %1190 to i8
  %1192 = xor i8 %1191, -1
  %1193 = and i8 %1192, 0
  %1194 = and i8 %1191, %1189
  %1195 = or i8 %1194, %1193
  %1196 = add i64 %1187, 64
  %1197 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1196
  %1198 = load i8, i8* %1197, align 1
  %1199 = icmp eq i64 %1186, %1196
  %1200 = sext i1 %1199 to i8
  %1201 = xor i8 %1200, -1
  %1202 = and i8 %1201, %1195
  %1203 = and i8 %1200, %1198
  %1204 = or i8 %1203, %1202
  %1205 = add i64 %1196, 64
  %1206 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1205
  %1207 = load i8, i8* %1206, align 1
  %1208 = icmp eq i64 %1186, %1205
  %1209 = sext i1 %1208 to i8
  %1210 = xor i8 %1209, -1
  %1211 = and i8 %1210, %1204
  %1212 = and i8 %1209, %1207
  %1213 = or i8 %1212, %1211
  %1214 = add i64 %1205, 64
  %1215 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1214
  %1216 = load i8, i8* %1215, align 1
  %1217 = icmp eq i64 %1186, %1214
  %1218 = sext i1 %1217 to i8
  %1219 = xor i8 %1218, -1
  %1220 = and i8 %1219, %1213
  %1221 = and i8 %1218, %1216
  %1222 = or i8 %1221, %1220
  %1223 = add i64 %1214, 64
  %1224 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1223
  %1225 = load i8, i8* %1224, align 1
  %1226 = icmp eq i64 %1186, %1223
  %1227 = sext i1 %1226 to i8
  %1228 = xor i8 %1227, -1
  %1229 = and i8 %1228, %1222
  %1230 = and i8 %1227, %1225
  %1231 = or i8 %1230, %1229
  %1232 = add i64 %1223, 64
  %1233 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1232
  %1234 = load i8, i8* %1233, align 1
  %1235 = icmp eq i64 %1186, %1232
  %1236 = sext i1 %1235 to i8
  %1237 = xor i8 %1236, -1
  %1238 = and i8 %1237, %1231
  %1239 = and i8 %1236, %1234
  %1240 = or i8 %1239, %1238
  %1241 = add i64 %1232, 64
  %1242 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1241
  %1243 = load i8, i8* %1242, align 1
  %1244 = icmp eq i64 %1186, %1241
  %1245 = sext i1 %1244 to i8
  %1246 = xor i8 %1245, -1
  %1247 = and i8 %1246, %1240
  %1248 = and i8 %1245, %1243
  %1249 = or i8 %1248, %1247
  %1250 = add i64 %1241, 64
  %1251 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1250
  %1252 = load i8, i8* %1251, align 1
  %1253 = icmp eq i64 %1186, %1250
  %1254 = sext i1 %1253 to i8
  %1255 = xor i8 %1254, -1
  %1256 = and i8 %1255, %1249
  %1257 = and i8 %1254, %1252
  %1258 = or i8 %1257, %1256
  %1259 = add i64 %1250, 64
  %1260 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1259
  %1261 = load i8, i8* %1260, align 1
  %1262 = icmp eq i64 %1186, %1259
  %1263 = sext i1 %1262 to i8
  %1264 = xor i8 %1263, -1
  %1265 = and i8 %1264, %1258
  %1266 = and i8 %1263, %1261
  %1267 = or i8 %1266, %1265
  %1268 = add i64 %1259, 64
  %1269 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1268
  %1270 = load i8, i8* %1269, align 1
  %1271 = icmp eq i64 %1186, %1268
  %1272 = sext i1 %1271 to i8
  %1273 = xor i8 %1272, -1
  %1274 = and i8 %1273, %1267
  %1275 = and i8 %1272, %1270
  %1276 = or i8 %1275, %1274
  %1277 = add i64 %1268, 64
  %1278 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1277
  %1279 = load i8, i8* %1278, align 1
  %1280 = icmp eq i64 %1186, %1277
  %1281 = sext i1 %1280 to i8
  %1282 = xor i8 %1281, -1
  %1283 = and i8 %1282, %1276
  %1284 = and i8 %1281, %1279
  %1285 = or i8 %1284, %1283
  %1286 = add i64 %1277, 64
  %1287 = icmp sge i64 %1286, 748
  %1288 = sext i1 %1287 to i64
  %1289 = xor i64 %1288, -1
  %1290 = and i64 %1288, 747
  %1291 = and i64 %1289, %1286
  %1292 = or i64 %1290, %1291
  %1293 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1292
  %1294 = load i8, i8* %1293, align 1
  %1295 = icmp eq i64 %1186, %1292
  %1296 = sext i1 %1295 to i8
  %1297 = xor i8 %1296, -1
  %1298 = and i8 %1297, %1285
  %1299 = and i8 %1296, %1294
  %Mitigated11 = or i8 %1299, %1298
  %1300 = zext i8 %Mitigated11 to i32
  %1301 = zext i8 %752 to i32
  %1302 = xor i32 %1301, %1300
  %1303 = trunc i32 %1302 to i8
  %1304 = add i32 %1184, 213
  %1305 = zext i32 %1304 to i64
  %1306 = srem i64 %1305, 64
  %1307 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1306
  %1308 = load i8, i8* %1307, align 1
  %1309 = icmp eq i64 %1305, %1306
  %1310 = sext i1 %1309 to i8
  %1311 = xor i8 %1310, -1
  %1312 = and i8 %1311, 0
  %1313 = and i8 %1310, %1308
  %1314 = or i8 %1313, %1312
  %1315 = add i64 %1306, 64
  %1316 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1315
  %1317 = load i8, i8* %1316, align 1
  %1318 = icmp eq i64 %1305, %1315
  %1319 = sext i1 %1318 to i8
  %1320 = xor i8 %1319, -1
  %1321 = and i8 %1320, %1314
  %1322 = and i8 %1319, %1317
  %1323 = or i8 %1322, %1321
  %1324 = add i64 %1315, 64
  %1325 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1324
  %1326 = load i8, i8* %1325, align 1
  %1327 = icmp eq i64 %1305, %1324
  %1328 = sext i1 %1327 to i8
  %1329 = xor i8 %1328, -1
  %1330 = and i8 %1329, %1323
  %1331 = and i8 %1328, %1326
  %1332 = or i8 %1331, %1330
  %1333 = add i64 %1324, 64
  %1334 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1333
  %1335 = load i8, i8* %1334, align 1
  %1336 = icmp eq i64 %1305, %1333
  %1337 = sext i1 %1336 to i8
  %1338 = xor i8 %1337, -1
  %1339 = and i8 %1338, %1332
  %1340 = and i8 %1337, %1335
  %1341 = or i8 %1340, %1339
  %1342 = add i64 %1333, 64
  %1343 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1342
  %1344 = load i8, i8* %1343, align 1
  %1345 = icmp eq i64 %1305, %1342
  %1346 = sext i1 %1345 to i8
  %1347 = xor i8 %1346, -1
  %1348 = and i8 %1347, %1341
  %1349 = and i8 %1346, %1344
  %1350 = or i8 %1349, %1348
  %1351 = add i64 %1342, 64
  %1352 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1351
  %1353 = load i8, i8* %1352, align 1
  %1354 = icmp eq i64 %1305, %1351
  %1355 = sext i1 %1354 to i8
  %1356 = xor i8 %1355, -1
  %1357 = and i8 %1356, %1350
  %1358 = and i8 %1355, %1353
  %1359 = or i8 %1358, %1357
  %1360 = add i64 %1351, 64
  %1361 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1360
  %1362 = load i8, i8* %1361, align 1
  %1363 = icmp eq i64 %1305, %1360
  %1364 = sext i1 %1363 to i8
  %1365 = xor i8 %1364, -1
  %1366 = and i8 %1365, %1359
  %1367 = and i8 %1364, %1362
  %1368 = or i8 %1367, %1366
  %1369 = add i64 %1360, 64
  %1370 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1369
  %1371 = load i8, i8* %1370, align 1
  %1372 = icmp eq i64 %1305, %1369
  %1373 = sext i1 %1372 to i8
  %1374 = xor i8 %1373, -1
  %1375 = and i8 %1374, %1368
  %1376 = and i8 %1373, %1371
  %1377 = or i8 %1376, %1375
  %1378 = add i64 %1369, 64
  %1379 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1378
  %1380 = load i8, i8* %1379, align 1
  %1381 = icmp eq i64 %1305, %1378
  %1382 = sext i1 %1381 to i8
  %1383 = xor i8 %1382, -1
  %1384 = and i8 %1383, %1377
  %1385 = and i8 %1382, %1380
  %1386 = or i8 %1385, %1384
  %1387 = add i64 %1378, 64
  %1388 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1387
  %1389 = load i8, i8* %1388, align 1
  %1390 = icmp eq i64 %1305, %1387
  %1391 = sext i1 %1390 to i8
  %1392 = xor i8 %1391, -1
  %1393 = and i8 %1392, %1386
  %1394 = and i8 %1391, %1389
  %1395 = or i8 %1394, %1393
  %1396 = add i64 %1387, 64
  %1397 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1396
  %1398 = load i8, i8* %1397, align 1
  %1399 = icmp eq i64 %1305, %1396
  %1400 = sext i1 %1399 to i8
  %1401 = xor i8 %1400, -1
  %1402 = and i8 %1401, %1395
  %1403 = and i8 %1400, %1398
  %1404 = or i8 %1403, %1402
  %1405 = add i64 %1396, 64
  %1406 = icmp sge i64 %1405, 748
  %1407 = sext i1 %1406 to i64
  %1408 = xor i64 %1407, -1
  %1409 = and i64 %1407, 747
  %1410 = and i64 %1408, %1405
  %1411 = or i64 %1409, %1410
  %1412 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1411
  %1413 = load i8, i8* %1412, align 1
  %1414 = icmp eq i64 %1305, %1411
  %1415 = sext i1 %1414 to i8
  %1416 = xor i8 %1415, -1
  %1417 = and i8 %1416, %1404
  %1418 = and i8 %1415, %1413
  %Mitigated12 = or i8 %1418, %1417
  %1419 = zext i8 %Mitigated12 to i32
  %1420 = zext i8 %871 to i32
  %1421 = xor i32 %1420, %1419
  %1422 = trunc i32 %1421 to i8
  %1423 = add i32 %1184, 191
  %1424 = zext i32 %1423 to i64
  %1425 = srem i64 %1424, 64
  %1426 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1425
  %1427 = load i8, i8* %1426, align 1
  %1428 = icmp eq i64 %1424, %1425
  %1429 = sext i1 %1428 to i8
  %1430 = xor i8 %1429, -1
  %1431 = and i8 %1430, 0
  %1432 = and i8 %1429, %1427
  %1433 = or i8 %1432, %1431
  %1434 = add i64 %1425, 64
  %1435 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1434
  %1436 = load i8, i8* %1435, align 1
  %1437 = icmp eq i64 %1424, %1434
  %1438 = sext i1 %1437 to i8
  %1439 = xor i8 %1438, -1
  %1440 = and i8 %1439, %1433
  %1441 = and i8 %1438, %1436
  %1442 = or i8 %1441, %1440
  %1443 = add i64 %1434, 64
  %1444 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1443
  %1445 = load i8, i8* %1444, align 1
  %1446 = icmp eq i64 %1424, %1443
  %1447 = sext i1 %1446 to i8
  %1448 = xor i8 %1447, -1
  %1449 = and i8 %1448, %1442
  %1450 = and i8 %1447, %1445
  %1451 = or i8 %1450, %1449
  %1452 = add i64 %1443, 64
  %1453 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1452
  %1454 = load i8, i8* %1453, align 1
  %1455 = icmp eq i64 %1424, %1452
  %1456 = sext i1 %1455 to i8
  %1457 = xor i8 %1456, -1
  %1458 = and i8 %1457, %1451
  %1459 = and i8 %1456, %1454
  %1460 = or i8 %1459, %1458
  %1461 = add i64 %1452, 64
  %1462 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1461
  %1463 = load i8, i8* %1462, align 1
  %1464 = icmp eq i64 %1424, %1461
  %1465 = sext i1 %1464 to i8
  %1466 = xor i8 %1465, -1
  %1467 = and i8 %1466, %1460
  %1468 = and i8 %1465, %1463
  %1469 = or i8 %1468, %1467
  %1470 = add i64 %1461, 64
  %1471 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1470
  %1472 = load i8, i8* %1471, align 1
  %1473 = icmp eq i64 %1424, %1470
  %1474 = sext i1 %1473 to i8
  %1475 = xor i8 %1474, -1
  %1476 = and i8 %1475, %1469
  %1477 = and i8 %1474, %1472
  %1478 = or i8 %1477, %1476
  %1479 = add i64 %1470, 64
  %1480 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1479
  %1481 = load i8, i8* %1480, align 1
  %1482 = icmp eq i64 %1424, %1479
  %1483 = sext i1 %1482 to i8
  %1484 = xor i8 %1483, -1
  %1485 = and i8 %1484, %1478
  %1486 = and i8 %1483, %1481
  %1487 = or i8 %1486, %1485
  %1488 = add i64 %1479, 64
  %1489 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1488
  %1490 = load i8, i8* %1489, align 1
  %1491 = icmp eq i64 %1424, %1488
  %1492 = sext i1 %1491 to i8
  %1493 = xor i8 %1492, -1
  %1494 = and i8 %1493, %1487
  %1495 = and i8 %1492, %1490
  %1496 = or i8 %1495, %1494
  %1497 = add i64 %1488, 64
  %1498 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1497
  %1499 = load i8, i8* %1498, align 1
  %1500 = icmp eq i64 %1424, %1497
  %1501 = sext i1 %1500 to i8
  %1502 = xor i8 %1501, -1
  %1503 = and i8 %1502, %1496
  %1504 = and i8 %1501, %1499
  %1505 = or i8 %1504, %1503
  %1506 = add i64 %1497, 64
  %1507 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1506
  %1508 = load i8, i8* %1507, align 1
  %1509 = icmp eq i64 %1424, %1506
  %1510 = sext i1 %1509 to i8
  %1511 = xor i8 %1510, -1
  %1512 = and i8 %1511, %1505
  %1513 = and i8 %1510, %1508
  %1514 = or i8 %1513, %1512
  %1515 = add i64 %1506, 64
  %1516 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1515
  %1517 = load i8, i8* %1516, align 1
  %1518 = icmp eq i64 %1424, %1515
  %1519 = sext i1 %1518 to i8
  %1520 = xor i8 %1519, -1
  %1521 = and i8 %1520, %1514
  %1522 = and i8 %1519, %1517
  %1523 = or i8 %1522, %1521
  %1524 = add i64 %1515, 64
  %1525 = icmp sge i64 %1524, 748
  %1526 = sext i1 %1525 to i64
  %1527 = xor i64 %1526, -1
  %1528 = and i64 %1526, 747
  %1529 = and i64 %1527, %1524
  %1530 = or i64 %1528, %1529
  %1531 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1530
  %1532 = load i8, i8* %1531, align 1
  %1533 = icmp eq i64 %1424, %1530
  %1534 = sext i1 %1533 to i8
  %1535 = xor i8 %1534, -1
  %1536 = and i8 %1535, %1523
  %1537 = and i8 %1534, %1532
  %Mitigated13 = or i8 %1537, %1536
  %1538 = zext i8 %Mitigated13 to i32
  %1539 = zext i8 %990 to i32
  %1540 = xor i32 %1539, %1538
  %1541 = trunc i32 %1540 to i8
  %1542 = add i32 %1184, 209
  %1543 = zext i32 %1542 to i64
  %1544 = srem i64 %1543, 64
  %1545 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1544
  %1546 = load i8, i8* %1545, align 1
  %1547 = icmp eq i64 %1543, %1544
  %1548 = sext i1 %1547 to i8
  %1549 = xor i8 %1548, -1
  %1550 = and i8 %1549, 0
  %1551 = and i8 %1548, %1546
  %1552 = or i8 %1551, %1550
  %1553 = add i64 %1544, 64
  %1554 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1553
  %1555 = load i8, i8* %1554, align 1
  %1556 = icmp eq i64 %1543, %1553
  %1557 = sext i1 %1556 to i8
  %1558 = xor i8 %1557, -1
  %1559 = and i8 %1558, %1552
  %1560 = and i8 %1557, %1555
  %1561 = or i8 %1560, %1559
  %1562 = add i64 %1553, 64
  %1563 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1562
  %1564 = load i8, i8* %1563, align 1
  %1565 = icmp eq i64 %1543, %1562
  %1566 = sext i1 %1565 to i8
  %1567 = xor i8 %1566, -1
  %1568 = and i8 %1567, %1561
  %1569 = and i8 %1566, %1564
  %1570 = or i8 %1569, %1568
  %1571 = add i64 %1562, 64
  %1572 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1571
  %1573 = load i8, i8* %1572, align 1
  %1574 = icmp eq i64 %1543, %1571
  %1575 = sext i1 %1574 to i8
  %1576 = xor i8 %1575, -1
  %1577 = and i8 %1576, %1570
  %1578 = and i8 %1575, %1573
  %1579 = or i8 %1578, %1577
  %1580 = add i64 %1571, 64
  %1581 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1580
  %1582 = load i8, i8* %1581, align 1
  %1583 = icmp eq i64 %1543, %1580
  %1584 = sext i1 %1583 to i8
  %1585 = xor i8 %1584, -1
  %1586 = and i8 %1585, %1579
  %1587 = and i8 %1584, %1582
  %1588 = or i8 %1587, %1586
  %1589 = add i64 %1580, 64
  %1590 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1589
  %1591 = load i8, i8* %1590, align 1
  %1592 = icmp eq i64 %1543, %1589
  %1593 = sext i1 %1592 to i8
  %1594 = xor i8 %1593, -1
  %1595 = and i8 %1594, %1588
  %1596 = and i8 %1593, %1591
  %1597 = or i8 %1596, %1595
  %1598 = add i64 %1589, 64
  %1599 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1598
  %1600 = load i8, i8* %1599, align 1
  %1601 = icmp eq i64 %1543, %1598
  %1602 = sext i1 %1601 to i8
  %1603 = xor i8 %1602, -1
  %1604 = and i8 %1603, %1597
  %1605 = and i8 %1602, %1600
  %1606 = or i8 %1605, %1604
  %1607 = add i64 %1598, 64
  %1608 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1607
  %1609 = load i8, i8* %1608, align 1
  %1610 = icmp eq i64 %1543, %1607
  %1611 = sext i1 %1610 to i8
  %1612 = xor i8 %1611, -1
  %1613 = and i8 %1612, %1606
  %1614 = and i8 %1611, %1609
  %1615 = or i8 %1614, %1613
  %1616 = add i64 %1607, 64
  %1617 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1616
  %1618 = load i8, i8* %1617, align 1
  %1619 = icmp eq i64 %1543, %1616
  %1620 = sext i1 %1619 to i8
  %1621 = xor i8 %1620, -1
  %1622 = and i8 %1621, %1615
  %1623 = and i8 %1620, %1618
  %1624 = or i8 %1623, %1622
  %1625 = add i64 %1616, 64
  %1626 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1625
  %1627 = load i8, i8* %1626, align 1
  %1628 = icmp eq i64 %1543, %1625
  %1629 = sext i1 %1628 to i8
  %1630 = xor i8 %1629, -1
  %1631 = and i8 %1630, %1624
  %1632 = and i8 %1629, %1627
  %1633 = or i8 %1632, %1631
  %1634 = add i64 %1625, 64
  %1635 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1634
  %1636 = load i8, i8* %1635, align 1
  %1637 = icmp eq i64 %1543, %1634
  %1638 = sext i1 %1637 to i8
  %1639 = xor i8 %1638, -1
  %1640 = and i8 %1639, %1633
  %1641 = and i8 %1638, %1636
  %1642 = or i8 %1641, %1640
  %1643 = add i64 %1634, 64
  %1644 = icmp sge i64 %1643, 748
  %1645 = sext i1 %1644 to i64
  %1646 = xor i64 %1645, -1
  %1647 = and i64 %1645, 747
  %1648 = and i64 %1646, %1643
  %1649 = or i64 %1647, %1648
  %1650 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1649
  %1651 = load i8, i8* %1650, align 1
  %1652 = icmp eq i64 %1543, %1649
  %1653 = sext i1 %1652 to i8
  %1654 = xor i8 %1653, -1
  %1655 = and i8 %1654, %1642
  %1656 = and i8 %1653, %1651
  %Mitigated14 = or i8 %1656, %1655
  %1657 = zext i8 %Mitigated14 to i32
  %1658 = zext i8 %1109 to i32
  %1659 = xor i32 %1658, %1657
  %1660 = trunc i32 %1659 to i8
  %1661 = getelementptr inbounds i8, i8* %0, i64 3
  %1662 = load i8, i8* %1661, align 1
  %1663 = zext i8 %1662 to i64
  %1664 = srem i64 %1663, 32
  %1665 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1664
  %1666 = load i16, i16* %1665, align 2
  %1667 = icmp eq i64 %1663, %1664
  %1668 = sext i1 %1667 to i16
  %1669 = xor i16 %1668, -1
  %1670 = and i16 %1669, 0
  %1671 = and i16 %1668, %1666
  %1672 = or i16 %1671, %1670
  %1673 = add i64 %1664, 32
  %1674 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1673
  %1675 = load i16, i16* %1674, align 2
  %1676 = icmp eq i64 %1663, %1673
  %1677 = sext i1 %1676 to i16
  %1678 = xor i16 %1677, -1
  %1679 = and i16 %1678, %1672
  %1680 = and i16 %1677, %1675
  %1681 = or i16 %1680, %1679
  %1682 = add i64 %1673, 32
  %1683 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1682
  %1684 = load i16, i16* %1683, align 2
  %1685 = icmp eq i64 %1663, %1682
  %1686 = sext i1 %1685 to i16
  %1687 = xor i16 %1686, -1
  %1688 = and i16 %1687, %1681
  %1689 = and i16 %1686, %1684
  %1690 = or i16 %1689, %1688
  %1691 = add i64 %1682, 32
  %1692 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1691
  %1693 = load i16, i16* %1692, align 2
  %1694 = icmp eq i64 %1663, %1691
  %1695 = sext i1 %1694 to i16
  %1696 = xor i16 %1695, -1
  %1697 = and i16 %1696, %1690
  %1698 = and i16 %1695, %1693
  %1699 = or i16 %1698, %1697
  %1700 = add i64 %1691, 32
  %1701 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1700
  %1702 = load i16, i16* %1701, align 2
  %1703 = icmp eq i64 %1663, %1700
  %1704 = sext i1 %1703 to i16
  %1705 = xor i16 %1704, -1
  %1706 = and i16 %1705, %1699
  %1707 = and i16 %1704, %1702
  %1708 = or i16 %1707, %1706
  %1709 = add i64 %1700, 32
  %1710 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1709
  %1711 = load i16, i16* %1710, align 2
  %1712 = icmp eq i64 %1663, %1709
  %1713 = sext i1 %1712 to i16
  %1714 = xor i16 %1713, -1
  %1715 = and i16 %1714, %1708
  %1716 = and i16 %1713, %1711
  %1717 = or i16 %1716, %1715
  %1718 = add i64 %1709, 32
  %1719 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1718
  %1720 = load i16, i16* %1719, align 2
  %1721 = icmp eq i64 %1663, %1718
  %1722 = sext i1 %1721 to i16
  %1723 = xor i16 %1722, -1
  %1724 = and i16 %1723, %1717
  %1725 = and i16 %1722, %1720
  %1726 = or i16 %1725, %1724
  %1727 = add i64 %1718, 32
  %1728 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %1727
  %1729 = load i16, i16* %1728, align 2
  %1730 = icmp eq i64 %1663, %1727
  %1731 = sext i1 %1730 to i16
  %1732 = xor i16 %1731, -1
  %1733 = and i16 %1732, %1726
  %1734 = and i16 %1731, %1729
  %Mitigated15 = or i16 %1734, %1733
  %1735 = zext i16 %Mitigated15 to i32
  %1736 = add i32 %1735, 209
  %1737 = zext i32 %1736 to i64
  %1738 = srem i64 %1737, 64
  %1739 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1738
  %1740 = load i8, i8* %1739, align 1
  %1741 = icmp eq i64 %1737, %1738
  %1742 = sext i1 %1741 to i8
  %1743 = xor i8 %1742, -1
  %1744 = and i8 %1743, 0
  %1745 = and i8 %1742, %1740
  %1746 = or i8 %1745, %1744
  %1747 = add i64 %1738, 64
  %1748 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1747
  %1749 = load i8, i8* %1748, align 1
  %1750 = icmp eq i64 %1737, %1747
  %1751 = sext i1 %1750 to i8
  %1752 = xor i8 %1751, -1
  %1753 = and i8 %1752, %1746
  %1754 = and i8 %1751, %1749
  %1755 = or i8 %1754, %1753
  %1756 = add i64 %1747, 64
  %1757 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1756
  %1758 = load i8, i8* %1757, align 1
  %1759 = icmp eq i64 %1737, %1756
  %1760 = sext i1 %1759 to i8
  %1761 = xor i8 %1760, -1
  %1762 = and i8 %1761, %1755
  %1763 = and i8 %1760, %1758
  %1764 = or i8 %1763, %1762
  %1765 = add i64 %1756, 64
  %1766 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1765
  %1767 = load i8, i8* %1766, align 1
  %1768 = icmp eq i64 %1737, %1765
  %1769 = sext i1 %1768 to i8
  %1770 = xor i8 %1769, -1
  %1771 = and i8 %1770, %1764
  %1772 = and i8 %1769, %1767
  %1773 = or i8 %1772, %1771
  %1774 = add i64 %1765, 64
  %1775 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1774
  %1776 = load i8, i8* %1775, align 1
  %1777 = icmp eq i64 %1737, %1774
  %1778 = sext i1 %1777 to i8
  %1779 = xor i8 %1778, -1
  %1780 = and i8 %1779, %1773
  %1781 = and i8 %1778, %1776
  %1782 = or i8 %1781, %1780
  %1783 = add i64 %1774, 64
  %1784 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1783
  %1785 = load i8, i8* %1784, align 1
  %1786 = icmp eq i64 %1737, %1783
  %1787 = sext i1 %1786 to i8
  %1788 = xor i8 %1787, -1
  %1789 = and i8 %1788, %1782
  %1790 = and i8 %1787, %1785
  %1791 = or i8 %1790, %1789
  %1792 = add i64 %1783, 64
  %1793 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1792
  %1794 = load i8, i8* %1793, align 1
  %1795 = icmp eq i64 %1737, %1792
  %1796 = sext i1 %1795 to i8
  %1797 = xor i8 %1796, -1
  %1798 = and i8 %1797, %1791
  %1799 = and i8 %1796, %1794
  %1800 = or i8 %1799, %1798
  %1801 = add i64 %1792, 64
  %1802 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1801
  %1803 = load i8, i8* %1802, align 1
  %1804 = icmp eq i64 %1737, %1801
  %1805 = sext i1 %1804 to i8
  %1806 = xor i8 %1805, -1
  %1807 = and i8 %1806, %1800
  %1808 = and i8 %1805, %1803
  %1809 = or i8 %1808, %1807
  %1810 = add i64 %1801, 64
  %1811 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1810
  %1812 = load i8, i8* %1811, align 1
  %1813 = icmp eq i64 %1737, %1810
  %1814 = sext i1 %1813 to i8
  %1815 = xor i8 %1814, -1
  %1816 = and i8 %1815, %1809
  %1817 = and i8 %1814, %1812
  %1818 = or i8 %1817, %1816
  %1819 = add i64 %1810, 64
  %1820 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1819
  %1821 = load i8, i8* %1820, align 1
  %1822 = icmp eq i64 %1737, %1819
  %1823 = sext i1 %1822 to i8
  %1824 = xor i8 %1823, -1
  %1825 = and i8 %1824, %1818
  %1826 = and i8 %1823, %1821
  %1827 = or i8 %1826, %1825
  %1828 = add i64 %1819, 64
  %1829 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1828
  %1830 = load i8, i8* %1829, align 1
  %1831 = icmp eq i64 %1737, %1828
  %1832 = sext i1 %1831 to i8
  %1833 = xor i8 %1832, -1
  %1834 = and i8 %1833, %1827
  %1835 = and i8 %1832, %1830
  %1836 = or i8 %1835, %1834
  %1837 = add i64 %1828, 64
  %1838 = icmp sge i64 %1837, 748
  %1839 = sext i1 %1838 to i64
  %1840 = xor i64 %1839, -1
  %1841 = and i64 %1839, 747
  %1842 = and i64 %1840, %1837
  %1843 = or i64 %1841, %1842
  %1844 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1843
  %1845 = load i8, i8* %1844, align 1
  %1846 = icmp eq i64 %1737, %1843
  %1847 = sext i1 %1846 to i8
  %1848 = xor i8 %1847, -1
  %1849 = and i8 %1848, %1836
  %1850 = and i8 %1847, %1845
  %Mitigated16 = or i8 %1850, %1849
  %1851 = zext i8 %Mitigated16 to i32
  %1852 = zext i8 %1303 to i32
  %1853 = xor i32 %1852, %1851
  %1854 = trunc i32 %1853 to i8
  %1855 = add i32 %1735, 127
  %1856 = zext i32 %1855 to i64
  %1857 = srem i64 %1856, 64
  %1858 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1857
  %1859 = load i8, i8* %1858, align 1
  %1860 = icmp eq i64 %1856, %1857
  %1861 = sext i1 %1860 to i8
  %1862 = xor i8 %1861, -1
  %1863 = and i8 %1862, 0
  %1864 = and i8 %1861, %1859
  %1865 = or i8 %1864, %1863
  %1866 = add i64 %1857, 64
  %1867 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1866
  %1868 = load i8, i8* %1867, align 1
  %1869 = icmp eq i64 %1856, %1866
  %1870 = sext i1 %1869 to i8
  %1871 = xor i8 %1870, -1
  %1872 = and i8 %1871, %1865
  %1873 = and i8 %1870, %1868
  %1874 = or i8 %1873, %1872
  %1875 = add i64 %1866, 64
  %1876 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1875
  %1877 = load i8, i8* %1876, align 1
  %1878 = icmp eq i64 %1856, %1875
  %1879 = sext i1 %1878 to i8
  %1880 = xor i8 %1879, -1
  %1881 = and i8 %1880, %1874
  %1882 = and i8 %1879, %1877
  %1883 = or i8 %1882, %1881
  %1884 = add i64 %1875, 64
  %1885 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1884
  %1886 = load i8, i8* %1885, align 1
  %1887 = icmp eq i64 %1856, %1884
  %1888 = sext i1 %1887 to i8
  %1889 = xor i8 %1888, -1
  %1890 = and i8 %1889, %1883
  %1891 = and i8 %1888, %1886
  %1892 = or i8 %1891, %1890
  %1893 = add i64 %1884, 64
  %1894 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1893
  %1895 = load i8, i8* %1894, align 1
  %1896 = icmp eq i64 %1856, %1893
  %1897 = sext i1 %1896 to i8
  %1898 = xor i8 %1897, -1
  %1899 = and i8 %1898, %1892
  %1900 = and i8 %1897, %1895
  %1901 = or i8 %1900, %1899
  %1902 = add i64 %1893, 64
  %1903 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1902
  %1904 = load i8, i8* %1903, align 1
  %1905 = icmp eq i64 %1856, %1902
  %1906 = sext i1 %1905 to i8
  %1907 = xor i8 %1906, -1
  %1908 = and i8 %1907, %1901
  %1909 = and i8 %1906, %1904
  %1910 = or i8 %1909, %1908
  %1911 = add i64 %1902, 64
  %1912 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1911
  %1913 = load i8, i8* %1912, align 1
  %1914 = icmp eq i64 %1856, %1911
  %1915 = sext i1 %1914 to i8
  %1916 = xor i8 %1915, -1
  %1917 = and i8 %1916, %1910
  %1918 = and i8 %1915, %1913
  %1919 = or i8 %1918, %1917
  %1920 = add i64 %1911, 64
  %1921 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1920
  %1922 = load i8, i8* %1921, align 1
  %1923 = icmp eq i64 %1856, %1920
  %1924 = sext i1 %1923 to i8
  %1925 = xor i8 %1924, -1
  %1926 = and i8 %1925, %1919
  %1927 = and i8 %1924, %1922
  %1928 = or i8 %1927, %1926
  %1929 = add i64 %1920, 64
  %1930 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1929
  %1931 = load i8, i8* %1930, align 1
  %1932 = icmp eq i64 %1856, %1929
  %1933 = sext i1 %1932 to i8
  %1934 = xor i8 %1933, -1
  %1935 = and i8 %1934, %1928
  %1936 = and i8 %1933, %1931
  %1937 = or i8 %1936, %1935
  %1938 = add i64 %1929, 64
  %1939 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1938
  %1940 = load i8, i8* %1939, align 1
  %1941 = icmp eq i64 %1856, %1938
  %1942 = sext i1 %1941 to i8
  %1943 = xor i8 %1942, -1
  %1944 = and i8 %1943, %1937
  %1945 = and i8 %1942, %1940
  %1946 = or i8 %1945, %1944
  %1947 = add i64 %1938, 64
  %1948 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1947
  %1949 = load i8, i8* %1948, align 1
  %1950 = icmp eq i64 %1856, %1947
  %1951 = sext i1 %1950 to i8
  %1952 = xor i8 %1951, -1
  %1953 = and i8 %1952, %1946
  %1954 = and i8 %1951, %1949
  %1955 = or i8 %1954, %1953
  %1956 = add i64 %1947, 64
  %1957 = icmp sge i64 %1956, 748
  %1958 = sext i1 %1957 to i64
  %1959 = xor i64 %1958, -1
  %1960 = and i64 %1958, 747
  %1961 = and i64 %1959, %1956
  %1962 = or i64 %1960, %1961
  %1963 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1962
  %1964 = load i8, i8* %1963, align 1
  %1965 = icmp eq i64 %1856, %1962
  %1966 = sext i1 %1965 to i8
  %1967 = xor i8 %1966, -1
  %1968 = and i8 %1967, %1955
  %1969 = and i8 %1966, %1964
  %Mitigated17 = or i8 %1969, %1968
  %1970 = zext i8 %Mitigated17 to i32
  %1971 = zext i8 %1422 to i32
  %1972 = xor i32 %1971, %1970
  %1973 = trunc i32 %1972 to i8
  %1974 = add i32 %1735, 61
  %1975 = zext i32 %1974 to i64
  %1976 = srem i64 %1975, 64
  %1977 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1976
  %1978 = load i8, i8* %1977, align 1
  %1979 = icmp eq i64 %1975, %1976
  %1980 = sext i1 %1979 to i8
  %1981 = xor i8 %1980, -1
  %1982 = and i8 %1981, 0
  %1983 = and i8 %1980, %1978
  %1984 = or i8 %1983, %1982
  %1985 = add i64 %1976, 64
  %1986 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1985
  %1987 = load i8, i8* %1986, align 1
  %1988 = icmp eq i64 %1975, %1985
  %1989 = sext i1 %1988 to i8
  %1990 = xor i8 %1989, -1
  %1991 = and i8 %1990, %1984
  %1992 = and i8 %1989, %1987
  %1993 = or i8 %1992, %1991
  %1994 = add i64 %1985, 64
  %1995 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %1994
  %1996 = load i8, i8* %1995, align 1
  %1997 = icmp eq i64 %1975, %1994
  %1998 = sext i1 %1997 to i8
  %1999 = xor i8 %1998, -1
  %2000 = and i8 %1999, %1993
  %2001 = and i8 %1998, %1996
  %2002 = or i8 %2001, %2000
  %2003 = add i64 %1994, 64
  %2004 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2003
  %2005 = load i8, i8* %2004, align 1
  %2006 = icmp eq i64 %1975, %2003
  %2007 = sext i1 %2006 to i8
  %2008 = xor i8 %2007, -1
  %2009 = and i8 %2008, %2002
  %2010 = and i8 %2007, %2005
  %2011 = or i8 %2010, %2009
  %2012 = add i64 %2003, 64
  %2013 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2012
  %2014 = load i8, i8* %2013, align 1
  %2015 = icmp eq i64 %1975, %2012
  %2016 = sext i1 %2015 to i8
  %2017 = xor i8 %2016, -1
  %2018 = and i8 %2017, %2011
  %2019 = and i8 %2016, %2014
  %2020 = or i8 %2019, %2018
  %2021 = add i64 %2012, 64
  %2022 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2021
  %2023 = load i8, i8* %2022, align 1
  %2024 = icmp eq i64 %1975, %2021
  %2025 = sext i1 %2024 to i8
  %2026 = xor i8 %2025, -1
  %2027 = and i8 %2026, %2020
  %2028 = and i8 %2025, %2023
  %2029 = or i8 %2028, %2027
  %2030 = add i64 %2021, 64
  %2031 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2030
  %2032 = load i8, i8* %2031, align 1
  %2033 = icmp eq i64 %1975, %2030
  %2034 = sext i1 %2033 to i8
  %2035 = xor i8 %2034, -1
  %2036 = and i8 %2035, %2029
  %2037 = and i8 %2034, %2032
  %2038 = or i8 %2037, %2036
  %2039 = add i64 %2030, 64
  %2040 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2039
  %2041 = load i8, i8* %2040, align 1
  %2042 = icmp eq i64 %1975, %2039
  %2043 = sext i1 %2042 to i8
  %2044 = xor i8 %2043, -1
  %2045 = and i8 %2044, %2038
  %2046 = and i8 %2043, %2041
  %2047 = or i8 %2046, %2045
  %2048 = add i64 %2039, 64
  %2049 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2048
  %2050 = load i8, i8* %2049, align 1
  %2051 = icmp eq i64 %1975, %2048
  %2052 = sext i1 %2051 to i8
  %2053 = xor i8 %2052, -1
  %2054 = and i8 %2053, %2047
  %2055 = and i8 %2052, %2050
  %2056 = or i8 %2055, %2054
  %2057 = add i64 %2048, 64
  %2058 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2057
  %2059 = load i8, i8* %2058, align 1
  %2060 = icmp eq i64 %1975, %2057
  %2061 = sext i1 %2060 to i8
  %2062 = xor i8 %2061, -1
  %2063 = and i8 %2062, %2056
  %2064 = and i8 %2061, %2059
  %2065 = or i8 %2064, %2063
  %2066 = add i64 %2057, 64
  %2067 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2066
  %2068 = load i8, i8* %2067, align 1
  %2069 = icmp eq i64 %1975, %2066
  %2070 = sext i1 %2069 to i8
  %2071 = xor i8 %2070, -1
  %2072 = and i8 %2071, %2065
  %2073 = and i8 %2070, %2068
  %2074 = or i8 %2073, %2072
  %2075 = add i64 %2066, 64
  %2076 = icmp sge i64 %2075, 748
  %2077 = sext i1 %2076 to i64
  %2078 = xor i64 %2077, -1
  %2079 = and i64 %2077, 747
  %2080 = and i64 %2078, %2075
  %2081 = or i64 %2079, %2080
  %2082 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2081
  %2083 = load i8, i8* %2082, align 1
  %2084 = icmp eq i64 %1975, %2081
  %2085 = sext i1 %2084 to i8
  %2086 = xor i8 %2085, -1
  %2087 = and i8 %2086, %2074
  %2088 = and i8 %2085, %2083
  %Mitigated18 = or i8 %2088, %2087
  %2089 = zext i8 %Mitigated18 to i32
  %2090 = zext i8 %1541 to i32
  %2091 = xor i32 %2090, %2089
  %2092 = trunc i32 %2091 to i8
  %2093 = add i32 %1735, 153
  %2094 = zext i32 %2093 to i64
  %2095 = srem i64 %2094, 64
  %2096 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2095
  %2097 = load i8, i8* %2096, align 1
  %2098 = icmp eq i64 %2094, %2095
  %2099 = sext i1 %2098 to i8
  %2100 = xor i8 %2099, -1
  %2101 = and i8 %2100, 0
  %2102 = and i8 %2099, %2097
  %2103 = or i8 %2102, %2101
  %2104 = add i64 %2095, 64
  %2105 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2104
  %2106 = load i8, i8* %2105, align 1
  %2107 = icmp eq i64 %2094, %2104
  %2108 = sext i1 %2107 to i8
  %2109 = xor i8 %2108, -1
  %2110 = and i8 %2109, %2103
  %2111 = and i8 %2108, %2106
  %2112 = or i8 %2111, %2110
  %2113 = add i64 %2104, 64
  %2114 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2113
  %2115 = load i8, i8* %2114, align 1
  %2116 = icmp eq i64 %2094, %2113
  %2117 = sext i1 %2116 to i8
  %2118 = xor i8 %2117, -1
  %2119 = and i8 %2118, %2112
  %2120 = and i8 %2117, %2115
  %2121 = or i8 %2120, %2119
  %2122 = add i64 %2113, 64
  %2123 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2122
  %2124 = load i8, i8* %2123, align 1
  %2125 = icmp eq i64 %2094, %2122
  %2126 = sext i1 %2125 to i8
  %2127 = xor i8 %2126, -1
  %2128 = and i8 %2127, %2121
  %2129 = and i8 %2126, %2124
  %2130 = or i8 %2129, %2128
  %2131 = add i64 %2122, 64
  %2132 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2131
  %2133 = load i8, i8* %2132, align 1
  %2134 = icmp eq i64 %2094, %2131
  %2135 = sext i1 %2134 to i8
  %2136 = xor i8 %2135, -1
  %2137 = and i8 %2136, %2130
  %2138 = and i8 %2135, %2133
  %2139 = or i8 %2138, %2137
  %2140 = add i64 %2131, 64
  %2141 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2140
  %2142 = load i8, i8* %2141, align 1
  %2143 = icmp eq i64 %2094, %2140
  %2144 = sext i1 %2143 to i8
  %2145 = xor i8 %2144, -1
  %2146 = and i8 %2145, %2139
  %2147 = and i8 %2144, %2142
  %2148 = or i8 %2147, %2146
  %2149 = add i64 %2140, 64
  %2150 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2149
  %2151 = load i8, i8* %2150, align 1
  %2152 = icmp eq i64 %2094, %2149
  %2153 = sext i1 %2152 to i8
  %2154 = xor i8 %2153, -1
  %2155 = and i8 %2154, %2148
  %2156 = and i8 %2153, %2151
  %2157 = or i8 %2156, %2155
  %2158 = add i64 %2149, 64
  %2159 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2158
  %2160 = load i8, i8* %2159, align 1
  %2161 = icmp eq i64 %2094, %2158
  %2162 = sext i1 %2161 to i8
  %2163 = xor i8 %2162, -1
  %2164 = and i8 %2163, %2157
  %2165 = and i8 %2162, %2160
  %2166 = or i8 %2165, %2164
  %2167 = add i64 %2158, 64
  %2168 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2167
  %2169 = load i8, i8* %2168, align 1
  %2170 = icmp eq i64 %2094, %2167
  %2171 = sext i1 %2170 to i8
  %2172 = xor i8 %2171, -1
  %2173 = and i8 %2172, %2166
  %2174 = and i8 %2171, %2169
  %2175 = or i8 %2174, %2173
  %2176 = add i64 %2167, 64
  %2177 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2176
  %2178 = load i8, i8* %2177, align 1
  %2179 = icmp eq i64 %2094, %2176
  %2180 = sext i1 %2179 to i8
  %2181 = xor i8 %2180, -1
  %2182 = and i8 %2181, %2175
  %2183 = and i8 %2180, %2178
  %2184 = or i8 %2183, %2182
  %2185 = add i64 %2176, 64
  %2186 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2185
  %2187 = load i8, i8* %2186, align 1
  %2188 = icmp eq i64 %2094, %2185
  %2189 = sext i1 %2188 to i8
  %2190 = xor i8 %2189, -1
  %2191 = and i8 %2190, %2184
  %2192 = and i8 %2189, %2187
  %2193 = or i8 %2192, %2191
  %2194 = add i64 %2185, 64
  %2195 = icmp sge i64 %2194, 748
  %2196 = sext i1 %2195 to i64
  %2197 = xor i64 %2196, -1
  %2198 = and i64 %2196, 747
  %2199 = and i64 %2197, %2194
  %2200 = or i64 %2198, %2199
  %2201 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2200
  %2202 = load i8, i8* %2201, align 1
  %2203 = icmp eq i64 %2094, %2200
  %2204 = sext i1 %2203 to i8
  %2205 = xor i8 %2204, -1
  %2206 = and i8 %2205, %2193
  %2207 = and i8 %2204, %2202
  %Mitigated19 = or i8 %2207, %2206
  %2208 = zext i8 %Mitigated19 to i32
  %2209 = zext i8 %1660 to i32
  %2210 = xor i32 %2209, %2208
  %2211 = trunc i32 %2210 to i8
  %2212 = getelementptr inbounds i8, i8* %0, i64 4
  %2213 = load i8, i8* %2212, align 1
  %2214 = zext i8 %2213 to i64
  %2215 = srem i64 %2214, 32
  %2216 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2215
  %2217 = load i16, i16* %2216, align 2
  %2218 = icmp eq i64 %2214, %2215
  %2219 = sext i1 %2218 to i16
  %2220 = xor i16 %2219, -1
  %2221 = and i16 %2220, 0
  %2222 = and i16 %2219, %2217
  %2223 = or i16 %2222, %2221
  %2224 = add i64 %2215, 32
  %2225 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2224
  %2226 = load i16, i16* %2225, align 2
  %2227 = icmp eq i64 %2214, %2224
  %2228 = sext i1 %2227 to i16
  %2229 = xor i16 %2228, -1
  %2230 = and i16 %2229, %2223
  %2231 = and i16 %2228, %2226
  %2232 = or i16 %2231, %2230
  %2233 = add i64 %2224, 32
  %2234 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2233
  %2235 = load i16, i16* %2234, align 2
  %2236 = icmp eq i64 %2214, %2233
  %2237 = sext i1 %2236 to i16
  %2238 = xor i16 %2237, -1
  %2239 = and i16 %2238, %2232
  %2240 = and i16 %2237, %2235
  %2241 = or i16 %2240, %2239
  %2242 = add i64 %2233, 32
  %2243 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2242
  %2244 = load i16, i16* %2243, align 2
  %2245 = icmp eq i64 %2214, %2242
  %2246 = sext i1 %2245 to i16
  %2247 = xor i16 %2246, -1
  %2248 = and i16 %2247, %2241
  %2249 = and i16 %2246, %2244
  %2250 = or i16 %2249, %2248
  %2251 = add i64 %2242, 32
  %2252 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2251
  %2253 = load i16, i16* %2252, align 2
  %2254 = icmp eq i64 %2214, %2251
  %2255 = sext i1 %2254 to i16
  %2256 = xor i16 %2255, -1
  %2257 = and i16 %2256, %2250
  %2258 = and i16 %2255, %2253
  %2259 = or i16 %2258, %2257
  %2260 = add i64 %2251, 32
  %2261 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2260
  %2262 = load i16, i16* %2261, align 2
  %2263 = icmp eq i64 %2214, %2260
  %2264 = sext i1 %2263 to i16
  %2265 = xor i16 %2264, -1
  %2266 = and i16 %2265, %2259
  %2267 = and i16 %2264, %2262
  %2268 = or i16 %2267, %2266
  %2269 = add i64 %2260, 32
  %2270 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2269
  %2271 = load i16, i16* %2270, align 2
  %2272 = icmp eq i64 %2214, %2269
  %2273 = sext i1 %2272 to i16
  %2274 = xor i16 %2273, -1
  %2275 = and i16 %2274, %2268
  %2276 = and i16 %2273, %2271
  %2277 = or i16 %2276, %2275
  %2278 = add i64 %2269, 32
  %2279 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2278
  %2280 = load i16, i16* %2279, align 2
  %2281 = icmp eq i64 %2214, %2278
  %2282 = sext i1 %2281 to i16
  %2283 = xor i16 %2282, -1
  %2284 = and i16 %2283, %2277
  %2285 = and i16 %2282, %2280
  %Mitigated20 = or i16 %2285, %2284
  %2286 = zext i16 %Mitigated20 to i32
  %2287 = add i32 %2286, 153
  %2288 = zext i32 %2287 to i64
  %2289 = srem i64 %2288, 64
  %2290 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2289
  %2291 = load i8, i8* %2290, align 1
  %2292 = icmp eq i64 %2288, %2289
  %2293 = sext i1 %2292 to i8
  %2294 = xor i8 %2293, -1
  %2295 = and i8 %2294, 0
  %2296 = and i8 %2293, %2291
  %2297 = or i8 %2296, %2295
  %2298 = add i64 %2289, 64
  %2299 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2298
  %2300 = load i8, i8* %2299, align 1
  %2301 = icmp eq i64 %2288, %2298
  %2302 = sext i1 %2301 to i8
  %2303 = xor i8 %2302, -1
  %2304 = and i8 %2303, %2297
  %2305 = and i8 %2302, %2300
  %2306 = or i8 %2305, %2304
  %2307 = add i64 %2298, 64
  %2308 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2307
  %2309 = load i8, i8* %2308, align 1
  %2310 = icmp eq i64 %2288, %2307
  %2311 = sext i1 %2310 to i8
  %2312 = xor i8 %2311, -1
  %2313 = and i8 %2312, %2306
  %2314 = and i8 %2311, %2309
  %2315 = or i8 %2314, %2313
  %2316 = add i64 %2307, 64
  %2317 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2316
  %2318 = load i8, i8* %2317, align 1
  %2319 = icmp eq i64 %2288, %2316
  %2320 = sext i1 %2319 to i8
  %2321 = xor i8 %2320, -1
  %2322 = and i8 %2321, %2315
  %2323 = and i8 %2320, %2318
  %2324 = or i8 %2323, %2322
  %2325 = add i64 %2316, 64
  %2326 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2325
  %2327 = load i8, i8* %2326, align 1
  %2328 = icmp eq i64 %2288, %2325
  %2329 = sext i1 %2328 to i8
  %2330 = xor i8 %2329, -1
  %2331 = and i8 %2330, %2324
  %2332 = and i8 %2329, %2327
  %2333 = or i8 %2332, %2331
  %2334 = add i64 %2325, 64
  %2335 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2334
  %2336 = load i8, i8* %2335, align 1
  %2337 = icmp eq i64 %2288, %2334
  %2338 = sext i1 %2337 to i8
  %2339 = xor i8 %2338, -1
  %2340 = and i8 %2339, %2333
  %2341 = and i8 %2338, %2336
  %2342 = or i8 %2341, %2340
  %2343 = add i64 %2334, 64
  %2344 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2343
  %2345 = load i8, i8* %2344, align 1
  %2346 = icmp eq i64 %2288, %2343
  %2347 = sext i1 %2346 to i8
  %2348 = xor i8 %2347, -1
  %2349 = and i8 %2348, %2342
  %2350 = and i8 %2347, %2345
  %2351 = or i8 %2350, %2349
  %2352 = add i64 %2343, 64
  %2353 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2352
  %2354 = load i8, i8* %2353, align 1
  %2355 = icmp eq i64 %2288, %2352
  %2356 = sext i1 %2355 to i8
  %2357 = xor i8 %2356, -1
  %2358 = and i8 %2357, %2351
  %2359 = and i8 %2356, %2354
  %2360 = or i8 %2359, %2358
  %2361 = add i64 %2352, 64
  %2362 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2361
  %2363 = load i8, i8* %2362, align 1
  %2364 = icmp eq i64 %2288, %2361
  %2365 = sext i1 %2364 to i8
  %2366 = xor i8 %2365, -1
  %2367 = and i8 %2366, %2360
  %2368 = and i8 %2365, %2363
  %2369 = or i8 %2368, %2367
  %2370 = add i64 %2361, 64
  %2371 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2370
  %2372 = load i8, i8* %2371, align 1
  %2373 = icmp eq i64 %2288, %2370
  %2374 = sext i1 %2373 to i8
  %2375 = xor i8 %2374, -1
  %2376 = and i8 %2375, %2369
  %2377 = and i8 %2374, %2372
  %2378 = or i8 %2377, %2376
  %2379 = add i64 %2370, 64
  %2380 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2379
  %2381 = load i8, i8* %2380, align 1
  %2382 = icmp eq i64 %2288, %2379
  %2383 = sext i1 %2382 to i8
  %2384 = xor i8 %2383, -1
  %2385 = and i8 %2384, %2378
  %2386 = and i8 %2383, %2381
  %2387 = or i8 %2386, %2385
  %2388 = add i64 %2379, 64
  %2389 = icmp sge i64 %2388, 748
  %2390 = sext i1 %2389 to i64
  %2391 = xor i64 %2390, -1
  %2392 = and i64 %2390, 747
  %2393 = and i64 %2391, %2388
  %2394 = or i64 %2392, %2393
  %2395 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2394
  %2396 = load i8, i8* %2395, align 1
  %2397 = icmp eq i64 %2288, %2394
  %2398 = sext i1 %2397 to i8
  %2399 = xor i8 %2398, -1
  %2400 = and i8 %2399, %2387
  %2401 = and i8 %2398, %2396
  %Mitigated21 = or i8 %2401, %2400
  %2402 = zext i8 %Mitigated21 to i32
  %2403 = zext i8 %1854 to i32
  %2404 = xor i32 %2403, %2402
  %2405 = trunc i32 %2404 to i8
  %2406 = add i32 %2286, 70
  %2407 = zext i32 %2406 to i64
  %2408 = srem i64 %2407, 64
  %2409 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2408
  %2410 = load i8, i8* %2409, align 1
  %2411 = icmp eq i64 %2407, %2408
  %2412 = sext i1 %2411 to i8
  %2413 = xor i8 %2412, -1
  %2414 = and i8 %2413, 0
  %2415 = and i8 %2412, %2410
  %2416 = or i8 %2415, %2414
  %2417 = add i64 %2408, 64
  %2418 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2417
  %2419 = load i8, i8* %2418, align 1
  %2420 = icmp eq i64 %2407, %2417
  %2421 = sext i1 %2420 to i8
  %2422 = xor i8 %2421, -1
  %2423 = and i8 %2422, %2416
  %2424 = and i8 %2421, %2419
  %2425 = or i8 %2424, %2423
  %2426 = add i64 %2417, 64
  %2427 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2426
  %2428 = load i8, i8* %2427, align 1
  %2429 = icmp eq i64 %2407, %2426
  %2430 = sext i1 %2429 to i8
  %2431 = xor i8 %2430, -1
  %2432 = and i8 %2431, %2425
  %2433 = and i8 %2430, %2428
  %2434 = or i8 %2433, %2432
  %2435 = add i64 %2426, 64
  %2436 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2435
  %2437 = load i8, i8* %2436, align 1
  %2438 = icmp eq i64 %2407, %2435
  %2439 = sext i1 %2438 to i8
  %2440 = xor i8 %2439, -1
  %2441 = and i8 %2440, %2434
  %2442 = and i8 %2439, %2437
  %2443 = or i8 %2442, %2441
  %2444 = add i64 %2435, 64
  %2445 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2444
  %2446 = load i8, i8* %2445, align 1
  %2447 = icmp eq i64 %2407, %2444
  %2448 = sext i1 %2447 to i8
  %2449 = xor i8 %2448, -1
  %2450 = and i8 %2449, %2443
  %2451 = and i8 %2448, %2446
  %2452 = or i8 %2451, %2450
  %2453 = add i64 %2444, 64
  %2454 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2453
  %2455 = load i8, i8* %2454, align 1
  %2456 = icmp eq i64 %2407, %2453
  %2457 = sext i1 %2456 to i8
  %2458 = xor i8 %2457, -1
  %2459 = and i8 %2458, %2452
  %2460 = and i8 %2457, %2455
  %2461 = or i8 %2460, %2459
  %2462 = add i64 %2453, 64
  %2463 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2462
  %2464 = load i8, i8* %2463, align 1
  %2465 = icmp eq i64 %2407, %2462
  %2466 = sext i1 %2465 to i8
  %2467 = xor i8 %2466, -1
  %2468 = and i8 %2467, %2461
  %2469 = and i8 %2466, %2464
  %2470 = or i8 %2469, %2468
  %2471 = add i64 %2462, 64
  %2472 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2471
  %2473 = load i8, i8* %2472, align 1
  %2474 = icmp eq i64 %2407, %2471
  %2475 = sext i1 %2474 to i8
  %2476 = xor i8 %2475, -1
  %2477 = and i8 %2476, %2470
  %2478 = and i8 %2475, %2473
  %2479 = or i8 %2478, %2477
  %2480 = add i64 %2471, 64
  %2481 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2480
  %2482 = load i8, i8* %2481, align 1
  %2483 = icmp eq i64 %2407, %2480
  %2484 = sext i1 %2483 to i8
  %2485 = xor i8 %2484, -1
  %2486 = and i8 %2485, %2479
  %2487 = and i8 %2484, %2482
  %2488 = or i8 %2487, %2486
  %2489 = add i64 %2480, 64
  %2490 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2489
  %2491 = load i8, i8* %2490, align 1
  %2492 = icmp eq i64 %2407, %2489
  %2493 = sext i1 %2492 to i8
  %2494 = xor i8 %2493, -1
  %2495 = and i8 %2494, %2488
  %2496 = and i8 %2493, %2491
  %2497 = or i8 %2496, %2495
  %2498 = add i64 %2489, 64
  %2499 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2498
  %2500 = load i8, i8* %2499, align 1
  %2501 = icmp eq i64 %2407, %2498
  %2502 = sext i1 %2501 to i8
  %2503 = xor i8 %2502, -1
  %2504 = and i8 %2503, %2497
  %2505 = and i8 %2502, %2500
  %2506 = or i8 %2505, %2504
  %2507 = add i64 %2498, 64
  %2508 = icmp sge i64 %2507, 748
  %2509 = sext i1 %2508 to i64
  %2510 = xor i64 %2509, -1
  %2511 = and i64 %2509, 747
  %2512 = and i64 %2510, %2507
  %2513 = or i64 %2511, %2512
  %2514 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2513
  %2515 = load i8, i8* %2514, align 1
  %2516 = icmp eq i64 %2407, %2513
  %2517 = sext i1 %2516 to i8
  %2518 = xor i8 %2517, -1
  %2519 = and i8 %2518, %2506
  %2520 = and i8 %2517, %2515
  %Mitigated22 = or i8 %2520, %2519
  %2521 = zext i8 %Mitigated22 to i32
  %2522 = zext i8 %1973 to i32
  %2523 = xor i32 %2522, %2521
  %2524 = trunc i32 %2523 to i8
  %2525 = add i32 %2286, 102
  %2526 = zext i32 %2525 to i64
  %2527 = srem i64 %2526, 64
  %2528 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2527
  %2529 = load i8, i8* %2528, align 1
  %2530 = icmp eq i64 %2526, %2527
  %2531 = sext i1 %2530 to i8
  %2532 = xor i8 %2531, -1
  %2533 = and i8 %2532, 0
  %2534 = and i8 %2531, %2529
  %2535 = or i8 %2534, %2533
  %2536 = add i64 %2527, 64
  %2537 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2536
  %2538 = load i8, i8* %2537, align 1
  %2539 = icmp eq i64 %2526, %2536
  %2540 = sext i1 %2539 to i8
  %2541 = xor i8 %2540, -1
  %2542 = and i8 %2541, %2535
  %2543 = and i8 %2540, %2538
  %2544 = or i8 %2543, %2542
  %2545 = add i64 %2536, 64
  %2546 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2545
  %2547 = load i8, i8* %2546, align 1
  %2548 = icmp eq i64 %2526, %2545
  %2549 = sext i1 %2548 to i8
  %2550 = xor i8 %2549, -1
  %2551 = and i8 %2550, %2544
  %2552 = and i8 %2549, %2547
  %2553 = or i8 %2552, %2551
  %2554 = add i64 %2545, 64
  %2555 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2554
  %2556 = load i8, i8* %2555, align 1
  %2557 = icmp eq i64 %2526, %2554
  %2558 = sext i1 %2557 to i8
  %2559 = xor i8 %2558, -1
  %2560 = and i8 %2559, %2553
  %2561 = and i8 %2558, %2556
  %2562 = or i8 %2561, %2560
  %2563 = add i64 %2554, 64
  %2564 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2563
  %2565 = load i8, i8* %2564, align 1
  %2566 = icmp eq i64 %2526, %2563
  %2567 = sext i1 %2566 to i8
  %2568 = xor i8 %2567, -1
  %2569 = and i8 %2568, %2562
  %2570 = and i8 %2567, %2565
  %2571 = or i8 %2570, %2569
  %2572 = add i64 %2563, 64
  %2573 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2572
  %2574 = load i8, i8* %2573, align 1
  %2575 = icmp eq i64 %2526, %2572
  %2576 = sext i1 %2575 to i8
  %2577 = xor i8 %2576, -1
  %2578 = and i8 %2577, %2571
  %2579 = and i8 %2576, %2574
  %2580 = or i8 %2579, %2578
  %2581 = add i64 %2572, 64
  %2582 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2581
  %2583 = load i8, i8* %2582, align 1
  %2584 = icmp eq i64 %2526, %2581
  %2585 = sext i1 %2584 to i8
  %2586 = xor i8 %2585, -1
  %2587 = and i8 %2586, %2580
  %2588 = and i8 %2585, %2583
  %2589 = or i8 %2588, %2587
  %2590 = add i64 %2581, 64
  %2591 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2590
  %2592 = load i8, i8* %2591, align 1
  %2593 = icmp eq i64 %2526, %2590
  %2594 = sext i1 %2593 to i8
  %2595 = xor i8 %2594, -1
  %2596 = and i8 %2595, %2589
  %2597 = and i8 %2594, %2592
  %2598 = or i8 %2597, %2596
  %2599 = add i64 %2590, 64
  %2600 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2599
  %2601 = load i8, i8* %2600, align 1
  %2602 = icmp eq i64 %2526, %2599
  %2603 = sext i1 %2602 to i8
  %2604 = xor i8 %2603, -1
  %2605 = and i8 %2604, %2598
  %2606 = and i8 %2603, %2601
  %2607 = or i8 %2606, %2605
  %2608 = add i64 %2599, 64
  %2609 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2608
  %2610 = load i8, i8* %2609, align 1
  %2611 = icmp eq i64 %2526, %2608
  %2612 = sext i1 %2611 to i8
  %2613 = xor i8 %2612, -1
  %2614 = and i8 %2613, %2607
  %2615 = and i8 %2612, %2610
  %2616 = or i8 %2615, %2614
  %2617 = add i64 %2608, 64
  %2618 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2617
  %2619 = load i8, i8* %2618, align 1
  %2620 = icmp eq i64 %2526, %2617
  %2621 = sext i1 %2620 to i8
  %2622 = xor i8 %2621, -1
  %2623 = and i8 %2622, %2616
  %2624 = and i8 %2621, %2619
  %2625 = or i8 %2624, %2623
  %2626 = add i64 %2617, 64
  %2627 = icmp sge i64 %2626, 748
  %2628 = sext i1 %2627 to i64
  %2629 = xor i64 %2628, -1
  %2630 = and i64 %2628, 747
  %2631 = and i64 %2629, %2626
  %2632 = or i64 %2630, %2631
  %2633 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2632
  %2634 = load i8, i8* %2633, align 1
  %2635 = icmp eq i64 %2526, %2632
  %2636 = sext i1 %2635 to i8
  %2637 = xor i8 %2636, -1
  %2638 = and i8 %2637, %2625
  %2639 = and i8 %2636, %2634
  %Mitigated23 = or i8 %2639, %2638
  %2640 = zext i8 %Mitigated23 to i32
  %2641 = zext i8 %2092 to i32
  %2642 = xor i32 %2641, %2640
  %2643 = trunc i32 %2642 to i8
  %2644 = add i32 %2286, 150
  %2645 = zext i32 %2644 to i64
  %2646 = srem i64 %2645, 64
  %2647 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2646
  %2648 = load i8, i8* %2647, align 1
  %2649 = icmp eq i64 %2645, %2646
  %2650 = sext i1 %2649 to i8
  %2651 = xor i8 %2650, -1
  %2652 = and i8 %2651, 0
  %2653 = and i8 %2650, %2648
  %2654 = or i8 %2653, %2652
  %2655 = add i64 %2646, 64
  %2656 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2655
  %2657 = load i8, i8* %2656, align 1
  %2658 = icmp eq i64 %2645, %2655
  %2659 = sext i1 %2658 to i8
  %2660 = xor i8 %2659, -1
  %2661 = and i8 %2660, %2654
  %2662 = and i8 %2659, %2657
  %2663 = or i8 %2662, %2661
  %2664 = add i64 %2655, 64
  %2665 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2664
  %2666 = load i8, i8* %2665, align 1
  %2667 = icmp eq i64 %2645, %2664
  %2668 = sext i1 %2667 to i8
  %2669 = xor i8 %2668, -1
  %2670 = and i8 %2669, %2663
  %2671 = and i8 %2668, %2666
  %2672 = or i8 %2671, %2670
  %2673 = add i64 %2664, 64
  %2674 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2673
  %2675 = load i8, i8* %2674, align 1
  %2676 = icmp eq i64 %2645, %2673
  %2677 = sext i1 %2676 to i8
  %2678 = xor i8 %2677, -1
  %2679 = and i8 %2678, %2672
  %2680 = and i8 %2677, %2675
  %2681 = or i8 %2680, %2679
  %2682 = add i64 %2673, 64
  %2683 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2682
  %2684 = load i8, i8* %2683, align 1
  %2685 = icmp eq i64 %2645, %2682
  %2686 = sext i1 %2685 to i8
  %2687 = xor i8 %2686, -1
  %2688 = and i8 %2687, %2681
  %2689 = and i8 %2686, %2684
  %2690 = or i8 %2689, %2688
  %2691 = add i64 %2682, 64
  %2692 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2691
  %2693 = load i8, i8* %2692, align 1
  %2694 = icmp eq i64 %2645, %2691
  %2695 = sext i1 %2694 to i8
  %2696 = xor i8 %2695, -1
  %2697 = and i8 %2696, %2690
  %2698 = and i8 %2695, %2693
  %2699 = or i8 %2698, %2697
  %2700 = add i64 %2691, 64
  %2701 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2700
  %2702 = load i8, i8* %2701, align 1
  %2703 = icmp eq i64 %2645, %2700
  %2704 = sext i1 %2703 to i8
  %2705 = xor i8 %2704, -1
  %2706 = and i8 %2705, %2699
  %2707 = and i8 %2704, %2702
  %2708 = or i8 %2707, %2706
  %2709 = add i64 %2700, 64
  %2710 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2709
  %2711 = load i8, i8* %2710, align 1
  %2712 = icmp eq i64 %2645, %2709
  %2713 = sext i1 %2712 to i8
  %2714 = xor i8 %2713, -1
  %2715 = and i8 %2714, %2708
  %2716 = and i8 %2713, %2711
  %2717 = or i8 %2716, %2715
  %2718 = add i64 %2709, 64
  %2719 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2718
  %2720 = load i8, i8* %2719, align 1
  %2721 = icmp eq i64 %2645, %2718
  %2722 = sext i1 %2721 to i8
  %2723 = xor i8 %2722, -1
  %2724 = and i8 %2723, %2717
  %2725 = and i8 %2722, %2720
  %2726 = or i8 %2725, %2724
  %2727 = add i64 %2718, 64
  %2728 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2727
  %2729 = load i8, i8* %2728, align 1
  %2730 = icmp eq i64 %2645, %2727
  %2731 = sext i1 %2730 to i8
  %2732 = xor i8 %2731, -1
  %2733 = and i8 %2732, %2726
  %2734 = and i8 %2731, %2729
  %2735 = or i8 %2734, %2733
  %2736 = add i64 %2727, 64
  %2737 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2736
  %2738 = load i8, i8* %2737, align 1
  %2739 = icmp eq i64 %2645, %2736
  %2740 = sext i1 %2739 to i8
  %2741 = xor i8 %2740, -1
  %2742 = and i8 %2741, %2735
  %2743 = and i8 %2740, %2738
  %2744 = or i8 %2743, %2742
  %2745 = add i64 %2736, 64
  %2746 = icmp sge i64 %2745, 748
  %2747 = sext i1 %2746 to i64
  %2748 = xor i64 %2747, -1
  %2749 = and i64 %2747, 747
  %2750 = and i64 %2748, %2745
  %2751 = or i64 %2749, %2750
  %2752 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2751
  %2753 = load i8, i8* %2752, align 1
  %2754 = icmp eq i64 %2645, %2751
  %2755 = sext i1 %2754 to i8
  %2756 = xor i8 %2755, -1
  %2757 = and i8 %2756, %2744
  %2758 = and i8 %2755, %2753
  %Mitigated24 = or i8 %2758, %2757
  %2759 = zext i8 %Mitigated24 to i32
  %2760 = zext i8 %2211 to i32
  %2761 = xor i32 %2760, %2759
  %2762 = trunc i32 %2761 to i8
  %2763 = getelementptr inbounds i8, i8* %0, i64 5
  %2764 = load i8, i8* %2763, align 1
  %2765 = zext i8 %2764 to i64
  %2766 = srem i64 %2765, 32
  %2767 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2766
  %2768 = load i16, i16* %2767, align 2
  %2769 = icmp eq i64 %2765, %2766
  %2770 = sext i1 %2769 to i16
  %2771 = xor i16 %2770, -1
  %2772 = and i16 %2771, 0
  %2773 = and i16 %2770, %2768
  %2774 = or i16 %2773, %2772
  %2775 = add i64 %2766, 32
  %2776 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2775
  %2777 = load i16, i16* %2776, align 2
  %2778 = icmp eq i64 %2765, %2775
  %2779 = sext i1 %2778 to i16
  %2780 = xor i16 %2779, -1
  %2781 = and i16 %2780, %2774
  %2782 = and i16 %2779, %2777
  %2783 = or i16 %2782, %2781
  %2784 = add i64 %2775, 32
  %2785 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2784
  %2786 = load i16, i16* %2785, align 2
  %2787 = icmp eq i64 %2765, %2784
  %2788 = sext i1 %2787 to i16
  %2789 = xor i16 %2788, -1
  %2790 = and i16 %2789, %2783
  %2791 = and i16 %2788, %2786
  %2792 = or i16 %2791, %2790
  %2793 = add i64 %2784, 32
  %2794 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2793
  %2795 = load i16, i16* %2794, align 2
  %2796 = icmp eq i64 %2765, %2793
  %2797 = sext i1 %2796 to i16
  %2798 = xor i16 %2797, -1
  %2799 = and i16 %2798, %2792
  %2800 = and i16 %2797, %2795
  %2801 = or i16 %2800, %2799
  %2802 = add i64 %2793, 32
  %2803 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2802
  %2804 = load i16, i16* %2803, align 2
  %2805 = icmp eq i64 %2765, %2802
  %2806 = sext i1 %2805 to i16
  %2807 = xor i16 %2806, -1
  %2808 = and i16 %2807, %2801
  %2809 = and i16 %2806, %2804
  %2810 = or i16 %2809, %2808
  %2811 = add i64 %2802, 32
  %2812 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2811
  %2813 = load i16, i16* %2812, align 2
  %2814 = icmp eq i64 %2765, %2811
  %2815 = sext i1 %2814 to i16
  %2816 = xor i16 %2815, -1
  %2817 = and i16 %2816, %2810
  %2818 = and i16 %2815, %2813
  %2819 = or i16 %2818, %2817
  %2820 = add i64 %2811, 32
  %2821 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2820
  %2822 = load i16, i16* %2821, align 2
  %2823 = icmp eq i64 %2765, %2820
  %2824 = sext i1 %2823 to i16
  %2825 = xor i16 %2824, -1
  %2826 = and i16 %2825, %2819
  %2827 = and i16 %2824, %2822
  %2828 = or i16 %2827, %2826
  %2829 = add i64 %2820, 32
  %2830 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %2829
  %2831 = load i16, i16* %2830, align 2
  %2832 = icmp eq i64 %2765, %2829
  %2833 = sext i1 %2832 to i16
  %2834 = xor i16 %2833, -1
  %2835 = and i16 %2834, %2828
  %2836 = and i16 %2833, %2831
  %Mitigated25 = or i16 %2836, %2835
  %2837 = zext i16 %Mitigated25 to i32
  %2838 = add i32 %2837, 150
  %2839 = zext i32 %2838 to i64
  %2840 = srem i64 %2839, 64
  %2841 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2840
  %2842 = load i8, i8* %2841, align 1
  %2843 = icmp eq i64 %2839, %2840
  %2844 = sext i1 %2843 to i8
  %2845 = xor i8 %2844, -1
  %2846 = and i8 %2845, 0
  %2847 = and i8 %2844, %2842
  %2848 = or i8 %2847, %2846
  %2849 = add i64 %2840, 64
  %2850 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2849
  %2851 = load i8, i8* %2850, align 1
  %2852 = icmp eq i64 %2839, %2849
  %2853 = sext i1 %2852 to i8
  %2854 = xor i8 %2853, -1
  %2855 = and i8 %2854, %2848
  %2856 = and i8 %2853, %2851
  %2857 = or i8 %2856, %2855
  %2858 = add i64 %2849, 64
  %2859 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2858
  %2860 = load i8, i8* %2859, align 1
  %2861 = icmp eq i64 %2839, %2858
  %2862 = sext i1 %2861 to i8
  %2863 = xor i8 %2862, -1
  %2864 = and i8 %2863, %2857
  %2865 = and i8 %2862, %2860
  %2866 = or i8 %2865, %2864
  %2867 = add i64 %2858, 64
  %2868 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2867
  %2869 = load i8, i8* %2868, align 1
  %2870 = icmp eq i64 %2839, %2867
  %2871 = sext i1 %2870 to i8
  %2872 = xor i8 %2871, -1
  %2873 = and i8 %2872, %2866
  %2874 = and i8 %2871, %2869
  %2875 = or i8 %2874, %2873
  %2876 = add i64 %2867, 64
  %2877 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2876
  %2878 = load i8, i8* %2877, align 1
  %2879 = icmp eq i64 %2839, %2876
  %2880 = sext i1 %2879 to i8
  %2881 = xor i8 %2880, -1
  %2882 = and i8 %2881, %2875
  %2883 = and i8 %2880, %2878
  %2884 = or i8 %2883, %2882
  %2885 = add i64 %2876, 64
  %2886 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2885
  %2887 = load i8, i8* %2886, align 1
  %2888 = icmp eq i64 %2839, %2885
  %2889 = sext i1 %2888 to i8
  %2890 = xor i8 %2889, -1
  %2891 = and i8 %2890, %2884
  %2892 = and i8 %2889, %2887
  %2893 = or i8 %2892, %2891
  %2894 = add i64 %2885, 64
  %2895 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2894
  %2896 = load i8, i8* %2895, align 1
  %2897 = icmp eq i64 %2839, %2894
  %2898 = sext i1 %2897 to i8
  %2899 = xor i8 %2898, -1
  %2900 = and i8 %2899, %2893
  %2901 = and i8 %2898, %2896
  %2902 = or i8 %2901, %2900
  %2903 = add i64 %2894, 64
  %2904 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2903
  %2905 = load i8, i8* %2904, align 1
  %2906 = icmp eq i64 %2839, %2903
  %2907 = sext i1 %2906 to i8
  %2908 = xor i8 %2907, -1
  %2909 = and i8 %2908, %2902
  %2910 = and i8 %2907, %2905
  %2911 = or i8 %2910, %2909
  %2912 = add i64 %2903, 64
  %2913 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2912
  %2914 = load i8, i8* %2913, align 1
  %2915 = icmp eq i64 %2839, %2912
  %2916 = sext i1 %2915 to i8
  %2917 = xor i8 %2916, -1
  %2918 = and i8 %2917, %2911
  %2919 = and i8 %2916, %2914
  %2920 = or i8 %2919, %2918
  %2921 = add i64 %2912, 64
  %2922 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2921
  %2923 = load i8, i8* %2922, align 1
  %2924 = icmp eq i64 %2839, %2921
  %2925 = sext i1 %2924 to i8
  %2926 = xor i8 %2925, -1
  %2927 = and i8 %2926, %2920
  %2928 = and i8 %2925, %2923
  %2929 = or i8 %2928, %2927
  %2930 = add i64 %2921, 64
  %2931 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2930
  %2932 = load i8, i8* %2931, align 1
  %2933 = icmp eq i64 %2839, %2930
  %2934 = sext i1 %2933 to i8
  %2935 = xor i8 %2934, -1
  %2936 = and i8 %2935, %2929
  %2937 = and i8 %2934, %2932
  %2938 = or i8 %2937, %2936
  %2939 = add i64 %2930, 64
  %2940 = icmp sge i64 %2939, 748
  %2941 = sext i1 %2940 to i64
  %2942 = xor i64 %2941, -1
  %2943 = and i64 %2941, 747
  %2944 = and i64 %2942, %2939
  %2945 = or i64 %2943, %2944
  %2946 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2945
  %2947 = load i8, i8* %2946, align 1
  %2948 = icmp eq i64 %2839, %2945
  %2949 = sext i1 %2948 to i8
  %2950 = xor i8 %2949, -1
  %2951 = and i8 %2950, %2938
  %2952 = and i8 %2949, %2947
  %Mitigated26 = or i8 %2952, %2951
  %2953 = zext i8 %Mitigated26 to i32
  %2954 = zext i8 %2405 to i32
  %2955 = xor i32 %2954, %2953
  %2956 = trunc i32 %2955 to i8
  %2957 = add i32 %2837, 60
  %2958 = zext i32 %2957 to i64
  %2959 = srem i64 %2958, 64
  %2960 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2959
  %2961 = load i8, i8* %2960, align 1
  %2962 = icmp eq i64 %2958, %2959
  %2963 = sext i1 %2962 to i8
  %2964 = xor i8 %2963, -1
  %2965 = and i8 %2964, 0
  %2966 = and i8 %2963, %2961
  %2967 = or i8 %2966, %2965
  %2968 = add i64 %2959, 64
  %2969 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2968
  %2970 = load i8, i8* %2969, align 1
  %2971 = icmp eq i64 %2958, %2968
  %2972 = sext i1 %2971 to i8
  %2973 = xor i8 %2972, -1
  %2974 = and i8 %2973, %2967
  %2975 = and i8 %2972, %2970
  %2976 = or i8 %2975, %2974
  %2977 = add i64 %2968, 64
  %2978 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2977
  %2979 = load i8, i8* %2978, align 1
  %2980 = icmp eq i64 %2958, %2977
  %2981 = sext i1 %2980 to i8
  %2982 = xor i8 %2981, -1
  %2983 = and i8 %2982, %2976
  %2984 = and i8 %2981, %2979
  %2985 = or i8 %2984, %2983
  %2986 = add i64 %2977, 64
  %2987 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2986
  %2988 = load i8, i8* %2987, align 1
  %2989 = icmp eq i64 %2958, %2986
  %2990 = sext i1 %2989 to i8
  %2991 = xor i8 %2990, -1
  %2992 = and i8 %2991, %2985
  %2993 = and i8 %2990, %2988
  %2994 = or i8 %2993, %2992
  %2995 = add i64 %2986, 64
  %2996 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %2995
  %2997 = load i8, i8* %2996, align 1
  %2998 = icmp eq i64 %2958, %2995
  %2999 = sext i1 %2998 to i8
  %3000 = xor i8 %2999, -1
  %3001 = and i8 %3000, %2994
  %3002 = and i8 %2999, %2997
  %3003 = or i8 %3002, %3001
  %3004 = add i64 %2995, 64
  %3005 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3004
  %3006 = load i8, i8* %3005, align 1
  %3007 = icmp eq i64 %2958, %3004
  %3008 = sext i1 %3007 to i8
  %3009 = xor i8 %3008, -1
  %3010 = and i8 %3009, %3003
  %3011 = and i8 %3008, %3006
  %3012 = or i8 %3011, %3010
  %3013 = add i64 %3004, 64
  %3014 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3013
  %3015 = load i8, i8* %3014, align 1
  %3016 = icmp eq i64 %2958, %3013
  %3017 = sext i1 %3016 to i8
  %3018 = xor i8 %3017, -1
  %3019 = and i8 %3018, %3012
  %3020 = and i8 %3017, %3015
  %3021 = or i8 %3020, %3019
  %3022 = add i64 %3013, 64
  %3023 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3022
  %3024 = load i8, i8* %3023, align 1
  %3025 = icmp eq i64 %2958, %3022
  %3026 = sext i1 %3025 to i8
  %3027 = xor i8 %3026, -1
  %3028 = and i8 %3027, %3021
  %3029 = and i8 %3026, %3024
  %3030 = or i8 %3029, %3028
  %3031 = add i64 %3022, 64
  %3032 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3031
  %3033 = load i8, i8* %3032, align 1
  %3034 = icmp eq i64 %2958, %3031
  %3035 = sext i1 %3034 to i8
  %3036 = xor i8 %3035, -1
  %3037 = and i8 %3036, %3030
  %3038 = and i8 %3035, %3033
  %3039 = or i8 %3038, %3037
  %3040 = add i64 %3031, 64
  %3041 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3040
  %3042 = load i8, i8* %3041, align 1
  %3043 = icmp eq i64 %2958, %3040
  %3044 = sext i1 %3043 to i8
  %3045 = xor i8 %3044, -1
  %3046 = and i8 %3045, %3039
  %3047 = and i8 %3044, %3042
  %3048 = or i8 %3047, %3046
  %3049 = add i64 %3040, 64
  %3050 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3049
  %3051 = load i8, i8* %3050, align 1
  %3052 = icmp eq i64 %2958, %3049
  %3053 = sext i1 %3052 to i8
  %3054 = xor i8 %3053, -1
  %3055 = and i8 %3054, %3048
  %3056 = and i8 %3053, %3051
  %3057 = or i8 %3056, %3055
  %3058 = add i64 %3049, 64
  %3059 = icmp sge i64 %3058, 748
  %3060 = sext i1 %3059 to i64
  %3061 = xor i64 %3060, -1
  %3062 = and i64 %3060, 747
  %3063 = and i64 %3061, %3058
  %3064 = or i64 %3062, %3063
  %3065 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3064
  %3066 = load i8, i8* %3065, align 1
  %3067 = icmp eq i64 %2958, %3064
  %3068 = sext i1 %3067 to i8
  %3069 = xor i8 %3068, -1
  %3070 = and i8 %3069, %3057
  %3071 = and i8 %3068, %3066
  %Mitigated27 = or i8 %3071, %3070
  %3072 = zext i8 %Mitigated27 to i32
  %3073 = zext i8 %2524 to i32
  %3074 = xor i32 %3073, %3072
  %3075 = trunc i32 %3074 to i8
  %3076 = add i32 %2837, 91
  %3077 = zext i32 %3076 to i64
  %3078 = srem i64 %3077, 64
  %3079 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3078
  %3080 = load i8, i8* %3079, align 1
  %3081 = icmp eq i64 %3077, %3078
  %3082 = sext i1 %3081 to i8
  %3083 = xor i8 %3082, -1
  %3084 = and i8 %3083, 0
  %3085 = and i8 %3082, %3080
  %3086 = or i8 %3085, %3084
  %3087 = add i64 %3078, 64
  %3088 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3087
  %3089 = load i8, i8* %3088, align 1
  %3090 = icmp eq i64 %3077, %3087
  %3091 = sext i1 %3090 to i8
  %3092 = xor i8 %3091, -1
  %3093 = and i8 %3092, %3086
  %3094 = and i8 %3091, %3089
  %3095 = or i8 %3094, %3093
  %3096 = add i64 %3087, 64
  %3097 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3096
  %3098 = load i8, i8* %3097, align 1
  %3099 = icmp eq i64 %3077, %3096
  %3100 = sext i1 %3099 to i8
  %3101 = xor i8 %3100, -1
  %3102 = and i8 %3101, %3095
  %3103 = and i8 %3100, %3098
  %3104 = or i8 %3103, %3102
  %3105 = add i64 %3096, 64
  %3106 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3105
  %3107 = load i8, i8* %3106, align 1
  %3108 = icmp eq i64 %3077, %3105
  %3109 = sext i1 %3108 to i8
  %3110 = xor i8 %3109, -1
  %3111 = and i8 %3110, %3104
  %3112 = and i8 %3109, %3107
  %3113 = or i8 %3112, %3111
  %3114 = add i64 %3105, 64
  %3115 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3114
  %3116 = load i8, i8* %3115, align 1
  %3117 = icmp eq i64 %3077, %3114
  %3118 = sext i1 %3117 to i8
  %3119 = xor i8 %3118, -1
  %3120 = and i8 %3119, %3113
  %3121 = and i8 %3118, %3116
  %3122 = or i8 %3121, %3120
  %3123 = add i64 %3114, 64
  %3124 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3123
  %3125 = load i8, i8* %3124, align 1
  %3126 = icmp eq i64 %3077, %3123
  %3127 = sext i1 %3126 to i8
  %3128 = xor i8 %3127, -1
  %3129 = and i8 %3128, %3122
  %3130 = and i8 %3127, %3125
  %3131 = or i8 %3130, %3129
  %3132 = add i64 %3123, 64
  %3133 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3132
  %3134 = load i8, i8* %3133, align 1
  %3135 = icmp eq i64 %3077, %3132
  %3136 = sext i1 %3135 to i8
  %3137 = xor i8 %3136, -1
  %3138 = and i8 %3137, %3131
  %3139 = and i8 %3136, %3134
  %3140 = or i8 %3139, %3138
  %3141 = add i64 %3132, 64
  %3142 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3141
  %3143 = load i8, i8* %3142, align 1
  %3144 = icmp eq i64 %3077, %3141
  %3145 = sext i1 %3144 to i8
  %3146 = xor i8 %3145, -1
  %3147 = and i8 %3146, %3140
  %3148 = and i8 %3145, %3143
  %3149 = or i8 %3148, %3147
  %3150 = add i64 %3141, 64
  %3151 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3150
  %3152 = load i8, i8* %3151, align 1
  %3153 = icmp eq i64 %3077, %3150
  %3154 = sext i1 %3153 to i8
  %3155 = xor i8 %3154, -1
  %3156 = and i8 %3155, %3149
  %3157 = and i8 %3154, %3152
  %3158 = or i8 %3157, %3156
  %3159 = add i64 %3150, 64
  %3160 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3159
  %3161 = load i8, i8* %3160, align 1
  %3162 = icmp eq i64 %3077, %3159
  %3163 = sext i1 %3162 to i8
  %3164 = xor i8 %3163, -1
  %3165 = and i8 %3164, %3158
  %3166 = and i8 %3163, %3161
  %3167 = or i8 %3166, %3165
  %3168 = add i64 %3159, 64
  %3169 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3168
  %3170 = load i8, i8* %3169, align 1
  %3171 = icmp eq i64 %3077, %3168
  %3172 = sext i1 %3171 to i8
  %3173 = xor i8 %3172, -1
  %3174 = and i8 %3173, %3167
  %3175 = and i8 %3172, %3170
  %3176 = or i8 %3175, %3174
  %3177 = add i64 %3168, 64
  %3178 = icmp sge i64 %3177, 748
  %3179 = sext i1 %3178 to i64
  %3180 = xor i64 %3179, -1
  %3181 = and i64 %3179, 747
  %3182 = and i64 %3180, %3177
  %3183 = or i64 %3181, %3182
  %3184 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3183
  %3185 = load i8, i8* %3184, align 1
  %3186 = icmp eq i64 %3077, %3183
  %3187 = sext i1 %3186 to i8
  %3188 = xor i8 %3187, -1
  %3189 = and i8 %3188, %3176
  %3190 = and i8 %3187, %3185
  %Mitigated28 = or i8 %3190, %3189
  %3191 = zext i8 %Mitigated28 to i32
  %3192 = zext i8 %2643 to i32
  %3193 = xor i32 %3192, %3191
  %3194 = trunc i32 %3193 to i8
  %3195 = add i32 %2837, 237
  %3196 = zext i32 %3195 to i64
  %3197 = srem i64 %3196, 64
  %3198 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3197
  %3199 = load i8, i8* %3198, align 1
  %3200 = icmp eq i64 %3196, %3197
  %3201 = sext i1 %3200 to i8
  %3202 = xor i8 %3201, -1
  %3203 = and i8 %3202, 0
  %3204 = and i8 %3201, %3199
  %3205 = or i8 %3204, %3203
  %3206 = add i64 %3197, 64
  %3207 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3206
  %3208 = load i8, i8* %3207, align 1
  %3209 = icmp eq i64 %3196, %3206
  %3210 = sext i1 %3209 to i8
  %3211 = xor i8 %3210, -1
  %3212 = and i8 %3211, %3205
  %3213 = and i8 %3210, %3208
  %3214 = or i8 %3213, %3212
  %3215 = add i64 %3206, 64
  %3216 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3215
  %3217 = load i8, i8* %3216, align 1
  %3218 = icmp eq i64 %3196, %3215
  %3219 = sext i1 %3218 to i8
  %3220 = xor i8 %3219, -1
  %3221 = and i8 %3220, %3214
  %3222 = and i8 %3219, %3217
  %3223 = or i8 %3222, %3221
  %3224 = add i64 %3215, 64
  %3225 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3224
  %3226 = load i8, i8* %3225, align 1
  %3227 = icmp eq i64 %3196, %3224
  %3228 = sext i1 %3227 to i8
  %3229 = xor i8 %3228, -1
  %3230 = and i8 %3229, %3223
  %3231 = and i8 %3228, %3226
  %3232 = or i8 %3231, %3230
  %3233 = add i64 %3224, 64
  %3234 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3233
  %3235 = load i8, i8* %3234, align 1
  %3236 = icmp eq i64 %3196, %3233
  %3237 = sext i1 %3236 to i8
  %3238 = xor i8 %3237, -1
  %3239 = and i8 %3238, %3232
  %3240 = and i8 %3237, %3235
  %3241 = or i8 %3240, %3239
  %3242 = add i64 %3233, 64
  %3243 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3242
  %3244 = load i8, i8* %3243, align 1
  %3245 = icmp eq i64 %3196, %3242
  %3246 = sext i1 %3245 to i8
  %3247 = xor i8 %3246, -1
  %3248 = and i8 %3247, %3241
  %3249 = and i8 %3246, %3244
  %3250 = or i8 %3249, %3248
  %3251 = add i64 %3242, 64
  %3252 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3251
  %3253 = load i8, i8* %3252, align 1
  %3254 = icmp eq i64 %3196, %3251
  %3255 = sext i1 %3254 to i8
  %3256 = xor i8 %3255, -1
  %3257 = and i8 %3256, %3250
  %3258 = and i8 %3255, %3253
  %3259 = or i8 %3258, %3257
  %3260 = add i64 %3251, 64
  %3261 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3260
  %3262 = load i8, i8* %3261, align 1
  %3263 = icmp eq i64 %3196, %3260
  %3264 = sext i1 %3263 to i8
  %3265 = xor i8 %3264, -1
  %3266 = and i8 %3265, %3259
  %3267 = and i8 %3264, %3262
  %3268 = or i8 %3267, %3266
  %3269 = add i64 %3260, 64
  %3270 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3269
  %3271 = load i8, i8* %3270, align 1
  %3272 = icmp eq i64 %3196, %3269
  %3273 = sext i1 %3272 to i8
  %3274 = xor i8 %3273, -1
  %3275 = and i8 %3274, %3268
  %3276 = and i8 %3273, %3271
  %3277 = or i8 %3276, %3275
  %3278 = add i64 %3269, 64
  %3279 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3278
  %3280 = load i8, i8* %3279, align 1
  %3281 = icmp eq i64 %3196, %3278
  %3282 = sext i1 %3281 to i8
  %3283 = xor i8 %3282, -1
  %3284 = and i8 %3283, %3277
  %3285 = and i8 %3282, %3280
  %3286 = or i8 %3285, %3284
  %3287 = add i64 %3278, 64
  %3288 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3287
  %3289 = load i8, i8* %3288, align 1
  %3290 = icmp eq i64 %3196, %3287
  %3291 = sext i1 %3290 to i8
  %3292 = xor i8 %3291, -1
  %3293 = and i8 %3292, %3286
  %3294 = and i8 %3291, %3289
  %3295 = or i8 %3294, %3293
  %3296 = add i64 %3287, 64
  %3297 = icmp sge i64 %3296, 748
  %3298 = sext i1 %3297 to i64
  %3299 = xor i64 %3298, -1
  %3300 = and i64 %3298, 747
  %3301 = and i64 %3299, %3296
  %3302 = or i64 %3300, %3301
  %3303 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3302
  %3304 = load i8, i8* %3303, align 1
  %3305 = icmp eq i64 %3196, %3302
  %3306 = sext i1 %3305 to i8
  %3307 = xor i8 %3306, -1
  %3308 = and i8 %3307, %3295
  %3309 = and i8 %3306, %3304
  %Mitigated29 = or i8 %3309, %3308
  %3310 = zext i8 %Mitigated29 to i32
  %3311 = zext i8 %2762 to i32
  %3312 = xor i32 %3311, %3310
  %3313 = trunc i32 %3312 to i8
  %3314 = getelementptr inbounds i8, i8* %0, i64 6
  %3315 = load i8, i8* %3314, align 1
  %3316 = zext i8 %3315 to i64
  %3317 = srem i64 %3316, 32
  %3318 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3317
  %3319 = load i16, i16* %3318, align 2
  %3320 = icmp eq i64 %3316, %3317
  %3321 = sext i1 %3320 to i16
  %3322 = xor i16 %3321, -1
  %3323 = and i16 %3322, 0
  %3324 = and i16 %3321, %3319
  %3325 = or i16 %3324, %3323
  %3326 = add i64 %3317, 32
  %3327 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3326
  %3328 = load i16, i16* %3327, align 2
  %3329 = icmp eq i64 %3316, %3326
  %3330 = sext i1 %3329 to i16
  %3331 = xor i16 %3330, -1
  %3332 = and i16 %3331, %3325
  %3333 = and i16 %3330, %3328
  %3334 = or i16 %3333, %3332
  %3335 = add i64 %3326, 32
  %3336 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3335
  %3337 = load i16, i16* %3336, align 2
  %3338 = icmp eq i64 %3316, %3335
  %3339 = sext i1 %3338 to i16
  %3340 = xor i16 %3339, -1
  %3341 = and i16 %3340, %3334
  %3342 = and i16 %3339, %3337
  %3343 = or i16 %3342, %3341
  %3344 = add i64 %3335, 32
  %3345 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3344
  %3346 = load i16, i16* %3345, align 2
  %3347 = icmp eq i64 %3316, %3344
  %3348 = sext i1 %3347 to i16
  %3349 = xor i16 %3348, -1
  %3350 = and i16 %3349, %3343
  %3351 = and i16 %3348, %3346
  %3352 = or i16 %3351, %3350
  %3353 = add i64 %3344, 32
  %3354 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3353
  %3355 = load i16, i16* %3354, align 2
  %3356 = icmp eq i64 %3316, %3353
  %3357 = sext i1 %3356 to i16
  %3358 = xor i16 %3357, -1
  %3359 = and i16 %3358, %3352
  %3360 = and i16 %3357, %3355
  %3361 = or i16 %3360, %3359
  %3362 = add i64 %3353, 32
  %3363 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3362
  %3364 = load i16, i16* %3363, align 2
  %3365 = icmp eq i64 %3316, %3362
  %3366 = sext i1 %3365 to i16
  %3367 = xor i16 %3366, -1
  %3368 = and i16 %3367, %3361
  %3369 = and i16 %3366, %3364
  %3370 = or i16 %3369, %3368
  %3371 = add i64 %3362, 32
  %3372 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3371
  %3373 = load i16, i16* %3372, align 2
  %3374 = icmp eq i64 %3316, %3371
  %3375 = sext i1 %3374 to i16
  %3376 = xor i16 %3375, -1
  %3377 = and i16 %3376, %3370
  %3378 = and i16 %3375, %3373
  %3379 = or i16 %3378, %3377
  %3380 = add i64 %3371, 32
  %3381 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3380
  %3382 = load i16, i16* %3381, align 2
  %3383 = icmp eq i64 %3316, %3380
  %3384 = sext i1 %3383 to i16
  %3385 = xor i16 %3384, -1
  %3386 = and i16 %3385, %3379
  %3387 = and i16 %3384, %3382
  %Mitigated30 = or i16 %3387, %3386
  %3388 = zext i16 %Mitigated30 to i32
  %3389 = add i32 %3388, 237
  %3390 = zext i32 %3389 to i64
  %3391 = srem i64 %3390, 64
  %3392 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3391
  %3393 = load i8, i8* %3392, align 1
  %3394 = icmp eq i64 %3390, %3391
  %3395 = sext i1 %3394 to i8
  %3396 = xor i8 %3395, -1
  %3397 = and i8 %3396, 0
  %3398 = and i8 %3395, %3393
  %3399 = or i8 %3398, %3397
  %3400 = add i64 %3391, 64
  %3401 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3400
  %3402 = load i8, i8* %3401, align 1
  %3403 = icmp eq i64 %3390, %3400
  %3404 = sext i1 %3403 to i8
  %3405 = xor i8 %3404, -1
  %3406 = and i8 %3405, %3399
  %3407 = and i8 %3404, %3402
  %3408 = or i8 %3407, %3406
  %3409 = add i64 %3400, 64
  %3410 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3409
  %3411 = load i8, i8* %3410, align 1
  %3412 = icmp eq i64 %3390, %3409
  %3413 = sext i1 %3412 to i8
  %3414 = xor i8 %3413, -1
  %3415 = and i8 %3414, %3408
  %3416 = and i8 %3413, %3411
  %3417 = or i8 %3416, %3415
  %3418 = add i64 %3409, 64
  %3419 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3418
  %3420 = load i8, i8* %3419, align 1
  %3421 = icmp eq i64 %3390, %3418
  %3422 = sext i1 %3421 to i8
  %3423 = xor i8 %3422, -1
  %3424 = and i8 %3423, %3417
  %3425 = and i8 %3422, %3420
  %3426 = or i8 %3425, %3424
  %3427 = add i64 %3418, 64
  %3428 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3427
  %3429 = load i8, i8* %3428, align 1
  %3430 = icmp eq i64 %3390, %3427
  %3431 = sext i1 %3430 to i8
  %3432 = xor i8 %3431, -1
  %3433 = and i8 %3432, %3426
  %3434 = and i8 %3431, %3429
  %3435 = or i8 %3434, %3433
  %3436 = add i64 %3427, 64
  %3437 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3436
  %3438 = load i8, i8* %3437, align 1
  %3439 = icmp eq i64 %3390, %3436
  %3440 = sext i1 %3439 to i8
  %3441 = xor i8 %3440, -1
  %3442 = and i8 %3441, %3435
  %3443 = and i8 %3440, %3438
  %3444 = or i8 %3443, %3442
  %3445 = add i64 %3436, 64
  %3446 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3445
  %3447 = load i8, i8* %3446, align 1
  %3448 = icmp eq i64 %3390, %3445
  %3449 = sext i1 %3448 to i8
  %3450 = xor i8 %3449, -1
  %3451 = and i8 %3450, %3444
  %3452 = and i8 %3449, %3447
  %3453 = or i8 %3452, %3451
  %3454 = add i64 %3445, 64
  %3455 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3454
  %3456 = load i8, i8* %3455, align 1
  %3457 = icmp eq i64 %3390, %3454
  %3458 = sext i1 %3457 to i8
  %3459 = xor i8 %3458, -1
  %3460 = and i8 %3459, %3453
  %3461 = and i8 %3458, %3456
  %3462 = or i8 %3461, %3460
  %3463 = add i64 %3454, 64
  %3464 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3463
  %3465 = load i8, i8* %3464, align 1
  %3466 = icmp eq i64 %3390, %3463
  %3467 = sext i1 %3466 to i8
  %3468 = xor i8 %3467, -1
  %3469 = and i8 %3468, %3462
  %3470 = and i8 %3467, %3465
  %3471 = or i8 %3470, %3469
  %3472 = add i64 %3463, 64
  %3473 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3472
  %3474 = load i8, i8* %3473, align 1
  %3475 = icmp eq i64 %3390, %3472
  %3476 = sext i1 %3475 to i8
  %3477 = xor i8 %3476, -1
  %3478 = and i8 %3477, %3471
  %3479 = and i8 %3476, %3474
  %3480 = or i8 %3479, %3478
  %3481 = add i64 %3472, 64
  %3482 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3481
  %3483 = load i8, i8* %3482, align 1
  %3484 = icmp eq i64 %3390, %3481
  %3485 = sext i1 %3484 to i8
  %3486 = xor i8 %3485, -1
  %3487 = and i8 %3486, %3480
  %3488 = and i8 %3485, %3483
  %3489 = or i8 %3488, %3487
  %3490 = add i64 %3481, 64
  %3491 = icmp sge i64 %3490, 748
  %3492 = sext i1 %3491 to i64
  %3493 = xor i64 %3492, -1
  %3494 = and i64 %3492, 747
  %3495 = and i64 %3493, %3490
  %3496 = or i64 %3494, %3495
  %3497 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3496
  %3498 = load i8, i8* %3497, align 1
  %3499 = icmp eq i64 %3390, %3496
  %3500 = sext i1 %3499 to i8
  %3501 = xor i8 %3500, -1
  %3502 = and i8 %3501, %3489
  %3503 = and i8 %3500, %3498
  %Mitigated31 = or i8 %3503, %3502
  %3504 = zext i8 %Mitigated31 to i32
  %3505 = zext i8 %2956 to i32
  %3506 = xor i32 %3505, %3504
  %3507 = trunc i32 %3506 to i8
  %3508 = add i32 %3388, 55
  %3509 = zext i32 %3508 to i64
  %3510 = srem i64 %3509, 64
  %3511 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3510
  %3512 = load i8, i8* %3511, align 1
  %3513 = icmp eq i64 %3509, %3510
  %3514 = sext i1 %3513 to i8
  %3515 = xor i8 %3514, -1
  %3516 = and i8 %3515, 0
  %3517 = and i8 %3514, %3512
  %3518 = or i8 %3517, %3516
  %3519 = add i64 %3510, 64
  %3520 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3519
  %3521 = load i8, i8* %3520, align 1
  %3522 = icmp eq i64 %3509, %3519
  %3523 = sext i1 %3522 to i8
  %3524 = xor i8 %3523, -1
  %3525 = and i8 %3524, %3518
  %3526 = and i8 %3523, %3521
  %3527 = or i8 %3526, %3525
  %3528 = add i64 %3519, 64
  %3529 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3528
  %3530 = load i8, i8* %3529, align 1
  %3531 = icmp eq i64 %3509, %3528
  %3532 = sext i1 %3531 to i8
  %3533 = xor i8 %3532, -1
  %3534 = and i8 %3533, %3527
  %3535 = and i8 %3532, %3530
  %3536 = or i8 %3535, %3534
  %3537 = add i64 %3528, 64
  %3538 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3537
  %3539 = load i8, i8* %3538, align 1
  %3540 = icmp eq i64 %3509, %3537
  %3541 = sext i1 %3540 to i8
  %3542 = xor i8 %3541, -1
  %3543 = and i8 %3542, %3536
  %3544 = and i8 %3541, %3539
  %3545 = or i8 %3544, %3543
  %3546 = add i64 %3537, 64
  %3547 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3546
  %3548 = load i8, i8* %3547, align 1
  %3549 = icmp eq i64 %3509, %3546
  %3550 = sext i1 %3549 to i8
  %3551 = xor i8 %3550, -1
  %3552 = and i8 %3551, %3545
  %3553 = and i8 %3550, %3548
  %3554 = or i8 %3553, %3552
  %3555 = add i64 %3546, 64
  %3556 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3555
  %3557 = load i8, i8* %3556, align 1
  %3558 = icmp eq i64 %3509, %3555
  %3559 = sext i1 %3558 to i8
  %3560 = xor i8 %3559, -1
  %3561 = and i8 %3560, %3554
  %3562 = and i8 %3559, %3557
  %3563 = or i8 %3562, %3561
  %3564 = add i64 %3555, 64
  %3565 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3564
  %3566 = load i8, i8* %3565, align 1
  %3567 = icmp eq i64 %3509, %3564
  %3568 = sext i1 %3567 to i8
  %3569 = xor i8 %3568, -1
  %3570 = and i8 %3569, %3563
  %3571 = and i8 %3568, %3566
  %3572 = or i8 %3571, %3570
  %3573 = add i64 %3564, 64
  %3574 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3573
  %3575 = load i8, i8* %3574, align 1
  %3576 = icmp eq i64 %3509, %3573
  %3577 = sext i1 %3576 to i8
  %3578 = xor i8 %3577, -1
  %3579 = and i8 %3578, %3572
  %3580 = and i8 %3577, %3575
  %3581 = or i8 %3580, %3579
  %3582 = add i64 %3573, 64
  %3583 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3582
  %3584 = load i8, i8* %3583, align 1
  %3585 = icmp eq i64 %3509, %3582
  %3586 = sext i1 %3585 to i8
  %3587 = xor i8 %3586, -1
  %3588 = and i8 %3587, %3581
  %3589 = and i8 %3586, %3584
  %3590 = or i8 %3589, %3588
  %3591 = add i64 %3582, 64
  %3592 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3591
  %3593 = load i8, i8* %3592, align 1
  %3594 = icmp eq i64 %3509, %3591
  %3595 = sext i1 %3594 to i8
  %3596 = xor i8 %3595, -1
  %3597 = and i8 %3596, %3590
  %3598 = and i8 %3595, %3593
  %3599 = or i8 %3598, %3597
  %3600 = add i64 %3591, 64
  %3601 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3600
  %3602 = load i8, i8* %3601, align 1
  %3603 = icmp eq i64 %3509, %3600
  %3604 = sext i1 %3603 to i8
  %3605 = xor i8 %3604, -1
  %3606 = and i8 %3605, %3599
  %3607 = and i8 %3604, %3602
  %3608 = or i8 %3607, %3606
  %3609 = add i64 %3600, 64
  %3610 = icmp sge i64 %3609, 748
  %3611 = sext i1 %3610 to i64
  %3612 = xor i64 %3611, -1
  %3613 = and i64 %3611, 747
  %3614 = and i64 %3612, %3609
  %3615 = or i64 %3613, %3614
  %3616 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3615
  %3617 = load i8, i8* %3616, align 1
  %3618 = icmp eq i64 %3509, %3615
  %3619 = sext i1 %3618 to i8
  %3620 = xor i8 %3619, -1
  %3621 = and i8 %3620, %3608
  %3622 = and i8 %3619, %3617
  %Mitigated32 = or i8 %3622, %3621
  %3623 = zext i8 %Mitigated32 to i32
  %3624 = zext i8 %3075 to i32
  %3625 = xor i32 %3624, %3623
  %3626 = trunc i32 %3625 to i8
  %3627 = add i32 %3388, 79
  %3628 = zext i32 %3627 to i64
  %3629 = srem i64 %3628, 64
  %3630 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3629
  %3631 = load i8, i8* %3630, align 1
  %3632 = icmp eq i64 %3628, %3629
  %3633 = sext i1 %3632 to i8
  %3634 = xor i8 %3633, -1
  %3635 = and i8 %3634, 0
  %3636 = and i8 %3633, %3631
  %3637 = or i8 %3636, %3635
  %3638 = add i64 %3629, 64
  %3639 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3638
  %3640 = load i8, i8* %3639, align 1
  %3641 = icmp eq i64 %3628, %3638
  %3642 = sext i1 %3641 to i8
  %3643 = xor i8 %3642, -1
  %3644 = and i8 %3643, %3637
  %3645 = and i8 %3642, %3640
  %3646 = or i8 %3645, %3644
  %3647 = add i64 %3638, 64
  %3648 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3647
  %3649 = load i8, i8* %3648, align 1
  %3650 = icmp eq i64 %3628, %3647
  %3651 = sext i1 %3650 to i8
  %3652 = xor i8 %3651, -1
  %3653 = and i8 %3652, %3646
  %3654 = and i8 %3651, %3649
  %3655 = or i8 %3654, %3653
  %3656 = add i64 %3647, 64
  %3657 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3656
  %3658 = load i8, i8* %3657, align 1
  %3659 = icmp eq i64 %3628, %3656
  %3660 = sext i1 %3659 to i8
  %3661 = xor i8 %3660, -1
  %3662 = and i8 %3661, %3655
  %3663 = and i8 %3660, %3658
  %3664 = or i8 %3663, %3662
  %3665 = add i64 %3656, 64
  %3666 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3665
  %3667 = load i8, i8* %3666, align 1
  %3668 = icmp eq i64 %3628, %3665
  %3669 = sext i1 %3668 to i8
  %3670 = xor i8 %3669, -1
  %3671 = and i8 %3670, %3664
  %3672 = and i8 %3669, %3667
  %3673 = or i8 %3672, %3671
  %3674 = add i64 %3665, 64
  %3675 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3674
  %3676 = load i8, i8* %3675, align 1
  %3677 = icmp eq i64 %3628, %3674
  %3678 = sext i1 %3677 to i8
  %3679 = xor i8 %3678, -1
  %3680 = and i8 %3679, %3673
  %3681 = and i8 %3678, %3676
  %3682 = or i8 %3681, %3680
  %3683 = add i64 %3674, 64
  %3684 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3683
  %3685 = load i8, i8* %3684, align 1
  %3686 = icmp eq i64 %3628, %3683
  %3687 = sext i1 %3686 to i8
  %3688 = xor i8 %3687, -1
  %3689 = and i8 %3688, %3682
  %3690 = and i8 %3687, %3685
  %3691 = or i8 %3690, %3689
  %3692 = add i64 %3683, 64
  %3693 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3692
  %3694 = load i8, i8* %3693, align 1
  %3695 = icmp eq i64 %3628, %3692
  %3696 = sext i1 %3695 to i8
  %3697 = xor i8 %3696, -1
  %3698 = and i8 %3697, %3691
  %3699 = and i8 %3696, %3694
  %3700 = or i8 %3699, %3698
  %3701 = add i64 %3692, 64
  %3702 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3701
  %3703 = load i8, i8* %3702, align 1
  %3704 = icmp eq i64 %3628, %3701
  %3705 = sext i1 %3704 to i8
  %3706 = xor i8 %3705, -1
  %3707 = and i8 %3706, %3700
  %3708 = and i8 %3705, %3703
  %3709 = or i8 %3708, %3707
  %3710 = add i64 %3701, 64
  %3711 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3710
  %3712 = load i8, i8* %3711, align 1
  %3713 = icmp eq i64 %3628, %3710
  %3714 = sext i1 %3713 to i8
  %3715 = xor i8 %3714, -1
  %3716 = and i8 %3715, %3709
  %3717 = and i8 %3714, %3712
  %3718 = or i8 %3717, %3716
  %3719 = add i64 %3710, 64
  %3720 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3719
  %3721 = load i8, i8* %3720, align 1
  %3722 = icmp eq i64 %3628, %3719
  %3723 = sext i1 %3722 to i8
  %3724 = xor i8 %3723, -1
  %3725 = and i8 %3724, %3718
  %3726 = and i8 %3723, %3721
  %3727 = or i8 %3726, %3725
  %3728 = add i64 %3719, 64
  %3729 = icmp sge i64 %3728, 748
  %3730 = sext i1 %3729 to i64
  %3731 = xor i64 %3730, -1
  %3732 = and i64 %3730, 747
  %3733 = and i64 %3731, %3728
  %3734 = or i64 %3732, %3733
  %3735 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3734
  %3736 = load i8, i8* %3735, align 1
  %3737 = icmp eq i64 %3628, %3734
  %3738 = sext i1 %3737 to i8
  %3739 = xor i8 %3738, -1
  %3740 = and i8 %3739, %3727
  %3741 = and i8 %3738, %3736
  %Mitigated33 = or i8 %3741, %3740
  %3742 = zext i8 %Mitigated33 to i32
  %3743 = zext i8 %3194 to i32
  %3744 = xor i32 %3743, %3742
  %3745 = trunc i32 %3744 to i8
  %3746 = add i32 %3388, 224
  %3747 = zext i32 %3746 to i64
  %3748 = srem i64 %3747, 64
  %3749 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3748
  %3750 = load i8, i8* %3749, align 1
  %3751 = icmp eq i64 %3747, %3748
  %3752 = sext i1 %3751 to i8
  %3753 = xor i8 %3752, -1
  %3754 = and i8 %3753, 0
  %3755 = and i8 %3752, %3750
  %3756 = or i8 %3755, %3754
  %3757 = add i64 %3748, 64
  %3758 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3757
  %3759 = load i8, i8* %3758, align 1
  %3760 = icmp eq i64 %3747, %3757
  %3761 = sext i1 %3760 to i8
  %3762 = xor i8 %3761, -1
  %3763 = and i8 %3762, %3756
  %3764 = and i8 %3761, %3759
  %3765 = or i8 %3764, %3763
  %3766 = add i64 %3757, 64
  %3767 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3766
  %3768 = load i8, i8* %3767, align 1
  %3769 = icmp eq i64 %3747, %3766
  %3770 = sext i1 %3769 to i8
  %3771 = xor i8 %3770, -1
  %3772 = and i8 %3771, %3765
  %3773 = and i8 %3770, %3768
  %3774 = or i8 %3773, %3772
  %3775 = add i64 %3766, 64
  %3776 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3775
  %3777 = load i8, i8* %3776, align 1
  %3778 = icmp eq i64 %3747, %3775
  %3779 = sext i1 %3778 to i8
  %3780 = xor i8 %3779, -1
  %3781 = and i8 %3780, %3774
  %3782 = and i8 %3779, %3777
  %3783 = or i8 %3782, %3781
  %3784 = add i64 %3775, 64
  %3785 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3784
  %3786 = load i8, i8* %3785, align 1
  %3787 = icmp eq i64 %3747, %3784
  %3788 = sext i1 %3787 to i8
  %3789 = xor i8 %3788, -1
  %3790 = and i8 %3789, %3783
  %3791 = and i8 %3788, %3786
  %3792 = or i8 %3791, %3790
  %3793 = add i64 %3784, 64
  %3794 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3793
  %3795 = load i8, i8* %3794, align 1
  %3796 = icmp eq i64 %3747, %3793
  %3797 = sext i1 %3796 to i8
  %3798 = xor i8 %3797, -1
  %3799 = and i8 %3798, %3792
  %3800 = and i8 %3797, %3795
  %3801 = or i8 %3800, %3799
  %3802 = add i64 %3793, 64
  %3803 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3802
  %3804 = load i8, i8* %3803, align 1
  %3805 = icmp eq i64 %3747, %3802
  %3806 = sext i1 %3805 to i8
  %3807 = xor i8 %3806, -1
  %3808 = and i8 %3807, %3801
  %3809 = and i8 %3806, %3804
  %3810 = or i8 %3809, %3808
  %3811 = add i64 %3802, 64
  %3812 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3811
  %3813 = load i8, i8* %3812, align 1
  %3814 = icmp eq i64 %3747, %3811
  %3815 = sext i1 %3814 to i8
  %3816 = xor i8 %3815, -1
  %3817 = and i8 %3816, %3810
  %3818 = and i8 %3815, %3813
  %3819 = or i8 %3818, %3817
  %3820 = add i64 %3811, 64
  %3821 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3820
  %3822 = load i8, i8* %3821, align 1
  %3823 = icmp eq i64 %3747, %3820
  %3824 = sext i1 %3823 to i8
  %3825 = xor i8 %3824, -1
  %3826 = and i8 %3825, %3819
  %3827 = and i8 %3824, %3822
  %3828 = or i8 %3827, %3826
  %3829 = add i64 %3820, 64
  %3830 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3829
  %3831 = load i8, i8* %3830, align 1
  %3832 = icmp eq i64 %3747, %3829
  %3833 = sext i1 %3832 to i8
  %3834 = xor i8 %3833, -1
  %3835 = and i8 %3834, %3828
  %3836 = and i8 %3833, %3831
  %3837 = or i8 %3836, %3835
  %3838 = add i64 %3829, 64
  %3839 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3838
  %3840 = load i8, i8* %3839, align 1
  %3841 = icmp eq i64 %3747, %3838
  %3842 = sext i1 %3841 to i8
  %3843 = xor i8 %3842, -1
  %3844 = and i8 %3843, %3837
  %3845 = and i8 %3842, %3840
  %3846 = or i8 %3845, %3844
  %3847 = add i64 %3838, 64
  %3848 = icmp sge i64 %3847, 748
  %3849 = sext i1 %3848 to i64
  %3850 = xor i64 %3849, -1
  %3851 = and i64 %3849, 747
  %3852 = and i64 %3850, %3847
  %3853 = or i64 %3851, %3852
  %3854 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3853
  %3855 = load i8, i8* %3854, align 1
  %3856 = icmp eq i64 %3747, %3853
  %3857 = sext i1 %3856 to i8
  %3858 = xor i8 %3857, -1
  %3859 = and i8 %3858, %3846
  %3860 = and i8 %3857, %3855
  %Mitigated34 = or i8 %3860, %3859
  %3861 = zext i8 %Mitigated34 to i32
  %3862 = zext i8 %3313 to i32
  %3863 = xor i32 %3862, %3861
  %3864 = trunc i32 %3863 to i8
  %3865 = getelementptr inbounds i8, i8* %0, i64 7
  %3866 = load i8, i8* %3865, align 1
  %3867 = zext i8 %3866 to i64
  %3868 = srem i64 %3867, 32
  %3869 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3868
  %3870 = load i16, i16* %3869, align 2
  %3871 = icmp eq i64 %3867, %3868
  %3872 = sext i1 %3871 to i16
  %3873 = xor i16 %3872, -1
  %3874 = and i16 %3873, 0
  %3875 = and i16 %3872, %3870
  %3876 = or i16 %3875, %3874
  %3877 = add i64 %3868, 32
  %3878 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3877
  %3879 = load i16, i16* %3878, align 2
  %3880 = icmp eq i64 %3867, %3877
  %3881 = sext i1 %3880 to i16
  %3882 = xor i16 %3881, -1
  %3883 = and i16 %3882, %3876
  %3884 = and i16 %3881, %3879
  %3885 = or i16 %3884, %3883
  %3886 = add i64 %3877, 32
  %3887 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3886
  %3888 = load i16, i16* %3887, align 2
  %3889 = icmp eq i64 %3867, %3886
  %3890 = sext i1 %3889 to i16
  %3891 = xor i16 %3890, -1
  %3892 = and i16 %3891, %3885
  %3893 = and i16 %3890, %3888
  %3894 = or i16 %3893, %3892
  %3895 = add i64 %3886, 32
  %3896 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3895
  %3897 = load i16, i16* %3896, align 2
  %3898 = icmp eq i64 %3867, %3895
  %3899 = sext i1 %3898 to i16
  %3900 = xor i16 %3899, -1
  %3901 = and i16 %3900, %3894
  %3902 = and i16 %3899, %3897
  %3903 = or i16 %3902, %3901
  %3904 = add i64 %3895, 32
  %3905 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3904
  %3906 = load i16, i16* %3905, align 2
  %3907 = icmp eq i64 %3867, %3904
  %3908 = sext i1 %3907 to i16
  %3909 = xor i16 %3908, -1
  %3910 = and i16 %3909, %3903
  %3911 = and i16 %3908, %3906
  %3912 = or i16 %3911, %3910
  %3913 = add i64 %3904, 32
  %3914 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3913
  %3915 = load i16, i16* %3914, align 2
  %3916 = icmp eq i64 %3867, %3913
  %3917 = sext i1 %3916 to i16
  %3918 = xor i16 %3917, -1
  %3919 = and i16 %3918, %3912
  %3920 = and i16 %3917, %3915
  %3921 = or i16 %3920, %3919
  %3922 = add i64 %3913, 32
  %3923 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3922
  %3924 = load i16, i16* %3923, align 2
  %3925 = icmp eq i64 %3867, %3922
  %3926 = sext i1 %3925 to i16
  %3927 = xor i16 %3926, -1
  %3928 = and i16 %3927, %3921
  %3929 = and i16 %3926, %3924
  %3930 = or i16 %3929, %3928
  %3931 = add i64 %3922, 32
  %3932 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %3931
  %3933 = load i16, i16* %3932, align 2
  %3934 = icmp eq i64 %3867, %3931
  %3935 = sext i1 %3934 to i16
  %3936 = xor i16 %3935, -1
  %3937 = and i16 %3936, %3930
  %3938 = and i16 %3935, %3933
  %Mitigated35 = or i16 %3938, %3937
  %3939 = zext i16 %Mitigated35 to i32
  %3940 = add i32 %3939, 224
  %3941 = zext i32 %3940 to i64
  %3942 = srem i64 %3941, 64
  %3943 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3942
  %3944 = load i8, i8* %3943, align 1
  %3945 = icmp eq i64 %3941, %3942
  %3946 = sext i1 %3945 to i8
  %3947 = xor i8 %3946, -1
  %3948 = and i8 %3947, 0
  %3949 = and i8 %3946, %3944
  %3950 = or i8 %3949, %3948
  %3951 = add i64 %3942, 64
  %3952 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3951
  %3953 = load i8, i8* %3952, align 1
  %3954 = icmp eq i64 %3941, %3951
  %3955 = sext i1 %3954 to i8
  %3956 = xor i8 %3955, -1
  %3957 = and i8 %3956, %3950
  %3958 = and i8 %3955, %3953
  %3959 = or i8 %3958, %3957
  %3960 = add i64 %3951, 64
  %3961 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3960
  %3962 = load i8, i8* %3961, align 1
  %3963 = icmp eq i64 %3941, %3960
  %3964 = sext i1 %3963 to i8
  %3965 = xor i8 %3964, -1
  %3966 = and i8 %3965, %3959
  %3967 = and i8 %3964, %3962
  %3968 = or i8 %3967, %3966
  %3969 = add i64 %3960, 64
  %3970 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3969
  %3971 = load i8, i8* %3970, align 1
  %3972 = icmp eq i64 %3941, %3969
  %3973 = sext i1 %3972 to i8
  %3974 = xor i8 %3973, -1
  %3975 = and i8 %3974, %3968
  %3976 = and i8 %3973, %3971
  %3977 = or i8 %3976, %3975
  %3978 = add i64 %3969, 64
  %3979 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3978
  %3980 = load i8, i8* %3979, align 1
  %3981 = icmp eq i64 %3941, %3978
  %3982 = sext i1 %3981 to i8
  %3983 = xor i8 %3982, -1
  %3984 = and i8 %3983, %3977
  %3985 = and i8 %3982, %3980
  %3986 = or i8 %3985, %3984
  %3987 = add i64 %3978, 64
  %3988 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3987
  %3989 = load i8, i8* %3988, align 1
  %3990 = icmp eq i64 %3941, %3987
  %3991 = sext i1 %3990 to i8
  %3992 = xor i8 %3991, -1
  %3993 = and i8 %3992, %3986
  %3994 = and i8 %3991, %3989
  %3995 = or i8 %3994, %3993
  %3996 = add i64 %3987, 64
  %3997 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %3996
  %3998 = load i8, i8* %3997, align 1
  %3999 = icmp eq i64 %3941, %3996
  %4000 = sext i1 %3999 to i8
  %4001 = xor i8 %4000, -1
  %4002 = and i8 %4001, %3995
  %4003 = and i8 %4000, %3998
  %4004 = or i8 %4003, %4002
  %4005 = add i64 %3996, 64
  %4006 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4005
  %4007 = load i8, i8* %4006, align 1
  %4008 = icmp eq i64 %3941, %4005
  %4009 = sext i1 %4008 to i8
  %4010 = xor i8 %4009, -1
  %4011 = and i8 %4010, %4004
  %4012 = and i8 %4009, %4007
  %4013 = or i8 %4012, %4011
  %4014 = add i64 %4005, 64
  %4015 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4014
  %4016 = load i8, i8* %4015, align 1
  %4017 = icmp eq i64 %3941, %4014
  %4018 = sext i1 %4017 to i8
  %4019 = xor i8 %4018, -1
  %4020 = and i8 %4019, %4013
  %4021 = and i8 %4018, %4016
  %4022 = or i8 %4021, %4020
  %4023 = add i64 %4014, 64
  %4024 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4023
  %4025 = load i8, i8* %4024, align 1
  %4026 = icmp eq i64 %3941, %4023
  %4027 = sext i1 %4026 to i8
  %4028 = xor i8 %4027, -1
  %4029 = and i8 %4028, %4022
  %4030 = and i8 %4027, %4025
  %4031 = or i8 %4030, %4029
  %4032 = add i64 %4023, 64
  %4033 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4032
  %4034 = load i8, i8* %4033, align 1
  %4035 = icmp eq i64 %3941, %4032
  %4036 = sext i1 %4035 to i8
  %4037 = xor i8 %4036, -1
  %4038 = and i8 %4037, %4031
  %4039 = and i8 %4036, %4034
  %4040 = or i8 %4039, %4038
  %4041 = add i64 %4032, 64
  %4042 = icmp sge i64 %4041, 748
  %4043 = sext i1 %4042 to i64
  %4044 = xor i64 %4043, -1
  %4045 = and i64 %4043, 747
  %4046 = and i64 %4044, %4041
  %4047 = or i64 %4045, %4046
  %4048 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4047
  %4049 = load i8, i8* %4048, align 1
  %4050 = icmp eq i64 %3941, %4047
  %4051 = sext i1 %4050 to i8
  %4052 = xor i8 %4051, -1
  %4053 = and i8 %4052, %4040
  %4054 = and i8 %4051, %4049
  %Mitigated36 = or i8 %4054, %4053
  %4055 = zext i8 %Mitigated36 to i32
  %4056 = zext i8 %3507 to i32
  %4057 = xor i32 %4056, %4055
  %4058 = trunc i32 %4057 to i8
  %4059 = add i32 %3939, 208
  %4060 = zext i32 %4059 to i64
  %4061 = srem i64 %4060, 64
  %4062 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4061
  %4063 = load i8, i8* %4062, align 1
  %4064 = icmp eq i64 %4060, %4061
  %4065 = sext i1 %4064 to i8
  %4066 = xor i8 %4065, -1
  %4067 = and i8 %4066, 0
  %4068 = and i8 %4065, %4063
  %4069 = or i8 %4068, %4067
  %4070 = add i64 %4061, 64
  %4071 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4070
  %4072 = load i8, i8* %4071, align 1
  %4073 = icmp eq i64 %4060, %4070
  %4074 = sext i1 %4073 to i8
  %4075 = xor i8 %4074, -1
  %4076 = and i8 %4075, %4069
  %4077 = and i8 %4074, %4072
  %4078 = or i8 %4077, %4076
  %4079 = add i64 %4070, 64
  %4080 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4079
  %4081 = load i8, i8* %4080, align 1
  %4082 = icmp eq i64 %4060, %4079
  %4083 = sext i1 %4082 to i8
  %4084 = xor i8 %4083, -1
  %4085 = and i8 %4084, %4078
  %4086 = and i8 %4083, %4081
  %4087 = or i8 %4086, %4085
  %4088 = add i64 %4079, 64
  %4089 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4088
  %4090 = load i8, i8* %4089, align 1
  %4091 = icmp eq i64 %4060, %4088
  %4092 = sext i1 %4091 to i8
  %4093 = xor i8 %4092, -1
  %4094 = and i8 %4093, %4087
  %4095 = and i8 %4092, %4090
  %4096 = or i8 %4095, %4094
  %4097 = add i64 %4088, 64
  %4098 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4097
  %4099 = load i8, i8* %4098, align 1
  %4100 = icmp eq i64 %4060, %4097
  %4101 = sext i1 %4100 to i8
  %4102 = xor i8 %4101, -1
  %4103 = and i8 %4102, %4096
  %4104 = and i8 %4101, %4099
  %4105 = or i8 %4104, %4103
  %4106 = add i64 %4097, 64
  %4107 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4106
  %4108 = load i8, i8* %4107, align 1
  %4109 = icmp eq i64 %4060, %4106
  %4110 = sext i1 %4109 to i8
  %4111 = xor i8 %4110, -1
  %4112 = and i8 %4111, %4105
  %4113 = and i8 %4110, %4108
  %4114 = or i8 %4113, %4112
  %4115 = add i64 %4106, 64
  %4116 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4115
  %4117 = load i8, i8* %4116, align 1
  %4118 = icmp eq i64 %4060, %4115
  %4119 = sext i1 %4118 to i8
  %4120 = xor i8 %4119, -1
  %4121 = and i8 %4120, %4114
  %4122 = and i8 %4119, %4117
  %4123 = or i8 %4122, %4121
  %4124 = add i64 %4115, 64
  %4125 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4124
  %4126 = load i8, i8* %4125, align 1
  %4127 = icmp eq i64 %4060, %4124
  %4128 = sext i1 %4127 to i8
  %4129 = xor i8 %4128, -1
  %4130 = and i8 %4129, %4123
  %4131 = and i8 %4128, %4126
  %4132 = or i8 %4131, %4130
  %4133 = add i64 %4124, 64
  %4134 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4133
  %4135 = load i8, i8* %4134, align 1
  %4136 = icmp eq i64 %4060, %4133
  %4137 = sext i1 %4136 to i8
  %4138 = xor i8 %4137, -1
  %4139 = and i8 %4138, %4132
  %4140 = and i8 %4137, %4135
  %4141 = or i8 %4140, %4139
  %4142 = add i64 %4133, 64
  %4143 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4142
  %4144 = load i8, i8* %4143, align 1
  %4145 = icmp eq i64 %4060, %4142
  %4146 = sext i1 %4145 to i8
  %4147 = xor i8 %4146, -1
  %4148 = and i8 %4147, %4141
  %4149 = and i8 %4146, %4144
  %4150 = or i8 %4149, %4148
  %4151 = add i64 %4142, 64
  %4152 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4151
  %4153 = load i8, i8* %4152, align 1
  %4154 = icmp eq i64 %4060, %4151
  %4155 = sext i1 %4154 to i8
  %4156 = xor i8 %4155, -1
  %4157 = and i8 %4156, %4150
  %4158 = and i8 %4155, %4153
  %4159 = or i8 %4158, %4157
  %4160 = add i64 %4151, 64
  %4161 = icmp sge i64 %4160, 748
  %4162 = sext i1 %4161 to i64
  %4163 = xor i64 %4162, -1
  %4164 = and i64 %4162, 747
  %4165 = and i64 %4163, %4160
  %4166 = or i64 %4164, %4165
  %4167 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4166
  %4168 = load i8, i8* %4167, align 1
  %4169 = icmp eq i64 %4060, %4166
  %4170 = sext i1 %4169 to i8
  %4171 = xor i8 %4170, -1
  %4172 = and i8 %4171, %4159
  %4173 = and i8 %4170, %4168
  %Mitigated37 = or i8 %4173, %4172
  %4174 = zext i8 %Mitigated37 to i32
  %4175 = zext i8 %3626 to i32
  %4176 = xor i32 %4175, %4174
  %4177 = trunc i32 %4176 to i8
  %4178 = add i32 %3939, 140
  %4179 = zext i32 %4178 to i64
  %4180 = srem i64 %4179, 64
  %4181 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4180
  %4182 = load i8, i8* %4181, align 1
  %4183 = icmp eq i64 %4179, %4180
  %4184 = sext i1 %4183 to i8
  %4185 = xor i8 %4184, -1
  %4186 = and i8 %4185, 0
  %4187 = and i8 %4184, %4182
  %4188 = or i8 %4187, %4186
  %4189 = add i64 %4180, 64
  %4190 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4189
  %4191 = load i8, i8* %4190, align 1
  %4192 = icmp eq i64 %4179, %4189
  %4193 = sext i1 %4192 to i8
  %4194 = xor i8 %4193, -1
  %4195 = and i8 %4194, %4188
  %4196 = and i8 %4193, %4191
  %4197 = or i8 %4196, %4195
  %4198 = add i64 %4189, 64
  %4199 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4198
  %4200 = load i8, i8* %4199, align 1
  %4201 = icmp eq i64 %4179, %4198
  %4202 = sext i1 %4201 to i8
  %4203 = xor i8 %4202, -1
  %4204 = and i8 %4203, %4197
  %4205 = and i8 %4202, %4200
  %4206 = or i8 %4205, %4204
  %4207 = add i64 %4198, 64
  %4208 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4207
  %4209 = load i8, i8* %4208, align 1
  %4210 = icmp eq i64 %4179, %4207
  %4211 = sext i1 %4210 to i8
  %4212 = xor i8 %4211, -1
  %4213 = and i8 %4212, %4206
  %4214 = and i8 %4211, %4209
  %4215 = or i8 %4214, %4213
  %4216 = add i64 %4207, 64
  %4217 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4216
  %4218 = load i8, i8* %4217, align 1
  %4219 = icmp eq i64 %4179, %4216
  %4220 = sext i1 %4219 to i8
  %4221 = xor i8 %4220, -1
  %4222 = and i8 %4221, %4215
  %4223 = and i8 %4220, %4218
  %4224 = or i8 %4223, %4222
  %4225 = add i64 %4216, 64
  %4226 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4225
  %4227 = load i8, i8* %4226, align 1
  %4228 = icmp eq i64 %4179, %4225
  %4229 = sext i1 %4228 to i8
  %4230 = xor i8 %4229, -1
  %4231 = and i8 %4230, %4224
  %4232 = and i8 %4229, %4227
  %4233 = or i8 %4232, %4231
  %4234 = add i64 %4225, 64
  %4235 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4234
  %4236 = load i8, i8* %4235, align 1
  %4237 = icmp eq i64 %4179, %4234
  %4238 = sext i1 %4237 to i8
  %4239 = xor i8 %4238, -1
  %4240 = and i8 %4239, %4233
  %4241 = and i8 %4238, %4236
  %4242 = or i8 %4241, %4240
  %4243 = add i64 %4234, 64
  %4244 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4243
  %4245 = load i8, i8* %4244, align 1
  %4246 = icmp eq i64 %4179, %4243
  %4247 = sext i1 %4246 to i8
  %4248 = xor i8 %4247, -1
  %4249 = and i8 %4248, %4242
  %4250 = and i8 %4247, %4245
  %4251 = or i8 %4250, %4249
  %4252 = add i64 %4243, 64
  %4253 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4252
  %4254 = load i8, i8* %4253, align 1
  %4255 = icmp eq i64 %4179, %4252
  %4256 = sext i1 %4255 to i8
  %4257 = xor i8 %4256, -1
  %4258 = and i8 %4257, %4251
  %4259 = and i8 %4256, %4254
  %4260 = or i8 %4259, %4258
  %4261 = add i64 %4252, 64
  %4262 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4261
  %4263 = load i8, i8* %4262, align 1
  %4264 = icmp eq i64 %4179, %4261
  %4265 = sext i1 %4264 to i8
  %4266 = xor i8 %4265, -1
  %4267 = and i8 %4266, %4260
  %4268 = and i8 %4265, %4263
  %4269 = or i8 %4268, %4267
  %4270 = add i64 %4261, 64
  %4271 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4270
  %4272 = load i8, i8* %4271, align 1
  %4273 = icmp eq i64 %4179, %4270
  %4274 = sext i1 %4273 to i8
  %4275 = xor i8 %4274, -1
  %4276 = and i8 %4275, %4269
  %4277 = and i8 %4274, %4272
  %4278 = or i8 %4277, %4276
  %4279 = add i64 %4270, 64
  %4280 = icmp sge i64 %4279, 748
  %4281 = sext i1 %4280 to i64
  %4282 = xor i64 %4281, -1
  %4283 = and i64 %4281, 747
  %4284 = and i64 %4282, %4279
  %4285 = or i64 %4283, %4284
  %4286 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4285
  %4287 = load i8, i8* %4286, align 1
  %4288 = icmp eq i64 %4179, %4285
  %4289 = sext i1 %4288 to i8
  %4290 = xor i8 %4289, -1
  %4291 = and i8 %4290, %4278
  %4292 = and i8 %4289, %4287
  %Mitigated38 = or i8 %4292, %4291
  %4293 = zext i8 %Mitigated38 to i32
  %4294 = zext i8 %3745 to i32
  %4295 = xor i32 %4294, %4293
  %4296 = trunc i32 %4295 to i8
  %4297 = add i32 %3939, 23
  %4298 = zext i32 %4297 to i64
  %4299 = srem i64 %4298, 64
  %4300 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4299
  %4301 = load i8, i8* %4300, align 1
  %4302 = icmp eq i64 %4298, %4299
  %4303 = sext i1 %4302 to i8
  %4304 = xor i8 %4303, -1
  %4305 = and i8 %4304, 0
  %4306 = and i8 %4303, %4301
  %4307 = or i8 %4306, %4305
  %4308 = add i64 %4299, 64
  %4309 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4308
  %4310 = load i8, i8* %4309, align 1
  %4311 = icmp eq i64 %4298, %4308
  %4312 = sext i1 %4311 to i8
  %4313 = xor i8 %4312, -1
  %4314 = and i8 %4313, %4307
  %4315 = and i8 %4312, %4310
  %4316 = or i8 %4315, %4314
  %4317 = add i64 %4308, 64
  %4318 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4317
  %4319 = load i8, i8* %4318, align 1
  %4320 = icmp eq i64 %4298, %4317
  %4321 = sext i1 %4320 to i8
  %4322 = xor i8 %4321, -1
  %4323 = and i8 %4322, %4316
  %4324 = and i8 %4321, %4319
  %4325 = or i8 %4324, %4323
  %4326 = add i64 %4317, 64
  %4327 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4326
  %4328 = load i8, i8* %4327, align 1
  %4329 = icmp eq i64 %4298, %4326
  %4330 = sext i1 %4329 to i8
  %4331 = xor i8 %4330, -1
  %4332 = and i8 %4331, %4325
  %4333 = and i8 %4330, %4328
  %4334 = or i8 %4333, %4332
  %4335 = add i64 %4326, 64
  %4336 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4335
  %4337 = load i8, i8* %4336, align 1
  %4338 = icmp eq i64 %4298, %4335
  %4339 = sext i1 %4338 to i8
  %4340 = xor i8 %4339, -1
  %4341 = and i8 %4340, %4334
  %4342 = and i8 %4339, %4337
  %4343 = or i8 %4342, %4341
  %4344 = add i64 %4335, 64
  %4345 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4344
  %4346 = load i8, i8* %4345, align 1
  %4347 = icmp eq i64 %4298, %4344
  %4348 = sext i1 %4347 to i8
  %4349 = xor i8 %4348, -1
  %4350 = and i8 %4349, %4343
  %4351 = and i8 %4348, %4346
  %4352 = or i8 %4351, %4350
  %4353 = add i64 %4344, 64
  %4354 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4353
  %4355 = load i8, i8* %4354, align 1
  %4356 = icmp eq i64 %4298, %4353
  %4357 = sext i1 %4356 to i8
  %4358 = xor i8 %4357, -1
  %4359 = and i8 %4358, %4352
  %4360 = and i8 %4357, %4355
  %4361 = or i8 %4360, %4359
  %4362 = add i64 %4353, 64
  %4363 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4362
  %4364 = load i8, i8* %4363, align 1
  %4365 = icmp eq i64 %4298, %4362
  %4366 = sext i1 %4365 to i8
  %4367 = xor i8 %4366, -1
  %4368 = and i8 %4367, %4361
  %4369 = and i8 %4366, %4364
  %4370 = or i8 %4369, %4368
  %4371 = add i64 %4362, 64
  %4372 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4371
  %4373 = load i8, i8* %4372, align 1
  %4374 = icmp eq i64 %4298, %4371
  %4375 = sext i1 %4374 to i8
  %4376 = xor i8 %4375, -1
  %4377 = and i8 %4376, %4370
  %4378 = and i8 %4375, %4373
  %4379 = or i8 %4378, %4377
  %4380 = add i64 %4371, 64
  %4381 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4380
  %4382 = load i8, i8* %4381, align 1
  %4383 = icmp eq i64 %4298, %4380
  %4384 = sext i1 %4383 to i8
  %4385 = xor i8 %4384, -1
  %4386 = and i8 %4385, %4379
  %4387 = and i8 %4384, %4382
  %4388 = or i8 %4387, %4386
  %4389 = add i64 %4380, 64
  %4390 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4389
  %4391 = load i8, i8* %4390, align 1
  %4392 = icmp eq i64 %4298, %4389
  %4393 = sext i1 %4392 to i8
  %4394 = xor i8 %4393, -1
  %4395 = and i8 %4394, %4388
  %4396 = and i8 %4393, %4391
  %4397 = or i8 %4396, %4395
  %4398 = add i64 %4389, 64
  %4399 = icmp sge i64 %4398, 748
  %4400 = sext i1 %4399 to i64
  %4401 = xor i64 %4400, -1
  %4402 = and i64 %4400, 747
  %4403 = and i64 %4401, %4398
  %4404 = or i64 %4402, %4403
  %4405 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4404
  %4406 = load i8, i8* %4405, align 1
  %4407 = icmp eq i64 %4298, %4404
  %4408 = sext i1 %4407 to i8
  %4409 = xor i8 %4408, -1
  %4410 = and i8 %4409, %4397
  %4411 = and i8 %4408, %4406
  %Mitigated39 = or i8 %4411, %4410
  %4412 = zext i8 %Mitigated39 to i32
  %4413 = zext i8 %3864 to i32
  %4414 = xor i32 %4413, %4412
  %4415 = trunc i32 %4414 to i8
  %4416 = getelementptr inbounds i8, i8* %0, i64 8
  %4417 = load i8, i8* %4416, align 1
  %4418 = zext i8 %4417 to i64
  %4419 = srem i64 %4418, 32
  %4420 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4419
  %4421 = load i16, i16* %4420, align 2
  %4422 = icmp eq i64 %4418, %4419
  %4423 = sext i1 %4422 to i16
  %4424 = xor i16 %4423, -1
  %4425 = and i16 %4424, 0
  %4426 = and i16 %4423, %4421
  %4427 = or i16 %4426, %4425
  %4428 = add i64 %4419, 32
  %4429 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4428
  %4430 = load i16, i16* %4429, align 2
  %4431 = icmp eq i64 %4418, %4428
  %4432 = sext i1 %4431 to i16
  %4433 = xor i16 %4432, -1
  %4434 = and i16 %4433, %4427
  %4435 = and i16 %4432, %4430
  %4436 = or i16 %4435, %4434
  %4437 = add i64 %4428, 32
  %4438 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4437
  %4439 = load i16, i16* %4438, align 2
  %4440 = icmp eq i64 %4418, %4437
  %4441 = sext i1 %4440 to i16
  %4442 = xor i16 %4441, -1
  %4443 = and i16 %4442, %4436
  %4444 = and i16 %4441, %4439
  %4445 = or i16 %4444, %4443
  %4446 = add i64 %4437, 32
  %4447 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4446
  %4448 = load i16, i16* %4447, align 2
  %4449 = icmp eq i64 %4418, %4446
  %4450 = sext i1 %4449 to i16
  %4451 = xor i16 %4450, -1
  %4452 = and i16 %4451, %4445
  %4453 = and i16 %4450, %4448
  %4454 = or i16 %4453, %4452
  %4455 = add i64 %4446, 32
  %4456 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4455
  %4457 = load i16, i16* %4456, align 2
  %4458 = icmp eq i64 %4418, %4455
  %4459 = sext i1 %4458 to i16
  %4460 = xor i16 %4459, -1
  %4461 = and i16 %4460, %4454
  %4462 = and i16 %4459, %4457
  %4463 = or i16 %4462, %4461
  %4464 = add i64 %4455, 32
  %4465 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4464
  %4466 = load i16, i16* %4465, align 2
  %4467 = icmp eq i64 %4418, %4464
  %4468 = sext i1 %4467 to i16
  %4469 = xor i16 %4468, -1
  %4470 = and i16 %4469, %4463
  %4471 = and i16 %4468, %4466
  %4472 = or i16 %4471, %4470
  %4473 = add i64 %4464, 32
  %4474 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4473
  %4475 = load i16, i16* %4474, align 2
  %4476 = icmp eq i64 %4418, %4473
  %4477 = sext i1 %4476 to i16
  %4478 = xor i16 %4477, -1
  %4479 = and i16 %4478, %4472
  %4480 = and i16 %4477, %4475
  %4481 = or i16 %4480, %4479
  %4482 = add i64 %4473, 32
  %4483 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4482
  %4484 = load i16, i16* %4483, align 2
  %4485 = icmp eq i64 %4418, %4482
  %4486 = sext i1 %4485 to i16
  %4487 = xor i16 %4486, -1
  %4488 = and i16 %4487, %4481
  %4489 = and i16 %4486, %4484
  %Mitigated40 = or i16 %4489, %4488
  %4490 = zext i16 %Mitigated40 to i32
  %4491 = add i32 %4490, 0
  %4492 = zext i32 %4491 to i64
  %4493 = srem i64 %4492, 64
  %4494 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4493
  %4495 = load i8, i8* %4494, align 1
  %4496 = icmp eq i64 %4492, %4493
  %4497 = sext i1 %4496 to i8
  %4498 = xor i8 %4497, -1
  %4499 = and i8 %4498, 0
  %4500 = and i8 %4497, %4495
  %4501 = or i8 %4500, %4499
  %4502 = add i64 %4493, 64
  %4503 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4502
  %4504 = load i8, i8* %4503, align 1
  %4505 = icmp eq i64 %4492, %4502
  %4506 = sext i1 %4505 to i8
  %4507 = xor i8 %4506, -1
  %4508 = and i8 %4507, %4501
  %4509 = and i8 %4506, %4504
  %4510 = or i8 %4509, %4508
  %4511 = add i64 %4502, 64
  %4512 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4511
  %4513 = load i8, i8* %4512, align 1
  %4514 = icmp eq i64 %4492, %4511
  %4515 = sext i1 %4514 to i8
  %4516 = xor i8 %4515, -1
  %4517 = and i8 %4516, %4510
  %4518 = and i8 %4515, %4513
  %4519 = or i8 %4518, %4517
  %4520 = add i64 %4511, 64
  %4521 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4520
  %4522 = load i8, i8* %4521, align 1
  %4523 = icmp eq i64 %4492, %4520
  %4524 = sext i1 %4523 to i8
  %4525 = xor i8 %4524, -1
  %4526 = and i8 %4525, %4519
  %4527 = and i8 %4524, %4522
  %4528 = or i8 %4527, %4526
  %4529 = add i64 %4520, 64
  %4530 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4529
  %4531 = load i8, i8* %4530, align 1
  %4532 = icmp eq i64 %4492, %4529
  %4533 = sext i1 %4532 to i8
  %4534 = xor i8 %4533, -1
  %4535 = and i8 %4534, %4528
  %4536 = and i8 %4533, %4531
  %4537 = or i8 %4536, %4535
  %4538 = add i64 %4529, 64
  %4539 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4538
  %4540 = load i8, i8* %4539, align 1
  %4541 = icmp eq i64 %4492, %4538
  %4542 = sext i1 %4541 to i8
  %4543 = xor i8 %4542, -1
  %4544 = and i8 %4543, %4537
  %4545 = and i8 %4542, %4540
  %4546 = or i8 %4545, %4544
  %4547 = add i64 %4538, 64
  %4548 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4547
  %4549 = load i8, i8* %4548, align 1
  %4550 = icmp eq i64 %4492, %4547
  %4551 = sext i1 %4550 to i8
  %4552 = xor i8 %4551, -1
  %4553 = and i8 %4552, %4546
  %4554 = and i8 %4551, %4549
  %4555 = or i8 %4554, %4553
  %4556 = add i64 %4547, 64
  %4557 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4556
  %4558 = load i8, i8* %4557, align 1
  %4559 = icmp eq i64 %4492, %4556
  %4560 = sext i1 %4559 to i8
  %4561 = xor i8 %4560, -1
  %4562 = and i8 %4561, %4555
  %4563 = and i8 %4560, %4558
  %4564 = or i8 %4563, %4562
  %4565 = add i64 %4556, 64
  %4566 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4565
  %4567 = load i8, i8* %4566, align 1
  %4568 = icmp eq i64 %4492, %4565
  %4569 = sext i1 %4568 to i8
  %4570 = xor i8 %4569, -1
  %4571 = and i8 %4570, %4564
  %4572 = and i8 %4569, %4567
  %4573 = or i8 %4572, %4571
  %4574 = add i64 %4565, 64
  %4575 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4574
  %4576 = load i8, i8* %4575, align 1
  %4577 = icmp eq i64 %4492, %4574
  %4578 = sext i1 %4577 to i8
  %4579 = xor i8 %4578, -1
  %4580 = and i8 %4579, %4573
  %4581 = and i8 %4578, %4576
  %4582 = or i8 %4581, %4580
  %4583 = add i64 %4574, 64
  %4584 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4583
  %4585 = load i8, i8* %4584, align 1
  %4586 = icmp eq i64 %4492, %4583
  %4587 = sext i1 %4586 to i8
  %4588 = xor i8 %4587, -1
  %4589 = and i8 %4588, %4582
  %4590 = and i8 %4587, %4585
  %4591 = or i8 %4590, %4589
  %4592 = add i64 %4583, 64
  %4593 = icmp sge i64 %4592, 748
  %4594 = sext i1 %4593 to i64
  %4595 = xor i64 %4594, -1
  %4596 = and i64 %4594, 747
  %4597 = and i64 %4595, %4592
  %4598 = or i64 %4596, %4597
  %4599 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4598
  %4600 = load i8, i8* %4599, align 1
  %4601 = icmp eq i64 %4492, %4598
  %4602 = sext i1 %4601 to i8
  %4603 = xor i8 %4602, -1
  %4604 = and i8 %4603, %4591
  %4605 = and i8 %4602, %4600
  %Mitigated41 = or i8 %4605, %4604
  %4606 = zext i8 %Mitigated41 to i32
  %4607 = zext i8 0 to i32
  %4608 = xor i32 %4607, %4606
  %4609 = trunc i32 %4608 to i8
  %4610 = add i32 %4490, 45
  %4611 = zext i32 %4610 to i64
  %4612 = srem i64 %4611, 64
  %4613 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4612
  %4614 = load i8, i8* %4613, align 1
  %4615 = icmp eq i64 %4611, %4612
  %4616 = sext i1 %4615 to i8
  %4617 = xor i8 %4616, -1
  %4618 = and i8 %4617, 0
  %4619 = and i8 %4616, %4614
  %4620 = or i8 %4619, %4618
  %4621 = add i64 %4612, 64
  %4622 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4621
  %4623 = load i8, i8* %4622, align 1
  %4624 = icmp eq i64 %4611, %4621
  %4625 = sext i1 %4624 to i8
  %4626 = xor i8 %4625, -1
  %4627 = and i8 %4626, %4620
  %4628 = and i8 %4625, %4623
  %4629 = or i8 %4628, %4627
  %4630 = add i64 %4621, 64
  %4631 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4630
  %4632 = load i8, i8* %4631, align 1
  %4633 = icmp eq i64 %4611, %4630
  %4634 = sext i1 %4633 to i8
  %4635 = xor i8 %4634, -1
  %4636 = and i8 %4635, %4629
  %4637 = and i8 %4634, %4632
  %4638 = or i8 %4637, %4636
  %4639 = add i64 %4630, 64
  %4640 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4639
  %4641 = load i8, i8* %4640, align 1
  %4642 = icmp eq i64 %4611, %4639
  %4643 = sext i1 %4642 to i8
  %4644 = xor i8 %4643, -1
  %4645 = and i8 %4644, %4638
  %4646 = and i8 %4643, %4641
  %4647 = or i8 %4646, %4645
  %4648 = add i64 %4639, 64
  %4649 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4648
  %4650 = load i8, i8* %4649, align 1
  %4651 = icmp eq i64 %4611, %4648
  %4652 = sext i1 %4651 to i8
  %4653 = xor i8 %4652, -1
  %4654 = and i8 %4653, %4647
  %4655 = and i8 %4652, %4650
  %4656 = or i8 %4655, %4654
  %4657 = add i64 %4648, 64
  %4658 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4657
  %4659 = load i8, i8* %4658, align 1
  %4660 = icmp eq i64 %4611, %4657
  %4661 = sext i1 %4660 to i8
  %4662 = xor i8 %4661, -1
  %4663 = and i8 %4662, %4656
  %4664 = and i8 %4661, %4659
  %4665 = or i8 %4664, %4663
  %4666 = add i64 %4657, 64
  %4667 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4666
  %4668 = load i8, i8* %4667, align 1
  %4669 = icmp eq i64 %4611, %4666
  %4670 = sext i1 %4669 to i8
  %4671 = xor i8 %4670, -1
  %4672 = and i8 %4671, %4665
  %4673 = and i8 %4670, %4668
  %4674 = or i8 %4673, %4672
  %4675 = add i64 %4666, 64
  %4676 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4675
  %4677 = load i8, i8* %4676, align 1
  %4678 = icmp eq i64 %4611, %4675
  %4679 = sext i1 %4678 to i8
  %4680 = xor i8 %4679, -1
  %4681 = and i8 %4680, %4674
  %4682 = and i8 %4679, %4677
  %4683 = or i8 %4682, %4681
  %4684 = add i64 %4675, 64
  %4685 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4684
  %4686 = load i8, i8* %4685, align 1
  %4687 = icmp eq i64 %4611, %4684
  %4688 = sext i1 %4687 to i8
  %4689 = xor i8 %4688, -1
  %4690 = and i8 %4689, %4683
  %4691 = and i8 %4688, %4686
  %4692 = or i8 %4691, %4690
  %4693 = add i64 %4684, 64
  %4694 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4693
  %4695 = load i8, i8* %4694, align 1
  %4696 = icmp eq i64 %4611, %4693
  %4697 = sext i1 %4696 to i8
  %4698 = xor i8 %4697, -1
  %4699 = and i8 %4698, %4692
  %4700 = and i8 %4697, %4695
  %4701 = or i8 %4700, %4699
  %4702 = add i64 %4693, 64
  %4703 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4702
  %4704 = load i8, i8* %4703, align 1
  %4705 = icmp eq i64 %4611, %4702
  %4706 = sext i1 %4705 to i8
  %4707 = xor i8 %4706, -1
  %4708 = and i8 %4707, %4701
  %4709 = and i8 %4706, %4704
  %4710 = or i8 %4709, %4708
  %4711 = add i64 %4702, 64
  %4712 = icmp sge i64 %4711, 748
  %4713 = sext i1 %4712 to i64
  %4714 = xor i64 %4713, -1
  %4715 = and i64 %4713, 747
  %4716 = and i64 %4714, %4711
  %4717 = or i64 %4715, %4716
  %4718 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4717
  %4719 = load i8, i8* %4718, align 1
  %4720 = icmp eq i64 %4611, %4717
  %4721 = sext i1 %4720 to i8
  %4722 = xor i8 %4721, -1
  %4723 = and i8 %4722, %4710
  %4724 = and i8 %4721, %4719
  %Mitigated42 = or i8 %4724, %4723
  %4725 = zext i8 %Mitigated42 to i32
  %4726 = zext i8 0 to i32
  %4727 = xor i32 %4726, %4725
  %4728 = trunc i32 %4727 to i8
  %4729 = add i32 %4490, 1
  %4730 = zext i32 %4729 to i64
  %4731 = srem i64 %4730, 64
  %4732 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4731
  %4733 = load i8, i8* %4732, align 1
  %4734 = icmp eq i64 %4730, %4731
  %4735 = sext i1 %4734 to i8
  %4736 = xor i8 %4735, -1
  %4737 = and i8 %4736, 0
  %4738 = and i8 %4735, %4733
  %4739 = or i8 %4738, %4737
  %4740 = add i64 %4731, 64
  %4741 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4740
  %4742 = load i8, i8* %4741, align 1
  %4743 = icmp eq i64 %4730, %4740
  %4744 = sext i1 %4743 to i8
  %4745 = xor i8 %4744, -1
  %4746 = and i8 %4745, %4739
  %4747 = and i8 %4744, %4742
  %4748 = or i8 %4747, %4746
  %4749 = add i64 %4740, 64
  %4750 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4749
  %4751 = load i8, i8* %4750, align 1
  %4752 = icmp eq i64 %4730, %4749
  %4753 = sext i1 %4752 to i8
  %4754 = xor i8 %4753, -1
  %4755 = and i8 %4754, %4748
  %4756 = and i8 %4753, %4751
  %4757 = or i8 %4756, %4755
  %4758 = add i64 %4749, 64
  %4759 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4758
  %4760 = load i8, i8* %4759, align 1
  %4761 = icmp eq i64 %4730, %4758
  %4762 = sext i1 %4761 to i8
  %4763 = xor i8 %4762, -1
  %4764 = and i8 %4763, %4757
  %4765 = and i8 %4762, %4760
  %4766 = or i8 %4765, %4764
  %4767 = add i64 %4758, 64
  %4768 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4767
  %4769 = load i8, i8* %4768, align 1
  %4770 = icmp eq i64 %4730, %4767
  %4771 = sext i1 %4770 to i8
  %4772 = xor i8 %4771, -1
  %4773 = and i8 %4772, %4766
  %4774 = and i8 %4771, %4769
  %4775 = or i8 %4774, %4773
  %4776 = add i64 %4767, 64
  %4777 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4776
  %4778 = load i8, i8* %4777, align 1
  %4779 = icmp eq i64 %4730, %4776
  %4780 = sext i1 %4779 to i8
  %4781 = xor i8 %4780, -1
  %4782 = and i8 %4781, %4775
  %4783 = and i8 %4780, %4778
  %4784 = or i8 %4783, %4782
  %4785 = add i64 %4776, 64
  %4786 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4785
  %4787 = load i8, i8* %4786, align 1
  %4788 = icmp eq i64 %4730, %4785
  %4789 = sext i1 %4788 to i8
  %4790 = xor i8 %4789, -1
  %4791 = and i8 %4790, %4784
  %4792 = and i8 %4789, %4787
  %4793 = or i8 %4792, %4791
  %4794 = add i64 %4785, 64
  %4795 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4794
  %4796 = load i8, i8* %4795, align 1
  %4797 = icmp eq i64 %4730, %4794
  %4798 = sext i1 %4797 to i8
  %4799 = xor i8 %4798, -1
  %4800 = and i8 %4799, %4793
  %4801 = and i8 %4798, %4796
  %4802 = or i8 %4801, %4800
  %4803 = add i64 %4794, 64
  %4804 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4803
  %4805 = load i8, i8* %4804, align 1
  %4806 = icmp eq i64 %4730, %4803
  %4807 = sext i1 %4806 to i8
  %4808 = xor i8 %4807, -1
  %4809 = and i8 %4808, %4802
  %4810 = and i8 %4807, %4805
  %4811 = or i8 %4810, %4809
  %4812 = add i64 %4803, 64
  %4813 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4812
  %4814 = load i8, i8* %4813, align 1
  %4815 = icmp eq i64 %4730, %4812
  %4816 = sext i1 %4815 to i8
  %4817 = xor i8 %4816, -1
  %4818 = and i8 %4817, %4811
  %4819 = and i8 %4816, %4814
  %4820 = or i8 %4819, %4818
  %4821 = add i64 %4812, 64
  %4822 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4821
  %4823 = load i8, i8* %4822, align 1
  %4824 = icmp eq i64 %4730, %4821
  %4825 = sext i1 %4824 to i8
  %4826 = xor i8 %4825, -1
  %4827 = and i8 %4826, %4820
  %4828 = and i8 %4825, %4823
  %4829 = or i8 %4828, %4827
  %4830 = add i64 %4821, 64
  %4831 = icmp sge i64 %4830, 748
  %4832 = sext i1 %4831 to i64
  %4833 = xor i64 %4832, -1
  %4834 = and i64 %4832, 747
  %4835 = and i64 %4833, %4830
  %4836 = or i64 %4834, %4835
  %4837 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4836
  %4838 = load i8, i8* %4837, align 1
  %4839 = icmp eq i64 %4730, %4836
  %4840 = sext i1 %4839 to i8
  %4841 = xor i8 %4840, -1
  %4842 = and i8 %4841, %4829
  %4843 = and i8 %4840, %4838
  %Mitigated43 = or i8 %4843, %4842
  %4844 = zext i8 %Mitigated43 to i32
  %4845 = zext i8 0 to i32
  %4846 = xor i32 %4845, %4844
  %4847 = trunc i32 %4846 to i8
  %4848 = add i32 %4490, 45
  %4849 = zext i32 %4848 to i64
  %4850 = srem i64 %4849, 64
  %4851 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4850
  %4852 = load i8, i8* %4851, align 1
  %4853 = icmp eq i64 %4849, %4850
  %4854 = sext i1 %4853 to i8
  %4855 = xor i8 %4854, -1
  %4856 = and i8 %4855, 0
  %4857 = and i8 %4854, %4852
  %4858 = or i8 %4857, %4856
  %4859 = add i64 %4850, 64
  %4860 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4859
  %4861 = load i8, i8* %4860, align 1
  %4862 = icmp eq i64 %4849, %4859
  %4863 = sext i1 %4862 to i8
  %4864 = xor i8 %4863, -1
  %4865 = and i8 %4864, %4858
  %4866 = and i8 %4863, %4861
  %4867 = or i8 %4866, %4865
  %4868 = add i64 %4859, 64
  %4869 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4868
  %4870 = load i8, i8* %4869, align 1
  %4871 = icmp eq i64 %4849, %4868
  %4872 = sext i1 %4871 to i8
  %4873 = xor i8 %4872, -1
  %4874 = and i8 %4873, %4867
  %4875 = and i8 %4872, %4870
  %4876 = or i8 %4875, %4874
  %4877 = add i64 %4868, 64
  %4878 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4877
  %4879 = load i8, i8* %4878, align 1
  %4880 = icmp eq i64 %4849, %4877
  %4881 = sext i1 %4880 to i8
  %4882 = xor i8 %4881, -1
  %4883 = and i8 %4882, %4876
  %4884 = and i8 %4881, %4879
  %4885 = or i8 %4884, %4883
  %4886 = add i64 %4877, 64
  %4887 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4886
  %4888 = load i8, i8* %4887, align 1
  %4889 = icmp eq i64 %4849, %4886
  %4890 = sext i1 %4889 to i8
  %4891 = xor i8 %4890, -1
  %4892 = and i8 %4891, %4885
  %4893 = and i8 %4890, %4888
  %4894 = or i8 %4893, %4892
  %4895 = add i64 %4886, 64
  %4896 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4895
  %4897 = load i8, i8* %4896, align 1
  %4898 = icmp eq i64 %4849, %4895
  %4899 = sext i1 %4898 to i8
  %4900 = xor i8 %4899, -1
  %4901 = and i8 %4900, %4894
  %4902 = and i8 %4899, %4897
  %4903 = or i8 %4902, %4901
  %4904 = add i64 %4895, 64
  %4905 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4904
  %4906 = load i8, i8* %4905, align 1
  %4907 = icmp eq i64 %4849, %4904
  %4908 = sext i1 %4907 to i8
  %4909 = xor i8 %4908, -1
  %4910 = and i8 %4909, %4903
  %4911 = and i8 %4908, %4906
  %4912 = or i8 %4911, %4910
  %4913 = add i64 %4904, 64
  %4914 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4913
  %4915 = load i8, i8* %4914, align 1
  %4916 = icmp eq i64 %4849, %4913
  %4917 = sext i1 %4916 to i8
  %4918 = xor i8 %4917, -1
  %4919 = and i8 %4918, %4912
  %4920 = and i8 %4917, %4915
  %4921 = or i8 %4920, %4919
  %4922 = add i64 %4913, 64
  %4923 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4922
  %4924 = load i8, i8* %4923, align 1
  %4925 = icmp eq i64 %4849, %4922
  %4926 = sext i1 %4925 to i8
  %4927 = xor i8 %4926, -1
  %4928 = and i8 %4927, %4921
  %4929 = and i8 %4926, %4924
  %4930 = or i8 %4929, %4928
  %4931 = add i64 %4922, 64
  %4932 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4931
  %4933 = load i8, i8* %4932, align 1
  %4934 = icmp eq i64 %4849, %4931
  %4935 = sext i1 %4934 to i8
  %4936 = xor i8 %4935, -1
  %4937 = and i8 %4936, %4930
  %4938 = and i8 %4935, %4933
  %4939 = or i8 %4938, %4937
  %4940 = add i64 %4931, 64
  %4941 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4940
  %4942 = load i8, i8* %4941, align 1
  %4943 = icmp eq i64 %4849, %4940
  %4944 = sext i1 %4943 to i8
  %4945 = xor i8 %4944, -1
  %4946 = and i8 %4945, %4939
  %4947 = and i8 %4944, %4942
  %4948 = or i8 %4947, %4946
  %4949 = add i64 %4940, 64
  %4950 = icmp sge i64 %4949, 748
  %4951 = sext i1 %4950 to i64
  %4952 = xor i64 %4951, -1
  %4953 = and i64 %4951, 747
  %4954 = and i64 %4952, %4949
  %4955 = or i64 %4953, %4954
  %4956 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %4955
  %4957 = load i8, i8* %4956, align 1
  %4958 = icmp eq i64 %4849, %4955
  %4959 = sext i1 %4958 to i8
  %4960 = xor i8 %4959, -1
  %4961 = and i8 %4960, %4948
  %4962 = and i8 %4959, %4957
  %Mitigated44 = or i8 %4962, %4961
  %4963 = zext i8 %Mitigated44 to i32
  %4964 = zext i8 0 to i32
  %4965 = xor i32 %4964, %4963
  %4966 = trunc i32 %4965 to i8
  %4967 = getelementptr inbounds i8, i8* %0, i64 9
  %4968 = load i8, i8* %4967, align 1
  %4969 = zext i8 %4968 to i64
  %4970 = srem i64 %4969, 32
  %4971 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4970
  %4972 = load i16, i16* %4971, align 2
  %4973 = icmp eq i64 %4969, %4970
  %4974 = sext i1 %4973 to i16
  %4975 = xor i16 %4974, -1
  %4976 = and i16 %4975, 0
  %4977 = and i16 %4974, %4972
  %4978 = or i16 %4977, %4976
  %4979 = add i64 %4970, 32
  %4980 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4979
  %4981 = load i16, i16* %4980, align 2
  %4982 = icmp eq i64 %4969, %4979
  %4983 = sext i1 %4982 to i16
  %4984 = xor i16 %4983, -1
  %4985 = and i16 %4984, %4978
  %4986 = and i16 %4983, %4981
  %4987 = or i16 %4986, %4985
  %4988 = add i64 %4979, 32
  %4989 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4988
  %4990 = load i16, i16* %4989, align 2
  %4991 = icmp eq i64 %4969, %4988
  %4992 = sext i1 %4991 to i16
  %4993 = xor i16 %4992, -1
  %4994 = and i16 %4993, %4987
  %4995 = and i16 %4992, %4990
  %4996 = or i16 %4995, %4994
  %4997 = add i64 %4988, 32
  %4998 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %4997
  %4999 = load i16, i16* %4998, align 2
  %5000 = icmp eq i64 %4969, %4997
  %5001 = sext i1 %5000 to i16
  %5002 = xor i16 %5001, -1
  %5003 = and i16 %5002, %4996
  %5004 = and i16 %5001, %4999
  %5005 = or i16 %5004, %5003
  %5006 = add i64 %4997, 32
  %5007 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5006
  %5008 = load i16, i16* %5007, align 2
  %5009 = icmp eq i64 %4969, %5006
  %5010 = sext i1 %5009 to i16
  %5011 = xor i16 %5010, -1
  %5012 = and i16 %5011, %5005
  %5013 = and i16 %5010, %5008
  %5014 = or i16 %5013, %5012
  %5015 = add i64 %5006, 32
  %5016 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5015
  %5017 = load i16, i16* %5016, align 2
  %5018 = icmp eq i64 %4969, %5015
  %5019 = sext i1 %5018 to i16
  %5020 = xor i16 %5019, -1
  %5021 = and i16 %5020, %5014
  %5022 = and i16 %5019, %5017
  %5023 = or i16 %5022, %5021
  %5024 = add i64 %5015, 32
  %5025 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5024
  %5026 = load i16, i16* %5025, align 2
  %5027 = icmp eq i64 %4969, %5024
  %5028 = sext i1 %5027 to i16
  %5029 = xor i16 %5028, -1
  %5030 = and i16 %5029, %5023
  %5031 = and i16 %5028, %5026
  %5032 = or i16 %5031, %5030
  %5033 = add i64 %5024, 32
  %5034 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5033
  %5035 = load i16, i16* %5034, align 2
  %5036 = icmp eq i64 %4969, %5033
  %5037 = sext i1 %5036 to i16
  %5038 = xor i16 %5037, -1
  %5039 = and i16 %5038, %5032
  %5040 = and i16 %5037, %5035
  %Mitigated45 = or i16 %5040, %5039
  %5041 = zext i16 %Mitigated45 to i32
  %5042 = add i32 %5041, 45
  %5043 = zext i32 %5042 to i64
  %5044 = srem i64 %5043, 64
  %5045 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5044
  %5046 = load i8, i8* %5045, align 1
  %5047 = icmp eq i64 %5043, %5044
  %5048 = sext i1 %5047 to i8
  %5049 = xor i8 %5048, -1
  %5050 = and i8 %5049, 0
  %5051 = and i8 %5048, %5046
  %5052 = or i8 %5051, %5050
  %5053 = add i64 %5044, 64
  %5054 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5053
  %5055 = load i8, i8* %5054, align 1
  %5056 = icmp eq i64 %5043, %5053
  %5057 = sext i1 %5056 to i8
  %5058 = xor i8 %5057, -1
  %5059 = and i8 %5058, %5052
  %5060 = and i8 %5057, %5055
  %5061 = or i8 %5060, %5059
  %5062 = add i64 %5053, 64
  %5063 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5062
  %5064 = load i8, i8* %5063, align 1
  %5065 = icmp eq i64 %5043, %5062
  %5066 = sext i1 %5065 to i8
  %5067 = xor i8 %5066, -1
  %5068 = and i8 %5067, %5061
  %5069 = and i8 %5066, %5064
  %5070 = or i8 %5069, %5068
  %5071 = add i64 %5062, 64
  %5072 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5071
  %5073 = load i8, i8* %5072, align 1
  %5074 = icmp eq i64 %5043, %5071
  %5075 = sext i1 %5074 to i8
  %5076 = xor i8 %5075, -1
  %5077 = and i8 %5076, %5070
  %5078 = and i8 %5075, %5073
  %5079 = or i8 %5078, %5077
  %5080 = add i64 %5071, 64
  %5081 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5080
  %5082 = load i8, i8* %5081, align 1
  %5083 = icmp eq i64 %5043, %5080
  %5084 = sext i1 %5083 to i8
  %5085 = xor i8 %5084, -1
  %5086 = and i8 %5085, %5079
  %5087 = and i8 %5084, %5082
  %5088 = or i8 %5087, %5086
  %5089 = add i64 %5080, 64
  %5090 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5089
  %5091 = load i8, i8* %5090, align 1
  %5092 = icmp eq i64 %5043, %5089
  %5093 = sext i1 %5092 to i8
  %5094 = xor i8 %5093, -1
  %5095 = and i8 %5094, %5088
  %5096 = and i8 %5093, %5091
  %5097 = or i8 %5096, %5095
  %5098 = add i64 %5089, 64
  %5099 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5098
  %5100 = load i8, i8* %5099, align 1
  %5101 = icmp eq i64 %5043, %5098
  %5102 = sext i1 %5101 to i8
  %5103 = xor i8 %5102, -1
  %5104 = and i8 %5103, %5097
  %5105 = and i8 %5102, %5100
  %5106 = or i8 %5105, %5104
  %5107 = add i64 %5098, 64
  %5108 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5107
  %5109 = load i8, i8* %5108, align 1
  %5110 = icmp eq i64 %5043, %5107
  %5111 = sext i1 %5110 to i8
  %5112 = xor i8 %5111, -1
  %5113 = and i8 %5112, %5106
  %5114 = and i8 %5111, %5109
  %5115 = or i8 %5114, %5113
  %5116 = add i64 %5107, 64
  %5117 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5116
  %5118 = load i8, i8* %5117, align 1
  %5119 = icmp eq i64 %5043, %5116
  %5120 = sext i1 %5119 to i8
  %5121 = xor i8 %5120, -1
  %5122 = and i8 %5121, %5115
  %5123 = and i8 %5120, %5118
  %5124 = or i8 %5123, %5122
  %5125 = add i64 %5116, 64
  %5126 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5125
  %5127 = load i8, i8* %5126, align 1
  %5128 = icmp eq i64 %5043, %5125
  %5129 = sext i1 %5128 to i8
  %5130 = xor i8 %5129, -1
  %5131 = and i8 %5130, %5124
  %5132 = and i8 %5129, %5127
  %5133 = or i8 %5132, %5131
  %5134 = add i64 %5125, 64
  %5135 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5134
  %5136 = load i8, i8* %5135, align 1
  %5137 = icmp eq i64 %5043, %5134
  %5138 = sext i1 %5137 to i8
  %5139 = xor i8 %5138, -1
  %5140 = and i8 %5139, %5133
  %5141 = and i8 %5138, %5136
  %5142 = or i8 %5141, %5140
  %5143 = add i64 %5134, 64
  %5144 = icmp sge i64 %5143, 748
  %5145 = sext i1 %5144 to i64
  %5146 = xor i64 %5145, -1
  %5147 = and i64 %5145, 747
  %5148 = and i64 %5146, %5143
  %5149 = or i64 %5147, %5148
  %5150 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5149
  %5151 = load i8, i8* %5150, align 1
  %5152 = icmp eq i64 %5043, %5149
  %5153 = sext i1 %5152 to i8
  %5154 = xor i8 %5153, -1
  %5155 = and i8 %5154, %5142
  %5156 = and i8 %5153, %5151
  %Mitigated46 = or i8 %5156, %5155
  %5157 = zext i8 %Mitigated46 to i32
  %5158 = zext i8 %4609 to i32
  %5159 = xor i32 %5158, %5157
  %5160 = trunc i32 %5159 to i8
  %5161 = add i32 %5041, 164
  %5162 = zext i32 %5161 to i64
  %5163 = srem i64 %5162, 64
  %5164 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5163
  %5165 = load i8, i8* %5164, align 1
  %5166 = icmp eq i64 %5162, %5163
  %5167 = sext i1 %5166 to i8
  %5168 = xor i8 %5167, -1
  %5169 = and i8 %5168, 0
  %5170 = and i8 %5167, %5165
  %5171 = or i8 %5170, %5169
  %5172 = add i64 %5163, 64
  %5173 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5172
  %5174 = load i8, i8* %5173, align 1
  %5175 = icmp eq i64 %5162, %5172
  %5176 = sext i1 %5175 to i8
  %5177 = xor i8 %5176, -1
  %5178 = and i8 %5177, %5171
  %5179 = and i8 %5176, %5174
  %5180 = or i8 %5179, %5178
  %5181 = add i64 %5172, 64
  %5182 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5181
  %5183 = load i8, i8* %5182, align 1
  %5184 = icmp eq i64 %5162, %5181
  %5185 = sext i1 %5184 to i8
  %5186 = xor i8 %5185, -1
  %5187 = and i8 %5186, %5180
  %5188 = and i8 %5185, %5183
  %5189 = or i8 %5188, %5187
  %5190 = add i64 %5181, 64
  %5191 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5190
  %5192 = load i8, i8* %5191, align 1
  %5193 = icmp eq i64 %5162, %5190
  %5194 = sext i1 %5193 to i8
  %5195 = xor i8 %5194, -1
  %5196 = and i8 %5195, %5189
  %5197 = and i8 %5194, %5192
  %5198 = or i8 %5197, %5196
  %5199 = add i64 %5190, 64
  %5200 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5199
  %5201 = load i8, i8* %5200, align 1
  %5202 = icmp eq i64 %5162, %5199
  %5203 = sext i1 %5202 to i8
  %5204 = xor i8 %5203, -1
  %5205 = and i8 %5204, %5198
  %5206 = and i8 %5203, %5201
  %5207 = or i8 %5206, %5205
  %5208 = add i64 %5199, 64
  %5209 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5208
  %5210 = load i8, i8* %5209, align 1
  %5211 = icmp eq i64 %5162, %5208
  %5212 = sext i1 %5211 to i8
  %5213 = xor i8 %5212, -1
  %5214 = and i8 %5213, %5207
  %5215 = and i8 %5212, %5210
  %5216 = or i8 %5215, %5214
  %5217 = add i64 %5208, 64
  %5218 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5217
  %5219 = load i8, i8* %5218, align 1
  %5220 = icmp eq i64 %5162, %5217
  %5221 = sext i1 %5220 to i8
  %5222 = xor i8 %5221, -1
  %5223 = and i8 %5222, %5216
  %5224 = and i8 %5221, %5219
  %5225 = or i8 %5224, %5223
  %5226 = add i64 %5217, 64
  %5227 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5226
  %5228 = load i8, i8* %5227, align 1
  %5229 = icmp eq i64 %5162, %5226
  %5230 = sext i1 %5229 to i8
  %5231 = xor i8 %5230, -1
  %5232 = and i8 %5231, %5225
  %5233 = and i8 %5230, %5228
  %5234 = or i8 %5233, %5232
  %5235 = add i64 %5226, 64
  %5236 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5235
  %5237 = load i8, i8* %5236, align 1
  %5238 = icmp eq i64 %5162, %5235
  %5239 = sext i1 %5238 to i8
  %5240 = xor i8 %5239, -1
  %5241 = and i8 %5240, %5234
  %5242 = and i8 %5239, %5237
  %5243 = or i8 %5242, %5241
  %5244 = add i64 %5235, 64
  %5245 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5244
  %5246 = load i8, i8* %5245, align 1
  %5247 = icmp eq i64 %5162, %5244
  %5248 = sext i1 %5247 to i8
  %5249 = xor i8 %5248, -1
  %5250 = and i8 %5249, %5243
  %5251 = and i8 %5248, %5246
  %5252 = or i8 %5251, %5250
  %5253 = add i64 %5244, 64
  %5254 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5253
  %5255 = load i8, i8* %5254, align 1
  %5256 = icmp eq i64 %5162, %5253
  %5257 = sext i1 %5256 to i8
  %5258 = xor i8 %5257, -1
  %5259 = and i8 %5258, %5252
  %5260 = and i8 %5257, %5255
  %5261 = or i8 %5260, %5259
  %5262 = add i64 %5253, 64
  %5263 = icmp sge i64 %5262, 748
  %5264 = sext i1 %5263 to i64
  %5265 = xor i64 %5264, -1
  %5266 = and i64 %5264, 747
  %5267 = and i64 %5265, %5262
  %5268 = or i64 %5266, %5267
  %5269 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5268
  %5270 = load i8, i8* %5269, align 1
  %5271 = icmp eq i64 %5162, %5268
  %5272 = sext i1 %5271 to i8
  %5273 = xor i8 %5272, -1
  %5274 = and i8 %5273, %5261
  %5275 = and i8 %5272, %5270
  %Mitigated47 = or i8 %5275, %5274
  %5276 = zext i8 %Mitigated47 to i32
  %5277 = zext i8 %4728 to i32
  %5278 = xor i32 %5277, %5276
  %5279 = trunc i32 %5278 to i8
  %5280 = add i32 %5041, 68
  %5281 = zext i32 %5280 to i64
  %5282 = srem i64 %5281, 64
  %5283 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5282
  %5284 = load i8, i8* %5283, align 1
  %5285 = icmp eq i64 %5281, %5282
  %5286 = sext i1 %5285 to i8
  %5287 = xor i8 %5286, -1
  %5288 = and i8 %5287, 0
  %5289 = and i8 %5286, %5284
  %5290 = or i8 %5289, %5288
  %5291 = add i64 %5282, 64
  %5292 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5291
  %5293 = load i8, i8* %5292, align 1
  %5294 = icmp eq i64 %5281, %5291
  %5295 = sext i1 %5294 to i8
  %5296 = xor i8 %5295, -1
  %5297 = and i8 %5296, %5290
  %5298 = and i8 %5295, %5293
  %5299 = or i8 %5298, %5297
  %5300 = add i64 %5291, 64
  %5301 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5300
  %5302 = load i8, i8* %5301, align 1
  %5303 = icmp eq i64 %5281, %5300
  %5304 = sext i1 %5303 to i8
  %5305 = xor i8 %5304, -1
  %5306 = and i8 %5305, %5299
  %5307 = and i8 %5304, %5302
  %5308 = or i8 %5307, %5306
  %5309 = add i64 %5300, 64
  %5310 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5309
  %5311 = load i8, i8* %5310, align 1
  %5312 = icmp eq i64 %5281, %5309
  %5313 = sext i1 %5312 to i8
  %5314 = xor i8 %5313, -1
  %5315 = and i8 %5314, %5308
  %5316 = and i8 %5313, %5311
  %5317 = or i8 %5316, %5315
  %5318 = add i64 %5309, 64
  %5319 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5318
  %5320 = load i8, i8* %5319, align 1
  %5321 = icmp eq i64 %5281, %5318
  %5322 = sext i1 %5321 to i8
  %5323 = xor i8 %5322, -1
  %5324 = and i8 %5323, %5317
  %5325 = and i8 %5322, %5320
  %5326 = or i8 %5325, %5324
  %5327 = add i64 %5318, 64
  %5328 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5327
  %5329 = load i8, i8* %5328, align 1
  %5330 = icmp eq i64 %5281, %5327
  %5331 = sext i1 %5330 to i8
  %5332 = xor i8 %5331, -1
  %5333 = and i8 %5332, %5326
  %5334 = and i8 %5331, %5329
  %5335 = or i8 %5334, %5333
  %5336 = add i64 %5327, 64
  %5337 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5336
  %5338 = load i8, i8* %5337, align 1
  %5339 = icmp eq i64 %5281, %5336
  %5340 = sext i1 %5339 to i8
  %5341 = xor i8 %5340, -1
  %5342 = and i8 %5341, %5335
  %5343 = and i8 %5340, %5338
  %5344 = or i8 %5343, %5342
  %5345 = add i64 %5336, 64
  %5346 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5345
  %5347 = load i8, i8* %5346, align 1
  %5348 = icmp eq i64 %5281, %5345
  %5349 = sext i1 %5348 to i8
  %5350 = xor i8 %5349, -1
  %5351 = and i8 %5350, %5344
  %5352 = and i8 %5349, %5347
  %5353 = or i8 %5352, %5351
  %5354 = add i64 %5345, 64
  %5355 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5354
  %5356 = load i8, i8* %5355, align 1
  %5357 = icmp eq i64 %5281, %5354
  %5358 = sext i1 %5357 to i8
  %5359 = xor i8 %5358, -1
  %5360 = and i8 %5359, %5353
  %5361 = and i8 %5358, %5356
  %5362 = or i8 %5361, %5360
  %5363 = add i64 %5354, 64
  %5364 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5363
  %5365 = load i8, i8* %5364, align 1
  %5366 = icmp eq i64 %5281, %5363
  %5367 = sext i1 %5366 to i8
  %5368 = xor i8 %5367, -1
  %5369 = and i8 %5368, %5362
  %5370 = and i8 %5367, %5365
  %5371 = or i8 %5370, %5369
  %5372 = add i64 %5363, 64
  %5373 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5372
  %5374 = load i8, i8* %5373, align 1
  %5375 = icmp eq i64 %5281, %5372
  %5376 = sext i1 %5375 to i8
  %5377 = xor i8 %5376, -1
  %5378 = and i8 %5377, %5371
  %5379 = and i8 %5376, %5374
  %5380 = or i8 %5379, %5378
  %5381 = add i64 %5372, 64
  %5382 = icmp sge i64 %5381, 748
  %5383 = sext i1 %5382 to i64
  %5384 = xor i64 %5383, -1
  %5385 = and i64 %5383, 747
  %5386 = and i64 %5384, %5381
  %5387 = or i64 %5385, %5386
  %5388 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5387
  %5389 = load i8, i8* %5388, align 1
  %5390 = icmp eq i64 %5281, %5387
  %5391 = sext i1 %5390 to i8
  %5392 = xor i8 %5391, -1
  %5393 = and i8 %5392, %5380
  %5394 = and i8 %5391, %5389
  %Mitigated48 = or i8 %5394, %5393
  %5395 = zext i8 %Mitigated48 to i32
  %5396 = zext i8 %4847 to i32
  %5397 = xor i32 %5396, %5395
  %5398 = trunc i32 %5397 to i8
  %5399 = add i32 %5041, 138
  %5400 = zext i32 %5399 to i64
  %5401 = srem i64 %5400, 64
  %5402 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5401
  %5403 = load i8, i8* %5402, align 1
  %5404 = icmp eq i64 %5400, %5401
  %5405 = sext i1 %5404 to i8
  %5406 = xor i8 %5405, -1
  %5407 = and i8 %5406, 0
  %5408 = and i8 %5405, %5403
  %5409 = or i8 %5408, %5407
  %5410 = add i64 %5401, 64
  %5411 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5410
  %5412 = load i8, i8* %5411, align 1
  %5413 = icmp eq i64 %5400, %5410
  %5414 = sext i1 %5413 to i8
  %5415 = xor i8 %5414, -1
  %5416 = and i8 %5415, %5409
  %5417 = and i8 %5414, %5412
  %5418 = or i8 %5417, %5416
  %5419 = add i64 %5410, 64
  %5420 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5419
  %5421 = load i8, i8* %5420, align 1
  %5422 = icmp eq i64 %5400, %5419
  %5423 = sext i1 %5422 to i8
  %5424 = xor i8 %5423, -1
  %5425 = and i8 %5424, %5418
  %5426 = and i8 %5423, %5421
  %5427 = or i8 %5426, %5425
  %5428 = add i64 %5419, 64
  %5429 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5428
  %5430 = load i8, i8* %5429, align 1
  %5431 = icmp eq i64 %5400, %5428
  %5432 = sext i1 %5431 to i8
  %5433 = xor i8 %5432, -1
  %5434 = and i8 %5433, %5427
  %5435 = and i8 %5432, %5430
  %5436 = or i8 %5435, %5434
  %5437 = add i64 %5428, 64
  %5438 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5437
  %5439 = load i8, i8* %5438, align 1
  %5440 = icmp eq i64 %5400, %5437
  %5441 = sext i1 %5440 to i8
  %5442 = xor i8 %5441, -1
  %5443 = and i8 %5442, %5436
  %5444 = and i8 %5441, %5439
  %5445 = or i8 %5444, %5443
  %5446 = add i64 %5437, 64
  %5447 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5446
  %5448 = load i8, i8* %5447, align 1
  %5449 = icmp eq i64 %5400, %5446
  %5450 = sext i1 %5449 to i8
  %5451 = xor i8 %5450, -1
  %5452 = and i8 %5451, %5445
  %5453 = and i8 %5450, %5448
  %5454 = or i8 %5453, %5452
  %5455 = add i64 %5446, 64
  %5456 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5455
  %5457 = load i8, i8* %5456, align 1
  %5458 = icmp eq i64 %5400, %5455
  %5459 = sext i1 %5458 to i8
  %5460 = xor i8 %5459, -1
  %5461 = and i8 %5460, %5454
  %5462 = and i8 %5459, %5457
  %5463 = or i8 %5462, %5461
  %5464 = add i64 %5455, 64
  %5465 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5464
  %5466 = load i8, i8* %5465, align 1
  %5467 = icmp eq i64 %5400, %5464
  %5468 = sext i1 %5467 to i8
  %5469 = xor i8 %5468, -1
  %5470 = and i8 %5469, %5463
  %5471 = and i8 %5468, %5466
  %5472 = or i8 %5471, %5470
  %5473 = add i64 %5464, 64
  %5474 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5473
  %5475 = load i8, i8* %5474, align 1
  %5476 = icmp eq i64 %5400, %5473
  %5477 = sext i1 %5476 to i8
  %5478 = xor i8 %5477, -1
  %5479 = and i8 %5478, %5472
  %5480 = and i8 %5477, %5475
  %5481 = or i8 %5480, %5479
  %5482 = add i64 %5473, 64
  %5483 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5482
  %5484 = load i8, i8* %5483, align 1
  %5485 = icmp eq i64 %5400, %5482
  %5486 = sext i1 %5485 to i8
  %5487 = xor i8 %5486, -1
  %5488 = and i8 %5487, %5481
  %5489 = and i8 %5486, %5484
  %5490 = or i8 %5489, %5488
  %5491 = add i64 %5482, 64
  %5492 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5491
  %5493 = load i8, i8* %5492, align 1
  %5494 = icmp eq i64 %5400, %5491
  %5495 = sext i1 %5494 to i8
  %5496 = xor i8 %5495, -1
  %5497 = and i8 %5496, %5490
  %5498 = and i8 %5495, %5493
  %5499 = or i8 %5498, %5497
  %5500 = add i64 %5491, 64
  %5501 = icmp sge i64 %5500, 748
  %5502 = sext i1 %5501 to i64
  %5503 = xor i64 %5502, -1
  %5504 = and i64 %5502, 747
  %5505 = and i64 %5503, %5500
  %5506 = or i64 %5504, %5505
  %5507 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5506
  %5508 = load i8, i8* %5507, align 1
  %5509 = icmp eq i64 %5400, %5506
  %5510 = sext i1 %5509 to i8
  %5511 = xor i8 %5510, -1
  %5512 = and i8 %5511, %5499
  %5513 = and i8 %5510, %5508
  %Mitigated49 = or i8 %5513, %5512
  %5514 = zext i8 %Mitigated49 to i32
  %5515 = zext i8 %4966 to i32
  %5516 = xor i32 %5515, %5514
  %5517 = trunc i32 %5516 to i8
  %5518 = getelementptr inbounds i8, i8* %0, i64 10
  %5519 = load i8, i8* %5518, align 1
  %5520 = zext i8 %5519 to i64
  %5521 = srem i64 %5520, 32
  %5522 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5521
  %5523 = load i16, i16* %5522, align 2
  %5524 = icmp eq i64 %5520, %5521
  %5525 = sext i1 %5524 to i16
  %5526 = xor i16 %5525, -1
  %5527 = and i16 %5526, 0
  %5528 = and i16 %5525, %5523
  %5529 = or i16 %5528, %5527
  %5530 = add i64 %5521, 32
  %5531 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5530
  %5532 = load i16, i16* %5531, align 2
  %5533 = icmp eq i64 %5520, %5530
  %5534 = sext i1 %5533 to i16
  %5535 = xor i16 %5534, -1
  %5536 = and i16 %5535, %5529
  %5537 = and i16 %5534, %5532
  %5538 = or i16 %5537, %5536
  %5539 = add i64 %5530, 32
  %5540 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5539
  %5541 = load i16, i16* %5540, align 2
  %5542 = icmp eq i64 %5520, %5539
  %5543 = sext i1 %5542 to i16
  %5544 = xor i16 %5543, -1
  %5545 = and i16 %5544, %5538
  %5546 = and i16 %5543, %5541
  %5547 = or i16 %5546, %5545
  %5548 = add i64 %5539, 32
  %5549 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5548
  %5550 = load i16, i16* %5549, align 2
  %5551 = icmp eq i64 %5520, %5548
  %5552 = sext i1 %5551 to i16
  %5553 = xor i16 %5552, -1
  %5554 = and i16 %5553, %5547
  %5555 = and i16 %5552, %5550
  %5556 = or i16 %5555, %5554
  %5557 = add i64 %5548, 32
  %5558 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5557
  %5559 = load i16, i16* %5558, align 2
  %5560 = icmp eq i64 %5520, %5557
  %5561 = sext i1 %5560 to i16
  %5562 = xor i16 %5561, -1
  %5563 = and i16 %5562, %5556
  %5564 = and i16 %5561, %5559
  %5565 = or i16 %5564, %5563
  %5566 = add i64 %5557, 32
  %5567 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5566
  %5568 = load i16, i16* %5567, align 2
  %5569 = icmp eq i64 %5520, %5566
  %5570 = sext i1 %5569 to i16
  %5571 = xor i16 %5570, -1
  %5572 = and i16 %5571, %5565
  %5573 = and i16 %5570, %5568
  %5574 = or i16 %5573, %5572
  %5575 = add i64 %5566, 32
  %5576 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5575
  %5577 = load i16, i16* %5576, align 2
  %5578 = icmp eq i64 %5520, %5575
  %5579 = sext i1 %5578 to i16
  %5580 = xor i16 %5579, -1
  %5581 = and i16 %5580, %5574
  %5582 = and i16 %5579, %5577
  %5583 = or i16 %5582, %5581
  %5584 = add i64 %5575, 32
  %5585 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %5584
  %5586 = load i16, i16* %5585, align 2
  %5587 = icmp eq i64 %5520, %5584
  %5588 = sext i1 %5587 to i16
  %5589 = xor i16 %5588, -1
  %5590 = and i16 %5589, %5583
  %5591 = and i16 %5588, %5586
  %Mitigated50 = or i16 %5591, %5590
  %5592 = zext i16 %Mitigated50 to i32
  %5593 = add i32 %5592, 138
  %5594 = zext i32 %5593 to i64
  %5595 = srem i64 %5594, 64
  %5596 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5595
  %5597 = load i8, i8* %5596, align 1
  %5598 = icmp eq i64 %5594, %5595
  %5599 = sext i1 %5598 to i8
  %5600 = xor i8 %5599, -1
  %5601 = and i8 %5600, 0
  %5602 = and i8 %5599, %5597
  %5603 = or i8 %5602, %5601
  %5604 = add i64 %5595, 64
  %5605 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5604
  %5606 = load i8, i8* %5605, align 1
  %5607 = icmp eq i64 %5594, %5604
  %5608 = sext i1 %5607 to i8
  %5609 = xor i8 %5608, -1
  %5610 = and i8 %5609, %5603
  %5611 = and i8 %5608, %5606
  %5612 = or i8 %5611, %5610
  %5613 = add i64 %5604, 64
  %5614 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5613
  %5615 = load i8, i8* %5614, align 1
  %5616 = icmp eq i64 %5594, %5613
  %5617 = sext i1 %5616 to i8
  %5618 = xor i8 %5617, -1
  %5619 = and i8 %5618, %5612
  %5620 = and i8 %5617, %5615
  %5621 = or i8 %5620, %5619
  %5622 = add i64 %5613, 64
  %5623 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5622
  %5624 = load i8, i8* %5623, align 1
  %5625 = icmp eq i64 %5594, %5622
  %5626 = sext i1 %5625 to i8
  %5627 = xor i8 %5626, -1
  %5628 = and i8 %5627, %5621
  %5629 = and i8 %5626, %5624
  %5630 = or i8 %5629, %5628
  %5631 = add i64 %5622, 64
  %5632 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5631
  %5633 = load i8, i8* %5632, align 1
  %5634 = icmp eq i64 %5594, %5631
  %5635 = sext i1 %5634 to i8
  %5636 = xor i8 %5635, -1
  %5637 = and i8 %5636, %5630
  %5638 = and i8 %5635, %5633
  %5639 = or i8 %5638, %5637
  %5640 = add i64 %5631, 64
  %5641 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5640
  %5642 = load i8, i8* %5641, align 1
  %5643 = icmp eq i64 %5594, %5640
  %5644 = sext i1 %5643 to i8
  %5645 = xor i8 %5644, -1
  %5646 = and i8 %5645, %5639
  %5647 = and i8 %5644, %5642
  %5648 = or i8 %5647, %5646
  %5649 = add i64 %5640, 64
  %5650 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5649
  %5651 = load i8, i8* %5650, align 1
  %5652 = icmp eq i64 %5594, %5649
  %5653 = sext i1 %5652 to i8
  %5654 = xor i8 %5653, -1
  %5655 = and i8 %5654, %5648
  %5656 = and i8 %5653, %5651
  %5657 = or i8 %5656, %5655
  %5658 = add i64 %5649, 64
  %5659 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5658
  %5660 = load i8, i8* %5659, align 1
  %5661 = icmp eq i64 %5594, %5658
  %5662 = sext i1 %5661 to i8
  %5663 = xor i8 %5662, -1
  %5664 = and i8 %5663, %5657
  %5665 = and i8 %5662, %5660
  %5666 = or i8 %5665, %5664
  %5667 = add i64 %5658, 64
  %5668 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5667
  %5669 = load i8, i8* %5668, align 1
  %5670 = icmp eq i64 %5594, %5667
  %5671 = sext i1 %5670 to i8
  %5672 = xor i8 %5671, -1
  %5673 = and i8 %5672, %5666
  %5674 = and i8 %5671, %5669
  %5675 = or i8 %5674, %5673
  %5676 = add i64 %5667, 64
  %5677 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5676
  %5678 = load i8, i8* %5677, align 1
  %5679 = icmp eq i64 %5594, %5676
  %5680 = sext i1 %5679 to i8
  %5681 = xor i8 %5680, -1
  %5682 = and i8 %5681, %5675
  %5683 = and i8 %5680, %5678
  %5684 = or i8 %5683, %5682
  %5685 = add i64 %5676, 64
  %5686 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5685
  %5687 = load i8, i8* %5686, align 1
  %5688 = icmp eq i64 %5594, %5685
  %5689 = sext i1 %5688 to i8
  %5690 = xor i8 %5689, -1
  %5691 = and i8 %5690, %5684
  %5692 = and i8 %5689, %5687
  %5693 = or i8 %5692, %5691
  %5694 = add i64 %5685, 64
  %5695 = icmp sge i64 %5694, 748
  %5696 = sext i1 %5695 to i64
  %5697 = xor i64 %5696, -1
  %5698 = and i64 %5696, 747
  %5699 = and i64 %5697, %5694
  %5700 = or i64 %5698, %5699
  %5701 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5700
  %5702 = load i8, i8* %5701, align 1
  %5703 = icmp eq i64 %5594, %5700
  %5704 = sext i1 %5703 to i8
  %5705 = xor i8 %5704, -1
  %5706 = and i8 %5705, %5693
  %5707 = and i8 %5704, %5702
  %Mitigated51 = or i8 %5707, %5706
  %5708 = zext i8 %Mitigated51 to i32
  %5709 = zext i8 %5160 to i32
  %5710 = xor i32 %5709, %5708
  %5711 = trunc i32 %5710 to i8
  %5712 = add i32 %5592, 213
  %5713 = zext i32 %5712 to i64
  %5714 = srem i64 %5713, 64
  %5715 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5714
  %5716 = load i8, i8* %5715, align 1
  %5717 = icmp eq i64 %5713, %5714
  %5718 = sext i1 %5717 to i8
  %5719 = xor i8 %5718, -1
  %5720 = and i8 %5719, 0
  %5721 = and i8 %5718, %5716
  %5722 = or i8 %5721, %5720
  %5723 = add i64 %5714, 64
  %5724 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5723
  %5725 = load i8, i8* %5724, align 1
  %5726 = icmp eq i64 %5713, %5723
  %5727 = sext i1 %5726 to i8
  %5728 = xor i8 %5727, -1
  %5729 = and i8 %5728, %5722
  %5730 = and i8 %5727, %5725
  %5731 = or i8 %5730, %5729
  %5732 = add i64 %5723, 64
  %5733 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5732
  %5734 = load i8, i8* %5733, align 1
  %5735 = icmp eq i64 %5713, %5732
  %5736 = sext i1 %5735 to i8
  %5737 = xor i8 %5736, -1
  %5738 = and i8 %5737, %5731
  %5739 = and i8 %5736, %5734
  %5740 = or i8 %5739, %5738
  %5741 = add i64 %5732, 64
  %5742 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5741
  %5743 = load i8, i8* %5742, align 1
  %5744 = icmp eq i64 %5713, %5741
  %5745 = sext i1 %5744 to i8
  %5746 = xor i8 %5745, -1
  %5747 = and i8 %5746, %5740
  %5748 = and i8 %5745, %5743
  %5749 = or i8 %5748, %5747
  %5750 = add i64 %5741, 64
  %5751 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5750
  %5752 = load i8, i8* %5751, align 1
  %5753 = icmp eq i64 %5713, %5750
  %5754 = sext i1 %5753 to i8
  %5755 = xor i8 %5754, -1
  %5756 = and i8 %5755, %5749
  %5757 = and i8 %5754, %5752
  %5758 = or i8 %5757, %5756
  %5759 = add i64 %5750, 64
  %5760 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5759
  %5761 = load i8, i8* %5760, align 1
  %5762 = icmp eq i64 %5713, %5759
  %5763 = sext i1 %5762 to i8
  %5764 = xor i8 %5763, -1
  %5765 = and i8 %5764, %5758
  %5766 = and i8 %5763, %5761
  %5767 = or i8 %5766, %5765
  %5768 = add i64 %5759, 64
  %5769 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5768
  %5770 = load i8, i8* %5769, align 1
  %5771 = icmp eq i64 %5713, %5768
  %5772 = sext i1 %5771 to i8
  %5773 = xor i8 %5772, -1
  %5774 = and i8 %5773, %5767
  %5775 = and i8 %5772, %5770
  %5776 = or i8 %5775, %5774
  %5777 = add i64 %5768, 64
  %5778 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5777
  %5779 = load i8, i8* %5778, align 1
  %5780 = icmp eq i64 %5713, %5777
  %5781 = sext i1 %5780 to i8
  %5782 = xor i8 %5781, -1
  %5783 = and i8 %5782, %5776
  %5784 = and i8 %5781, %5779
  %5785 = or i8 %5784, %5783
  %5786 = add i64 %5777, 64
  %5787 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5786
  %5788 = load i8, i8* %5787, align 1
  %5789 = icmp eq i64 %5713, %5786
  %5790 = sext i1 %5789 to i8
  %5791 = xor i8 %5790, -1
  %5792 = and i8 %5791, %5785
  %5793 = and i8 %5790, %5788
  %5794 = or i8 %5793, %5792
  %5795 = add i64 %5786, 64
  %5796 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5795
  %5797 = load i8, i8* %5796, align 1
  %5798 = icmp eq i64 %5713, %5795
  %5799 = sext i1 %5798 to i8
  %5800 = xor i8 %5799, -1
  %5801 = and i8 %5800, %5794
  %5802 = and i8 %5799, %5797
  %5803 = or i8 %5802, %5801
  %5804 = add i64 %5795, 64
  %5805 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5804
  %5806 = load i8, i8* %5805, align 1
  %5807 = icmp eq i64 %5713, %5804
  %5808 = sext i1 %5807 to i8
  %5809 = xor i8 %5808, -1
  %5810 = and i8 %5809, %5803
  %5811 = and i8 %5808, %5806
  %5812 = or i8 %5811, %5810
  %5813 = add i64 %5804, 64
  %5814 = icmp sge i64 %5813, 748
  %5815 = sext i1 %5814 to i64
  %5816 = xor i64 %5815, -1
  %5817 = and i64 %5815, 747
  %5818 = and i64 %5816, %5813
  %5819 = or i64 %5817, %5818
  %5820 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5819
  %5821 = load i8, i8* %5820, align 1
  %5822 = icmp eq i64 %5713, %5819
  %5823 = sext i1 %5822 to i8
  %5824 = xor i8 %5823, -1
  %5825 = and i8 %5824, %5812
  %5826 = and i8 %5823, %5821
  %Mitigated52 = or i8 %5826, %5825
  %5827 = zext i8 %Mitigated52 to i32
  %5828 = zext i8 %5279 to i32
  %5829 = xor i32 %5828, %5827
  %5830 = trunc i32 %5829 to i8
  %5831 = add i32 %5592, 191
  %5832 = zext i32 %5831 to i64
  %5833 = srem i64 %5832, 64
  %5834 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5833
  %5835 = load i8, i8* %5834, align 1
  %5836 = icmp eq i64 %5832, %5833
  %5837 = sext i1 %5836 to i8
  %5838 = xor i8 %5837, -1
  %5839 = and i8 %5838, 0
  %5840 = and i8 %5837, %5835
  %5841 = or i8 %5840, %5839
  %5842 = add i64 %5833, 64
  %5843 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5842
  %5844 = load i8, i8* %5843, align 1
  %5845 = icmp eq i64 %5832, %5842
  %5846 = sext i1 %5845 to i8
  %5847 = xor i8 %5846, -1
  %5848 = and i8 %5847, %5841
  %5849 = and i8 %5846, %5844
  %5850 = or i8 %5849, %5848
  %5851 = add i64 %5842, 64
  %5852 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5851
  %5853 = load i8, i8* %5852, align 1
  %5854 = icmp eq i64 %5832, %5851
  %5855 = sext i1 %5854 to i8
  %5856 = xor i8 %5855, -1
  %5857 = and i8 %5856, %5850
  %5858 = and i8 %5855, %5853
  %5859 = or i8 %5858, %5857
  %5860 = add i64 %5851, 64
  %5861 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5860
  %5862 = load i8, i8* %5861, align 1
  %5863 = icmp eq i64 %5832, %5860
  %5864 = sext i1 %5863 to i8
  %5865 = xor i8 %5864, -1
  %5866 = and i8 %5865, %5859
  %5867 = and i8 %5864, %5862
  %5868 = or i8 %5867, %5866
  %5869 = add i64 %5860, 64
  %5870 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5869
  %5871 = load i8, i8* %5870, align 1
  %5872 = icmp eq i64 %5832, %5869
  %5873 = sext i1 %5872 to i8
  %5874 = xor i8 %5873, -1
  %5875 = and i8 %5874, %5868
  %5876 = and i8 %5873, %5871
  %5877 = or i8 %5876, %5875
  %5878 = add i64 %5869, 64
  %5879 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5878
  %5880 = load i8, i8* %5879, align 1
  %5881 = icmp eq i64 %5832, %5878
  %5882 = sext i1 %5881 to i8
  %5883 = xor i8 %5882, -1
  %5884 = and i8 %5883, %5877
  %5885 = and i8 %5882, %5880
  %5886 = or i8 %5885, %5884
  %5887 = add i64 %5878, 64
  %5888 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5887
  %5889 = load i8, i8* %5888, align 1
  %5890 = icmp eq i64 %5832, %5887
  %5891 = sext i1 %5890 to i8
  %5892 = xor i8 %5891, -1
  %5893 = and i8 %5892, %5886
  %5894 = and i8 %5891, %5889
  %5895 = or i8 %5894, %5893
  %5896 = add i64 %5887, 64
  %5897 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5896
  %5898 = load i8, i8* %5897, align 1
  %5899 = icmp eq i64 %5832, %5896
  %5900 = sext i1 %5899 to i8
  %5901 = xor i8 %5900, -1
  %5902 = and i8 %5901, %5895
  %5903 = and i8 %5900, %5898
  %5904 = or i8 %5903, %5902
  %5905 = add i64 %5896, 64
  %5906 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5905
  %5907 = load i8, i8* %5906, align 1
  %5908 = icmp eq i64 %5832, %5905
  %5909 = sext i1 %5908 to i8
  %5910 = xor i8 %5909, -1
  %5911 = and i8 %5910, %5904
  %5912 = and i8 %5909, %5907
  %5913 = or i8 %5912, %5911
  %5914 = add i64 %5905, 64
  %5915 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5914
  %5916 = load i8, i8* %5915, align 1
  %5917 = icmp eq i64 %5832, %5914
  %5918 = sext i1 %5917 to i8
  %5919 = xor i8 %5918, -1
  %5920 = and i8 %5919, %5913
  %5921 = and i8 %5918, %5916
  %5922 = or i8 %5921, %5920
  %5923 = add i64 %5914, 64
  %5924 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5923
  %5925 = load i8, i8* %5924, align 1
  %5926 = icmp eq i64 %5832, %5923
  %5927 = sext i1 %5926 to i8
  %5928 = xor i8 %5927, -1
  %5929 = and i8 %5928, %5922
  %5930 = and i8 %5927, %5925
  %5931 = or i8 %5930, %5929
  %5932 = add i64 %5923, 64
  %5933 = icmp sge i64 %5932, 748
  %5934 = sext i1 %5933 to i64
  %5935 = xor i64 %5934, -1
  %5936 = and i64 %5934, 747
  %5937 = and i64 %5935, %5932
  %5938 = or i64 %5936, %5937
  %5939 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5938
  %5940 = load i8, i8* %5939, align 1
  %5941 = icmp eq i64 %5832, %5938
  %5942 = sext i1 %5941 to i8
  %5943 = xor i8 %5942, -1
  %5944 = and i8 %5943, %5931
  %5945 = and i8 %5942, %5940
  %Mitigated53 = or i8 %5945, %5944
  %5946 = zext i8 %Mitigated53 to i32
  %5947 = zext i8 %5398 to i32
  %5948 = xor i32 %5947, %5946
  %5949 = trunc i32 %5948 to i8
  %5950 = add i32 %5592, 209
  %5951 = zext i32 %5950 to i64
  %5952 = srem i64 %5951, 64
  %5953 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5952
  %5954 = load i8, i8* %5953, align 1
  %5955 = icmp eq i64 %5951, %5952
  %5956 = sext i1 %5955 to i8
  %5957 = xor i8 %5956, -1
  %5958 = and i8 %5957, 0
  %5959 = and i8 %5956, %5954
  %5960 = or i8 %5959, %5958
  %5961 = add i64 %5952, 64
  %5962 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5961
  %5963 = load i8, i8* %5962, align 1
  %5964 = icmp eq i64 %5951, %5961
  %5965 = sext i1 %5964 to i8
  %5966 = xor i8 %5965, -1
  %5967 = and i8 %5966, %5960
  %5968 = and i8 %5965, %5963
  %5969 = or i8 %5968, %5967
  %5970 = add i64 %5961, 64
  %5971 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5970
  %5972 = load i8, i8* %5971, align 1
  %5973 = icmp eq i64 %5951, %5970
  %5974 = sext i1 %5973 to i8
  %5975 = xor i8 %5974, -1
  %5976 = and i8 %5975, %5969
  %5977 = and i8 %5974, %5972
  %5978 = or i8 %5977, %5976
  %5979 = add i64 %5970, 64
  %5980 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5979
  %5981 = load i8, i8* %5980, align 1
  %5982 = icmp eq i64 %5951, %5979
  %5983 = sext i1 %5982 to i8
  %5984 = xor i8 %5983, -1
  %5985 = and i8 %5984, %5978
  %5986 = and i8 %5983, %5981
  %5987 = or i8 %5986, %5985
  %5988 = add i64 %5979, 64
  %5989 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5988
  %5990 = load i8, i8* %5989, align 1
  %5991 = icmp eq i64 %5951, %5988
  %5992 = sext i1 %5991 to i8
  %5993 = xor i8 %5992, -1
  %5994 = and i8 %5993, %5987
  %5995 = and i8 %5992, %5990
  %5996 = or i8 %5995, %5994
  %5997 = add i64 %5988, 64
  %5998 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %5997
  %5999 = load i8, i8* %5998, align 1
  %6000 = icmp eq i64 %5951, %5997
  %6001 = sext i1 %6000 to i8
  %6002 = xor i8 %6001, -1
  %6003 = and i8 %6002, %5996
  %6004 = and i8 %6001, %5999
  %6005 = or i8 %6004, %6003
  %6006 = add i64 %5997, 64
  %6007 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6006
  %6008 = load i8, i8* %6007, align 1
  %6009 = icmp eq i64 %5951, %6006
  %6010 = sext i1 %6009 to i8
  %6011 = xor i8 %6010, -1
  %6012 = and i8 %6011, %6005
  %6013 = and i8 %6010, %6008
  %6014 = or i8 %6013, %6012
  %6015 = add i64 %6006, 64
  %6016 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6015
  %6017 = load i8, i8* %6016, align 1
  %6018 = icmp eq i64 %5951, %6015
  %6019 = sext i1 %6018 to i8
  %6020 = xor i8 %6019, -1
  %6021 = and i8 %6020, %6014
  %6022 = and i8 %6019, %6017
  %6023 = or i8 %6022, %6021
  %6024 = add i64 %6015, 64
  %6025 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6024
  %6026 = load i8, i8* %6025, align 1
  %6027 = icmp eq i64 %5951, %6024
  %6028 = sext i1 %6027 to i8
  %6029 = xor i8 %6028, -1
  %6030 = and i8 %6029, %6023
  %6031 = and i8 %6028, %6026
  %6032 = or i8 %6031, %6030
  %6033 = add i64 %6024, 64
  %6034 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6033
  %6035 = load i8, i8* %6034, align 1
  %6036 = icmp eq i64 %5951, %6033
  %6037 = sext i1 %6036 to i8
  %6038 = xor i8 %6037, -1
  %6039 = and i8 %6038, %6032
  %6040 = and i8 %6037, %6035
  %6041 = or i8 %6040, %6039
  %6042 = add i64 %6033, 64
  %6043 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6042
  %6044 = load i8, i8* %6043, align 1
  %6045 = icmp eq i64 %5951, %6042
  %6046 = sext i1 %6045 to i8
  %6047 = xor i8 %6046, -1
  %6048 = and i8 %6047, %6041
  %6049 = and i8 %6046, %6044
  %6050 = or i8 %6049, %6048
  %6051 = add i64 %6042, 64
  %6052 = icmp sge i64 %6051, 748
  %6053 = sext i1 %6052 to i64
  %6054 = xor i64 %6053, -1
  %6055 = and i64 %6053, 747
  %6056 = and i64 %6054, %6051
  %6057 = or i64 %6055, %6056
  %6058 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6057
  %6059 = load i8, i8* %6058, align 1
  %6060 = icmp eq i64 %5951, %6057
  %6061 = sext i1 %6060 to i8
  %6062 = xor i8 %6061, -1
  %6063 = and i8 %6062, %6050
  %6064 = and i8 %6061, %6059
  %Mitigated54 = or i8 %6064, %6063
  %6065 = zext i8 %Mitigated54 to i32
  %6066 = zext i8 %5517 to i32
  %6067 = xor i32 %6066, %6065
  %6068 = trunc i32 %6067 to i8
  %6069 = getelementptr inbounds i8, i8* %0, i64 11
  %6070 = load i8, i8* %6069, align 1
  %6071 = zext i8 %6070 to i64
  %6072 = srem i64 %6071, 32
  %6073 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6072
  %6074 = load i16, i16* %6073, align 2
  %6075 = icmp eq i64 %6071, %6072
  %6076 = sext i1 %6075 to i16
  %6077 = xor i16 %6076, -1
  %6078 = and i16 %6077, 0
  %6079 = and i16 %6076, %6074
  %6080 = or i16 %6079, %6078
  %6081 = add i64 %6072, 32
  %6082 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6081
  %6083 = load i16, i16* %6082, align 2
  %6084 = icmp eq i64 %6071, %6081
  %6085 = sext i1 %6084 to i16
  %6086 = xor i16 %6085, -1
  %6087 = and i16 %6086, %6080
  %6088 = and i16 %6085, %6083
  %6089 = or i16 %6088, %6087
  %6090 = add i64 %6081, 32
  %6091 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6090
  %6092 = load i16, i16* %6091, align 2
  %6093 = icmp eq i64 %6071, %6090
  %6094 = sext i1 %6093 to i16
  %6095 = xor i16 %6094, -1
  %6096 = and i16 %6095, %6089
  %6097 = and i16 %6094, %6092
  %6098 = or i16 %6097, %6096
  %6099 = add i64 %6090, 32
  %6100 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6099
  %6101 = load i16, i16* %6100, align 2
  %6102 = icmp eq i64 %6071, %6099
  %6103 = sext i1 %6102 to i16
  %6104 = xor i16 %6103, -1
  %6105 = and i16 %6104, %6098
  %6106 = and i16 %6103, %6101
  %6107 = or i16 %6106, %6105
  %6108 = add i64 %6099, 32
  %6109 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6108
  %6110 = load i16, i16* %6109, align 2
  %6111 = icmp eq i64 %6071, %6108
  %6112 = sext i1 %6111 to i16
  %6113 = xor i16 %6112, -1
  %6114 = and i16 %6113, %6107
  %6115 = and i16 %6112, %6110
  %6116 = or i16 %6115, %6114
  %6117 = add i64 %6108, 32
  %6118 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6117
  %6119 = load i16, i16* %6118, align 2
  %6120 = icmp eq i64 %6071, %6117
  %6121 = sext i1 %6120 to i16
  %6122 = xor i16 %6121, -1
  %6123 = and i16 %6122, %6116
  %6124 = and i16 %6121, %6119
  %6125 = or i16 %6124, %6123
  %6126 = add i64 %6117, 32
  %6127 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6126
  %6128 = load i16, i16* %6127, align 2
  %6129 = icmp eq i64 %6071, %6126
  %6130 = sext i1 %6129 to i16
  %6131 = xor i16 %6130, -1
  %6132 = and i16 %6131, %6125
  %6133 = and i16 %6130, %6128
  %6134 = or i16 %6133, %6132
  %6135 = add i64 %6126, 32
  %6136 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6135
  %6137 = load i16, i16* %6136, align 2
  %6138 = icmp eq i64 %6071, %6135
  %6139 = sext i1 %6138 to i16
  %6140 = xor i16 %6139, -1
  %6141 = and i16 %6140, %6134
  %6142 = and i16 %6139, %6137
  %Mitigated55 = or i16 %6142, %6141
  %6143 = zext i16 %Mitigated55 to i32
  %6144 = add i32 %6143, 209
  %6145 = zext i32 %6144 to i64
  %6146 = srem i64 %6145, 64
  %6147 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6146
  %6148 = load i8, i8* %6147, align 1
  %6149 = icmp eq i64 %6145, %6146
  %6150 = sext i1 %6149 to i8
  %6151 = xor i8 %6150, -1
  %6152 = and i8 %6151, 0
  %6153 = and i8 %6150, %6148
  %6154 = or i8 %6153, %6152
  %6155 = add i64 %6146, 64
  %6156 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6155
  %6157 = load i8, i8* %6156, align 1
  %6158 = icmp eq i64 %6145, %6155
  %6159 = sext i1 %6158 to i8
  %6160 = xor i8 %6159, -1
  %6161 = and i8 %6160, %6154
  %6162 = and i8 %6159, %6157
  %6163 = or i8 %6162, %6161
  %6164 = add i64 %6155, 64
  %6165 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6164
  %6166 = load i8, i8* %6165, align 1
  %6167 = icmp eq i64 %6145, %6164
  %6168 = sext i1 %6167 to i8
  %6169 = xor i8 %6168, -1
  %6170 = and i8 %6169, %6163
  %6171 = and i8 %6168, %6166
  %6172 = or i8 %6171, %6170
  %6173 = add i64 %6164, 64
  %6174 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6173
  %6175 = load i8, i8* %6174, align 1
  %6176 = icmp eq i64 %6145, %6173
  %6177 = sext i1 %6176 to i8
  %6178 = xor i8 %6177, -1
  %6179 = and i8 %6178, %6172
  %6180 = and i8 %6177, %6175
  %6181 = or i8 %6180, %6179
  %6182 = add i64 %6173, 64
  %6183 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6182
  %6184 = load i8, i8* %6183, align 1
  %6185 = icmp eq i64 %6145, %6182
  %6186 = sext i1 %6185 to i8
  %6187 = xor i8 %6186, -1
  %6188 = and i8 %6187, %6181
  %6189 = and i8 %6186, %6184
  %6190 = or i8 %6189, %6188
  %6191 = add i64 %6182, 64
  %6192 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6191
  %6193 = load i8, i8* %6192, align 1
  %6194 = icmp eq i64 %6145, %6191
  %6195 = sext i1 %6194 to i8
  %6196 = xor i8 %6195, -1
  %6197 = and i8 %6196, %6190
  %6198 = and i8 %6195, %6193
  %6199 = or i8 %6198, %6197
  %6200 = add i64 %6191, 64
  %6201 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6200
  %6202 = load i8, i8* %6201, align 1
  %6203 = icmp eq i64 %6145, %6200
  %6204 = sext i1 %6203 to i8
  %6205 = xor i8 %6204, -1
  %6206 = and i8 %6205, %6199
  %6207 = and i8 %6204, %6202
  %6208 = or i8 %6207, %6206
  %6209 = add i64 %6200, 64
  %6210 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6209
  %6211 = load i8, i8* %6210, align 1
  %6212 = icmp eq i64 %6145, %6209
  %6213 = sext i1 %6212 to i8
  %6214 = xor i8 %6213, -1
  %6215 = and i8 %6214, %6208
  %6216 = and i8 %6213, %6211
  %6217 = or i8 %6216, %6215
  %6218 = add i64 %6209, 64
  %6219 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6218
  %6220 = load i8, i8* %6219, align 1
  %6221 = icmp eq i64 %6145, %6218
  %6222 = sext i1 %6221 to i8
  %6223 = xor i8 %6222, -1
  %6224 = and i8 %6223, %6217
  %6225 = and i8 %6222, %6220
  %6226 = or i8 %6225, %6224
  %6227 = add i64 %6218, 64
  %6228 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6227
  %6229 = load i8, i8* %6228, align 1
  %6230 = icmp eq i64 %6145, %6227
  %6231 = sext i1 %6230 to i8
  %6232 = xor i8 %6231, -1
  %6233 = and i8 %6232, %6226
  %6234 = and i8 %6231, %6229
  %6235 = or i8 %6234, %6233
  %6236 = add i64 %6227, 64
  %6237 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6236
  %6238 = load i8, i8* %6237, align 1
  %6239 = icmp eq i64 %6145, %6236
  %6240 = sext i1 %6239 to i8
  %6241 = xor i8 %6240, -1
  %6242 = and i8 %6241, %6235
  %6243 = and i8 %6240, %6238
  %6244 = or i8 %6243, %6242
  %6245 = add i64 %6236, 64
  %6246 = icmp sge i64 %6245, 748
  %6247 = sext i1 %6246 to i64
  %6248 = xor i64 %6247, -1
  %6249 = and i64 %6247, 747
  %6250 = and i64 %6248, %6245
  %6251 = or i64 %6249, %6250
  %6252 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6251
  %6253 = load i8, i8* %6252, align 1
  %6254 = icmp eq i64 %6145, %6251
  %6255 = sext i1 %6254 to i8
  %6256 = xor i8 %6255, -1
  %6257 = and i8 %6256, %6244
  %6258 = and i8 %6255, %6253
  %Mitigated56 = or i8 %6258, %6257
  %6259 = zext i8 %Mitigated56 to i32
  %6260 = zext i8 %5711 to i32
  %6261 = xor i32 %6260, %6259
  %6262 = trunc i32 %6261 to i8
  %6263 = add i32 %6143, 127
  %6264 = zext i32 %6263 to i64
  %6265 = srem i64 %6264, 64
  %6266 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6265
  %6267 = load i8, i8* %6266, align 1
  %6268 = icmp eq i64 %6264, %6265
  %6269 = sext i1 %6268 to i8
  %6270 = xor i8 %6269, -1
  %6271 = and i8 %6270, 0
  %6272 = and i8 %6269, %6267
  %6273 = or i8 %6272, %6271
  %6274 = add i64 %6265, 64
  %6275 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6274
  %6276 = load i8, i8* %6275, align 1
  %6277 = icmp eq i64 %6264, %6274
  %6278 = sext i1 %6277 to i8
  %6279 = xor i8 %6278, -1
  %6280 = and i8 %6279, %6273
  %6281 = and i8 %6278, %6276
  %6282 = or i8 %6281, %6280
  %6283 = add i64 %6274, 64
  %6284 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6283
  %6285 = load i8, i8* %6284, align 1
  %6286 = icmp eq i64 %6264, %6283
  %6287 = sext i1 %6286 to i8
  %6288 = xor i8 %6287, -1
  %6289 = and i8 %6288, %6282
  %6290 = and i8 %6287, %6285
  %6291 = or i8 %6290, %6289
  %6292 = add i64 %6283, 64
  %6293 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6292
  %6294 = load i8, i8* %6293, align 1
  %6295 = icmp eq i64 %6264, %6292
  %6296 = sext i1 %6295 to i8
  %6297 = xor i8 %6296, -1
  %6298 = and i8 %6297, %6291
  %6299 = and i8 %6296, %6294
  %6300 = or i8 %6299, %6298
  %6301 = add i64 %6292, 64
  %6302 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6301
  %6303 = load i8, i8* %6302, align 1
  %6304 = icmp eq i64 %6264, %6301
  %6305 = sext i1 %6304 to i8
  %6306 = xor i8 %6305, -1
  %6307 = and i8 %6306, %6300
  %6308 = and i8 %6305, %6303
  %6309 = or i8 %6308, %6307
  %6310 = add i64 %6301, 64
  %6311 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6310
  %6312 = load i8, i8* %6311, align 1
  %6313 = icmp eq i64 %6264, %6310
  %6314 = sext i1 %6313 to i8
  %6315 = xor i8 %6314, -1
  %6316 = and i8 %6315, %6309
  %6317 = and i8 %6314, %6312
  %6318 = or i8 %6317, %6316
  %6319 = add i64 %6310, 64
  %6320 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6319
  %6321 = load i8, i8* %6320, align 1
  %6322 = icmp eq i64 %6264, %6319
  %6323 = sext i1 %6322 to i8
  %6324 = xor i8 %6323, -1
  %6325 = and i8 %6324, %6318
  %6326 = and i8 %6323, %6321
  %6327 = or i8 %6326, %6325
  %6328 = add i64 %6319, 64
  %6329 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6328
  %6330 = load i8, i8* %6329, align 1
  %6331 = icmp eq i64 %6264, %6328
  %6332 = sext i1 %6331 to i8
  %6333 = xor i8 %6332, -1
  %6334 = and i8 %6333, %6327
  %6335 = and i8 %6332, %6330
  %6336 = or i8 %6335, %6334
  %6337 = add i64 %6328, 64
  %6338 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6337
  %6339 = load i8, i8* %6338, align 1
  %6340 = icmp eq i64 %6264, %6337
  %6341 = sext i1 %6340 to i8
  %6342 = xor i8 %6341, -1
  %6343 = and i8 %6342, %6336
  %6344 = and i8 %6341, %6339
  %6345 = or i8 %6344, %6343
  %6346 = add i64 %6337, 64
  %6347 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6346
  %6348 = load i8, i8* %6347, align 1
  %6349 = icmp eq i64 %6264, %6346
  %6350 = sext i1 %6349 to i8
  %6351 = xor i8 %6350, -1
  %6352 = and i8 %6351, %6345
  %6353 = and i8 %6350, %6348
  %6354 = or i8 %6353, %6352
  %6355 = add i64 %6346, 64
  %6356 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6355
  %6357 = load i8, i8* %6356, align 1
  %6358 = icmp eq i64 %6264, %6355
  %6359 = sext i1 %6358 to i8
  %6360 = xor i8 %6359, -1
  %6361 = and i8 %6360, %6354
  %6362 = and i8 %6359, %6357
  %6363 = or i8 %6362, %6361
  %6364 = add i64 %6355, 64
  %6365 = icmp sge i64 %6364, 748
  %6366 = sext i1 %6365 to i64
  %6367 = xor i64 %6366, -1
  %6368 = and i64 %6366, 747
  %6369 = and i64 %6367, %6364
  %6370 = or i64 %6368, %6369
  %6371 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6370
  %6372 = load i8, i8* %6371, align 1
  %6373 = icmp eq i64 %6264, %6370
  %6374 = sext i1 %6373 to i8
  %6375 = xor i8 %6374, -1
  %6376 = and i8 %6375, %6363
  %6377 = and i8 %6374, %6372
  %Mitigated57 = or i8 %6377, %6376
  %6378 = zext i8 %Mitigated57 to i32
  %6379 = zext i8 %5830 to i32
  %6380 = xor i32 %6379, %6378
  %6381 = trunc i32 %6380 to i8
  %6382 = add i32 %6143, 61
  %6383 = zext i32 %6382 to i64
  %6384 = srem i64 %6383, 64
  %6385 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6384
  %6386 = load i8, i8* %6385, align 1
  %6387 = icmp eq i64 %6383, %6384
  %6388 = sext i1 %6387 to i8
  %6389 = xor i8 %6388, -1
  %6390 = and i8 %6389, 0
  %6391 = and i8 %6388, %6386
  %6392 = or i8 %6391, %6390
  %6393 = add i64 %6384, 64
  %6394 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6393
  %6395 = load i8, i8* %6394, align 1
  %6396 = icmp eq i64 %6383, %6393
  %6397 = sext i1 %6396 to i8
  %6398 = xor i8 %6397, -1
  %6399 = and i8 %6398, %6392
  %6400 = and i8 %6397, %6395
  %6401 = or i8 %6400, %6399
  %6402 = add i64 %6393, 64
  %6403 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6402
  %6404 = load i8, i8* %6403, align 1
  %6405 = icmp eq i64 %6383, %6402
  %6406 = sext i1 %6405 to i8
  %6407 = xor i8 %6406, -1
  %6408 = and i8 %6407, %6401
  %6409 = and i8 %6406, %6404
  %6410 = or i8 %6409, %6408
  %6411 = add i64 %6402, 64
  %6412 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6411
  %6413 = load i8, i8* %6412, align 1
  %6414 = icmp eq i64 %6383, %6411
  %6415 = sext i1 %6414 to i8
  %6416 = xor i8 %6415, -1
  %6417 = and i8 %6416, %6410
  %6418 = and i8 %6415, %6413
  %6419 = or i8 %6418, %6417
  %6420 = add i64 %6411, 64
  %6421 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6420
  %6422 = load i8, i8* %6421, align 1
  %6423 = icmp eq i64 %6383, %6420
  %6424 = sext i1 %6423 to i8
  %6425 = xor i8 %6424, -1
  %6426 = and i8 %6425, %6419
  %6427 = and i8 %6424, %6422
  %6428 = or i8 %6427, %6426
  %6429 = add i64 %6420, 64
  %6430 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6429
  %6431 = load i8, i8* %6430, align 1
  %6432 = icmp eq i64 %6383, %6429
  %6433 = sext i1 %6432 to i8
  %6434 = xor i8 %6433, -1
  %6435 = and i8 %6434, %6428
  %6436 = and i8 %6433, %6431
  %6437 = or i8 %6436, %6435
  %6438 = add i64 %6429, 64
  %6439 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6438
  %6440 = load i8, i8* %6439, align 1
  %6441 = icmp eq i64 %6383, %6438
  %6442 = sext i1 %6441 to i8
  %6443 = xor i8 %6442, -1
  %6444 = and i8 %6443, %6437
  %6445 = and i8 %6442, %6440
  %6446 = or i8 %6445, %6444
  %6447 = add i64 %6438, 64
  %6448 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6447
  %6449 = load i8, i8* %6448, align 1
  %6450 = icmp eq i64 %6383, %6447
  %6451 = sext i1 %6450 to i8
  %6452 = xor i8 %6451, -1
  %6453 = and i8 %6452, %6446
  %6454 = and i8 %6451, %6449
  %6455 = or i8 %6454, %6453
  %6456 = add i64 %6447, 64
  %6457 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6456
  %6458 = load i8, i8* %6457, align 1
  %6459 = icmp eq i64 %6383, %6456
  %6460 = sext i1 %6459 to i8
  %6461 = xor i8 %6460, -1
  %6462 = and i8 %6461, %6455
  %6463 = and i8 %6460, %6458
  %6464 = or i8 %6463, %6462
  %6465 = add i64 %6456, 64
  %6466 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6465
  %6467 = load i8, i8* %6466, align 1
  %6468 = icmp eq i64 %6383, %6465
  %6469 = sext i1 %6468 to i8
  %6470 = xor i8 %6469, -1
  %6471 = and i8 %6470, %6464
  %6472 = and i8 %6469, %6467
  %6473 = or i8 %6472, %6471
  %6474 = add i64 %6465, 64
  %6475 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6474
  %6476 = load i8, i8* %6475, align 1
  %6477 = icmp eq i64 %6383, %6474
  %6478 = sext i1 %6477 to i8
  %6479 = xor i8 %6478, -1
  %6480 = and i8 %6479, %6473
  %6481 = and i8 %6478, %6476
  %6482 = or i8 %6481, %6480
  %6483 = add i64 %6474, 64
  %6484 = icmp sge i64 %6483, 748
  %6485 = sext i1 %6484 to i64
  %6486 = xor i64 %6485, -1
  %6487 = and i64 %6485, 747
  %6488 = and i64 %6486, %6483
  %6489 = or i64 %6487, %6488
  %6490 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6489
  %6491 = load i8, i8* %6490, align 1
  %6492 = icmp eq i64 %6383, %6489
  %6493 = sext i1 %6492 to i8
  %6494 = xor i8 %6493, -1
  %6495 = and i8 %6494, %6482
  %6496 = and i8 %6493, %6491
  %Mitigated58 = or i8 %6496, %6495
  %6497 = zext i8 %Mitigated58 to i32
  %6498 = zext i8 %5949 to i32
  %6499 = xor i32 %6498, %6497
  %6500 = trunc i32 %6499 to i8
  %6501 = add i32 %6143, 153
  %6502 = zext i32 %6501 to i64
  %6503 = srem i64 %6502, 64
  %6504 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6503
  %6505 = load i8, i8* %6504, align 1
  %6506 = icmp eq i64 %6502, %6503
  %6507 = sext i1 %6506 to i8
  %6508 = xor i8 %6507, -1
  %6509 = and i8 %6508, 0
  %6510 = and i8 %6507, %6505
  %6511 = or i8 %6510, %6509
  %6512 = add i64 %6503, 64
  %6513 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6512
  %6514 = load i8, i8* %6513, align 1
  %6515 = icmp eq i64 %6502, %6512
  %6516 = sext i1 %6515 to i8
  %6517 = xor i8 %6516, -1
  %6518 = and i8 %6517, %6511
  %6519 = and i8 %6516, %6514
  %6520 = or i8 %6519, %6518
  %6521 = add i64 %6512, 64
  %6522 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6521
  %6523 = load i8, i8* %6522, align 1
  %6524 = icmp eq i64 %6502, %6521
  %6525 = sext i1 %6524 to i8
  %6526 = xor i8 %6525, -1
  %6527 = and i8 %6526, %6520
  %6528 = and i8 %6525, %6523
  %6529 = or i8 %6528, %6527
  %6530 = add i64 %6521, 64
  %6531 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6530
  %6532 = load i8, i8* %6531, align 1
  %6533 = icmp eq i64 %6502, %6530
  %6534 = sext i1 %6533 to i8
  %6535 = xor i8 %6534, -1
  %6536 = and i8 %6535, %6529
  %6537 = and i8 %6534, %6532
  %6538 = or i8 %6537, %6536
  %6539 = add i64 %6530, 64
  %6540 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6539
  %6541 = load i8, i8* %6540, align 1
  %6542 = icmp eq i64 %6502, %6539
  %6543 = sext i1 %6542 to i8
  %6544 = xor i8 %6543, -1
  %6545 = and i8 %6544, %6538
  %6546 = and i8 %6543, %6541
  %6547 = or i8 %6546, %6545
  %6548 = add i64 %6539, 64
  %6549 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6548
  %6550 = load i8, i8* %6549, align 1
  %6551 = icmp eq i64 %6502, %6548
  %6552 = sext i1 %6551 to i8
  %6553 = xor i8 %6552, -1
  %6554 = and i8 %6553, %6547
  %6555 = and i8 %6552, %6550
  %6556 = or i8 %6555, %6554
  %6557 = add i64 %6548, 64
  %6558 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6557
  %6559 = load i8, i8* %6558, align 1
  %6560 = icmp eq i64 %6502, %6557
  %6561 = sext i1 %6560 to i8
  %6562 = xor i8 %6561, -1
  %6563 = and i8 %6562, %6556
  %6564 = and i8 %6561, %6559
  %6565 = or i8 %6564, %6563
  %6566 = add i64 %6557, 64
  %6567 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6566
  %6568 = load i8, i8* %6567, align 1
  %6569 = icmp eq i64 %6502, %6566
  %6570 = sext i1 %6569 to i8
  %6571 = xor i8 %6570, -1
  %6572 = and i8 %6571, %6565
  %6573 = and i8 %6570, %6568
  %6574 = or i8 %6573, %6572
  %6575 = add i64 %6566, 64
  %6576 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6575
  %6577 = load i8, i8* %6576, align 1
  %6578 = icmp eq i64 %6502, %6575
  %6579 = sext i1 %6578 to i8
  %6580 = xor i8 %6579, -1
  %6581 = and i8 %6580, %6574
  %6582 = and i8 %6579, %6577
  %6583 = or i8 %6582, %6581
  %6584 = add i64 %6575, 64
  %6585 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6584
  %6586 = load i8, i8* %6585, align 1
  %6587 = icmp eq i64 %6502, %6584
  %6588 = sext i1 %6587 to i8
  %6589 = xor i8 %6588, -1
  %6590 = and i8 %6589, %6583
  %6591 = and i8 %6588, %6586
  %6592 = or i8 %6591, %6590
  %6593 = add i64 %6584, 64
  %6594 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6593
  %6595 = load i8, i8* %6594, align 1
  %6596 = icmp eq i64 %6502, %6593
  %6597 = sext i1 %6596 to i8
  %6598 = xor i8 %6597, -1
  %6599 = and i8 %6598, %6592
  %6600 = and i8 %6597, %6595
  %6601 = or i8 %6600, %6599
  %6602 = add i64 %6593, 64
  %6603 = icmp sge i64 %6602, 748
  %6604 = sext i1 %6603 to i64
  %6605 = xor i64 %6604, -1
  %6606 = and i64 %6604, 747
  %6607 = and i64 %6605, %6602
  %6608 = or i64 %6606, %6607
  %6609 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6608
  %6610 = load i8, i8* %6609, align 1
  %6611 = icmp eq i64 %6502, %6608
  %6612 = sext i1 %6611 to i8
  %6613 = xor i8 %6612, -1
  %6614 = and i8 %6613, %6601
  %6615 = and i8 %6612, %6610
  %Mitigated59 = or i8 %6615, %6614
  %6616 = zext i8 %Mitigated59 to i32
  %6617 = zext i8 %6068 to i32
  %6618 = xor i32 %6617, %6616
  %6619 = trunc i32 %6618 to i8
  %6620 = getelementptr inbounds i8, i8* %0, i64 12
  %6621 = load i8, i8* %6620, align 1
  %6622 = zext i8 %6621 to i64
  %6623 = srem i64 %6622, 32
  %6624 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6623
  %6625 = load i16, i16* %6624, align 2
  %6626 = icmp eq i64 %6622, %6623
  %6627 = sext i1 %6626 to i16
  %6628 = xor i16 %6627, -1
  %6629 = and i16 %6628, 0
  %6630 = and i16 %6627, %6625
  %6631 = or i16 %6630, %6629
  %6632 = add i64 %6623, 32
  %6633 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6632
  %6634 = load i16, i16* %6633, align 2
  %6635 = icmp eq i64 %6622, %6632
  %6636 = sext i1 %6635 to i16
  %6637 = xor i16 %6636, -1
  %6638 = and i16 %6637, %6631
  %6639 = and i16 %6636, %6634
  %6640 = or i16 %6639, %6638
  %6641 = add i64 %6632, 32
  %6642 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6641
  %6643 = load i16, i16* %6642, align 2
  %6644 = icmp eq i64 %6622, %6641
  %6645 = sext i1 %6644 to i16
  %6646 = xor i16 %6645, -1
  %6647 = and i16 %6646, %6640
  %6648 = and i16 %6645, %6643
  %6649 = or i16 %6648, %6647
  %6650 = add i64 %6641, 32
  %6651 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6650
  %6652 = load i16, i16* %6651, align 2
  %6653 = icmp eq i64 %6622, %6650
  %6654 = sext i1 %6653 to i16
  %6655 = xor i16 %6654, -1
  %6656 = and i16 %6655, %6649
  %6657 = and i16 %6654, %6652
  %6658 = or i16 %6657, %6656
  %6659 = add i64 %6650, 32
  %6660 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6659
  %6661 = load i16, i16* %6660, align 2
  %6662 = icmp eq i64 %6622, %6659
  %6663 = sext i1 %6662 to i16
  %6664 = xor i16 %6663, -1
  %6665 = and i16 %6664, %6658
  %6666 = and i16 %6663, %6661
  %6667 = or i16 %6666, %6665
  %6668 = add i64 %6659, 32
  %6669 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6668
  %6670 = load i16, i16* %6669, align 2
  %6671 = icmp eq i64 %6622, %6668
  %6672 = sext i1 %6671 to i16
  %6673 = xor i16 %6672, -1
  %6674 = and i16 %6673, %6667
  %6675 = and i16 %6672, %6670
  %6676 = or i16 %6675, %6674
  %6677 = add i64 %6668, 32
  %6678 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6677
  %6679 = load i16, i16* %6678, align 2
  %6680 = icmp eq i64 %6622, %6677
  %6681 = sext i1 %6680 to i16
  %6682 = xor i16 %6681, -1
  %6683 = and i16 %6682, %6676
  %6684 = and i16 %6681, %6679
  %6685 = or i16 %6684, %6683
  %6686 = add i64 %6677, 32
  %6687 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %6686
  %6688 = load i16, i16* %6687, align 2
  %6689 = icmp eq i64 %6622, %6686
  %6690 = sext i1 %6689 to i16
  %6691 = xor i16 %6690, -1
  %6692 = and i16 %6691, %6685
  %6693 = and i16 %6690, %6688
  %Mitigated60 = or i16 %6693, %6692
  %6694 = zext i16 %Mitigated60 to i32
  %6695 = add i32 %6694, 153
  %6696 = zext i32 %6695 to i64
  %6697 = srem i64 %6696, 64
  %6698 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6697
  %6699 = load i8, i8* %6698, align 1
  %6700 = icmp eq i64 %6696, %6697
  %6701 = sext i1 %6700 to i8
  %6702 = xor i8 %6701, -1
  %6703 = and i8 %6702, 0
  %6704 = and i8 %6701, %6699
  %6705 = or i8 %6704, %6703
  %6706 = add i64 %6697, 64
  %6707 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6706
  %6708 = load i8, i8* %6707, align 1
  %6709 = icmp eq i64 %6696, %6706
  %6710 = sext i1 %6709 to i8
  %6711 = xor i8 %6710, -1
  %6712 = and i8 %6711, %6705
  %6713 = and i8 %6710, %6708
  %6714 = or i8 %6713, %6712
  %6715 = add i64 %6706, 64
  %6716 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6715
  %6717 = load i8, i8* %6716, align 1
  %6718 = icmp eq i64 %6696, %6715
  %6719 = sext i1 %6718 to i8
  %6720 = xor i8 %6719, -1
  %6721 = and i8 %6720, %6714
  %6722 = and i8 %6719, %6717
  %6723 = or i8 %6722, %6721
  %6724 = add i64 %6715, 64
  %6725 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6724
  %6726 = load i8, i8* %6725, align 1
  %6727 = icmp eq i64 %6696, %6724
  %6728 = sext i1 %6727 to i8
  %6729 = xor i8 %6728, -1
  %6730 = and i8 %6729, %6723
  %6731 = and i8 %6728, %6726
  %6732 = or i8 %6731, %6730
  %6733 = add i64 %6724, 64
  %6734 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6733
  %6735 = load i8, i8* %6734, align 1
  %6736 = icmp eq i64 %6696, %6733
  %6737 = sext i1 %6736 to i8
  %6738 = xor i8 %6737, -1
  %6739 = and i8 %6738, %6732
  %6740 = and i8 %6737, %6735
  %6741 = or i8 %6740, %6739
  %6742 = add i64 %6733, 64
  %6743 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6742
  %6744 = load i8, i8* %6743, align 1
  %6745 = icmp eq i64 %6696, %6742
  %6746 = sext i1 %6745 to i8
  %6747 = xor i8 %6746, -1
  %6748 = and i8 %6747, %6741
  %6749 = and i8 %6746, %6744
  %6750 = or i8 %6749, %6748
  %6751 = add i64 %6742, 64
  %6752 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6751
  %6753 = load i8, i8* %6752, align 1
  %6754 = icmp eq i64 %6696, %6751
  %6755 = sext i1 %6754 to i8
  %6756 = xor i8 %6755, -1
  %6757 = and i8 %6756, %6750
  %6758 = and i8 %6755, %6753
  %6759 = or i8 %6758, %6757
  %6760 = add i64 %6751, 64
  %6761 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6760
  %6762 = load i8, i8* %6761, align 1
  %6763 = icmp eq i64 %6696, %6760
  %6764 = sext i1 %6763 to i8
  %6765 = xor i8 %6764, -1
  %6766 = and i8 %6765, %6759
  %6767 = and i8 %6764, %6762
  %6768 = or i8 %6767, %6766
  %6769 = add i64 %6760, 64
  %6770 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6769
  %6771 = load i8, i8* %6770, align 1
  %6772 = icmp eq i64 %6696, %6769
  %6773 = sext i1 %6772 to i8
  %6774 = xor i8 %6773, -1
  %6775 = and i8 %6774, %6768
  %6776 = and i8 %6773, %6771
  %6777 = or i8 %6776, %6775
  %6778 = add i64 %6769, 64
  %6779 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6778
  %6780 = load i8, i8* %6779, align 1
  %6781 = icmp eq i64 %6696, %6778
  %6782 = sext i1 %6781 to i8
  %6783 = xor i8 %6782, -1
  %6784 = and i8 %6783, %6777
  %6785 = and i8 %6782, %6780
  %6786 = or i8 %6785, %6784
  %6787 = add i64 %6778, 64
  %6788 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6787
  %6789 = load i8, i8* %6788, align 1
  %6790 = icmp eq i64 %6696, %6787
  %6791 = sext i1 %6790 to i8
  %6792 = xor i8 %6791, -1
  %6793 = and i8 %6792, %6786
  %6794 = and i8 %6791, %6789
  %6795 = or i8 %6794, %6793
  %6796 = add i64 %6787, 64
  %6797 = icmp sge i64 %6796, 748
  %6798 = sext i1 %6797 to i64
  %6799 = xor i64 %6798, -1
  %6800 = and i64 %6798, 747
  %6801 = and i64 %6799, %6796
  %6802 = or i64 %6800, %6801
  %6803 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6802
  %6804 = load i8, i8* %6803, align 1
  %6805 = icmp eq i64 %6696, %6802
  %6806 = sext i1 %6805 to i8
  %6807 = xor i8 %6806, -1
  %6808 = and i8 %6807, %6795
  %6809 = and i8 %6806, %6804
  %Mitigated61 = or i8 %6809, %6808
  %6810 = zext i8 %Mitigated61 to i32
  %6811 = zext i8 %6262 to i32
  %6812 = xor i32 %6811, %6810
  %6813 = trunc i32 %6812 to i8
  %6814 = add i32 %6694, 70
  %6815 = zext i32 %6814 to i64
  %6816 = srem i64 %6815, 64
  %6817 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6816
  %6818 = load i8, i8* %6817, align 1
  %6819 = icmp eq i64 %6815, %6816
  %6820 = sext i1 %6819 to i8
  %6821 = xor i8 %6820, -1
  %6822 = and i8 %6821, 0
  %6823 = and i8 %6820, %6818
  %6824 = or i8 %6823, %6822
  %6825 = add i64 %6816, 64
  %6826 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6825
  %6827 = load i8, i8* %6826, align 1
  %6828 = icmp eq i64 %6815, %6825
  %6829 = sext i1 %6828 to i8
  %6830 = xor i8 %6829, -1
  %6831 = and i8 %6830, %6824
  %6832 = and i8 %6829, %6827
  %6833 = or i8 %6832, %6831
  %6834 = add i64 %6825, 64
  %6835 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6834
  %6836 = load i8, i8* %6835, align 1
  %6837 = icmp eq i64 %6815, %6834
  %6838 = sext i1 %6837 to i8
  %6839 = xor i8 %6838, -1
  %6840 = and i8 %6839, %6833
  %6841 = and i8 %6838, %6836
  %6842 = or i8 %6841, %6840
  %6843 = add i64 %6834, 64
  %6844 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6843
  %6845 = load i8, i8* %6844, align 1
  %6846 = icmp eq i64 %6815, %6843
  %6847 = sext i1 %6846 to i8
  %6848 = xor i8 %6847, -1
  %6849 = and i8 %6848, %6842
  %6850 = and i8 %6847, %6845
  %6851 = or i8 %6850, %6849
  %6852 = add i64 %6843, 64
  %6853 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6852
  %6854 = load i8, i8* %6853, align 1
  %6855 = icmp eq i64 %6815, %6852
  %6856 = sext i1 %6855 to i8
  %6857 = xor i8 %6856, -1
  %6858 = and i8 %6857, %6851
  %6859 = and i8 %6856, %6854
  %6860 = or i8 %6859, %6858
  %6861 = add i64 %6852, 64
  %6862 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6861
  %6863 = load i8, i8* %6862, align 1
  %6864 = icmp eq i64 %6815, %6861
  %6865 = sext i1 %6864 to i8
  %6866 = xor i8 %6865, -1
  %6867 = and i8 %6866, %6860
  %6868 = and i8 %6865, %6863
  %6869 = or i8 %6868, %6867
  %6870 = add i64 %6861, 64
  %6871 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6870
  %6872 = load i8, i8* %6871, align 1
  %6873 = icmp eq i64 %6815, %6870
  %6874 = sext i1 %6873 to i8
  %6875 = xor i8 %6874, -1
  %6876 = and i8 %6875, %6869
  %6877 = and i8 %6874, %6872
  %6878 = or i8 %6877, %6876
  %6879 = add i64 %6870, 64
  %6880 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6879
  %6881 = load i8, i8* %6880, align 1
  %6882 = icmp eq i64 %6815, %6879
  %6883 = sext i1 %6882 to i8
  %6884 = xor i8 %6883, -1
  %6885 = and i8 %6884, %6878
  %6886 = and i8 %6883, %6881
  %6887 = or i8 %6886, %6885
  %6888 = add i64 %6879, 64
  %6889 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6888
  %6890 = load i8, i8* %6889, align 1
  %6891 = icmp eq i64 %6815, %6888
  %6892 = sext i1 %6891 to i8
  %6893 = xor i8 %6892, -1
  %6894 = and i8 %6893, %6887
  %6895 = and i8 %6892, %6890
  %6896 = or i8 %6895, %6894
  %6897 = add i64 %6888, 64
  %6898 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6897
  %6899 = load i8, i8* %6898, align 1
  %6900 = icmp eq i64 %6815, %6897
  %6901 = sext i1 %6900 to i8
  %6902 = xor i8 %6901, -1
  %6903 = and i8 %6902, %6896
  %6904 = and i8 %6901, %6899
  %6905 = or i8 %6904, %6903
  %6906 = add i64 %6897, 64
  %6907 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6906
  %6908 = load i8, i8* %6907, align 1
  %6909 = icmp eq i64 %6815, %6906
  %6910 = sext i1 %6909 to i8
  %6911 = xor i8 %6910, -1
  %6912 = and i8 %6911, %6905
  %6913 = and i8 %6910, %6908
  %6914 = or i8 %6913, %6912
  %6915 = add i64 %6906, 64
  %6916 = icmp sge i64 %6915, 748
  %6917 = sext i1 %6916 to i64
  %6918 = xor i64 %6917, -1
  %6919 = and i64 %6917, 747
  %6920 = and i64 %6918, %6915
  %6921 = or i64 %6919, %6920
  %6922 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6921
  %6923 = load i8, i8* %6922, align 1
  %6924 = icmp eq i64 %6815, %6921
  %6925 = sext i1 %6924 to i8
  %6926 = xor i8 %6925, -1
  %6927 = and i8 %6926, %6914
  %6928 = and i8 %6925, %6923
  %Mitigated62 = or i8 %6928, %6927
  %6929 = zext i8 %Mitigated62 to i32
  %6930 = zext i8 %6381 to i32
  %6931 = xor i32 %6930, %6929
  %6932 = trunc i32 %6931 to i8
  %6933 = add i32 %6694, 102
  %6934 = zext i32 %6933 to i64
  %6935 = srem i64 %6934, 64
  %6936 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6935
  %6937 = load i8, i8* %6936, align 1
  %6938 = icmp eq i64 %6934, %6935
  %6939 = sext i1 %6938 to i8
  %6940 = xor i8 %6939, -1
  %6941 = and i8 %6940, 0
  %6942 = and i8 %6939, %6937
  %6943 = or i8 %6942, %6941
  %6944 = add i64 %6935, 64
  %6945 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6944
  %6946 = load i8, i8* %6945, align 1
  %6947 = icmp eq i64 %6934, %6944
  %6948 = sext i1 %6947 to i8
  %6949 = xor i8 %6948, -1
  %6950 = and i8 %6949, %6943
  %6951 = and i8 %6948, %6946
  %6952 = or i8 %6951, %6950
  %6953 = add i64 %6944, 64
  %6954 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6953
  %6955 = load i8, i8* %6954, align 1
  %6956 = icmp eq i64 %6934, %6953
  %6957 = sext i1 %6956 to i8
  %6958 = xor i8 %6957, -1
  %6959 = and i8 %6958, %6952
  %6960 = and i8 %6957, %6955
  %6961 = or i8 %6960, %6959
  %6962 = add i64 %6953, 64
  %6963 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6962
  %6964 = load i8, i8* %6963, align 1
  %6965 = icmp eq i64 %6934, %6962
  %6966 = sext i1 %6965 to i8
  %6967 = xor i8 %6966, -1
  %6968 = and i8 %6967, %6961
  %6969 = and i8 %6966, %6964
  %6970 = or i8 %6969, %6968
  %6971 = add i64 %6962, 64
  %6972 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6971
  %6973 = load i8, i8* %6972, align 1
  %6974 = icmp eq i64 %6934, %6971
  %6975 = sext i1 %6974 to i8
  %6976 = xor i8 %6975, -1
  %6977 = and i8 %6976, %6970
  %6978 = and i8 %6975, %6973
  %6979 = or i8 %6978, %6977
  %6980 = add i64 %6971, 64
  %6981 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6980
  %6982 = load i8, i8* %6981, align 1
  %6983 = icmp eq i64 %6934, %6980
  %6984 = sext i1 %6983 to i8
  %6985 = xor i8 %6984, -1
  %6986 = and i8 %6985, %6979
  %6987 = and i8 %6984, %6982
  %6988 = or i8 %6987, %6986
  %6989 = add i64 %6980, 64
  %6990 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6989
  %6991 = load i8, i8* %6990, align 1
  %6992 = icmp eq i64 %6934, %6989
  %6993 = sext i1 %6992 to i8
  %6994 = xor i8 %6993, -1
  %6995 = and i8 %6994, %6988
  %6996 = and i8 %6993, %6991
  %6997 = or i8 %6996, %6995
  %6998 = add i64 %6989, 64
  %6999 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %6998
  %7000 = load i8, i8* %6999, align 1
  %7001 = icmp eq i64 %6934, %6998
  %7002 = sext i1 %7001 to i8
  %7003 = xor i8 %7002, -1
  %7004 = and i8 %7003, %6997
  %7005 = and i8 %7002, %7000
  %7006 = or i8 %7005, %7004
  %7007 = add i64 %6998, 64
  %7008 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7007
  %7009 = load i8, i8* %7008, align 1
  %7010 = icmp eq i64 %6934, %7007
  %7011 = sext i1 %7010 to i8
  %7012 = xor i8 %7011, -1
  %7013 = and i8 %7012, %7006
  %7014 = and i8 %7011, %7009
  %7015 = or i8 %7014, %7013
  %7016 = add i64 %7007, 64
  %7017 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7016
  %7018 = load i8, i8* %7017, align 1
  %7019 = icmp eq i64 %6934, %7016
  %7020 = sext i1 %7019 to i8
  %7021 = xor i8 %7020, -1
  %7022 = and i8 %7021, %7015
  %7023 = and i8 %7020, %7018
  %7024 = or i8 %7023, %7022
  %7025 = add i64 %7016, 64
  %7026 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7025
  %7027 = load i8, i8* %7026, align 1
  %7028 = icmp eq i64 %6934, %7025
  %7029 = sext i1 %7028 to i8
  %7030 = xor i8 %7029, -1
  %7031 = and i8 %7030, %7024
  %7032 = and i8 %7029, %7027
  %7033 = or i8 %7032, %7031
  %7034 = add i64 %7025, 64
  %7035 = icmp sge i64 %7034, 748
  %7036 = sext i1 %7035 to i64
  %7037 = xor i64 %7036, -1
  %7038 = and i64 %7036, 747
  %7039 = and i64 %7037, %7034
  %7040 = or i64 %7038, %7039
  %7041 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7040
  %7042 = load i8, i8* %7041, align 1
  %7043 = icmp eq i64 %6934, %7040
  %7044 = sext i1 %7043 to i8
  %7045 = xor i8 %7044, -1
  %7046 = and i8 %7045, %7033
  %7047 = and i8 %7044, %7042
  %Mitigated63 = or i8 %7047, %7046
  %7048 = zext i8 %Mitigated63 to i32
  %7049 = zext i8 %6500 to i32
  %7050 = xor i32 %7049, %7048
  %7051 = trunc i32 %7050 to i8
  %7052 = add i32 %6694, 150
  %7053 = zext i32 %7052 to i64
  %7054 = srem i64 %7053, 64
  %7055 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7054
  %7056 = load i8, i8* %7055, align 1
  %7057 = icmp eq i64 %7053, %7054
  %7058 = sext i1 %7057 to i8
  %7059 = xor i8 %7058, -1
  %7060 = and i8 %7059, 0
  %7061 = and i8 %7058, %7056
  %7062 = or i8 %7061, %7060
  %7063 = add i64 %7054, 64
  %7064 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7063
  %7065 = load i8, i8* %7064, align 1
  %7066 = icmp eq i64 %7053, %7063
  %7067 = sext i1 %7066 to i8
  %7068 = xor i8 %7067, -1
  %7069 = and i8 %7068, %7062
  %7070 = and i8 %7067, %7065
  %7071 = or i8 %7070, %7069
  %7072 = add i64 %7063, 64
  %7073 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7072
  %7074 = load i8, i8* %7073, align 1
  %7075 = icmp eq i64 %7053, %7072
  %7076 = sext i1 %7075 to i8
  %7077 = xor i8 %7076, -1
  %7078 = and i8 %7077, %7071
  %7079 = and i8 %7076, %7074
  %7080 = or i8 %7079, %7078
  %7081 = add i64 %7072, 64
  %7082 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7081
  %7083 = load i8, i8* %7082, align 1
  %7084 = icmp eq i64 %7053, %7081
  %7085 = sext i1 %7084 to i8
  %7086 = xor i8 %7085, -1
  %7087 = and i8 %7086, %7080
  %7088 = and i8 %7085, %7083
  %7089 = or i8 %7088, %7087
  %7090 = add i64 %7081, 64
  %7091 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7090
  %7092 = load i8, i8* %7091, align 1
  %7093 = icmp eq i64 %7053, %7090
  %7094 = sext i1 %7093 to i8
  %7095 = xor i8 %7094, -1
  %7096 = and i8 %7095, %7089
  %7097 = and i8 %7094, %7092
  %7098 = or i8 %7097, %7096
  %7099 = add i64 %7090, 64
  %7100 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7099
  %7101 = load i8, i8* %7100, align 1
  %7102 = icmp eq i64 %7053, %7099
  %7103 = sext i1 %7102 to i8
  %7104 = xor i8 %7103, -1
  %7105 = and i8 %7104, %7098
  %7106 = and i8 %7103, %7101
  %7107 = or i8 %7106, %7105
  %7108 = add i64 %7099, 64
  %7109 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7108
  %7110 = load i8, i8* %7109, align 1
  %7111 = icmp eq i64 %7053, %7108
  %7112 = sext i1 %7111 to i8
  %7113 = xor i8 %7112, -1
  %7114 = and i8 %7113, %7107
  %7115 = and i8 %7112, %7110
  %7116 = or i8 %7115, %7114
  %7117 = add i64 %7108, 64
  %7118 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7117
  %7119 = load i8, i8* %7118, align 1
  %7120 = icmp eq i64 %7053, %7117
  %7121 = sext i1 %7120 to i8
  %7122 = xor i8 %7121, -1
  %7123 = and i8 %7122, %7116
  %7124 = and i8 %7121, %7119
  %7125 = or i8 %7124, %7123
  %7126 = add i64 %7117, 64
  %7127 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7126
  %7128 = load i8, i8* %7127, align 1
  %7129 = icmp eq i64 %7053, %7126
  %7130 = sext i1 %7129 to i8
  %7131 = xor i8 %7130, -1
  %7132 = and i8 %7131, %7125
  %7133 = and i8 %7130, %7128
  %7134 = or i8 %7133, %7132
  %7135 = add i64 %7126, 64
  %7136 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7135
  %7137 = load i8, i8* %7136, align 1
  %7138 = icmp eq i64 %7053, %7135
  %7139 = sext i1 %7138 to i8
  %7140 = xor i8 %7139, -1
  %7141 = and i8 %7140, %7134
  %7142 = and i8 %7139, %7137
  %7143 = or i8 %7142, %7141
  %7144 = add i64 %7135, 64
  %7145 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7144
  %7146 = load i8, i8* %7145, align 1
  %7147 = icmp eq i64 %7053, %7144
  %7148 = sext i1 %7147 to i8
  %7149 = xor i8 %7148, -1
  %7150 = and i8 %7149, %7143
  %7151 = and i8 %7148, %7146
  %7152 = or i8 %7151, %7150
  %7153 = add i64 %7144, 64
  %7154 = icmp sge i64 %7153, 748
  %7155 = sext i1 %7154 to i64
  %7156 = xor i64 %7155, -1
  %7157 = and i64 %7155, 747
  %7158 = and i64 %7156, %7153
  %7159 = or i64 %7157, %7158
  %7160 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7159
  %7161 = load i8, i8* %7160, align 1
  %7162 = icmp eq i64 %7053, %7159
  %7163 = sext i1 %7162 to i8
  %7164 = xor i8 %7163, -1
  %7165 = and i8 %7164, %7152
  %7166 = and i8 %7163, %7161
  %Mitigated64 = or i8 %7166, %7165
  %7167 = zext i8 %Mitigated64 to i32
  %7168 = zext i8 %6619 to i32
  %7169 = xor i32 %7168, %7167
  %7170 = trunc i32 %7169 to i8
  %7171 = getelementptr inbounds i8, i8* %0, i64 13
  %7172 = load i8, i8* %7171, align 1
  %7173 = zext i8 %7172 to i64
  %7174 = srem i64 %7173, 32
  %7175 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7174
  %7176 = load i16, i16* %7175, align 2
  %7177 = icmp eq i64 %7173, %7174
  %7178 = sext i1 %7177 to i16
  %7179 = xor i16 %7178, -1
  %7180 = and i16 %7179, 0
  %7181 = and i16 %7178, %7176
  %7182 = or i16 %7181, %7180
  %7183 = add i64 %7174, 32
  %7184 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7183
  %7185 = load i16, i16* %7184, align 2
  %7186 = icmp eq i64 %7173, %7183
  %7187 = sext i1 %7186 to i16
  %7188 = xor i16 %7187, -1
  %7189 = and i16 %7188, %7182
  %7190 = and i16 %7187, %7185
  %7191 = or i16 %7190, %7189
  %7192 = add i64 %7183, 32
  %7193 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7192
  %7194 = load i16, i16* %7193, align 2
  %7195 = icmp eq i64 %7173, %7192
  %7196 = sext i1 %7195 to i16
  %7197 = xor i16 %7196, -1
  %7198 = and i16 %7197, %7191
  %7199 = and i16 %7196, %7194
  %7200 = or i16 %7199, %7198
  %7201 = add i64 %7192, 32
  %7202 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7201
  %7203 = load i16, i16* %7202, align 2
  %7204 = icmp eq i64 %7173, %7201
  %7205 = sext i1 %7204 to i16
  %7206 = xor i16 %7205, -1
  %7207 = and i16 %7206, %7200
  %7208 = and i16 %7205, %7203
  %7209 = or i16 %7208, %7207
  %7210 = add i64 %7201, 32
  %7211 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7210
  %7212 = load i16, i16* %7211, align 2
  %7213 = icmp eq i64 %7173, %7210
  %7214 = sext i1 %7213 to i16
  %7215 = xor i16 %7214, -1
  %7216 = and i16 %7215, %7209
  %7217 = and i16 %7214, %7212
  %7218 = or i16 %7217, %7216
  %7219 = add i64 %7210, 32
  %7220 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7219
  %7221 = load i16, i16* %7220, align 2
  %7222 = icmp eq i64 %7173, %7219
  %7223 = sext i1 %7222 to i16
  %7224 = xor i16 %7223, -1
  %7225 = and i16 %7224, %7218
  %7226 = and i16 %7223, %7221
  %7227 = or i16 %7226, %7225
  %7228 = add i64 %7219, 32
  %7229 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7228
  %7230 = load i16, i16* %7229, align 2
  %7231 = icmp eq i64 %7173, %7228
  %7232 = sext i1 %7231 to i16
  %7233 = xor i16 %7232, -1
  %7234 = and i16 %7233, %7227
  %7235 = and i16 %7232, %7230
  %7236 = or i16 %7235, %7234
  %7237 = add i64 %7228, 32
  %7238 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7237
  %7239 = load i16, i16* %7238, align 2
  %7240 = icmp eq i64 %7173, %7237
  %7241 = sext i1 %7240 to i16
  %7242 = xor i16 %7241, -1
  %7243 = and i16 %7242, %7236
  %7244 = and i16 %7241, %7239
  %Mitigated65 = or i16 %7244, %7243
  %7245 = zext i16 %Mitigated65 to i32
  %7246 = add i32 %7245, 150
  %7247 = zext i32 %7246 to i64
  %7248 = srem i64 %7247, 64
  %7249 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7248
  %7250 = load i8, i8* %7249, align 1
  %7251 = icmp eq i64 %7247, %7248
  %7252 = sext i1 %7251 to i8
  %7253 = xor i8 %7252, -1
  %7254 = and i8 %7253, 0
  %7255 = and i8 %7252, %7250
  %7256 = or i8 %7255, %7254
  %7257 = add i64 %7248, 64
  %7258 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7257
  %7259 = load i8, i8* %7258, align 1
  %7260 = icmp eq i64 %7247, %7257
  %7261 = sext i1 %7260 to i8
  %7262 = xor i8 %7261, -1
  %7263 = and i8 %7262, %7256
  %7264 = and i8 %7261, %7259
  %7265 = or i8 %7264, %7263
  %7266 = add i64 %7257, 64
  %7267 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7266
  %7268 = load i8, i8* %7267, align 1
  %7269 = icmp eq i64 %7247, %7266
  %7270 = sext i1 %7269 to i8
  %7271 = xor i8 %7270, -1
  %7272 = and i8 %7271, %7265
  %7273 = and i8 %7270, %7268
  %7274 = or i8 %7273, %7272
  %7275 = add i64 %7266, 64
  %7276 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7275
  %7277 = load i8, i8* %7276, align 1
  %7278 = icmp eq i64 %7247, %7275
  %7279 = sext i1 %7278 to i8
  %7280 = xor i8 %7279, -1
  %7281 = and i8 %7280, %7274
  %7282 = and i8 %7279, %7277
  %7283 = or i8 %7282, %7281
  %7284 = add i64 %7275, 64
  %7285 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7284
  %7286 = load i8, i8* %7285, align 1
  %7287 = icmp eq i64 %7247, %7284
  %7288 = sext i1 %7287 to i8
  %7289 = xor i8 %7288, -1
  %7290 = and i8 %7289, %7283
  %7291 = and i8 %7288, %7286
  %7292 = or i8 %7291, %7290
  %7293 = add i64 %7284, 64
  %7294 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7293
  %7295 = load i8, i8* %7294, align 1
  %7296 = icmp eq i64 %7247, %7293
  %7297 = sext i1 %7296 to i8
  %7298 = xor i8 %7297, -1
  %7299 = and i8 %7298, %7292
  %7300 = and i8 %7297, %7295
  %7301 = or i8 %7300, %7299
  %7302 = add i64 %7293, 64
  %7303 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7302
  %7304 = load i8, i8* %7303, align 1
  %7305 = icmp eq i64 %7247, %7302
  %7306 = sext i1 %7305 to i8
  %7307 = xor i8 %7306, -1
  %7308 = and i8 %7307, %7301
  %7309 = and i8 %7306, %7304
  %7310 = or i8 %7309, %7308
  %7311 = add i64 %7302, 64
  %7312 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7311
  %7313 = load i8, i8* %7312, align 1
  %7314 = icmp eq i64 %7247, %7311
  %7315 = sext i1 %7314 to i8
  %7316 = xor i8 %7315, -1
  %7317 = and i8 %7316, %7310
  %7318 = and i8 %7315, %7313
  %7319 = or i8 %7318, %7317
  %7320 = add i64 %7311, 64
  %7321 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7320
  %7322 = load i8, i8* %7321, align 1
  %7323 = icmp eq i64 %7247, %7320
  %7324 = sext i1 %7323 to i8
  %7325 = xor i8 %7324, -1
  %7326 = and i8 %7325, %7319
  %7327 = and i8 %7324, %7322
  %7328 = or i8 %7327, %7326
  %7329 = add i64 %7320, 64
  %7330 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7329
  %7331 = load i8, i8* %7330, align 1
  %7332 = icmp eq i64 %7247, %7329
  %7333 = sext i1 %7332 to i8
  %7334 = xor i8 %7333, -1
  %7335 = and i8 %7334, %7328
  %7336 = and i8 %7333, %7331
  %7337 = or i8 %7336, %7335
  %7338 = add i64 %7329, 64
  %7339 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7338
  %7340 = load i8, i8* %7339, align 1
  %7341 = icmp eq i64 %7247, %7338
  %7342 = sext i1 %7341 to i8
  %7343 = xor i8 %7342, -1
  %7344 = and i8 %7343, %7337
  %7345 = and i8 %7342, %7340
  %7346 = or i8 %7345, %7344
  %7347 = add i64 %7338, 64
  %7348 = icmp sge i64 %7347, 748
  %7349 = sext i1 %7348 to i64
  %7350 = xor i64 %7349, -1
  %7351 = and i64 %7349, 747
  %7352 = and i64 %7350, %7347
  %7353 = or i64 %7351, %7352
  %7354 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7353
  %7355 = load i8, i8* %7354, align 1
  %7356 = icmp eq i64 %7247, %7353
  %7357 = sext i1 %7356 to i8
  %7358 = xor i8 %7357, -1
  %7359 = and i8 %7358, %7346
  %7360 = and i8 %7357, %7355
  %Mitigated66 = or i8 %7360, %7359
  %7361 = zext i8 %Mitigated66 to i32
  %7362 = zext i8 %6813 to i32
  %7363 = xor i32 %7362, %7361
  %7364 = trunc i32 %7363 to i8
  %7365 = add i32 %7245, 60
  %7366 = zext i32 %7365 to i64
  %7367 = srem i64 %7366, 64
  %7368 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7367
  %7369 = load i8, i8* %7368, align 1
  %7370 = icmp eq i64 %7366, %7367
  %7371 = sext i1 %7370 to i8
  %7372 = xor i8 %7371, -1
  %7373 = and i8 %7372, 0
  %7374 = and i8 %7371, %7369
  %7375 = or i8 %7374, %7373
  %7376 = add i64 %7367, 64
  %7377 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7376
  %7378 = load i8, i8* %7377, align 1
  %7379 = icmp eq i64 %7366, %7376
  %7380 = sext i1 %7379 to i8
  %7381 = xor i8 %7380, -1
  %7382 = and i8 %7381, %7375
  %7383 = and i8 %7380, %7378
  %7384 = or i8 %7383, %7382
  %7385 = add i64 %7376, 64
  %7386 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7385
  %7387 = load i8, i8* %7386, align 1
  %7388 = icmp eq i64 %7366, %7385
  %7389 = sext i1 %7388 to i8
  %7390 = xor i8 %7389, -1
  %7391 = and i8 %7390, %7384
  %7392 = and i8 %7389, %7387
  %7393 = or i8 %7392, %7391
  %7394 = add i64 %7385, 64
  %7395 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7394
  %7396 = load i8, i8* %7395, align 1
  %7397 = icmp eq i64 %7366, %7394
  %7398 = sext i1 %7397 to i8
  %7399 = xor i8 %7398, -1
  %7400 = and i8 %7399, %7393
  %7401 = and i8 %7398, %7396
  %7402 = or i8 %7401, %7400
  %7403 = add i64 %7394, 64
  %7404 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7403
  %7405 = load i8, i8* %7404, align 1
  %7406 = icmp eq i64 %7366, %7403
  %7407 = sext i1 %7406 to i8
  %7408 = xor i8 %7407, -1
  %7409 = and i8 %7408, %7402
  %7410 = and i8 %7407, %7405
  %7411 = or i8 %7410, %7409
  %7412 = add i64 %7403, 64
  %7413 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7412
  %7414 = load i8, i8* %7413, align 1
  %7415 = icmp eq i64 %7366, %7412
  %7416 = sext i1 %7415 to i8
  %7417 = xor i8 %7416, -1
  %7418 = and i8 %7417, %7411
  %7419 = and i8 %7416, %7414
  %7420 = or i8 %7419, %7418
  %7421 = add i64 %7412, 64
  %7422 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7421
  %7423 = load i8, i8* %7422, align 1
  %7424 = icmp eq i64 %7366, %7421
  %7425 = sext i1 %7424 to i8
  %7426 = xor i8 %7425, -1
  %7427 = and i8 %7426, %7420
  %7428 = and i8 %7425, %7423
  %7429 = or i8 %7428, %7427
  %7430 = add i64 %7421, 64
  %7431 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7430
  %7432 = load i8, i8* %7431, align 1
  %7433 = icmp eq i64 %7366, %7430
  %7434 = sext i1 %7433 to i8
  %7435 = xor i8 %7434, -1
  %7436 = and i8 %7435, %7429
  %7437 = and i8 %7434, %7432
  %7438 = or i8 %7437, %7436
  %7439 = add i64 %7430, 64
  %7440 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7439
  %7441 = load i8, i8* %7440, align 1
  %7442 = icmp eq i64 %7366, %7439
  %7443 = sext i1 %7442 to i8
  %7444 = xor i8 %7443, -1
  %7445 = and i8 %7444, %7438
  %7446 = and i8 %7443, %7441
  %7447 = or i8 %7446, %7445
  %7448 = add i64 %7439, 64
  %7449 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7448
  %7450 = load i8, i8* %7449, align 1
  %7451 = icmp eq i64 %7366, %7448
  %7452 = sext i1 %7451 to i8
  %7453 = xor i8 %7452, -1
  %7454 = and i8 %7453, %7447
  %7455 = and i8 %7452, %7450
  %7456 = or i8 %7455, %7454
  %7457 = add i64 %7448, 64
  %7458 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7457
  %7459 = load i8, i8* %7458, align 1
  %7460 = icmp eq i64 %7366, %7457
  %7461 = sext i1 %7460 to i8
  %7462 = xor i8 %7461, -1
  %7463 = and i8 %7462, %7456
  %7464 = and i8 %7461, %7459
  %7465 = or i8 %7464, %7463
  %7466 = add i64 %7457, 64
  %7467 = icmp sge i64 %7466, 748
  %7468 = sext i1 %7467 to i64
  %7469 = xor i64 %7468, -1
  %7470 = and i64 %7468, 747
  %7471 = and i64 %7469, %7466
  %7472 = or i64 %7470, %7471
  %7473 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7472
  %7474 = load i8, i8* %7473, align 1
  %7475 = icmp eq i64 %7366, %7472
  %7476 = sext i1 %7475 to i8
  %7477 = xor i8 %7476, -1
  %7478 = and i8 %7477, %7465
  %7479 = and i8 %7476, %7474
  %Mitigated67 = or i8 %7479, %7478
  %7480 = zext i8 %Mitigated67 to i32
  %7481 = zext i8 %6932 to i32
  %7482 = xor i32 %7481, %7480
  %7483 = trunc i32 %7482 to i8
  %7484 = add i32 %7245, 91
  %7485 = zext i32 %7484 to i64
  %7486 = srem i64 %7485, 64
  %7487 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7486
  %7488 = load i8, i8* %7487, align 1
  %7489 = icmp eq i64 %7485, %7486
  %7490 = sext i1 %7489 to i8
  %7491 = xor i8 %7490, -1
  %7492 = and i8 %7491, 0
  %7493 = and i8 %7490, %7488
  %7494 = or i8 %7493, %7492
  %7495 = add i64 %7486, 64
  %7496 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7495
  %7497 = load i8, i8* %7496, align 1
  %7498 = icmp eq i64 %7485, %7495
  %7499 = sext i1 %7498 to i8
  %7500 = xor i8 %7499, -1
  %7501 = and i8 %7500, %7494
  %7502 = and i8 %7499, %7497
  %7503 = or i8 %7502, %7501
  %7504 = add i64 %7495, 64
  %7505 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7504
  %7506 = load i8, i8* %7505, align 1
  %7507 = icmp eq i64 %7485, %7504
  %7508 = sext i1 %7507 to i8
  %7509 = xor i8 %7508, -1
  %7510 = and i8 %7509, %7503
  %7511 = and i8 %7508, %7506
  %7512 = or i8 %7511, %7510
  %7513 = add i64 %7504, 64
  %7514 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7513
  %7515 = load i8, i8* %7514, align 1
  %7516 = icmp eq i64 %7485, %7513
  %7517 = sext i1 %7516 to i8
  %7518 = xor i8 %7517, -1
  %7519 = and i8 %7518, %7512
  %7520 = and i8 %7517, %7515
  %7521 = or i8 %7520, %7519
  %7522 = add i64 %7513, 64
  %7523 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7522
  %7524 = load i8, i8* %7523, align 1
  %7525 = icmp eq i64 %7485, %7522
  %7526 = sext i1 %7525 to i8
  %7527 = xor i8 %7526, -1
  %7528 = and i8 %7527, %7521
  %7529 = and i8 %7526, %7524
  %7530 = or i8 %7529, %7528
  %7531 = add i64 %7522, 64
  %7532 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7531
  %7533 = load i8, i8* %7532, align 1
  %7534 = icmp eq i64 %7485, %7531
  %7535 = sext i1 %7534 to i8
  %7536 = xor i8 %7535, -1
  %7537 = and i8 %7536, %7530
  %7538 = and i8 %7535, %7533
  %7539 = or i8 %7538, %7537
  %7540 = add i64 %7531, 64
  %7541 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7540
  %7542 = load i8, i8* %7541, align 1
  %7543 = icmp eq i64 %7485, %7540
  %7544 = sext i1 %7543 to i8
  %7545 = xor i8 %7544, -1
  %7546 = and i8 %7545, %7539
  %7547 = and i8 %7544, %7542
  %7548 = or i8 %7547, %7546
  %7549 = add i64 %7540, 64
  %7550 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7549
  %7551 = load i8, i8* %7550, align 1
  %7552 = icmp eq i64 %7485, %7549
  %7553 = sext i1 %7552 to i8
  %7554 = xor i8 %7553, -1
  %7555 = and i8 %7554, %7548
  %7556 = and i8 %7553, %7551
  %7557 = or i8 %7556, %7555
  %7558 = add i64 %7549, 64
  %7559 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7558
  %7560 = load i8, i8* %7559, align 1
  %7561 = icmp eq i64 %7485, %7558
  %7562 = sext i1 %7561 to i8
  %7563 = xor i8 %7562, -1
  %7564 = and i8 %7563, %7557
  %7565 = and i8 %7562, %7560
  %7566 = or i8 %7565, %7564
  %7567 = add i64 %7558, 64
  %7568 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7567
  %7569 = load i8, i8* %7568, align 1
  %7570 = icmp eq i64 %7485, %7567
  %7571 = sext i1 %7570 to i8
  %7572 = xor i8 %7571, -1
  %7573 = and i8 %7572, %7566
  %7574 = and i8 %7571, %7569
  %7575 = or i8 %7574, %7573
  %7576 = add i64 %7567, 64
  %7577 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7576
  %7578 = load i8, i8* %7577, align 1
  %7579 = icmp eq i64 %7485, %7576
  %7580 = sext i1 %7579 to i8
  %7581 = xor i8 %7580, -1
  %7582 = and i8 %7581, %7575
  %7583 = and i8 %7580, %7578
  %7584 = or i8 %7583, %7582
  %7585 = add i64 %7576, 64
  %7586 = icmp sge i64 %7585, 748
  %7587 = sext i1 %7586 to i64
  %7588 = xor i64 %7587, -1
  %7589 = and i64 %7587, 747
  %7590 = and i64 %7588, %7585
  %7591 = or i64 %7589, %7590
  %7592 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7591
  %7593 = load i8, i8* %7592, align 1
  %7594 = icmp eq i64 %7485, %7591
  %7595 = sext i1 %7594 to i8
  %7596 = xor i8 %7595, -1
  %7597 = and i8 %7596, %7584
  %7598 = and i8 %7595, %7593
  %Mitigated68 = or i8 %7598, %7597
  %7599 = zext i8 %Mitigated68 to i32
  %7600 = zext i8 %7051 to i32
  %7601 = xor i32 %7600, %7599
  %7602 = trunc i32 %7601 to i8
  %7603 = add i32 %7245, 237
  %7604 = zext i32 %7603 to i64
  %7605 = srem i64 %7604, 64
  %7606 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7605
  %7607 = load i8, i8* %7606, align 1
  %7608 = icmp eq i64 %7604, %7605
  %7609 = sext i1 %7608 to i8
  %7610 = xor i8 %7609, -1
  %7611 = and i8 %7610, 0
  %7612 = and i8 %7609, %7607
  %7613 = or i8 %7612, %7611
  %7614 = add i64 %7605, 64
  %7615 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7614
  %7616 = load i8, i8* %7615, align 1
  %7617 = icmp eq i64 %7604, %7614
  %7618 = sext i1 %7617 to i8
  %7619 = xor i8 %7618, -1
  %7620 = and i8 %7619, %7613
  %7621 = and i8 %7618, %7616
  %7622 = or i8 %7621, %7620
  %7623 = add i64 %7614, 64
  %7624 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7623
  %7625 = load i8, i8* %7624, align 1
  %7626 = icmp eq i64 %7604, %7623
  %7627 = sext i1 %7626 to i8
  %7628 = xor i8 %7627, -1
  %7629 = and i8 %7628, %7622
  %7630 = and i8 %7627, %7625
  %7631 = or i8 %7630, %7629
  %7632 = add i64 %7623, 64
  %7633 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7632
  %7634 = load i8, i8* %7633, align 1
  %7635 = icmp eq i64 %7604, %7632
  %7636 = sext i1 %7635 to i8
  %7637 = xor i8 %7636, -1
  %7638 = and i8 %7637, %7631
  %7639 = and i8 %7636, %7634
  %7640 = or i8 %7639, %7638
  %7641 = add i64 %7632, 64
  %7642 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7641
  %7643 = load i8, i8* %7642, align 1
  %7644 = icmp eq i64 %7604, %7641
  %7645 = sext i1 %7644 to i8
  %7646 = xor i8 %7645, -1
  %7647 = and i8 %7646, %7640
  %7648 = and i8 %7645, %7643
  %7649 = or i8 %7648, %7647
  %7650 = add i64 %7641, 64
  %7651 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7650
  %7652 = load i8, i8* %7651, align 1
  %7653 = icmp eq i64 %7604, %7650
  %7654 = sext i1 %7653 to i8
  %7655 = xor i8 %7654, -1
  %7656 = and i8 %7655, %7649
  %7657 = and i8 %7654, %7652
  %7658 = or i8 %7657, %7656
  %7659 = add i64 %7650, 64
  %7660 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7659
  %7661 = load i8, i8* %7660, align 1
  %7662 = icmp eq i64 %7604, %7659
  %7663 = sext i1 %7662 to i8
  %7664 = xor i8 %7663, -1
  %7665 = and i8 %7664, %7658
  %7666 = and i8 %7663, %7661
  %7667 = or i8 %7666, %7665
  %7668 = add i64 %7659, 64
  %7669 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7668
  %7670 = load i8, i8* %7669, align 1
  %7671 = icmp eq i64 %7604, %7668
  %7672 = sext i1 %7671 to i8
  %7673 = xor i8 %7672, -1
  %7674 = and i8 %7673, %7667
  %7675 = and i8 %7672, %7670
  %7676 = or i8 %7675, %7674
  %7677 = add i64 %7668, 64
  %7678 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7677
  %7679 = load i8, i8* %7678, align 1
  %7680 = icmp eq i64 %7604, %7677
  %7681 = sext i1 %7680 to i8
  %7682 = xor i8 %7681, -1
  %7683 = and i8 %7682, %7676
  %7684 = and i8 %7681, %7679
  %7685 = or i8 %7684, %7683
  %7686 = add i64 %7677, 64
  %7687 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7686
  %7688 = load i8, i8* %7687, align 1
  %7689 = icmp eq i64 %7604, %7686
  %7690 = sext i1 %7689 to i8
  %7691 = xor i8 %7690, -1
  %7692 = and i8 %7691, %7685
  %7693 = and i8 %7690, %7688
  %7694 = or i8 %7693, %7692
  %7695 = add i64 %7686, 64
  %7696 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7695
  %7697 = load i8, i8* %7696, align 1
  %7698 = icmp eq i64 %7604, %7695
  %7699 = sext i1 %7698 to i8
  %7700 = xor i8 %7699, -1
  %7701 = and i8 %7700, %7694
  %7702 = and i8 %7699, %7697
  %7703 = or i8 %7702, %7701
  %7704 = add i64 %7695, 64
  %7705 = icmp sge i64 %7704, 748
  %7706 = sext i1 %7705 to i64
  %7707 = xor i64 %7706, -1
  %7708 = and i64 %7706, 747
  %7709 = and i64 %7707, %7704
  %7710 = or i64 %7708, %7709
  %7711 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7710
  %7712 = load i8, i8* %7711, align 1
  %7713 = icmp eq i64 %7604, %7710
  %7714 = sext i1 %7713 to i8
  %7715 = xor i8 %7714, -1
  %7716 = and i8 %7715, %7703
  %7717 = and i8 %7714, %7712
  %Mitigated69 = or i8 %7717, %7716
  %7718 = zext i8 %Mitigated69 to i32
  %7719 = zext i8 %7170 to i32
  %7720 = xor i32 %7719, %7718
  %7721 = trunc i32 %7720 to i8
  %7722 = getelementptr inbounds i8, i8* %0, i64 14
  %7723 = load i8, i8* %7722, align 1
  %7724 = zext i8 %7723 to i64
  %7725 = srem i64 %7724, 32
  %7726 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7725
  %7727 = load i16, i16* %7726, align 2
  %7728 = icmp eq i64 %7724, %7725
  %7729 = sext i1 %7728 to i16
  %7730 = xor i16 %7729, -1
  %7731 = and i16 %7730, 0
  %7732 = and i16 %7729, %7727
  %7733 = or i16 %7732, %7731
  %7734 = add i64 %7725, 32
  %7735 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7734
  %7736 = load i16, i16* %7735, align 2
  %7737 = icmp eq i64 %7724, %7734
  %7738 = sext i1 %7737 to i16
  %7739 = xor i16 %7738, -1
  %7740 = and i16 %7739, %7733
  %7741 = and i16 %7738, %7736
  %7742 = or i16 %7741, %7740
  %7743 = add i64 %7734, 32
  %7744 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7743
  %7745 = load i16, i16* %7744, align 2
  %7746 = icmp eq i64 %7724, %7743
  %7747 = sext i1 %7746 to i16
  %7748 = xor i16 %7747, -1
  %7749 = and i16 %7748, %7742
  %7750 = and i16 %7747, %7745
  %7751 = or i16 %7750, %7749
  %7752 = add i64 %7743, 32
  %7753 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7752
  %7754 = load i16, i16* %7753, align 2
  %7755 = icmp eq i64 %7724, %7752
  %7756 = sext i1 %7755 to i16
  %7757 = xor i16 %7756, -1
  %7758 = and i16 %7757, %7751
  %7759 = and i16 %7756, %7754
  %7760 = or i16 %7759, %7758
  %7761 = add i64 %7752, 32
  %7762 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7761
  %7763 = load i16, i16* %7762, align 2
  %7764 = icmp eq i64 %7724, %7761
  %7765 = sext i1 %7764 to i16
  %7766 = xor i16 %7765, -1
  %7767 = and i16 %7766, %7760
  %7768 = and i16 %7765, %7763
  %7769 = or i16 %7768, %7767
  %7770 = add i64 %7761, 32
  %7771 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7770
  %7772 = load i16, i16* %7771, align 2
  %7773 = icmp eq i64 %7724, %7770
  %7774 = sext i1 %7773 to i16
  %7775 = xor i16 %7774, -1
  %7776 = and i16 %7775, %7769
  %7777 = and i16 %7774, %7772
  %7778 = or i16 %7777, %7776
  %7779 = add i64 %7770, 32
  %7780 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7779
  %7781 = load i16, i16* %7780, align 2
  %7782 = icmp eq i64 %7724, %7779
  %7783 = sext i1 %7782 to i16
  %7784 = xor i16 %7783, -1
  %7785 = and i16 %7784, %7778
  %7786 = and i16 %7783, %7781
  %7787 = or i16 %7786, %7785
  %7788 = add i64 %7779, 32
  %7789 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %7788
  %7790 = load i16, i16* %7789, align 2
  %7791 = icmp eq i64 %7724, %7788
  %7792 = sext i1 %7791 to i16
  %7793 = xor i16 %7792, -1
  %7794 = and i16 %7793, %7787
  %7795 = and i16 %7792, %7790
  %Mitigated70 = or i16 %7795, %7794
  %7796 = zext i16 %Mitigated70 to i32
  %7797 = add i32 %7796, 237
  %7798 = zext i32 %7797 to i64
  %7799 = srem i64 %7798, 64
  %7800 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7799
  %7801 = load i8, i8* %7800, align 1
  %7802 = icmp eq i64 %7798, %7799
  %7803 = sext i1 %7802 to i8
  %7804 = xor i8 %7803, -1
  %7805 = and i8 %7804, 0
  %7806 = and i8 %7803, %7801
  %7807 = or i8 %7806, %7805
  %7808 = add i64 %7799, 64
  %7809 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7808
  %7810 = load i8, i8* %7809, align 1
  %7811 = icmp eq i64 %7798, %7808
  %7812 = sext i1 %7811 to i8
  %7813 = xor i8 %7812, -1
  %7814 = and i8 %7813, %7807
  %7815 = and i8 %7812, %7810
  %7816 = or i8 %7815, %7814
  %7817 = add i64 %7808, 64
  %7818 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7817
  %7819 = load i8, i8* %7818, align 1
  %7820 = icmp eq i64 %7798, %7817
  %7821 = sext i1 %7820 to i8
  %7822 = xor i8 %7821, -1
  %7823 = and i8 %7822, %7816
  %7824 = and i8 %7821, %7819
  %7825 = or i8 %7824, %7823
  %7826 = add i64 %7817, 64
  %7827 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7826
  %7828 = load i8, i8* %7827, align 1
  %7829 = icmp eq i64 %7798, %7826
  %7830 = sext i1 %7829 to i8
  %7831 = xor i8 %7830, -1
  %7832 = and i8 %7831, %7825
  %7833 = and i8 %7830, %7828
  %7834 = or i8 %7833, %7832
  %7835 = add i64 %7826, 64
  %7836 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7835
  %7837 = load i8, i8* %7836, align 1
  %7838 = icmp eq i64 %7798, %7835
  %7839 = sext i1 %7838 to i8
  %7840 = xor i8 %7839, -1
  %7841 = and i8 %7840, %7834
  %7842 = and i8 %7839, %7837
  %7843 = or i8 %7842, %7841
  %7844 = add i64 %7835, 64
  %7845 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7844
  %7846 = load i8, i8* %7845, align 1
  %7847 = icmp eq i64 %7798, %7844
  %7848 = sext i1 %7847 to i8
  %7849 = xor i8 %7848, -1
  %7850 = and i8 %7849, %7843
  %7851 = and i8 %7848, %7846
  %7852 = or i8 %7851, %7850
  %7853 = add i64 %7844, 64
  %7854 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7853
  %7855 = load i8, i8* %7854, align 1
  %7856 = icmp eq i64 %7798, %7853
  %7857 = sext i1 %7856 to i8
  %7858 = xor i8 %7857, -1
  %7859 = and i8 %7858, %7852
  %7860 = and i8 %7857, %7855
  %7861 = or i8 %7860, %7859
  %7862 = add i64 %7853, 64
  %7863 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7862
  %7864 = load i8, i8* %7863, align 1
  %7865 = icmp eq i64 %7798, %7862
  %7866 = sext i1 %7865 to i8
  %7867 = xor i8 %7866, -1
  %7868 = and i8 %7867, %7861
  %7869 = and i8 %7866, %7864
  %7870 = or i8 %7869, %7868
  %7871 = add i64 %7862, 64
  %7872 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7871
  %7873 = load i8, i8* %7872, align 1
  %7874 = icmp eq i64 %7798, %7871
  %7875 = sext i1 %7874 to i8
  %7876 = xor i8 %7875, -1
  %7877 = and i8 %7876, %7870
  %7878 = and i8 %7875, %7873
  %7879 = or i8 %7878, %7877
  %7880 = add i64 %7871, 64
  %7881 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7880
  %7882 = load i8, i8* %7881, align 1
  %7883 = icmp eq i64 %7798, %7880
  %7884 = sext i1 %7883 to i8
  %7885 = xor i8 %7884, -1
  %7886 = and i8 %7885, %7879
  %7887 = and i8 %7884, %7882
  %7888 = or i8 %7887, %7886
  %7889 = add i64 %7880, 64
  %7890 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7889
  %7891 = load i8, i8* %7890, align 1
  %7892 = icmp eq i64 %7798, %7889
  %7893 = sext i1 %7892 to i8
  %7894 = xor i8 %7893, -1
  %7895 = and i8 %7894, %7888
  %7896 = and i8 %7893, %7891
  %7897 = or i8 %7896, %7895
  %7898 = add i64 %7889, 64
  %7899 = icmp sge i64 %7898, 748
  %7900 = sext i1 %7899 to i64
  %7901 = xor i64 %7900, -1
  %7902 = and i64 %7900, 747
  %7903 = and i64 %7901, %7898
  %7904 = or i64 %7902, %7903
  %7905 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7904
  %7906 = load i8, i8* %7905, align 1
  %7907 = icmp eq i64 %7798, %7904
  %7908 = sext i1 %7907 to i8
  %7909 = xor i8 %7908, -1
  %7910 = and i8 %7909, %7897
  %7911 = and i8 %7908, %7906
  %Mitigated71 = or i8 %7911, %7910
  %7912 = zext i8 %Mitigated71 to i32
  %7913 = zext i8 %7364 to i32
  %7914 = xor i32 %7913, %7912
  %7915 = trunc i32 %7914 to i8
  %7916 = add i32 %7796, 55
  %7917 = zext i32 %7916 to i64
  %7918 = srem i64 %7917, 64
  %7919 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7918
  %7920 = load i8, i8* %7919, align 1
  %7921 = icmp eq i64 %7917, %7918
  %7922 = sext i1 %7921 to i8
  %7923 = xor i8 %7922, -1
  %7924 = and i8 %7923, 0
  %7925 = and i8 %7922, %7920
  %7926 = or i8 %7925, %7924
  %7927 = add i64 %7918, 64
  %7928 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7927
  %7929 = load i8, i8* %7928, align 1
  %7930 = icmp eq i64 %7917, %7927
  %7931 = sext i1 %7930 to i8
  %7932 = xor i8 %7931, -1
  %7933 = and i8 %7932, %7926
  %7934 = and i8 %7931, %7929
  %7935 = or i8 %7934, %7933
  %7936 = add i64 %7927, 64
  %7937 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7936
  %7938 = load i8, i8* %7937, align 1
  %7939 = icmp eq i64 %7917, %7936
  %7940 = sext i1 %7939 to i8
  %7941 = xor i8 %7940, -1
  %7942 = and i8 %7941, %7935
  %7943 = and i8 %7940, %7938
  %7944 = or i8 %7943, %7942
  %7945 = add i64 %7936, 64
  %7946 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7945
  %7947 = load i8, i8* %7946, align 1
  %7948 = icmp eq i64 %7917, %7945
  %7949 = sext i1 %7948 to i8
  %7950 = xor i8 %7949, -1
  %7951 = and i8 %7950, %7944
  %7952 = and i8 %7949, %7947
  %7953 = or i8 %7952, %7951
  %7954 = add i64 %7945, 64
  %7955 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7954
  %7956 = load i8, i8* %7955, align 1
  %7957 = icmp eq i64 %7917, %7954
  %7958 = sext i1 %7957 to i8
  %7959 = xor i8 %7958, -1
  %7960 = and i8 %7959, %7953
  %7961 = and i8 %7958, %7956
  %7962 = or i8 %7961, %7960
  %7963 = add i64 %7954, 64
  %7964 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7963
  %7965 = load i8, i8* %7964, align 1
  %7966 = icmp eq i64 %7917, %7963
  %7967 = sext i1 %7966 to i8
  %7968 = xor i8 %7967, -1
  %7969 = and i8 %7968, %7962
  %7970 = and i8 %7967, %7965
  %7971 = or i8 %7970, %7969
  %7972 = add i64 %7963, 64
  %7973 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7972
  %7974 = load i8, i8* %7973, align 1
  %7975 = icmp eq i64 %7917, %7972
  %7976 = sext i1 %7975 to i8
  %7977 = xor i8 %7976, -1
  %7978 = and i8 %7977, %7971
  %7979 = and i8 %7976, %7974
  %7980 = or i8 %7979, %7978
  %7981 = add i64 %7972, 64
  %7982 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7981
  %7983 = load i8, i8* %7982, align 1
  %7984 = icmp eq i64 %7917, %7981
  %7985 = sext i1 %7984 to i8
  %7986 = xor i8 %7985, -1
  %7987 = and i8 %7986, %7980
  %7988 = and i8 %7985, %7983
  %7989 = or i8 %7988, %7987
  %7990 = add i64 %7981, 64
  %7991 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7990
  %7992 = load i8, i8* %7991, align 1
  %7993 = icmp eq i64 %7917, %7990
  %7994 = sext i1 %7993 to i8
  %7995 = xor i8 %7994, -1
  %7996 = and i8 %7995, %7989
  %7997 = and i8 %7994, %7992
  %7998 = or i8 %7997, %7996
  %7999 = add i64 %7990, 64
  %8000 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %7999
  %8001 = load i8, i8* %8000, align 1
  %8002 = icmp eq i64 %7917, %7999
  %8003 = sext i1 %8002 to i8
  %8004 = xor i8 %8003, -1
  %8005 = and i8 %8004, %7998
  %8006 = and i8 %8003, %8001
  %8007 = or i8 %8006, %8005
  %8008 = add i64 %7999, 64
  %8009 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8008
  %8010 = load i8, i8* %8009, align 1
  %8011 = icmp eq i64 %7917, %8008
  %8012 = sext i1 %8011 to i8
  %8013 = xor i8 %8012, -1
  %8014 = and i8 %8013, %8007
  %8015 = and i8 %8012, %8010
  %8016 = or i8 %8015, %8014
  %8017 = add i64 %8008, 64
  %8018 = icmp sge i64 %8017, 748
  %8019 = sext i1 %8018 to i64
  %8020 = xor i64 %8019, -1
  %8021 = and i64 %8019, 747
  %8022 = and i64 %8020, %8017
  %8023 = or i64 %8021, %8022
  %8024 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8023
  %8025 = load i8, i8* %8024, align 1
  %8026 = icmp eq i64 %7917, %8023
  %8027 = sext i1 %8026 to i8
  %8028 = xor i8 %8027, -1
  %8029 = and i8 %8028, %8016
  %8030 = and i8 %8027, %8025
  %Mitigated72 = or i8 %8030, %8029
  %8031 = zext i8 %Mitigated72 to i32
  %8032 = zext i8 %7483 to i32
  %8033 = xor i32 %8032, %8031
  %8034 = trunc i32 %8033 to i8
  %8035 = add i32 %7796, 79
  %8036 = zext i32 %8035 to i64
  %8037 = srem i64 %8036, 64
  %8038 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8037
  %8039 = load i8, i8* %8038, align 1
  %8040 = icmp eq i64 %8036, %8037
  %8041 = sext i1 %8040 to i8
  %8042 = xor i8 %8041, -1
  %8043 = and i8 %8042, 0
  %8044 = and i8 %8041, %8039
  %8045 = or i8 %8044, %8043
  %8046 = add i64 %8037, 64
  %8047 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8046
  %8048 = load i8, i8* %8047, align 1
  %8049 = icmp eq i64 %8036, %8046
  %8050 = sext i1 %8049 to i8
  %8051 = xor i8 %8050, -1
  %8052 = and i8 %8051, %8045
  %8053 = and i8 %8050, %8048
  %8054 = or i8 %8053, %8052
  %8055 = add i64 %8046, 64
  %8056 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8055
  %8057 = load i8, i8* %8056, align 1
  %8058 = icmp eq i64 %8036, %8055
  %8059 = sext i1 %8058 to i8
  %8060 = xor i8 %8059, -1
  %8061 = and i8 %8060, %8054
  %8062 = and i8 %8059, %8057
  %8063 = or i8 %8062, %8061
  %8064 = add i64 %8055, 64
  %8065 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8064
  %8066 = load i8, i8* %8065, align 1
  %8067 = icmp eq i64 %8036, %8064
  %8068 = sext i1 %8067 to i8
  %8069 = xor i8 %8068, -1
  %8070 = and i8 %8069, %8063
  %8071 = and i8 %8068, %8066
  %8072 = or i8 %8071, %8070
  %8073 = add i64 %8064, 64
  %8074 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8073
  %8075 = load i8, i8* %8074, align 1
  %8076 = icmp eq i64 %8036, %8073
  %8077 = sext i1 %8076 to i8
  %8078 = xor i8 %8077, -1
  %8079 = and i8 %8078, %8072
  %8080 = and i8 %8077, %8075
  %8081 = or i8 %8080, %8079
  %8082 = add i64 %8073, 64
  %8083 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8082
  %8084 = load i8, i8* %8083, align 1
  %8085 = icmp eq i64 %8036, %8082
  %8086 = sext i1 %8085 to i8
  %8087 = xor i8 %8086, -1
  %8088 = and i8 %8087, %8081
  %8089 = and i8 %8086, %8084
  %8090 = or i8 %8089, %8088
  %8091 = add i64 %8082, 64
  %8092 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8091
  %8093 = load i8, i8* %8092, align 1
  %8094 = icmp eq i64 %8036, %8091
  %8095 = sext i1 %8094 to i8
  %8096 = xor i8 %8095, -1
  %8097 = and i8 %8096, %8090
  %8098 = and i8 %8095, %8093
  %8099 = or i8 %8098, %8097
  %8100 = add i64 %8091, 64
  %8101 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8100
  %8102 = load i8, i8* %8101, align 1
  %8103 = icmp eq i64 %8036, %8100
  %8104 = sext i1 %8103 to i8
  %8105 = xor i8 %8104, -1
  %8106 = and i8 %8105, %8099
  %8107 = and i8 %8104, %8102
  %8108 = or i8 %8107, %8106
  %8109 = add i64 %8100, 64
  %8110 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8109
  %8111 = load i8, i8* %8110, align 1
  %8112 = icmp eq i64 %8036, %8109
  %8113 = sext i1 %8112 to i8
  %8114 = xor i8 %8113, -1
  %8115 = and i8 %8114, %8108
  %8116 = and i8 %8113, %8111
  %8117 = or i8 %8116, %8115
  %8118 = add i64 %8109, 64
  %8119 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8118
  %8120 = load i8, i8* %8119, align 1
  %8121 = icmp eq i64 %8036, %8118
  %8122 = sext i1 %8121 to i8
  %8123 = xor i8 %8122, -1
  %8124 = and i8 %8123, %8117
  %8125 = and i8 %8122, %8120
  %8126 = or i8 %8125, %8124
  %8127 = add i64 %8118, 64
  %8128 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8127
  %8129 = load i8, i8* %8128, align 1
  %8130 = icmp eq i64 %8036, %8127
  %8131 = sext i1 %8130 to i8
  %8132 = xor i8 %8131, -1
  %8133 = and i8 %8132, %8126
  %8134 = and i8 %8131, %8129
  %8135 = or i8 %8134, %8133
  %8136 = add i64 %8127, 64
  %8137 = icmp sge i64 %8136, 748
  %8138 = sext i1 %8137 to i64
  %8139 = xor i64 %8138, -1
  %8140 = and i64 %8138, 747
  %8141 = and i64 %8139, %8136
  %8142 = or i64 %8140, %8141
  %8143 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8142
  %8144 = load i8, i8* %8143, align 1
  %8145 = icmp eq i64 %8036, %8142
  %8146 = sext i1 %8145 to i8
  %8147 = xor i8 %8146, -1
  %8148 = and i8 %8147, %8135
  %8149 = and i8 %8146, %8144
  %Mitigated73 = or i8 %8149, %8148
  %8150 = zext i8 %Mitigated73 to i32
  %8151 = zext i8 %7602 to i32
  %8152 = xor i32 %8151, %8150
  %8153 = trunc i32 %8152 to i8
  %8154 = add i32 %7796, 224
  %8155 = zext i32 %8154 to i64
  %8156 = srem i64 %8155, 64
  %8157 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8156
  %8158 = load i8, i8* %8157, align 1
  %8159 = icmp eq i64 %8155, %8156
  %8160 = sext i1 %8159 to i8
  %8161 = xor i8 %8160, -1
  %8162 = and i8 %8161, 0
  %8163 = and i8 %8160, %8158
  %8164 = or i8 %8163, %8162
  %8165 = add i64 %8156, 64
  %8166 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8165
  %8167 = load i8, i8* %8166, align 1
  %8168 = icmp eq i64 %8155, %8165
  %8169 = sext i1 %8168 to i8
  %8170 = xor i8 %8169, -1
  %8171 = and i8 %8170, %8164
  %8172 = and i8 %8169, %8167
  %8173 = or i8 %8172, %8171
  %8174 = add i64 %8165, 64
  %8175 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8174
  %8176 = load i8, i8* %8175, align 1
  %8177 = icmp eq i64 %8155, %8174
  %8178 = sext i1 %8177 to i8
  %8179 = xor i8 %8178, -1
  %8180 = and i8 %8179, %8173
  %8181 = and i8 %8178, %8176
  %8182 = or i8 %8181, %8180
  %8183 = add i64 %8174, 64
  %8184 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8183
  %8185 = load i8, i8* %8184, align 1
  %8186 = icmp eq i64 %8155, %8183
  %8187 = sext i1 %8186 to i8
  %8188 = xor i8 %8187, -1
  %8189 = and i8 %8188, %8182
  %8190 = and i8 %8187, %8185
  %8191 = or i8 %8190, %8189
  %8192 = add i64 %8183, 64
  %8193 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8192
  %8194 = load i8, i8* %8193, align 1
  %8195 = icmp eq i64 %8155, %8192
  %8196 = sext i1 %8195 to i8
  %8197 = xor i8 %8196, -1
  %8198 = and i8 %8197, %8191
  %8199 = and i8 %8196, %8194
  %8200 = or i8 %8199, %8198
  %8201 = add i64 %8192, 64
  %8202 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8201
  %8203 = load i8, i8* %8202, align 1
  %8204 = icmp eq i64 %8155, %8201
  %8205 = sext i1 %8204 to i8
  %8206 = xor i8 %8205, -1
  %8207 = and i8 %8206, %8200
  %8208 = and i8 %8205, %8203
  %8209 = or i8 %8208, %8207
  %8210 = add i64 %8201, 64
  %8211 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8210
  %8212 = load i8, i8* %8211, align 1
  %8213 = icmp eq i64 %8155, %8210
  %8214 = sext i1 %8213 to i8
  %8215 = xor i8 %8214, -1
  %8216 = and i8 %8215, %8209
  %8217 = and i8 %8214, %8212
  %8218 = or i8 %8217, %8216
  %8219 = add i64 %8210, 64
  %8220 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8219
  %8221 = load i8, i8* %8220, align 1
  %8222 = icmp eq i64 %8155, %8219
  %8223 = sext i1 %8222 to i8
  %8224 = xor i8 %8223, -1
  %8225 = and i8 %8224, %8218
  %8226 = and i8 %8223, %8221
  %8227 = or i8 %8226, %8225
  %8228 = add i64 %8219, 64
  %8229 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8228
  %8230 = load i8, i8* %8229, align 1
  %8231 = icmp eq i64 %8155, %8228
  %8232 = sext i1 %8231 to i8
  %8233 = xor i8 %8232, -1
  %8234 = and i8 %8233, %8227
  %8235 = and i8 %8232, %8230
  %8236 = or i8 %8235, %8234
  %8237 = add i64 %8228, 64
  %8238 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8237
  %8239 = load i8, i8* %8238, align 1
  %8240 = icmp eq i64 %8155, %8237
  %8241 = sext i1 %8240 to i8
  %8242 = xor i8 %8241, -1
  %8243 = and i8 %8242, %8236
  %8244 = and i8 %8241, %8239
  %8245 = or i8 %8244, %8243
  %8246 = add i64 %8237, 64
  %8247 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8246
  %8248 = load i8, i8* %8247, align 1
  %8249 = icmp eq i64 %8155, %8246
  %8250 = sext i1 %8249 to i8
  %8251 = xor i8 %8250, -1
  %8252 = and i8 %8251, %8245
  %8253 = and i8 %8250, %8248
  %8254 = or i8 %8253, %8252
  %8255 = add i64 %8246, 64
  %8256 = icmp sge i64 %8255, 748
  %8257 = sext i1 %8256 to i64
  %8258 = xor i64 %8257, -1
  %8259 = and i64 %8257, 747
  %8260 = and i64 %8258, %8255
  %8261 = or i64 %8259, %8260
  %8262 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8261
  %8263 = load i8, i8* %8262, align 1
  %8264 = icmp eq i64 %8155, %8261
  %8265 = sext i1 %8264 to i8
  %8266 = xor i8 %8265, -1
  %8267 = and i8 %8266, %8254
  %8268 = and i8 %8265, %8263
  %Mitigated74 = or i8 %8268, %8267
  %8269 = zext i8 %Mitigated74 to i32
  %8270 = zext i8 %7721 to i32
  %8271 = xor i32 %8270, %8269
  %8272 = trunc i32 %8271 to i8
  %8273 = getelementptr inbounds i8, i8* %0, i64 15
  %8274 = load i8, i8* %8273, align 1
  %8275 = zext i8 %8274 to i64
  %8276 = srem i64 %8275, 32
  %8277 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8276
  %8278 = load i16, i16* %8277, align 2
  %8279 = icmp eq i64 %8275, %8276
  %8280 = sext i1 %8279 to i16
  %8281 = xor i16 %8280, -1
  %8282 = and i16 %8281, 0
  %8283 = and i16 %8280, %8278
  %8284 = or i16 %8283, %8282
  %8285 = add i64 %8276, 32
  %8286 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8285
  %8287 = load i16, i16* %8286, align 2
  %8288 = icmp eq i64 %8275, %8285
  %8289 = sext i1 %8288 to i16
  %8290 = xor i16 %8289, -1
  %8291 = and i16 %8290, %8284
  %8292 = and i16 %8289, %8287
  %8293 = or i16 %8292, %8291
  %8294 = add i64 %8285, 32
  %8295 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8294
  %8296 = load i16, i16* %8295, align 2
  %8297 = icmp eq i64 %8275, %8294
  %8298 = sext i1 %8297 to i16
  %8299 = xor i16 %8298, -1
  %8300 = and i16 %8299, %8293
  %8301 = and i16 %8298, %8296
  %8302 = or i16 %8301, %8300
  %8303 = add i64 %8294, 32
  %8304 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8303
  %8305 = load i16, i16* %8304, align 2
  %8306 = icmp eq i64 %8275, %8303
  %8307 = sext i1 %8306 to i16
  %8308 = xor i16 %8307, -1
  %8309 = and i16 %8308, %8302
  %8310 = and i16 %8307, %8305
  %8311 = or i16 %8310, %8309
  %8312 = add i64 %8303, 32
  %8313 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8312
  %8314 = load i16, i16* %8313, align 2
  %8315 = icmp eq i64 %8275, %8312
  %8316 = sext i1 %8315 to i16
  %8317 = xor i16 %8316, -1
  %8318 = and i16 %8317, %8311
  %8319 = and i16 %8316, %8314
  %8320 = or i16 %8319, %8318
  %8321 = add i64 %8312, 32
  %8322 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8321
  %8323 = load i16, i16* %8322, align 2
  %8324 = icmp eq i64 %8275, %8321
  %8325 = sext i1 %8324 to i16
  %8326 = xor i16 %8325, -1
  %8327 = and i16 %8326, %8320
  %8328 = and i16 %8325, %8323
  %8329 = or i16 %8328, %8327
  %8330 = add i64 %8321, 32
  %8331 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8330
  %8332 = load i16, i16* %8331, align 2
  %8333 = icmp eq i64 %8275, %8330
  %8334 = sext i1 %8333 to i16
  %8335 = xor i16 %8334, -1
  %8336 = and i16 %8335, %8329
  %8337 = and i16 %8334, %8332
  %8338 = or i16 %8337, %8336
  %8339 = add i64 %8330, 32
  %8340 = getelementptr inbounds [256 x i16], [256 x i16]* @poly_to_exp, i64 0, i64 %8339
  %8341 = load i16, i16* %8340, align 2
  %8342 = icmp eq i64 %8275, %8339
  %8343 = sext i1 %8342 to i16
  %8344 = xor i16 %8343, -1
  %8345 = and i16 %8344, %8338
  %8346 = and i16 %8343, %8341
  %Mitigated75 = or i16 %8346, %8345
  %8347 = zext i16 %Mitigated75 to i32
  %8348 = add i32 %8347, 224
  %8349 = zext i32 %8348 to i64
  %8350 = srem i64 %8349, 64
  %8351 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8350
  %8352 = load i8, i8* %8351, align 1
  %8353 = icmp eq i64 %8349, %8350
  %8354 = sext i1 %8353 to i8
  %8355 = xor i8 %8354, -1
  %8356 = and i8 %8355, 0
  %8357 = and i8 %8354, %8352
  %8358 = or i8 %8357, %8356
  %8359 = add i64 %8350, 64
  %8360 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8359
  %8361 = load i8, i8* %8360, align 1
  %8362 = icmp eq i64 %8349, %8359
  %8363 = sext i1 %8362 to i8
  %8364 = xor i8 %8363, -1
  %8365 = and i8 %8364, %8358
  %8366 = and i8 %8363, %8361
  %8367 = or i8 %8366, %8365
  %8368 = add i64 %8359, 64
  %8369 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8368
  %8370 = load i8, i8* %8369, align 1
  %8371 = icmp eq i64 %8349, %8368
  %8372 = sext i1 %8371 to i8
  %8373 = xor i8 %8372, -1
  %8374 = and i8 %8373, %8367
  %8375 = and i8 %8372, %8370
  %8376 = or i8 %8375, %8374
  %8377 = add i64 %8368, 64
  %8378 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8377
  %8379 = load i8, i8* %8378, align 1
  %8380 = icmp eq i64 %8349, %8377
  %8381 = sext i1 %8380 to i8
  %8382 = xor i8 %8381, -1
  %8383 = and i8 %8382, %8376
  %8384 = and i8 %8381, %8379
  %8385 = or i8 %8384, %8383
  %8386 = add i64 %8377, 64
  %8387 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8386
  %8388 = load i8, i8* %8387, align 1
  %8389 = icmp eq i64 %8349, %8386
  %8390 = sext i1 %8389 to i8
  %8391 = xor i8 %8390, -1
  %8392 = and i8 %8391, %8385
  %8393 = and i8 %8390, %8388
  %8394 = or i8 %8393, %8392
  %8395 = add i64 %8386, 64
  %8396 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8395
  %8397 = load i8, i8* %8396, align 1
  %8398 = icmp eq i64 %8349, %8395
  %8399 = sext i1 %8398 to i8
  %8400 = xor i8 %8399, -1
  %8401 = and i8 %8400, %8394
  %8402 = and i8 %8399, %8397
  %8403 = or i8 %8402, %8401
  %8404 = add i64 %8395, 64
  %8405 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8404
  %8406 = load i8, i8* %8405, align 1
  %8407 = icmp eq i64 %8349, %8404
  %8408 = sext i1 %8407 to i8
  %8409 = xor i8 %8408, -1
  %8410 = and i8 %8409, %8403
  %8411 = and i8 %8408, %8406
  %8412 = or i8 %8411, %8410
  %8413 = add i64 %8404, 64
  %8414 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8413
  %8415 = load i8, i8* %8414, align 1
  %8416 = icmp eq i64 %8349, %8413
  %8417 = sext i1 %8416 to i8
  %8418 = xor i8 %8417, -1
  %8419 = and i8 %8418, %8412
  %8420 = and i8 %8417, %8415
  %8421 = or i8 %8420, %8419
  %8422 = add i64 %8413, 64
  %8423 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8422
  %8424 = load i8, i8* %8423, align 1
  %8425 = icmp eq i64 %8349, %8422
  %8426 = sext i1 %8425 to i8
  %8427 = xor i8 %8426, -1
  %8428 = and i8 %8427, %8421
  %8429 = and i8 %8426, %8424
  %8430 = or i8 %8429, %8428
  %8431 = add i64 %8422, 64
  %8432 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8431
  %8433 = load i8, i8* %8432, align 1
  %8434 = icmp eq i64 %8349, %8431
  %8435 = sext i1 %8434 to i8
  %8436 = xor i8 %8435, -1
  %8437 = and i8 %8436, %8430
  %8438 = and i8 %8435, %8433
  %8439 = or i8 %8438, %8437
  %8440 = add i64 %8431, 64
  %8441 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8440
  %8442 = load i8, i8* %8441, align 1
  %8443 = icmp eq i64 %8349, %8440
  %8444 = sext i1 %8443 to i8
  %8445 = xor i8 %8444, -1
  %8446 = and i8 %8445, %8439
  %8447 = and i8 %8444, %8442
  %8448 = or i8 %8447, %8446
  %8449 = add i64 %8440, 64
  %8450 = icmp sge i64 %8449, 748
  %8451 = sext i1 %8450 to i64
  %8452 = xor i64 %8451, -1
  %8453 = and i64 %8451, 747
  %8454 = and i64 %8452, %8449
  %8455 = or i64 %8453, %8454
  %8456 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8455
  %8457 = load i8, i8* %8456, align 1
  %8458 = icmp eq i64 %8349, %8455
  %8459 = sext i1 %8458 to i8
  %8460 = xor i8 %8459, -1
  %8461 = and i8 %8460, %8448
  %8462 = and i8 %8459, %8457
  %Mitigated76 = or i8 %8462, %8461
  %8463 = zext i8 %Mitigated76 to i32
  %8464 = zext i8 %7915 to i32
  %8465 = xor i32 %8464, %8463
  %8466 = trunc i32 %8465 to i8
  %8467 = add i32 %8347, 208
  %8468 = zext i32 %8467 to i64
  %8469 = srem i64 %8468, 64
  %8470 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8469
  %8471 = load i8, i8* %8470, align 1
  %8472 = icmp eq i64 %8468, %8469
  %8473 = sext i1 %8472 to i8
  %8474 = xor i8 %8473, -1
  %8475 = and i8 %8474, 0
  %8476 = and i8 %8473, %8471
  %8477 = or i8 %8476, %8475
  %8478 = add i64 %8469, 64
  %8479 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8478
  %8480 = load i8, i8* %8479, align 1
  %8481 = icmp eq i64 %8468, %8478
  %8482 = sext i1 %8481 to i8
  %8483 = xor i8 %8482, -1
  %8484 = and i8 %8483, %8477
  %8485 = and i8 %8482, %8480
  %8486 = or i8 %8485, %8484
  %8487 = add i64 %8478, 64
  %8488 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8487
  %8489 = load i8, i8* %8488, align 1
  %8490 = icmp eq i64 %8468, %8487
  %8491 = sext i1 %8490 to i8
  %8492 = xor i8 %8491, -1
  %8493 = and i8 %8492, %8486
  %8494 = and i8 %8491, %8489
  %8495 = or i8 %8494, %8493
  %8496 = add i64 %8487, 64
  %8497 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8496
  %8498 = load i8, i8* %8497, align 1
  %8499 = icmp eq i64 %8468, %8496
  %8500 = sext i1 %8499 to i8
  %8501 = xor i8 %8500, -1
  %8502 = and i8 %8501, %8495
  %8503 = and i8 %8500, %8498
  %8504 = or i8 %8503, %8502
  %8505 = add i64 %8496, 64
  %8506 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8505
  %8507 = load i8, i8* %8506, align 1
  %8508 = icmp eq i64 %8468, %8505
  %8509 = sext i1 %8508 to i8
  %8510 = xor i8 %8509, -1
  %8511 = and i8 %8510, %8504
  %8512 = and i8 %8509, %8507
  %8513 = or i8 %8512, %8511
  %8514 = add i64 %8505, 64
  %8515 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8514
  %8516 = load i8, i8* %8515, align 1
  %8517 = icmp eq i64 %8468, %8514
  %8518 = sext i1 %8517 to i8
  %8519 = xor i8 %8518, -1
  %8520 = and i8 %8519, %8513
  %8521 = and i8 %8518, %8516
  %8522 = or i8 %8521, %8520
  %8523 = add i64 %8514, 64
  %8524 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8523
  %8525 = load i8, i8* %8524, align 1
  %8526 = icmp eq i64 %8468, %8523
  %8527 = sext i1 %8526 to i8
  %8528 = xor i8 %8527, -1
  %8529 = and i8 %8528, %8522
  %8530 = and i8 %8527, %8525
  %8531 = or i8 %8530, %8529
  %8532 = add i64 %8523, 64
  %8533 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8532
  %8534 = load i8, i8* %8533, align 1
  %8535 = icmp eq i64 %8468, %8532
  %8536 = sext i1 %8535 to i8
  %8537 = xor i8 %8536, -1
  %8538 = and i8 %8537, %8531
  %8539 = and i8 %8536, %8534
  %8540 = or i8 %8539, %8538
  %8541 = add i64 %8532, 64
  %8542 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8541
  %8543 = load i8, i8* %8542, align 1
  %8544 = icmp eq i64 %8468, %8541
  %8545 = sext i1 %8544 to i8
  %8546 = xor i8 %8545, -1
  %8547 = and i8 %8546, %8540
  %8548 = and i8 %8545, %8543
  %8549 = or i8 %8548, %8547
  %8550 = add i64 %8541, 64
  %8551 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8550
  %8552 = load i8, i8* %8551, align 1
  %8553 = icmp eq i64 %8468, %8550
  %8554 = sext i1 %8553 to i8
  %8555 = xor i8 %8554, -1
  %8556 = and i8 %8555, %8549
  %8557 = and i8 %8554, %8552
  %8558 = or i8 %8557, %8556
  %8559 = add i64 %8550, 64
  %8560 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8559
  %8561 = load i8, i8* %8560, align 1
  %8562 = icmp eq i64 %8468, %8559
  %8563 = sext i1 %8562 to i8
  %8564 = xor i8 %8563, -1
  %8565 = and i8 %8564, %8558
  %8566 = and i8 %8563, %8561
  %8567 = or i8 %8566, %8565
  %8568 = add i64 %8559, 64
  %8569 = icmp sge i64 %8568, 748
  %8570 = sext i1 %8569 to i64
  %8571 = xor i64 %8570, -1
  %8572 = and i64 %8570, 747
  %8573 = and i64 %8571, %8568
  %8574 = or i64 %8572, %8573
  %8575 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8574
  %8576 = load i8, i8* %8575, align 1
  %8577 = icmp eq i64 %8468, %8574
  %8578 = sext i1 %8577 to i8
  %8579 = xor i8 %8578, -1
  %8580 = and i8 %8579, %8567
  %8581 = and i8 %8578, %8576
  %Mitigated77 = or i8 %8581, %8580
  %8582 = zext i8 %Mitigated77 to i32
  %8583 = zext i8 %8034 to i32
  %8584 = xor i32 %8583, %8582
  %8585 = trunc i32 %8584 to i8
  %8586 = add i32 %8347, 140
  %8587 = zext i32 %8586 to i64
  %8588 = srem i64 %8587, 64
  %8589 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8588
  %8590 = load i8, i8* %8589, align 1
  %8591 = icmp eq i64 %8587, %8588
  %8592 = sext i1 %8591 to i8
  %8593 = xor i8 %8592, -1
  %8594 = and i8 %8593, 0
  %8595 = and i8 %8592, %8590
  %8596 = or i8 %8595, %8594
  %8597 = add i64 %8588, 64
  %8598 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8597
  %8599 = load i8, i8* %8598, align 1
  %8600 = icmp eq i64 %8587, %8597
  %8601 = sext i1 %8600 to i8
  %8602 = xor i8 %8601, -1
  %8603 = and i8 %8602, %8596
  %8604 = and i8 %8601, %8599
  %8605 = or i8 %8604, %8603
  %8606 = add i64 %8597, 64
  %8607 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8606
  %8608 = load i8, i8* %8607, align 1
  %8609 = icmp eq i64 %8587, %8606
  %8610 = sext i1 %8609 to i8
  %8611 = xor i8 %8610, -1
  %8612 = and i8 %8611, %8605
  %8613 = and i8 %8610, %8608
  %8614 = or i8 %8613, %8612
  %8615 = add i64 %8606, 64
  %8616 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8615
  %8617 = load i8, i8* %8616, align 1
  %8618 = icmp eq i64 %8587, %8615
  %8619 = sext i1 %8618 to i8
  %8620 = xor i8 %8619, -1
  %8621 = and i8 %8620, %8614
  %8622 = and i8 %8619, %8617
  %8623 = or i8 %8622, %8621
  %8624 = add i64 %8615, 64
  %8625 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8624
  %8626 = load i8, i8* %8625, align 1
  %8627 = icmp eq i64 %8587, %8624
  %8628 = sext i1 %8627 to i8
  %8629 = xor i8 %8628, -1
  %8630 = and i8 %8629, %8623
  %8631 = and i8 %8628, %8626
  %8632 = or i8 %8631, %8630
  %8633 = add i64 %8624, 64
  %8634 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8633
  %8635 = load i8, i8* %8634, align 1
  %8636 = icmp eq i64 %8587, %8633
  %8637 = sext i1 %8636 to i8
  %8638 = xor i8 %8637, -1
  %8639 = and i8 %8638, %8632
  %8640 = and i8 %8637, %8635
  %8641 = or i8 %8640, %8639
  %8642 = add i64 %8633, 64
  %8643 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8642
  %8644 = load i8, i8* %8643, align 1
  %8645 = icmp eq i64 %8587, %8642
  %8646 = sext i1 %8645 to i8
  %8647 = xor i8 %8646, -1
  %8648 = and i8 %8647, %8641
  %8649 = and i8 %8646, %8644
  %8650 = or i8 %8649, %8648
  %8651 = add i64 %8642, 64
  %8652 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8651
  %8653 = load i8, i8* %8652, align 1
  %8654 = icmp eq i64 %8587, %8651
  %8655 = sext i1 %8654 to i8
  %8656 = xor i8 %8655, -1
  %8657 = and i8 %8656, %8650
  %8658 = and i8 %8655, %8653
  %8659 = or i8 %8658, %8657
  %8660 = add i64 %8651, 64
  %8661 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8660
  %8662 = load i8, i8* %8661, align 1
  %8663 = icmp eq i64 %8587, %8660
  %8664 = sext i1 %8663 to i8
  %8665 = xor i8 %8664, -1
  %8666 = and i8 %8665, %8659
  %8667 = and i8 %8664, %8662
  %8668 = or i8 %8667, %8666
  %8669 = add i64 %8660, 64
  %8670 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8669
  %8671 = load i8, i8* %8670, align 1
  %8672 = icmp eq i64 %8587, %8669
  %8673 = sext i1 %8672 to i8
  %8674 = xor i8 %8673, -1
  %8675 = and i8 %8674, %8668
  %8676 = and i8 %8673, %8671
  %8677 = or i8 %8676, %8675
  %8678 = add i64 %8669, 64
  %8679 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8678
  %8680 = load i8, i8* %8679, align 1
  %8681 = icmp eq i64 %8587, %8678
  %8682 = sext i1 %8681 to i8
  %8683 = xor i8 %8682, -1
  %8684 = and i8 %8683, %8677
  %8685 = and i8 %8682, %8680
  %8686 = or i8 %8685, %8684
  %8687 = add i64 %8678, 64
  %8688 = icmp sge i64 %8687, 748
  %8689 = sext i1 %8688 to i64
  %8690 = xor i64 %8689, -1
  %8691 = and i64 %8689, 747
  %8692 = and i64 %8690, %8687
  %8693 = or i64 %8691, %8692
  %8694 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8693
  %8695 = load i8, i8* %8694, align 1
  %8696 = icmp eq i64 %8587, %8693
  %8697 = sext i1 %8696 to i8
  %8698 = xor i8 %8697, -1
  %8699 = and i8 %8698, %8686
  %8700 = and i8 %8697, %8695
  %Mitigated78 = or i8 %8700, %8699
  %8701 = zext i8 %Mitigated78 to i32
  %8702 = zext i8 %8153 to i32
  %8703 = xor i32 %8702, %8701
  %8704 = trunc i32 %8703 to i8
  %8705 = add i32 %8347, 23
  %8706 = zext i32 %8705 to i64
  %8707 = srem i64 %8706, 64
  %8708 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8707
  %8709 = load i8, i8* %8708, align 1
  %8710 = icmp eq i64 %8706, %8707
  %8711 = sext i1 %8710 to i8
  %8712 = xor i8 %8711, -1
  %8713 = and i8 %8712, 0
  %8714 = and i8 %8711, %8709
  %8715 = or i8 %8714, %8713
  %8716 = add i64 %8707, 64
  %8717 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8716
  %8718 = load i8, i8* %8717, align 1
  %8719 = icmp eq i64 %8706, %8716
  %8720 = sext i1 %8719 to i8
  %8721 = xor i8 %8720, -1
  %8722 = and i8 %8721, %8715
  %8723 = and i8 %8720, %8718
  %8724 = or i8 %8723, %8722
  %8725 = add i64 %8716, 64
  %8726 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8725
  %8727 = load i8, i8* %8726, align 1
  %8728 = icmp eq i64 %8706, %8725
  %8729 = sext i1 %8728 to i8
  %8730 = xor i8 %8729, -1
  %8731 = and i8 %8730, %8724
  %8732 = and i8 %8729, %8727
  %8733 = or i8 %8732, %8731
  %8734 = add i64 %8725, 64
  %8735 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8734
  %8736 = load i8, i8* %8735, align 1
  %8737 = icmp eq i64 %8706, %8734
  %8738 = sext i1 %8737 to i8
  %8739 = xor i8 %8738, -1
  %8740 = and i8 %8739, %8733
  %8741 = and i8 %8738, %8736
  %8742 = or i8 %8741, %8740
  %8743 = add i64 %8734, 64
  %8744 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8743
  %8745 = load i8, i8* %8744, align 1
  %8746 = icmp eq i64 %8706, %8743
  %8747 = sext i1 %8746 to i8
  %8748 = xor i8 %8747, -1
  %8749 = and i8 %8748, %8742
  %8750 = and i8 %8747, %8745
  %8751 = or i8 %8750, %8749
  %8752 = add i64 %8743, 64
  %8753 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8752
  %8754 = load i8, i8* %8753, align 1
  %8755 = icmp eq i64 %8706, %8752
  %8756 = sext i1 %8755 to i8
  %8757 = xor i8 %8756, -1
  %8758 = and i8 %8757, %8751
  %8759 = and i8 %8756, %8754
  %8760 = or i8 %8759, %8758
  %8761 = add i64 %8752, 64
  %8762 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8761
  %8763 = load i8, i8* %8762, align 1
  %8764 = icmp eq i64 %8706, %8761
  %8765 = sext i1 %8764 to i8
  %8766 = xor i8 %8765, -1
  %8767 = and i8 %8766, %8760
  %8768 = and i8 %8765, %8763
  %8769 = or i8 %8768, %8767
  %8770 = add i64 %8761, 64
  %8771 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8770
  %8772 = load i8, i8* %8771, align 1
  %8773 = icmp eq i64 %8706, %8770
  %8774 = sext i1 %8773 to i8
  %8775 = xor i8 %8774, -1
  %8776 = and i8 %8775, %8769
  %8777 = and i8 %8774, %8772
  %8778 = or i8 %8777, %8776
  %8779 = add i64 %8770, 64
  %8780 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8779
  %8781 = load i8, i8* %8780, align 1
  %8782 = icmp eq i64 %8706, %8779
  %8783 = sext i1 %8782 to i8
  %8784 = xor i8 %8783, -1
  %8785 = and i8 %8784, %8778
  %8786 = and i8 %8783, %8781
  %8787 = or i8 %8786, %8785
  %8788 = add i64 %8779, 64
  %8789 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8788
  %8790 = load i8, i8* %8789, align 1
  %8791 = icmp eq i64 %8706, %8788
  %8792 = sext i1 %8791 to i8
  %8793 = xor i8 %8792, -1
  %8794 = and i8 %8793, %8787
  %8795 = and i8 %8792, %8790
  %8796 = or i8 %8795, %8794
  %8797 = add i64 %8788, 64
  %8798 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8797
  %8799 = load i8, i8* %8798, align 1
  %8800 = icmp eq i64 %8706, %8797
  %8801 = sext i1 %8800 to i8
  %8802 = xor i8 %8801, -1
  %8803 = and i8 %8802, %8796
  %8804 = and i8 %8801, %8799
  %8805 = or i8 %8804, %8803
  %8806 = add i64 %8797, 64
  %8807 = icmp sge i64 %8806, 748
  %8808 = sext i1 %8807 to i64
  %8809 = xor i64 %8808, -1
  %8810 = and i64 %8808, 747
  %8811 = and i64 %8809, %8806
  %8812 = or i64 %8810, %8811
  %8813 = getelementptr inbounds [748 x i8], [748 x i8]* @exp_to_poly, i64 0, i64 %8812
  %8814 = load i8, i8* %8813, align 1
  %8815 = icmp eq i64 %8706, %8812
  %8816 = sext i1 %8815 to i8
  %8817 = xor i8 %8816, -1
  %8818 = and i8 %8817, %8805
  %8819 = and i8 %8816, %8814
  %Mitigated79 = or i8 %8819, %8818
  %8820 = zext i8 %Mitigated79 to i32
  %8821 = zext i8 %8272 to i32
  %8822 = xor i32 %8821, %8820
  %8823 = trunc i32 %8822 to i8
  br label %8824

.preheader5:                                      ; preds = %8824
  %.1.ph = phi i32 [ 0, %8824 ]
  br label %9601

; <label>:8824:                                   ; preds = %7, %8824
  %.0111 = phi i32 [ 0, %7 ], [ %9597, %8824 ]
  %.0210 = phi i32 [ 0, %7 ], [ %9598, %8824 ]
  %.049 = phi i32 [ 1, %7 ], [ %9599, %8824 ]
  %8825 = sext i32 %.0210 to i64
  %8826 = getelementptr inbounds [512 x i8], [512 x i8]* @calc_sb_tbl, i64 0, i64 %8825
  %8827 = load i8, i8* %8826, align 1
  %8828 = zext i8 %8827 to i32
  %8829 = zext i8 %4058 to i32
  %8830 = xor i32 %8828, %8829
  %8831 = sext i32 %8830 to i64
  %8832 = srem i64 %8831, 64
  %8833 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %8832
  %8834 = load i8, i8* %8833, align 1
  %8835 = icmp eq i64 %8831, %8832
  %8836 = sext i1 %8835 to i8
  %8837 = xor i8 %8836, -1
  %8838 = and i8 %8837, 0
  %8839 = and i8 %8836, %8834
  %8840 = or i8 %8839, %8838
  %8841 = add i64 %8832, 64
  %8842 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %8841
  %8843 = load i8, i8* %8842, align 1
  %8844 = icmp eq i64 %8831, %8841
  %8845 = sext i1 %8844 to i8
  %8846 = xor i8 %8845, -1
  %8847 = and i8 %8846, %8840
  %8848 = and i8 %8845, %8843
  %8849 = or i8 %8848, %8847
  %8850 = add i64 %8841, 64
  %8851 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %8850
  %8852 = load i8, i8* %8851, align 1
  %8853 = icmp eq i64 %8831, %8850
  %8854 = sext i1 %8853 to i8
  %8855 = xor i8 %8854, -1
  %8856 = and i8 %8855, %8849
  %8857 = and i8 %8854, %8852
  %8858 = or i8 %8857, %8856
  %8859 = add i64 %8850, 64
  %8860 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %8859
  %8861 = load i8, i8* %8860, align 1
  %8862 = icmp eq i64 %8831, %8859
  %8863 = sext i1 %8862 to i8
  %8864 = xor i8 %8863, -1
  %8865 = and i8 %8864, %8858
  %8866 = and i8 %8863, %8861
  %Mitigated80 = or i8 %8866, %8865
  %8867 = zext i8 %Mitigated80 to i32
  %8868 = zext i8 %8466 to i32
  %8869 = xor i32 %8867, %8868
  %8870 = sext i32 %8869 to i64
  %8871 = srem i64 %8870, 16
  %8872 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8871
  %8873 = load i32, i32* %8872, align 4
  %8874 = icmp eq i64 %8870, %8871
  %8875 = sext i1 %8874 to i32
  %8876 = xor i32 %8875, -1
  %8877 = and i32 %8876, 0
  %8878 = and i32 %8875, %8873
  %8879 = or i32 %8878, %8877
  %8880 = add i64 %8871, 16
  %8881 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8880
  %8882 = load i32, i32* %8881, align 4
  %8883 = icmp eq i64 %8870, %8880
  %8884 = sext i1 %8883 to i32
  %8885 = xor i32 %8884, -1
  %8886 = and i32 %8885, %8879
  %8887 = and i32 %8884, %8882
  %8888 = or i32 %8887, %8886
  %8889 = add i64 %8880, 16
  %8890 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8889
  %8891 = load i32, i32* %8890, align 4
  %8892 = icmp eq i64 %8870, %8889
  %8893 = sext i1 %8892 to i32
  %8894 = xor i32 %8893, -1
  %8895 = and i32 %8894, %8888
  %8896 = and i32 %8893, %8891
  %8897 = or i32 %8896, %8895
  %8898 = add i64 %8889, 16
  %8899 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8898
  %8900 = load i32, i32* %8899, align 4
  %8901 = icmp eq i64 %8870, %8898
  %8902 = sext i1 %8901 to i32
  %8903 = xor i32 %8902, -1
  %8904 = and i32 %8903, %8897
  %8905 = and i32 %8902, %8900
  %8906 = or i32 %8905, %8904
  %8907 = add i64 %8898, 16
  %8908 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8907
  %8909 = load i32, i32* %8908, align 4
  %8910 = icmp eq i64 %8870, %8907
  %8911 = sext i1 %8910 to i32
  %8912 = xor i32 %8911, -1
  %8913 = and i32 %8912, %8906
  %8914 = and i32 %8911, %8909
  %8915 = or i32 %8914, %8913
  %8916 = add i64 %8907, 16
  %8917 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8916
  %8918 = load i32, i32* %8917, align 4
  %8919 = icmp eq i64 %8870, %8916
  %8920 = sext i1 %8919 to i32
  %8921 = xor i32 %8920, -1
  %8922 = and i32 %8921, %8915
  %8923 = and i32 %8920, %8918
  %8924 = or i32 %8923, %8922
  %8925 = add i64 %8916, 16
  %8926 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8925
  %8927 = load i32, i32* %8926, align 4
  %8928 = icmp eq i64 %8870, %8925
  %8929 = sext i1 %8928 to i32
  %8930 = xor i32 %8929, -1
  %8931 = and i32 %8930, %8924
  %8932 = and i32 %8929, %8927
  %8933 = or i32 %8932, %8931
  %8934 = add i64 %8925, 16
  %8935 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8934
  %8936 = load i32, i32* %8935, align 4
  %8937 = icmp eq i64 %8870, %8934
  %8938 = sext i1 %8937 to i32
  %8939 = xor i32 %8938, -1
  %8940 = and i32 %8939, %8933
  %8941 = and i32 %8938, %8936
  %8942 = or i32 %8941, %8940
  %8943 = add i64 %8934, 16
  %8944 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8943
  %8945 = load i32, i32* %8944, align 4
  %8946 = icmp eq i64 %8870, %8943
  %8947 = sext i1 %8946 to i32
  %8948 = xor i32 %8947, -1
  %8949 = and i32 %8948, %8942
  %8950 = and i32 %8947, %8945
  %8951 = or i32 %8950, %8949
  %8952 = add i64 %8943, 16
  %8953 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8952
  %8954 = load i32, i32* %8953, align 4
  %8955 = icmp eq i64 %8870, %8952
  %8956 = sext i1 %8955 to i32
  %8957 = xor i32 %8956, -1
  %8958 = and i32 %8957, %8951
  %8959 = and i32 %8956, %8954
  %8960 = or i32 %8959, %8958
  %8961 = add i64 %8952, 16
  %8962 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8961
  %8963 = load i32, i32* %8962, align 4
  %8964 = icmp eq i64 %8870, %8961
  %8965 = sext i1 %8964 to i32
  %8966 = xor i32 %8965, -1
  %8967 = and i32 %8966, %8960
  %8968 = and i32 %8965, %8963
  %8969 = or i32 %8968, %8967
  %8970 = add i64 %8961, 16
  %8971 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8970
  %8972 = load i32, i32* %8971, align 4
  %8973 = icmp eq i64 %8870, %8970
  %8974 = sext i1 %8973 to i32
  %8975 = xor i32 %8974, -1
  %8976 = and i32 %8975, %8969
  %8977 = and i32 %8974, %8972
  %8978 = or i32 %8977, %8976
  %8979 = add i64 %8970, 16
  %8980 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8979
  %8981 = load i32, i32* %8980, align 4
  %8982 = icmp eq i64 %8870, %8979
  %8983 = sext i1 %8982 to i32
  %8984 = xor i32 %8983, -1
  %8985 = and i32 %8984, %8978
  %8986 = and i32 %8983, %8981
  %8987 = or i32 %8986, %8985
  %8988 = add i64 %8979, 16
  %8989 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8988
  %8990 = load i32, i32* %8989, align 4
  %8991 = icmp eq i64 %8870, %8988
  %8992 = sext i1 %8991 to i32
  %8993 = xor i32 %8992, -1
  %8994 = and i32 %8993, %8987
  %8995 = and i32 %8992, %8990
  %8996 = or i32 %8995, %8994
  %8997 = add i64 %8988, 16
  %8998 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %8997
  %8999 = load i32, i32* %8998, align 4
  %9000 = icmp eq i64 %8870, %8997
  %9001 = sext i1 %9000 to i32
  %9002 = xor i32 %9001, -1
  %9003 = and i32 %9002, %8996
  %9004 = and i32 %9001, %8999
  %9005 = or i32 %9004, %9003
  %9006 = add i64 %8997, 16
  %9007 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9006
  %9008 = load i32, i32* %9007, align 4
  %9009 = icmp eq i64 %8870, %9006
  %9010 = sext i1 %9009 to i32
  %9011 = xor i32 %9010, -1
  %9012 = and i32 %9011, %9005
  %9013 = and i32 %9010, %9008
  %Mitigated81 = or i32 %9013, %9012
  %9014 = sext i32 %.0111 to i64
  %9015 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 0
  %9016 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9015, i64 0, i64 0
  %9017 = getelementptr inbounds [256 x i32], [256 x i32]* %9016, i64 0, i64 %9014
  store i32 %Mitigated81, i32* %9017, align 4
  %9018 = sext i32 %.049 to i64
  %9019 = getelementptr inbounds [512 x i8], [512 x i8]* @calc_sb_tbl, i64 0, i64 %9018
  %9020 = load i8, i8* %9019, align 1
  %9021 = zext i8 %9020 to i32
  %9022 = zext i8 %4177 to i32
  %9023 = xor i32 %9021, %9022
  %9024 = sext i32 %9023 to i64
  %9025 = srem i64 %9024, 64
  %9026 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9025
  %9027 = load i8, i8* %9026, align 1
  %9028 = icmp eq i64 %9024, %9025
  %9029 = sext i1 %9028 to i8
  %9030 = xor i8 %9029, -1
  %9031 = and i8 %9030, 0
  %9032 = and i8 %9029, %9027
  %9033 = or i8 %9032, %9031
  %9034 = add i64 %9025, 64
  %9035 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9034
  %9036 = load i8, i8* %9035, align 1
  %9037 = icmp eq i64 %9024, %9034
  %9038 = sext i1 %9037 to i8
  %9039 = xor i8 %9038, -1
  %9040 = and i8 %9039, %9033
  %9041 = and i8 %9038, %9036
  %9042 = or i8 %9041, %9040
  %9043 = add i64 %9034, 64
  %9044 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9043
  %9045 = load i8, i8* %9044, align 1
  %9046 = icmp eq i64 %9024, %9043
  %9047 = sext i1 %9046 to i8
  %9048 = xor i8 %9047, -1
  %9049 = and i8 %9048, %9042
  %9050 = and i8 %9047, %9045
  %9051 = or i8 %9050, %9049
  %9052 = add i64 %9043, 64
  %9053 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9052
  %9054 = load i8, i8* %9053, align 1
  %9055 = icmp eq i64 %9024, %9052
  %9056 = sext i1 %9055 to i8
  %9057 = xor i8 %9056, -1
  %9058 = and i8 %9057, %9051
  %9059 = and i8 %9056, %9054
  %Mitigated82 = or i8 %9059, %9058
  %9060 = zext i8 %Mitigated82 to i32
  %9061 = zext i8 %8585 to i32
  %9062 = xor i32 %9060, %9061
  %9063 = sext i32 %9062 to i64
  %9064 = srem i64 %9063, 16
  %9065 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9064
  %9066 = load i32, i32* %9065, align 4
  %9067 = icmp eq i64 %9063, %9064
  %9068 = sext i1 %9067 to i32
  %9069 = xor i32 %9068, -1
  %9070 = and i32 %9069, 0
  %9071 = and i32 %9068, %9066
  %9072 = or i32 %9071, %9070
  %9073 = add i64 %9064, 16
  %9074 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9073
  %9075 = load i32, i32* %9074, align 4
  %9076 = icmp eq i64 %9063, %9073
  %9077 = sext i1 %9076 to i32
  %9078 = xor i32 %9077, -1
  %9079 = and i32 %9078, %9072
  %9080 = and i32 %9077, %9075
  %9081 = or i32 %9080, %9079
  %9082 = add i64 %9073, 16
  %9083 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9082
  %9084 = load i32, i32* %9083, align 4
  %9085 = icmp eq i64 %9063, %9082
  %9086 = sext i1 %9085 to i32
  %9087 = xor i32 %9086, -1
  %9088 = and i32 %9087, %9081
  %9089 = and i32 %9086, %9084
  %9090 = or i32 %9089, %9088
  %9091 = add i64 %9082, 16
  %9092 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9091
  %9093 = load i32, i32* %9092, align 4
  %9094 = icmp eq i64 %9063, %9091
  %9095 = sext i1 %9094 to i32
  %9096 = xor i32 %9095, -1
  %9097 = and i32 %9096, %9090
  %9098 = and i32 %9095, %9093
  %9099 = or i32 %9098, %9097
  %9100 = add i64 %9091, 16
  %9101 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9100
  %9102 = load i32, i32* %9101, align 4
  %9103 = icmp eq i64 %9063, %9100
  %9104 = sext i1 %9103 to i32
  %9105 = xor i32 %9104, -1
  %9106 = and i32 %9105, %9099
  %9107 = and i32 %9104, %9102
  %9108 = or i32 %9107, %9106
  %9109 = add i64 %9100, 16
  %9110 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9109
  %9111 = load i32, i32* %9110, align 4
  %9112 = icmp eq i64 %9063, %9109
  %9113 = sext i1 %9112 to i32
  %9114 = xor i32 %9113, -1
  %9115 = and i32 %9114, %9108
  %9116 = and i32 %9113, %9111
  %9117 = or i32 %9116, %9115
  %9118 = add i64 %9109, 16
  %9119 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9118
  %9120 = load i32, i32* %9119, align 4
  %9121 = icmp eq i64 %9063, %9118
  %9122 = sext i1 %9121 to i32
  %9123 = xor i32 %9122, -1
  %9124 = and i32 %9123, %9117
  %9125 = and i32 %9122, %9120
  %9126 = or i32 %9125, %9124
  %9127 = add i64 %9118, 16
  %9128 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9127
  %9129 = load i32, i32* %9128, align 4
  %9130 = icmp eq i64 %9063, %9127
  %9131 = sext i1 %9130 to i32
  %9132 = xor i32 %9131, -1
  %9133 = and i32 %9132, %9126
  %9134 = and i32 %9131, %9129
  %9135 = or i32 %9134, %9133
  %9136 = add i64 %9127, 16
  %9137 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9136
  %9138 = load i32, i32* %9137, align 4
  %9139 = icmp eq i64 %9063, %9136
  %9140 = sext i1 %9139 to i32
  %9141 = xor i32 %9140, -1
  %9142 = and i32 %9141, %9135
  %9143 = and i32 %9140, %9138
  %9144 = or i32 %9143, %9142
  %9145 = add i64 %9136, 16
  %9146 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9145
  %9147 = load i32, i32* %9146, align 4
  %9148 = icmp eq i64 %9063, %9145
  %9149 = sext i1 %9148 to i32
  %9150 = xor i32 %9149, -1
  %9151 = and i32 %9150, %9144
  %9152 = and i32 %9149, %9147
  %9153 = or i32 %9152, %9151
  %9154 = add i64 %9145, 16
  %9155 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9154
  %9156 = load i32, i32* %9155, align 4
  %9157 = icmp eq i64 %9063, %9154
  %9158 = sext i1 %9157 to i32
  %9159 = xor i32 %9158, -1
  %9160 = and i32 %9159, %9153
  %9161 = and i32 %9158, %9156
  %9162 = or i32 %9161, %9160
  %9163 = add i64 %9154, 16
  %9164 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9163
  %9165 = load i32, i32* %9164, align 4
  %9166 = icmp eq i64 %9063, %9163
  %9167 = sext i1 %9166 to i32
  %9168 = xor i32 %9167, -1
  %9169 = and i32 %9168, %9162
  %9170 = and i32 %9167, %9165
  %9171 = or i32 %9170, %9169
  %9172 = add i64 %9163, 16
  %9173 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9172
  %9174 = load i32, i32* %9173, align 4
  %9175 = icmp eq i64 %9063, %9172
  %9176 = sext i1 %9175 to i32
  %9177 = xor i32 %9176, -1
  %9178 = and i32 %9177, %9171
  %9179 = and i32 %9176, %9174
  %9180 = or i32 %9179, %9178
  %9181 = add i64 %9172, 16
  %9182 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9181
  %9183 = load i32, i32* %9182, align 4
  %9184 = icmp eq i64 %9063, %9181
  %9185 = sext i1 %9184 to i32
  %9186 = xor i32 %9185, -1
  %9187 = and i32 %9186, %9180
  %9188 = and i32 %9185, %9183
  %9189 = or i32 %9188, %9187
  %9190 = add i64 %9181, 16
  %9191 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9190
  %9192 = load i32, i32* %9191, align 4
  %9193 = icmp eq i64 %9063, %9190
  %9194 = sext i1 %9193 to i32
  %9195 = xor i32 %9194, -1
  %9196 = and i32 %9195, %9189
  %9197 = and i32 %9194, %9192
  %9198 = or i32 %9197, %9196
  %9199 = add i64 %9190, 16
  %9200 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9199
  %9201 = load i32, i32* %9200, align 4
  %9202 = icmp eq i64 %9063, %9199
  %9203 = sext i1 %9202 to i32
  %9204 = xor i32 %9203, -1
  %9205 = and i32 %9204, %9198
  %9206 = and i32 %9203, %9201
  %Mitigated83 = or i32 %9206, %9205
  %9207 = sext i32 %.0111 to i64
  %9208 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 0
  %9209 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9208, i64 0, i64 1
  %9210 = getelementptr inbounds [256 x i32], [256 x i32]* %9209, i64 0, i64 %9207
  store i32 %Mitigated83, i32* %9210, align 4
  %9211 = sext i32 %.0210 to i64
  %9212 = getelementptr inbounds [512 x i8], [512 x i8]* @calc_sb_tbl, i64 0, i64 %9211
  %9213 = load i8, i8* %9212, align 1
  %9214 = zext i8 %9213 to i32
  %9215 = zext i8 %4296 to i32
  %9216 = xor i32 %9214, %9215
  %9217 = sext i32 %9216 to i64
  %9218 = srem i64 %9217, 64
  %9219 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9218
  %9220 = load i8, i8* %9219, align 1
  %9221 = icmp eq i64 %9217, %9218
  %9222 = sext i1 %9221 to i8
  %9223 = xor i8 %9222, -1
  %9224 = and i8 %9223, 0
  %9225 = and i8 %9222, %9220
  %9226 = or i8 %9225, %9224
  %9227 = add i64 %9218, 64
  %9228 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9227
  %9229 = load i8, i8* %9228, align 1
  %9230 = icmp eq i64 %9217, %9227
  %9231 = sext i1 %9230 to i8
  %9232 = xor i8 %9231, -1
  %9233 = and i8 %9232, %9226
  %9234 = and i8 %9231, %9229
  %9235 = or i8 %9234, %9233
  %9236 = add i64 %9227, 64
  %9237 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9236
  %9238 = load i8, i8* %9237, align 1
  %9239 = icmp eq i64 %9217, %9236
  %9240 = sext i1 %9239 to i8
  %9241 = xor i8 %9240, -1
  %9242 = and i8 %9241, %9235
  %9243 = and i8 %9240, %9238
  %9244 = or i8 %9243, %9242
  %9245 = add i64 %9236, 64
  %9246 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9245
  %9247 = load i8, i8* %9246, align 1
  %9248 = icmp eq i64 %9217, %9245
  %9249 = sext i1 %9248 to i8
  %9250 = xor i8 %9249, -1
  %9251 = and i8 %9250, %9244
  %9252 = and i8 %9249, %9247
  %Mitigated84 = or i8 %9252, %9251
  %9253 = zext i8 %Mitigated84 to i32
  %9254 = zext i8 %8704 to i32
  %9255 = xor i32 %9253, %9254
  %9256 = sext i32 %9255 to i64
  %9257 = srem i64 %9256, 16
  %9258 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9257
  %9259 = load i32, i32* %9258, align 4
  %9260 = icmp eq i64 %9256, %9257
  %9261 = sext i1 %9260 to i32
  %9262 = xor i32 %9261, -1
  %9263 = and i32 %9262, 0
  %9264 = and i32 %9261, %9259
  %9265 = or i32 %9264, %9263
  %9266 = add i64 %9257, 16
  %9267 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9266
  %9268 = load i32, i32* %9267, align 4
  %9269 = icmp eq i64 %9256, %9266
  %9270 = sext i1 %9269 to i32
  %9271 = xor i32 %9270, -1
  %9272 = and i32 %9271, %9265
  %9273 = and i32 %9270, %9268
  %9274 = or i32 %9273, %9272
  %9275 = add i64 %9266, 16
  %9276 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9275
  %9277 = load i32, i32* %9276, align 4
  %9278 = icmp eq i64 %9256, %9275
  %9279 = sext i1 %9278 to i32
  %9280 = xor i32 %9279, -1
  %9281 = and i32 %9280, %9274
  %9282 = and i32 %9279, %9277
  %9283 = or i32 %9282, %9281
  %9284 = add i64 %9275, 16
  %9285 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9284
  %9286 = load i32, i32* %9285, align 4
  %9287 = icmp eq i64 %9256, %9284
  %9288 = sext i1 %9287 to i32
  %9289 = xor i32 %9288, -1
  %9290 = and i32 %9289, %9283
  %9291 = and i32 %9288, %9286
  %9292 = or i32 %9291, %9290
  %9293 = add i64 %9284, 16
  %9294 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9293
  %9295 = load i32, i32* %9294, align 4
  %9296 = icmp eq i64 %9256, %9293
  %9297 = sext i1 %9296 to i32
  %9298 = xor i32 %9297, -1
  %9299 = and i32 %9298, %9292
  %9300 = and i32 %9297, %9295
  %9301 = or i32 %9300, %9299
  %9302 = add i64 %9293, 16
  %9303 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9302
  %9304 = load i32, i32* %9303, align 4
  %9305 = icmp eq i64 %9256, %9302
  %9306 = sext i1 %9305 to i32
  %9307 = xor i32 %9306, -1
  %9308 = and i32 %9307, %9301
  %9309 = and i32 %9306, %9304
  %9310 = or i32 %9309, %9308
  %9311 = add i64 %9302, 16
  %9312 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9311
  %9313 = load i32, i32* %9312, align 4
  %9314 = icmp eq i64 %9256, %9311
  %9315 = sext i1 %9314 to i32
  %9316 = xor i32 %9315, -1
  %9317 = and i32 %9316, %9310
  %9318 = and i32 %9315, %9313
  %9319 = or i32 %9318, %9317
  %9320 = add i64 %9311, 16
  %9321 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9320
  %9322 = load i32, i32* %9321, align 4
  %9323 = icmp eq i64 %9256, %9320
  %9324 = sext i1 %9323 to i32
  %9325 = xor i32 %9324, -1
  %9326 = and i32 %9325, %9319
  %9327 = and i32 %9324, %9322
  %9328 = or i32 %9327, %9326
  %9329 = add i64 %9320, 16
  %9330 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9329
  %9331 = load i32, i32* %9330, align 4
  %9332 = icmp eq i64 %9256, %9329
  %9333 = sext i1 %9332 to i32
  %9334 = xor i32 %9333, -1
  %9335 = and i32 %9334, %9328
  %9336 = and i32 %9333, %9331
  %9337 = or i32 %9336, %9335
  %9338 = add i64 %9329, 16
  %9339 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9338
  %9340 = load i32, i32* %9339, align 4
  %9341 = icmp eq i64 %9256, %9338
  %9342 = sext i1 %9341 to i32
  %9343 = xor i32 %9342, -1
  %9344 = and i32 %9343, %9337
  %9345 = and i32 %9342, %9340
  %9346 = or i32 %9345, %9344
  %9347 = add i64 %9338, 16
  %9348 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9347
  %9349 = load i32, i32* %9348, align 4
  %9350 = icmp eq i64 %9256, %9347
  %9351 = sext i1 %9350 to i32
  %9352 = xor i32 %9351, -1
  %9353 = and i32 %9352, %9346
  %9354 = and i32 %9351, %9349
  %9355 = or i32 %9354, %9353
  %9356 = add i64 %9347, 16
  %9357 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9356
  %9358 = load i32, i32* %9357, align 4
  %9359 = icmp eq i64 %9256, %9356
  %9360 = sext i1 %9359 to i32
  %9361 = xor i32 %9360, -1
  %9362 = and i32 %9361, %9355
  %9363 = and i32 %9360, %9358
  %9364 = or i32 %9363, %9362
  %9365 = add i64 %9356, 16
  %9366 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9365
  %9367 = load i32, i32* %9366, align 4
  %9368 = icmp eq i64 %9256, %9365
  %9369 = sext i1 %9368 to i32
  %9370 = xor i32 %9369, -1
  %9371 = and i32 %9370, %9364
  %9372 = and i32 %9369, %9367
  %9373 = or i32 %9372, %9371
  %9374 = add i64 %9365, 16
  %9375 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9374
  %9376 = load i32, i32* %9375, align 4
  %9377 = icmp eq i64 %9256, %9374
  %9378 = sext i1 %9377 to i32
  %9379 = xor i32 %9378, -1
  %9380 = and i32 %9379, %9373
  %9381 = and i32 %9378, %9376
  %9382 = or i32 %9381, %9380
  %9383 = add i64 %9374, 16
  %9384 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9383
  %9385 = load i32, i32* %9384, align 4
  %9386 = icmp eq i64 %9256, %9383
  %9387 = sext i1 %9386 to i32
  %9388 = xor i32 %9387, -1
  %9389 = and i32 %9388, %9382
  %9390 = and i32 %9387, %9385
  %9391 = or i32 %9390, %9389
  %9392 = add i64 %9383, 16
  %9393 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %9392
  %9394 = load i32, i32* %9393, align 4
  %9395 = icmp eq i64 %9256, %9392
  %9396 = sext i1 %9395 to i32
  %9397 = xor i32 %9396, -1
  %9398 = and i32 %9397, %9391
  %9399 = and i32 %9396, %9394
  %Mitigated85 = or i32 %9399, %9398
  %9400 = sext i32 %.0111 to i64
  %9401 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 0
  %9402 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9401, i64 0, i64 2
  %9403 = getelementptr inbounds [256 x i32], [256 x i32]* %9402, i64 0, i64 %9400
  store i32 %Mitigated85, i32* %9403, align 4
  %9404 = sext i32 %.049 to i64
  %9405 = getelementptr inbounds [512 x i8], [512 x i8]* @calc_sb_tbl, i64 0, i64 %9404
  %9406 = load i8, i8* %9405, align 1
  %9407 = zext i8 %9406 to i32
  %9408 = zext i8 %4415 to i32
  %9409 = xor i32 %9407, %9408
  %9410 = sext i32 %9409 to i64
  %9411 = srem i64 %9410, 64
  %9412 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9411
  %9413 = load i8, i8* %9412, align 1
  %9414 = icmp eq i64 %9410, %9411
  %9415 = sext i1 %9414 to i8
  %9416 = xor i8 %9415, -1
  %9417 = and i8 %9416, 0
  %9418 = and i8 %9415, %9413
  %9419 = or i8 %9418, %9417
  %9420 = add i64 %9411, 64
  %9421 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9420
  %9422 = load i8, i8* %9421, align 1
  %9423 = icmp eq i64 %9410, %9420
  %9424 = sext i1 %9423 to i8
  %9425 = xor i8 %9424, -1
  %9426 = and i8 %9425, %9419
  %9427 = and i8 %9424, %9422
  %9428 = or i8 %9427, %9426
  %9429 = add i64 %9420, 64
  %9430 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9429
  %9431 = load i8, i8* %9430, align 1
  %9432 = icmp eq i64 %9410, %9429
  %9433 = sext i1 %9432 to i8
  %9434 = xor i8 %9433, -1
  %9435 = and i8 %9434, %9428
  %9436 = and i8 %9433, %9431
  %9437 = or i8 %9436, %9435
  %9438 = add i64 %9429, 64
  %9439 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9438
  %9440 = load i8, i8* %9439, align 1
  %9441 = icmp eq i64 %9410, %9438
  %9442 = sext i1 %9441 to i8
  %9443 = xor i8 %9442, -1
  %9444 = and i8 %9443, %9437
  %9445 = and i8 %9442, %9440
  %Mitigated86 = or i8 %9445, %9444
  %9446 = zext i8 %Mitigated86 to i32
  %9447 = zext i8 %8823 to i32
  %9448 = xor i32 %9446, %9447
  %9449 = sext i32 %9448 to i64
  %9450 = srem i64 %9449, 16
  %9451 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9450
  %9452 = load i32, i32* %9451, align 4
  %9453 = icmp eq i64 %9449, %9450
  %9454 = sext i1 %9453 to i32
  %9455 = xor i32 %9454, -1
  %9456 = and i32 %9455, 0
  %9457 = and i32 %9454, %9452
  %9458 = or i32 %9457, %9456
  %9459 = add i64 %9450, 16
  %9460 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9459
  %9461 = load i32, i32* %9460, align 4
  %9462 = icmp eq i64 %9449, %9459
  %9463 = sext i1 %9462 to i32
  %9464 = xor i32 %9463, -1
  %9465 = and i32 %9464, %9458
  %9466 = and i32 %9463, %9461
  %9467 = or i32 %9466, %9465
  %9468 = add i64 %9459, 16
  %9469 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9468
  %9470 = load i32, i32* %9469, align 4
  %9471 = icmp eq i64 %9449, %9468
  %9472 = sext i1 %9471 to i32
  %9473 = xor i32 %9472, -1
  %9474 = and i32 %9473, %9467
  %9475 = and i32 %9472, %9470
  %9476 = or i32 %9475, %9474
  %9477 = add i64 %9468, 16
  %9478 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9477
  %9479 = load i32, i32* %9478, align 4
  %9480 = icmp eq i64 %9449, %9477
  %9481 = sext i1 %9480 to i32
  %9482 = xor i32 %9481, -1
  %9483 = and i32 %9482, %9476
  %9484 = and i32 %9481, %9479
  %9485 = or i32 %9484, %9483
  %9486 = add i64 %9477, 16
  %9487 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9486
  %9488 = load i32, i32* %9487, align 4
  %9489 = icmp eq i64 %9449, %9486
  %9490 = sext i1 %9489 to i32
  %9491 = xor i32 %9490, -1
  %9492 = and i32 %9491, %9485
  %9493 = and i32 %9490, %9488
  %9494 = or i32 %9493, %9492
  %9495 = add i64 %9486, 16
  %9496 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9495
  %9497 = load i32, i32* %9496, align 4
  %9498 = icmp eq i64 %9449, %9495
  %9499 = sext i1 %9498 to i32
  %9500 = xor i32 %9499, -1
  %9501 = and i32 %9500, %9494
  %9502 = and i32 %9499, %9497
  %9503 = or i32 %9502, %9501
  %9504 = add i64 %9495, 16
  %9505 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9504
  %9506 = load i32, i32* %9505, align 4
  %9507 = icmp eq i64 %9449, %9504
  %9508 = sext i1 %9507 to i32
  %9509 = xor i32 %9508, -1
  %9510 = and i32 %9509, %9503
  %9511 = and i32 %9508, %9506
  %9512 = or i32 %9511, %9510
  %9513 = add i64 %9504, 16
  %9514 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9513
  %9515 = load i32, i32* %9514, align 4
  %9516 = icmp eq i64 %9449, %9513
  %9517 = sext i1 %9516 to i32
  %9518 = xor i32 %9517, -1
  %9519 = and i32 %9518, %9512
  %9520 = and i32 %9517, %9515
  %9521 = or i32 %9520, %9519
  %9522 = add i64 %9513, 16
  %9523 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9522
  %9524 = load i32, i32* %9523, align 4
  %9525 = icmp eq i64 %9449, %9522
  %9526 = sext i1 %9525 to i32
  %9527 = xor i32 %9526, -1
  %9528 = and i32 %9527, %9521
  %9529 = and i32 %9526, %9524
  %9530 = or i32 %9529, %9528
  %9531 = add i64 %9522, 16
  %9532 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9531
  %9533 = load i32, i32* %9532, align 4
  %9534 = icmp eq i64 %9449, %9531
  %9535 = sext i1 %9534 to i32
  %9536 = xor i32 %9535, -1
  %9537 = and i32 %9536, %9530
  %9538 = and i32 %9535, %9533
  %9539 = or i32 %9538, %9537
  %9540 = add i64 %9531, 16
  %9541 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9540
  %9542 = load i32, i32* %9541, align 4
  %9543 = icmp eq i64 %9449, %9540
  %9544 = sext i1 %9543 to i32
  %9545 = xor i32 %9544, -1
  %9546 = and i32 %9545, %9539
  %9547 = and i32 %9544, %9542
  %9548 = or i32 %9547, %9546
  %9549 = add i64 %9540, 16
  %9550 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9549
  %9551 = load i32, i32* %9550, align 4
  %9552 = icmp eq i64 %9449, %9549
  %9553 = sext i1 %9552 to i32
  %9554 = xor i32 %9553, -1
  %9555 = and i32 %9554, %9548
  %9556 = and i32 %9553, %9551
  %9557 = or i32 %9556, %9555
  %9558 = add i64 %9549, 16
  %9559 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9558
  %9560 = load i32, i32* %9559, align 4
  %9561 = icmp eq i64 %9449, %9558
  %9562 = sext i1 %9561 to i32
  %9563 = xor i32 %9562, -1
  %9564 = and i32 %9563, %9557
  %9565 = and i32 %9562, %9560
  %9566 = or i32 %9565, %9564
  %9567 = add i64 %9558, 16
  %9568 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9567
  %9569 = load i32, i32* %9568, align 4
  %9570 = icmp eq i64 %9449, %9567
  %9571 = sext i1 %9570 to i32
  %9572 = xor i32 %9571, -1
  %9573 = and i32 %9572, %9566
  %9574 = and i32 %9571, %9569
  %9575 = or i32 %9574, %9573
  %9576 = add i64 %9567, 16
  %9577 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9576
  %9578 = load i32, i32* %9577, align 4
  %9579 = icmp eq i64 %9449, %9576
  %9580 = sext i1 %9579 to i32
  %9581 = xor i32 %9580, -1
  %9582 = and i32 %9581, %9575
  %9583 = and i32 %9580, %9578
  %9584 = or i32 %9583, %9582
  %9585 = add i64 %9576, 16
  %9586 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %9585
  %9587 = load i32, i32* %9586, align 4
  %9588 = icmp eq i64 %9449, %9585
  %9589 = sext i1 %9588 to i32
  %9590 = xor i32 %9589, -1
  %9591 = and i32 %9590, %9584
  %9592 = and i32 %9589, %9587
  %Mitigated87 = or i32 %9592, %9591
  %9593 = sext i32 %.0111 to i64
  %9594 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 0
  %9595 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9594, i64 0, i64 3
  %9596 = getelementptr inbounds [256 x i32], [256 x i32]* %9595, i64 0, i64 %9593
  store i32 %Mitigated87, i32* %9596, align 4
  %9597 = add nsw i32 %.0111, 1
  %9598 = add nsw i32 %.0210, 2
  %9599 = add nsw i32 %.049, 2
  %9600 = icmp slt i32 %9597, 256
  br i1 %9600, label %8824, label %.preheader5

.preheader:                                       ; preds = %9601
  %.13.ph = phi i32 [ 0, %9601 ]
  %.2.ph = phi i32 [ %11171, %9601 ]
  br label %11173

; <label>:9601:                                   ; preds = %.preheader5, %9601
  %.18 = phi i32 [ %.1.ph, %.preheader5 ], [ %11171, %9601 ]
  %9602 = sext i32 %.18 to i64
  %9603 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9602
  %9604 = load i8, i8* %9603, align 1
  %9605 = zext i8 %9604 to i32
  %9606 = getelementptr inbounds i8, i8* %0, i64 8
  %9607 = load i8, i8* %9606, align 1
  %9608 = zext i8 %9607 to i32
  %9609 = xor i32 %9605, %9608
  %9610 = sext i32 %9609 to i64
  %9611 = srem i64 %9610, 64
  %9612 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9611
  %9613 = load i8, i8* %9612, align 1
  %9614 = icmp eq i64 %9610, %9611
  %9615 = sext i1 %9614 to i8
  %9616 = xor i8 %9615, -1
  %9617 = and i8 %9616, 0
  %9618 = and i8 %9615, %9613
  %9619 = or i8 %9618, %9617
  %9620 = add i64 %9611, 64
  %9621 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9620
  %9622 = load i8, i8* %9621, align 1
  %9623 = icmp eq i64 %9610, %9620
  %9624 = sext i1 %9623 to i8
  %9625 = xor i8 %9624, -1
  %9626 = and i8 %9625, %9619
  %9627 = and i8 %9624, %9622
  %9628 = or i8 %9627, %9626
  %9629 = add i64 %9620, 64
  %9630 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9629
  %9631 = load i8, i8* %9630, align 1
  %9632 = icmp eq i64 %9610, %9629
  %9633 = sext i1 %9632 to i8
  %9634 = xor i8 %9633, -1
  %9635 = and i8 %9634, %9628
  %9636 = and i8 %9633, %9631
  %9637 = or i8 %9636, %9635
  %9638 = add i64 %9629, 64
  %9639 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9638
  %9640 = load i8, i8* %9639, align 1
  %9641 = icmp eq i64 %9610, %9638
  %9642 = sext i1 %9641 to i8
  %9643 = xor i8 %9642, -1
  %9644 = and i8 %9643, %9637
  %9645 = and i8 %9642, %9640
  %Mitigated88 = or i8 %9645, %9644
  %9646 = zext i8 %Mitigated88 to i32
  %9647 = getelementptr inbounds i8, i8* %0, i64 0
  %9648 = load i8, i8* %9647, align 1
  %9649 = zext i8 %9648 to i32
  %9650 = xor i32 %9646, %9649
  %9651 = sext i32 %9650 to i64
  %9652 = srem i64 %9651, 16
  %9653 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9652
  %9654 = load i32, i32* %9653, align 4
  %9655 = icmp eq i64 %9651, %9652
  %9656 = sext i1 %9655 to i32
  %9657 = xor i32 %9656, -1
  %9658 = and i32 %9657, 0
  %9659 = and i32 %9656, %9654
  %9660 = or i32 %9659, %9658
  %9661 = add i64 %9652, 16
  %9662 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9661
  %9663 = load i32, i32* %9662, align 4
  %9664 = icmp eq i64 %9651, %9661
  %9665 = sext i1 %9664 to i32
  %9666 = xor i32 %9665, -1
  %9667 = and i32 %9666, %9660
  %9668 = and i32 %9665, %9663
  %9669 = or i32 %9668, %9667
  %9670 = add i64 %9661, 16
  %9671 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9670
  %9672 = load i32, i32* %9671, align 4
  %9673 = icmp eq i64 %9651, %9670
  %9674 = sext i1 %9673 to i32
  %9675 = xor i32 %9674, -1
  %9676 = and i32 %9675, %9669
  %9677 = and i32 %9674, %9672
  %9678 = or i32 %9677, %9676
  %9679 = add i64 %9670, 16
  %9680 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9679
  %9681 = load i32, i32* %9680, align 4
  %9682 = icmp eq i64 %9651, %9679
  %9683 = sext i1 %9682 to i32
  %9684 = xor i32 %9683, -1
  %9685 = and i32 %9684, %9678
  %9686 = and i32 %9683, %9681
  %9687 = or i32 %9686, %9685
  %9688 = add i64 %9679, 16
  %9689 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9688
  %9690 = load i32, i32* %9689, align 4
  %9691 = icmp eq i64 %9651, %9688
  %9692 = sext i1 %9691 to i32
  %9693 = xor i32 %9692, -1
  %9694 = and i32 %9693, %9687
  %9695 = and i32 %9692, %9690
  %9696 = or i32 %9695, %9694
  %9697 = add i64 %9688, 16
  %9698 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9697
  %9699 = load i32, i32* %9698, align 4
  %9700 = icmp eq i64 %9651, %9697
  %9701 = sext i1 %9700 to i32
  %9702 = xor i32 %9701, -1
  %9703 = and i32 %9702, %9696
  %9704 = and i32 %9701, %9699
  %9705 = or i32 %9704, %9703
  %9706 = add i64 %9697, 16
  %9707 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9706
  %9708 = load i32, i32* %9707, align 4
  %9709 = icmp eq i64 %9651, %9706
  %9710 = sext i1 %9709 to i32
  %9711 = xor i32 %9710, -1
  %9712 = and i32 %9711, %9705
  %9713 = and i32 %9710, %9708
  %9714 = or i32 %9713, %9712
  %9715 = add i64 %9706, 16
  %9716 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9715
  %9717 = load i32, i32* %9716, align 4
  %9718 = icmp eq i64 %9651, %9715
  %9719 = sext i1 %9718 to i32
  %9720 = xor i32 %9719, -1
  %9721 = and i32 %9720, %9714
  %9722 = and i32 %9719, %9717
  %9723 = or i32 %9722, %9721
  %9724 = add i64 %9715, 16
  %9725 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9724
  %9726 = load i32, i32* %9725, align 4
  %9727 = icmp eq i64 %9651, %9724
  %9728 = sext i1 %9727 to i32
  %9729 = xor i32 %9728, -1
  %9730 = and i32 %9729, %9723
  %9731 = and i32 %9728, %9726
  %9732 = or i32 %9731, %9730
  %9733 = add i64 %9724, 16
  %9734 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9733
  %9735 = load i32, i32* %9734, align 4
  %9736 = icmp eq i64 %9651, %9733
  %9737 = sext i1 %9736 to i32
  %9738 = xor i32 %9737, -1
  %9739 = and i32 %9738, %9732
  %9740 = and i32 %9737, %9735
  %9741 = or i32 %9740, %9739
  %9742 = add i64 %9733, 16
  %9743 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9742
  %9744 = load i32, i32* %9743, align 4
  %9745 = icmp eq i64 %9651, %9742
  %9746 = sext i1 %9745 to i32
  %9747 = xor i32 %9746, -1
  %9748 = and i32 %9747, %9741
  %9749 = and i32 %9746, %9744
  %9750 = or i32 %9749, %9748
  %9751 = add i64 %9742, 16
  %9752 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9751
  %9753 = load i32, i32* %9752, align 4
  %9754 = icmp eq i64 %9651, %9751
  %9755 = sext i1 %9754 to i32
  %9756 = xor i32 %9755, -1
  %9757 = and i32 %9756, %9750
  %9758 = and i32 %9755, %9753
  %9759 = or i32 %9758, %9757
  %9760 = add i64 %9751, 16
  %9761 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9760
  %9762 = load i32, i32* %9761, align 4
  %9763 = icmp eq i64 %9651, %9760
  %9764 = sext i1 %9763 to i32
  %9765 = xor i32 %9764, -1
  %9766 = and i32 %9765, %9759
  %9767 = and i32 %9764, %9762
  %9768 = or i32 %9767, %9766
  %9769 = add i64 %9760, 16
  %9770 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9769
  %9771 = load i32, i32* %9770, align 4
  %9772 = icmp eq i64 %9651, %9769
  %9773 = sext i1 %9772 to i32
  %9774 = xor i32 %9773, -1
  %9775 = and i32 %9774, %9768
  %9776 = and i32 %9773, %9771
  %9777 = or i32 %9776, %9775
  %9778 = add i64 %9769, 16
  %9779 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9778
  %9780 = load i32, i32* %9779, align 4
  %9781 = icmp eq i64 %9651, %9778
  %9782 = sext i1 %9781 to i32
  %9783 = xor i32 %9782, -1
  %9784 = and i32 %9783, %9777
  %9785 = and i32 %9782, %9780
  %9786 = or i32 %9785, %9784
  %9787 = add i64 %9778, 16
  %9788 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %9787
  %9789 = load i32, i32* %9788, align 4
  %9790 = icmp eq i64 %9651, %9787
  %9791 = sext i1 %9790 to i32
  %9792 = xor i32 %9791, -1
  %9793 = and i32 %9792, %9786
  %9794 = and i32 %9791, %9789
  %Mitigated89 = or i32 %9794, %9793
  %9795 = sext i32 %.18 to i64
  %9796 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9795
  %9797 = load i8, i8* %9796, align 1
  %9798 = zext i8 %9797 to i32
  %9799 = getelementptr inbounds i8, i8* %0, i64 9
  %9800 = load i8, i8* %9799, align 1
  %9801 = zext i8 %9800 to i32
  %9802 = xor i32 %9798, %9801
  %9803 = sext i32 %9802 to i64
  %9804 = srem i64 %9803, 64
  %9805 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9804
  %9806 = load i8, i8* %9805, align 1
  %9807 = icmp eq i64 %9803, %9804
  %9808 = sext i1 %9807 to i8
  %9809 = xor i8 %9808, -1
  %9810 = and i8 %9809, 0
  %9811 = and i8 %9808, %9806
  %9812 = or i8 %9811, %9810
  %9813 = add i64 %9804, 64
  %9814 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9813
  %9815 = load i8, i8* %9814, align 1
  %9816 = icmp eq i64 %9803, %9813
  %9817 = sext i1 %9816 to i8
  %9818 = xor i8 %9817, -1
  %9819 = and i8 %9818, %9812
  %9820 = and i8 %9817, %9815
  %9821 = or i8 %9820, %9819
  %9822 = add i64 %9813, 64
  %9823 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9822
  %9824 = load i8, i8* %9823, align 1
  %9825 = icmp eq i64 %9803, %9822
  %9826 = sext i1 %9825 to i8
  %9827 = xor i8 %9826, -1
  %9828 = and i8 %9827, %9821
  %9829 = and i8 %9826, %9824
  %9830 = or i8 %9829, %9828
  %9831 = add i64 %9822, 64
  %9832 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9831
  %9833 = load i8, i8* %9832, align 1
  %9834 = icmp eq i64 %9803, %9831
  %9835 = sext i1 %9834 to i8
  %9836 = xor i8 %9835, -1
  %9837 = and i8 %9836, %9830
  %9838 = and i8 %9835, %9833
  %Mitigated90 = or i8 %9838, %9837
  %9839 = zext i8 %Mitigated90 to i32
  %9840 = getelementptr inbounds i8, i8* %0, i64 1
  %9841 = load i8, i8* %9840, align 1
  %9842 = zext i8 %9841 to i32
  %9843 = xor i32 %9839, %9842
  %9844 = sext i32 %9843 to i64
  %9845 = srem i64 %9844, 16
  %9846 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9845
  %9847 = load i32, i32* %9846, align 4
  %9848 = icmp eq i64 %9844, %9845
  %9849 = sext i1 %9848 to i32
  %9850 = xor i32 %9849, -1
  %9851 = and i32 %9850, 0
  %9852 = and i32 %9849, %9847
  %9853 = or i32 %9852, %9851
  %9854 = add i64 %9845, 16
  %9855 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9854
  %9856 = load i32, i32* %9855, align 4
  %9857 = icmp eq i64 %9844, %9854
  %9858 = sext i1 %9857 to i32
  %9859 = xor i32 %9858, -1
  %9860 = and i32 %9859, %9853
  %9861 = and i32 %9858, %9856
  %9862 = or i32 %9861, %9860
  %9863 = add i64 %9854, 16
  %9864 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9863
  %9865 = load i32, i32* %9864, align 4
  %9866 = icmp eq i64 %9844, %9863
  %9867 = sext i1 %9866 to i32
  %9868 = xor i32 %9867, -1
  %9869 = and i32 %9868, %9862
  %9870 = and i32 %9867, %9865
  %9871 = or i32 %9870, %9869
  %9872 = add i64 %9863, 16
  %9873 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9872
  %9874 = load i32, i32* %9873, align 4
  %9875 = icmp eq i64 %9844, %9872
  %9876 = sext i1 %9875 to i32
  %9877 = xor i32 %9876, -1
  %9878 = and i32 %9877, %9871
  %9879 = and i32 %9876, %9874
  %9880 = or i32 %9879, %9878
  %9881 = add i64 %9872, 16
  %9882 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9881
  %9883 = load i32, i32* %9882, align 4
  %9884 = icmp eq i64 %9844, %9881
  %9885 = sext i1 %9884 to i32
  %9886 = xor i32 %9885, -1
  %9887 = and i32 %9886, %9880
  %9888 = and i32 %9885, %9883
  %9889 = or i32 %9888, %9887
  %9890 = add i64 %9881, 16
  %9891 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9890
  %9892 = load i32, i32* %9891, align 4
  %9893 = icmp eq i64 %9844, %9890
  %9894 = sext i1 %9893 to i32
  %9895 = xor i32 %9894, -1
  %9896 = and i32 %9895, %9889
  %9897 = and i32 %9894, %9892
  %9898 = or i32 %9897, %9896
  %9899 = add i64 %9890, 16
  %9900 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9899
  %9901 = load i32, i32* %9900, align 4
  %9902 = icmp eq i64 %9844, %9899
  %9903 = sext i1 %9902 to i32
  %9904 = xor i32 %9903, -1
  %9905 = and i32 %9904, %9898
  %9906 = and i32 %9903, %9901
  %9907 = or i32 %9906, %9905
  %9908 = add i64 %9899, 16
  %9909 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9908
  %9910 = load i32, i32* %9909, align 4
  %9911 = icmp eq i64 %9844, %9908
  %9912 = sext i1 %9911 to i32
  %9913 = xor i32 %9912, -1
  %9914 = and i32 %9913, %9907
  %9915 = and i32 %9912, %9910
  %9916 = or i32 %9915, %9914
  %9917 = add i64 %9908, 16
  %9918 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9917
  %9919 = load i32, i32* %9918, align 4
  %9920 = icmp eq i64 %9844, %9917
  %9921 = sext i1 %9920 to i32
  %9922 = xor i32 %9921, -1
  %9923 = and i32 %9922, %9916
  %9924 = and i32 %9921, %9919
  %9925 = or i32 %9924, %9923
  %9926 = add i64 %9917, 16
  %9927 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9926
  %9928 = load i32, i32* %9927, align 4
  %9929 = icmp eq i64 %9844, %9926
  %9930 = sext i1 %9929 to i32
  %9931 = xor i32 %9930, -1
  %9932 = and i32 %9931, %9925
  %9933 = and i32 %9930, %9928
  %9934 = or i32 %9933, %9932
  %9935 = add i64 %9926, 16
  %9936 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9935
  %9937 = load i32, i32* %9936, align 4
  %9938 = icmp eq i64 %9844, %9935
  %9939 = sext i1 %9938 to i32
  %9940 = xor i32 %9939, -1
  %9941 = and i32 %9940, %9934
  %9942 = and i32 %9939, %9937
  %9943 = or i32 %9942, %9941
  %9944 = add i64 %9935, 16
  %9945 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9944
  %9946 = load i32, i32* %9945, align 4
  %9947 = icmp eq i64 %9844, %9944
  %9948 = sext i1 %9947 to i32
  %9949 = xor i32 %9948, -1
  %9950 = and i32 %9949, %9943
  %9951 = and i32 %9948, %9946
  %9952 = or i32 %9951, %9950
  %9953 = add i64 %9944, 16
  %9954 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9953
  %9955 = load i32, i32* %9954, align 4
  %9956 = icmp eq i64 %9844, %9953
  %9957 = sext i1 %9956 to i32
  %9958 = xor i32 %9957, -1
  %9959 = and i32 %9958, %9952
  %9960 = and i32 %9957, %9955
  %9961 = or i32 %9960, %9959
  %9962 = add i64 %9953, 16
  %9963 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9962
  %9964 = load i32, i32* %9963, align 4
  %9965 = icmp eq i64 %9844, %9962
  %9966 = sext i1 %9965 to i32
  %9967 = xor i32 %9966, -1
  %9968 = and i32 %9967, %9961
  %9969 = and i32 %9966, %9964
  %9970 = or i32 %9969, %9968
  %9971 = add i64 %9962, 16
  %9972 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9971
  %9973 = load i32, i32* %9972, align 4
  %9974 = icmp eq i64 %9844, %9971
  %9975 = sext i1 %9974 to i32
  %9976 = xor i32 %9975, -1
  %9977 = and i32 %9976, %9970
  %9978 = and i32 %9975, %9973
  %9979 = or i32 %9978, %9977
  %9980 = add i64 %9971, 16
  %9981 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %9980
  %9982 = load i32, i32* %9981, align 4
  %9983 = icmp eq i64 %9844, %9980
  %9984 = sext i1 %9983 to i32
  %9985 = xor i32 %9984, -1
  %9986 = and i32 %9985, %9979
  %9987 = and i32 %9984, %9982
  %Mitigated91 = or i32 %9987, %9986
  %9988 = xor i32 %Mitigated89, %Mitigated91
  %9989 = sext i32 %.18 to i64
  %9990 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %9989
  %9991 = load i8, i8* %9990, align 1
  %9992 = zext i8 %9991 to i32
  %9993 = getelementptr inbounds i8, i8* %0, i64 10
  %9994 = load i8, i8* %9993, align 1
  %9995 = zext i8 %9994 to i32
  %9996 = xor i32 %9992, %9995
  %9997 = sext i32 %9996 to i64
  %9998 = srem i64 %9997, 64
  %9999 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %9998
  %10000 = load i8, i8* %9999, align 1
  %10001 = icmp eq i64 %9997, %9998
  %10002 = sext i1 %10001 to i8
  %10003 = xor i8 %10002, -1
  %10004 = and i8 %10003, 0
  %10005 = and i8 %10002, %10000
  %10006 = or i8 %10005, %10004
  %10007 = add i64 %9998, 64
  %10008 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10007
  %10009 = load i8, i8* %10008, align 1
  %10010 = icmp eq i64 %9997, %10007
  %10011 = sext i1 %10010 to i8
  %10012 = xor i8 %10011, -1
  %10013 = and i8 %10012, %10006
  %10014 = and i8 %10011, %10009
  %10015 = or i8 %10014, %10013
  %10016 = add i64 %10007, 64
  %10017 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10016
  %10018 = load i8, i8* %10017, align 1
  %10019 = icmp eq i64 %9997, %10016
  %10020 = sext i1 %10019 to i8
  %10021 = xor i8 %10020, -1
  %10022 = and i8 %10021, %10015
  %10023 = and i8 %10020, %10018
  %10024 = or i8 %10023, %10022
  %10025 = add i64 %10016, 64
  %10026 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10025
  %10027 = load i8, i8* %10026, align 1
  %10028 = icmp eq i64 %9997, %10025
  %10029 = sext i1 %10028 to i8
  %10030 = xor i8 %10029, -1
  %10031 = and i8 %10030, %10024
  %10032 = and i8 %10029, %10027
  %Mitigated92 = or i8 %10032, %10031
  %10033 = zext i8 %Mitigated92 to i32
  %10034 = getelementptr inbounds i8, i8* %0, i64 2
  %10035 = load i8, i8* %10034, align 1
  %10036 = zext i8 %10035 to i32
  %10037 = xor i32 %10033, %10036
  %10038 = sext i32 %10037 to i64
  %10039 = srem i64 %10038, 16
  %10040 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10039
  %10041 = load i32, i32* %10040, align 4
  %10042 = icmp eq i64 %10038, %10039
  %10043 = sext i1 %10042 to i32
  %10044 = xor i32 %10043, -1
  %10045 = and i32 %10044, 0
  %10046 = and i32 %10043, %10041
  %10047 = or i32 %10046, %10045
  %10048 = add i64 %10039, 16
  %10049 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10048
  %10050 = load i32, i32* %10049, align 4
  %10051 = icmp eq i64 %10038, %10048
  %10052 = sext i1 %10051 to i32
  %10053 = xor i32 %10052, -1
  %10054 = and i32 %10053, %10047
  %10055 = and i32 %10052, %10050
  %10056 = or i32 %10055, %10054
  %10057 = add i64 %10048, 16
  %10058 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10057
  %10059 = load i32, i32* %10058, align 4
  %10060 = icmp eq i64 %10038, %10057
  %10061 = sext i1 %10060 to i32
  %10062 = xor i32 %10061, -1
  %10063 = and i32 %10062, %10056
  %10064 = and i32 %10061, %10059
  %10065 = or i32 %10064, %10063
  %10066 = add i64 %10057, 16
  %10067 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10066
  %10068 = load i32, i32* %10067, align 4
  %10069 = icmp eq i64 %10038, %10066
  %10070 = sext i1 %10069 to i32
  %10071 = xor i32 %10070, -1
  %10072 = and i32 %10071, %10065
  %10073 = and i32 %10070, %10068
  %10074 = or i32 %10073, %10072
  %10075 = add i64 %10066, 16
  %10076 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10075
  %10077 = load i32, i32* %10076, align 4
  %10078 = icmp eq i64 %10038, %10075
  %10079 = sext i1 %10078 to i32
  %10080 = xor i32 %10079, -1
  %10081 = and i32 %10080, %10074
  %10082 = and i32 %10079, %10077
  %10083 = or i32 %10082, %10081
  %10084 = add i64 %10075, 16
  %10085 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10084
  %10086 = load i32, i32* %10085, align 4
  %10087 = icmp eq i64 %10038, %10084
  %10088 = sext i1 %10087 to i32
  %10089 = xor i32 %10088, -1
  %10090 = and i32 %10089, %10083
  %10091 = and i32 %10088, %10086
  %10092 = or i32 %10091, %10090
  %10093 = add i64 %10084, 16
  %10094 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10093
  %10095 = load i32, i32* %10094, align 4
  %10096 = icmp eq i64 %10038, %10093
  %10097 = sext i1 %10096 to i32
  %10098 = xor i32 %10097, -1
  %10099 = and i32 %10098, %10092
  %10100 = and i32 %10097, %10095
  %10101 = or i32 %10100, %10099
  %10102 = add i64 %10093, 16
  %10103 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10102
  %10104 = load i32, i32* %10103, align 4
  %10105 = icmp eq i64 %10038, %10102
  %10106 = sext i1 %10105 to i32
  %10107 = xor i32 %10106, -1
  %10108 = and i32 %10107, %10101
  %10109 = and i32 %10106, %10104
  %10110 = or i32 %10109, %10108
  %10111 = add i64 %10102, 16
  %10112 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10111
  %10113 = load i32, i32* %10112, align 4
  %10114 = icmp eq i64 %10038, %10111
  %10115 = sext i1 %10114 to i32
  %10116 = xor i32 %10115, -1
  %10117 = and i32 %10116, %10110
  %10118 = and i32 %10115, %10113
  %10119 = or i32 %10118, %10117
  %10120 = add i64 %10111, 16
  %10121 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10120
  %10122 = load i32, i32* %10121, align 4
  %10123 = icmp eq i64 %10038, %10120
  %10124 = sext i1 %10123 to i32
  %10125 = xor i32 %10124, -1
  %10126 = and i32 %10125, %10119
  %10127 = and i32 %10124, %10122
  %10128 = or i32 %10127, %10126
  %10129 = add i64 %10120, 16
  %10130 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10129
  %10131 = load i32, i32* %10130, align 4
  %10132 = icmp eq i64 %10038, %10129
  %10133 = sext i1 %10132 to i32
  %10134 = xor i32 %10133, -1
  %10135 = and i32 %10134, %10128
  %10136 = and i32 %10133, %10131
  %10137 = or i32 %10136, %10135
  %10138 = add i64 %10129, 16
  %10139 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10138
  %10140 = load i32, i32* %10139, align 4
  %10141 = icmp eq i64 %10038, %10138
  %10142 = sext i1 %10141 to i32
  %10143 = xor i32 %10142, -1
  %10144 = and i32 %10143, %10137
  %10145 = and i32 %10142, %10140
  %10146 = or i32 %10145, %10144
  %10147 = add i64 %10138, 16
  %10148 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10147
  %10149 = load i32, i32* %10148, align 4
  %10150 = icmp eq i64 %10038, %10147
  %10151 = sext i1 %10150 to i32
  %10152 = xor i32 %10151, -1
  %10153 = and i32 %10152, %10146
  %10154 = and i32 %10151, %10149
  %10155 = or i32 %10154, %10153
  %10156 = add i64 %10147, 16
  %10157 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10156
  %10158 = load i32, i32* %10157, align 4
  %10159 = icmp eq i64 %10038, %10156
  %10160 = sext i1 %10159 to i32
  %10161 = xor i32 %10160, -1
  %10162 = and i32 %10161, %10155
  %10163 = and i32 %10160, %10158
  %10164 = or i32 %10163, %10162
  %10165 = add i64 %10156, 16
  %10166 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10165
  %10167 = load i32, i32* %10166, align 4
  %10168 = icmp eq i64 %10038, %10165
  %10169 = sext i1 %10168 to i32
  %10170 = xor i32 %10169, -1
  %10171 = and i32 %10170, %10164
  %10172 = and i32 %10169, %10167
  %10173 = or i32 %10172, %10171
  %10174 = add i64 %10165, 16
  %10175 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10174
  %10176 = load i32, i32* %10175, align 4
  %10177 = icmp eq i64 %10038, %10174
  %10178 = sext i1 %10177 to i32
  %10179 = xor i32 %10178, -1
  %10180 = and i32 %10179, %10173
  %10181 = and i32 %10178, %10176
  %Mitigated93 = or i32 %10181, %10180
  %10182 = xor i32 %9988, %Mitigated93
  %10183 = sext i32 %.18 to i64
  %10184 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10183
  %10185 = load i8, i8* %10184, align 1
  %10186 = zext i8 %10185 to i32
  %10187 = getelementptr inbounds i8, i8* %0, i64 11
  %10188 = load i8, i8* %10187, align 1
  %10189 = zext i8 %10188 to i32
  %10190 = xor i32 %10186, %10189
  %10191 = sext i32 %10190 to i64
  %10192 = srem i64 %10191, 64
  %10193 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10192
  %10194 = load i8, i8* %10193, align 1
  %10195 = icmp eq i64 %10191, %10192
  %10196 = sext i1 %10195 to i8
  %10197 = xor i8 %10196, -1
  %10198 = and i8 %10197, 0
  %10199 = and i8 %10196, %10194
  %10200 = or i8 %10199, %10198
  %10201 = add i64 %10192, 64
  %10202 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10201
  %10203 = load i8, i8* %10202, align 1
  %10204 = icmp eq i64 %10191, %10201
  %10205 = sext i1 %10204 to i8
  %10206 = xor i8 %10205, -1
  %10207 = and i8 %10206, %10200
  %10208 = and i8 %10205, %10203
  %10209 = or i8 %10208, %10207
  %10210 = add i64 %10201, 64
  %10211 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10210
  %10212 = load i8, i8* %10211, align 1
  %10213 = icmp eq i64 %10191, %10210
  %10214 = sext i1 %10213 to i8
  %10215 = xor i8 %10214, -1
  %10216 = and i8 %10215, %10209
  %10217 = and i8 %10214, %10212
  %10218 = or i8 %10217, %10216
  %10219 = add i64 %10210, 64
  %10220 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10219
  %10221 = load i8, i8* %10220, align 1
  %10222 = icmp eq i64 %10191, %10219
  %10223 = sext i1 %10222 to i8
  %10224 = xor i8 %10223, -1
  %10225 = and i8 %10224, %10218
  %10226 = and i8 %10223, %10221
  %Mitigated94 = or i8 %10226, %10225
  %10227 = zext i8 %Mitigated94 to i32
  %10228 = getelementptr inbounds i8, i8* %0, i64 3
  %10229 = load i8, i8* %10228, align 1
  %10230 = zext i8 %10229 to i32
  %10231 = xor i32 %10227, %10230
  %10232 = sext i32 %10231 to i64
  %10233 = srem i64 %10232, 16
  %10234 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10233
  %10235 = load i32, i32* %10234, align 4
  %10236 = icmp eq i64 %10232, %10233
  %10237 = sext i1 %10236 to i32
  %10238 = xor i32 %10237, -1
  %10239 = and i32 %10238, 0
  %10240 = and i32 %10237, %10235
  %10241 = or i32 %10240, %10239
  %10242 = add i64 %10233, 16
  %10243 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10242
  %10244 = load i32, i32* %10243, align 4
  %10245 = icmp eq i64 %10232, %10242
  %10246 = sext i1 %10245 to i32
  %10247 = xor i32 %10246, -1
  %10248 = and i32 %10247, %10241
  %10249 = and i32 %10246, %10244
  %10250 = or i32 %10249, %10248
  %10251 = add i64 %10242, 16
  %10252 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10251
  %10253 = load i32, i32* %10252, align 4
  %10254 = icmp eq i64 %10232, %10251
  %10255 = sext i1 %10254 to i32
  %10256 = xor i32 %10255, -1
  %10257 = and i32 %10256, %10250
  %10258 = and i32 %10255, %10253
  %10259 = or i32 %10258, %10257
  %10260 = add i64 %10251, 16
  %10261 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10260
  %10262 = load i32, i32* %10261, align 4
  %10263 = icmp eq i64 %10232, %10260
  %10264 = sext i1 %10263 to i32
  %10265 = xor i32 %10264, -1
  %10266 = and i32 %10265, %10259
  %10267 = and i32 %10264, %10262
  %10268 = or i32 %10267, %10266
  %10269 = add i64 %10260, 16
  %10270 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10269
  %10271 = load i32, i32* %10270, align 4
  %10272 = icmp eq i64 %10232, %10269
  %10273 = sext i1 %10272 to i32
  %10274 = xor i32 %10273, -1
  %10275 = and i32 %10274, %10268
  %10276 = and i32 %10273, %10271
  %10277 = or i32 %10276, %10275
  %10278 = add i64 %10269, 16
  %10279 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10278
  %10280 = load i32, i32* %10279, align 4
  %10281 = icmp eq i64 %10232, %10278
  %10282 = sext i1 %10281 to i32
  %10283 = xor i32 %10282, -1
  %10284 = and i32 %10283, %10277
  %10285 = and i32 %10282, %10280
  %10286 = or i32 %10285, %10284
  %10287 = add i64 %10278, 16
  %10288 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10287
  %10289 = load i32, i32* %10288, align 4
  %10290 = icmp eq i64 %10232, %10287
  %10291 = sext i1 %10290 to i32
  %10292 = xor i32 %10291, -1
  %10293 = and i32 %10292, %10286
  %10294 = and i32 %10291, %10289
  %10295 = or i32 %10294, %10293
  %10296 = add i64 %10287, 16
  %10297 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10296
  %10298 = load i32, i32* %10297, align 4
  %10299 = icmp eq i64 %10232, %10296
  %10300 = sext i1 %10299 to i32
  %10301 = xor i32 %10300, -1
  %10302 = and i32 %10301, %10295
  %10303 = and i32 %10300, %10298
  %10304 = or i32 %10303, %10302
  %10305 = add i64 %10296, 16
  %10306 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10305
  %10307 = load i32, i32* %10306, align 4
  %10308 = icmp eq i64 %10232, %10305
  %10309 = sext i1 %10308 to i32
  %10310 = xor i32 %10309, -1
  %10311 = and i32 %10310, %10304
  %10312 = and i32 %10309, %10307
  %10313 = or i32 %10312, %10311
  %10314 = add i64 %10305, 16
  %10315 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10314
  %10316 = load i32, i32* %10315, align 4
  %10317 = icmp eq i64 %10232, %10314
  %10318 = sext i1 %10317 to i32
  %10319 = xor i32 %10318, -1
  %10320 = and i32 %10319, %10313
  %10321 = and i32 %10318, %10316
  %10322 = or i32 %10321, %10320
  %10323 = add i64 %10314, 16
  %10324 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10323
  %10325 = load i32, i32* %10324, align 4
  %10326 = icmp eq i64 %10232, %10323
  %10327 = sext i1 %10326 to i32
  %10328 = xor i32 %10327, -1
  %10329 = and i32 %10328, %10322
  %10330 = and i32 %10327, %10325
  %10331 = or i32 %10330, %10329
  %10332 = add i64 %10323, 16
  %10333 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10332
  %10334 = load i32, i32* %10333, align 4
  %10335 = icmp eq i64 %10232, %10332
  %10336 = sext i1 %10335 to i32
  %10337 = xor i32 %10336, -1
  %10338 = and i32 %10337, %10331
  %10339 = and i32 %10336, %10334
  %10340 = or i32 %10339, %10338
  %10341 = add i64 %10332, 16
  %10342 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10341
  %10343 = load i32, i32* %10342, align 4
  %10344 = icmp eq i64 %10232, %10341
  %10345 = sext i1 %10344 to i32
  %10346 = xor i32 %10345, -1
  %10347 = and i32 %10346, %10340
  %10348 = and i32 %10345, %10343
  %10349 = or i32 %10348, %10347
  %10350 = add i64 %10341, 16
  %10351 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10350
  %10352 = load i32, i32* %10351, align 4
  %10353 = icmp eq i64 %10232, %10350
  %10354 = sext i1 %10353 to i32
  %10355 = xor i32 %10354, -1
  %10356 = and i32 %10355, %10349
  %10357 = and i32 %10354, %10352
  %10358 = or i32 %10357, %10356
  %10359 = add i64 %10350, 16
  %10360 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10359
  %10361 = load i32, i32* %10360, align 4
  %10362 = icmp eq i64 %10232, %10359
  %10363 = sext i1 %10362 to i32
  %10364 = xor i32 %10363, -1
  %10365 = and i32 %10364, %10358
  %10366 = and i32 %10363, %10361
  %10367 = or i32 %10366, %10365
  %10368 = add i64 %10359, 16
  %10369 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %10368
  %10370 = load i32, i32* %10369, align 4
  %10371 = icmp eq i64 %10232, %10368
  %10372 = sext i1 %10371 to i32
  %10373 = xor i32 %10372, -1
  %10374 = and i32 %10373, %10367
  %10375 = and i32 %10372, %10370
  %Mitigated95 = or i32 %10375, %10374
  %10376 = xor i32 %10182, %Mitigated95
  %10377 = add nsw i32 %.18, 1
  %10378 = sext i32 %10377 to i64
  %10379 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10378
  %10380 = load i8, i8* %10379, align 1
  %10381 = zext i8 %10380 to i32
  %10382 = getelementptr inbounds i8, i8* %0, i64 12
  %10383 = load i8, i8* %10382, align 1
  %10384 = zext i8 %10383 to i32
  %10385 = xor i32 %10381, %10384
  %10386 = sext i32 %10385 to i64
  %10387 = srem i64 %10386, 64
  %10388 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10387
  %10389 = load i8, i8* %10388, align 1
  %10390 = icmp eq i64 %10386, %10387
  %10391 = sext i1 %10390 to i8
  %10392 = xor i8 %10391, -1
  %10393 = and i8 %10392, 0
  %10394 = and i8 %10391, %10389
  %10395 = or i8 %10394, %10393
  %10396 = add i64 %10387, 64
  %10397 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10396
  %10398 = load i8, i8* %10397, align 1
  %10399 = icmp eq i64 %10386, %10396
  %10400 = sext i1 %10399 to i8
  %10401 = xor i8 %10400, -1
  %10402 = and i8 %10401, %10395
  %10403 = and i8 %10400, %10398
  %10404 = or i8 %10403, %10402
  %10405 = add i64 %10396, 64
  %10406 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10405
  %10407 = load i8, i8* %10406, align 1
  %10408 = icmp eq i64 %10386, %10405
  %10409 = sext i1 %10408 to i8
  %10410 = xor i8 %10409, -1
  %10411 = and i8 %10410, %10404
  %10412 = and i8 %10409, %10407
  %10413 = or i8 %10412, %10411
  %10414 = add i64 %10405, 64
  %10415 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10414
  %10416 = load i8, i8* %10415, align 1
  %10417 = icmp eq i64 %10386, %10414
  %10418 = sext i1 %10417 to i8
  %10419 = xor i8 %10418, -1
  %10420 = and i8 %10419, %10413
  %10421 = and i8 %10418, %10416
  %Mitigated96 = or i8 %10421, %10420
  %10422 = zext i8 %Mitigated96 to i32
  %10423 = getelementptr inbounds i8, i8* %0, i64 4
  %10424 = load i8, i8* %10423, align 1
  %10425 = zext i8 %10424 to i32
  %10426 = xor i32 %10422, %10425
  %10427 = sext i32 %10426 to i64
  %10428 = srem i64 %10427, 16
  %10429 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10428
  %10430 = load i32, i32* %10429, align 4
  %10431 = icmp eq i64 %10427, %10428
  %10432 = sext i1 %10431 to i32
  %10433 = xor i32 %10432, -1
  %10434 = and i32 %10433, 0
  %10435 = and i32 %10432, %10430
  %10436 = or i32 %10435, %10434
  %10437 = add i64 %10428, 16
  %10438 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10437
  %10439 = load i32, i32* %10438, align 4
  %10440 = icmp eq i64 %10427, %10437
  %10441 = sext i1 %10440 to i32
  %10442 = xor i32 %10441, -1
  %10443 = and i32 %10442, %10436
  %10444 = and i32 %10441, %10439
  %10445 = or i32 %10444, %10443
  %10446 = add i64 %10437, 16
  %10447 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10446
  %10448 = load i32, i32* %10447, align 4
  %10449 = icmp eq i64 %10427, %10446
  %10450 = sext i1 %10449 to i32
  %10451 = xor i32 %10450, -1
  %10452 = and i32 %10451, %10445
  %10453 = and i32 %10450, %10448
  %10454 = or i32 %10453, %10452
  %10455 = add i64 %10446, 16
  %10456 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10455
  %10457 = load i32, i32* %10456, align 4
  %10458 = icmp eq i64 %10427, %10455
  %10459 = sext i1 %10458 to i32
  %10460 = xor i32 %10459, -1
  %10461 = and i32 %10460, %10454
  %10462 = and i32 %10459, %10457
  %10463 = or i32 %10462, %10461
  %10464 = add i64 %10455, 16
  %10465 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10464
  %10466 = load i32, i32* %10465, align 4
  %10467 = icmp eq i64 %10427, %10464
  %10468 = sext i1 %10467 to i32
  %10469 = xor i32 %10468, -1
  %10470 = and i32 %10469, %10463
  %10471 = and i32 %10468, %10466
  %10472 = or i32 %10471, %10470
  %10473 = add i64 %10464, 16
  %10474 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10473
  %10475 = load i32, i32* %10474, align 4
  %10476 = icmp eq i64 %10427, %10473
  %10477 = sext i1 %10476 to i32
  %10478 = xor i32 %10477, -1
  %10479 = and i32 %10478, %10472
  %10480 = and i32 %10477, %10475
  %10481 = or i32 %10480, %10479
  %10482 = add i64 %10473, 16
  %10483 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10482
  %10484 = load i32, i32* %10483, align 4
  %10485 = icmp eq i64 %10427, %10482
  %10486 = sext i1 %10485 to i32
  %10487 = xor i32 %10486, -1
  %10488 = and i32 %10487, %10481
  %10489 = and i32 %10486, %10484
  %10490 = or i32 %10489, %10488
  %10491 = add i64 %10482, 16
  %10492 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10491
  %10493 = load i32, i32* %10492, align 4
  %10494 = icmp eq i64 %10427, %10491
  %10495 = sext i1 %10494 to i32
  %10496 = xor i32 %10495, -1
  %10497 = and i32 %10496, %10490
  %10498 = and i32 %10495, %10493
  %10499 = or i32 %10498, %10497
  %10500 = add i64 %10491, 16
  %10501 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10500
  %10502 = load i32, i32* %10501, align 4
  %10503 = icmp eq i64 %10427, %10500
  %10504 = sext i1 %10503 to i32
  %10505 = xor i32 %10504, -1
  %10506 = and i32 %10505, %10499
  %10507 = and i32 %10504, %10502
  %10508 = or i32 %10507, %10506
  %10509 = add i64 %10500, 16
  %10510 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10509
  %10511 = load i32, i32* %10510, align 4
  %10512 = icmp eq i64 %10427, %10509
  %10513 = sext i1 %10512 to i32
  %10514 = xor i32 %10513, -1
  %10515 = and i32 %10514, %10508
  %10516 = and i32 %10513, %10511
  %10517 = or i32 %10516, %10515
  %10518 = add i64 %10509, 16
  %10519 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10518
  %10520 = load i32, i32* %10519, align 4
  %10521 = icmp eq i64 %10427, %10518
  %10522 = sext i1 %10521 to i32
  %10523 = xor i32 %10522, -1
  %10524 = and i32 %10523, %10517
  %10525 = and i32 %10522, %10520
  %10526 = or i32 %10525, %10524
  %10527 = add i64 %10518, 16
  %10528 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10527
  %10529 = load i32, i32* %10528, align 4
  %10530 = icmp eq i64 %10427, %10527
  %10531 = sext i1 %10530 to i32
  %10532 = xor i32 %10531, -1
  %10533 = and i32 %10532, %10526
  %10534 = and i32 %10531, %10529
  %10535 = or i32 %10534, %10533
  %10536 = add i64 %10527, 16
  %10537 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10536
  %10538 = load i32, i32* %10537, align 4
  %10539 = icmp eq i64 %10427, %10536
  %10540 = sext i1 %10539 to i32
  %10541 = xor i32 %10540, -1
  %10542 = and i32 %10541, %10535
  %10543 = and i32 %10540, %10538
  %10544 = or i32 %10543, %10542
  %10545 = add i64 %10536, 16
  %10546 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10545
  %10547 = load i32, i32* %10546, align 4
  %10548 = icmp eq i64 %10427, %10545
  %10549 = sext i1 %10548 to i32
  %10550 = xor i32 %10549, -1
  %10551 = and i32 %10550, %10544
  %10552 = and i32 %10549, %10547
  %10553 = or i32 %10552, %10551
  %10554 = add i64 %10545, 16
  %10555 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10554
  %10556 = load i32, i32* %10555, align 4
  %10557 = icmp eq i64 %10427, %10554
  %10558 = sext i1 %10557 to i32
  %10559 = xor i32 %10558, -1
  %10560 = and i32 %10559, %10553
  %10561 = and i32 %10558, %10556
  %10562 = or i32 %10561, %10560
  %10563 = add i64 %10554, 16
  %10564 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %10563
  %10565 = load i32, i32* %10564, align 4
  %10566 = icmp eq i64 %10427, %10563
  %10567 = sext i1 %10566 to i32
  %10568 = xor i32 %10567, -1
  %10569 = and i32 %10568, %10562
  %10570 = and i32 %10567, %10565
  %Mitigated97 = or i32 %10570, %10569
  %10571 = add nsw i32 %.18, 1
  %10572 = sext i32 %10571 to i64
  %10573 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10572
  %10574 = load i8, i8* %10573, align 1
  %10575 = zext i8 %10574 to i32
  %10576 = getelementptr inbounds i8, i8* %0, i64 13
  %10577 = load i8, i8* %10576, align 1
  %10578 = zext i8 %10577 to i32
  %10579 = xor i32 %10575, %10578
  %10580 = sext i32 %10579 to i64
  %10581 = srem i64 %10580, 64
  %10582 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10581
  %10583 = load i8, i8* %10582, align 1
  %10584 = icmp eq i64 %10580, %10581
  %10585 = sext i1 %10584 to i8
  %10586 = xor i8 %10585, -1
  %10587 = and i8 %10586, 0
  %10588 = and i8 %10585, %10583
  %10589 = or i8 %10588, %10587
  %10590 = add i64 %10581, 64
  %10591 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10590
  %10592 = load i8, i8* %10591, align 1
  %10593 = icmp eq i64 %10580, %10590
  %10594 = sext i1 %10593 to i8
  %10595 = xor i8 %10594, -1
  %10596 = and i8 %10595, %10589
  %10597 = and i8 %10594, %10592
  %10598 = or i8 %10597, %10596
  %10599 = add i64 %10590, 64
  %10600 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10599
  %10601 = load i8, i8* %10600, align 1
  %10602 = icmp eq i64 %10580, %10599
  %10603 = sext i1 %10602 to i8
  %10604 = xor i8 %10603, -1
  %10605 = and i8 %10604, %10598
  %10606 = and i8 %10603, %10601
  %10607 = or i8 %10606, %10605
  %10608 = add i64 %10599, 64
  %10609 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10608
  %10610 = load i8, i8* %10609, align 1
  %10611 = icmp eq i64 %10580, %10608
  %10612 = sext i1 %10611 to i8
  %10613 = xor i8 %10612, -1
  %10614 = and i8 %10613, %10607
  %10615 = and i8 %10612, %10610
  %Mitigated98 = or i8 %10615, %10614
  %10616 = zext i8 %Mitigated98 to i32
  %10617 = getelementptr inbounds i8, i8* %0, i64 5
  %10618 = load i8, i8* %10617, align 1
  %10619 = zext i8 %10618 to i32
  %10620 = xor i32 %10616, %10619
  %10621 = sext i32 %10620 to i64
  %10622 = srem i64 %10621, 16
  %10623 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10622
  %10624 = load i32, i32* %10623, align 4
  %10625 = icmp eq i64 %10621, %10622
  %10626 = sext i1 %10625 to i32
  %10627 = xor i32 %10626, -1
  %10628 = and i32 %10627, 0
  %10629 = and i32 %10626, %10624
  %10630 = or i32 %10629, %10628
  %10631 = add i64 %10622, 16
  %10632 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10631
  %10633 = load i32, i32* %10632, align 4
  %10634 = icmp eq i64 %10621, %10631
  %10635 = sext i1 %10634 to i32
  %10636 = xor i32 %10635, -1
  %10637 = and i32 %10636, %10630
  %10638 = and i32 %10635, %10633
  %10639 = or i32 %10638, %10637
  %10640 = add i64 %10631, 16
  %10641 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10640
  %10642 = load i32, i32* %10641, align 4
  %10643 = icmp eq i64 %10621, %10640
  %10644 = sext i1 %10643 to i32
  %10645 = xor i32 %10644, -1
  %10646 = and i32 %10645, %10639
  %10647 = and i32 %10644, %10642
  %10648 = or i32 %10647, %10646
  %10649 = add i64 %10640, 16
  %10650 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10649
  %10651 = load i32, i32* %10650, align 4
  %10652 = icmp eq i64 %10621, %10649
  %10653 = sext i1 %10652 to i32
  %10654 = xor i32 %10653, -1
  %10655 = and i32 %10654, %10648
  %10656 = and i32 %10653, %10651
  %10657 = or i32 %10656, %10655
  %10658 = add i64 %10649, 16
  %10659 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10658
  %10660 = load i32, i32* %10659, align 4
  %10661 = icmp eq i64 %10621, %10658
  %10662 = sext i1 %10661 to i32
  %10663 = xor i32 %10662, -1
  %10664 = and i32 %10663, %10657
  %10665 = and i32 %10662, %10660
  %10666 = or i32 %10665, %10664
  %10667 = add i64 %10658, 16
  %10668 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10667
  %10669 = load i32, i32* %10668, align 4
  %10670 = icmp eq i64 %10621, %10667
  %10671 = sext i1 %10670 to i32
  %10672 = xor i32 %10671, -1
  %10673 = and i32 %10672, %10666
  %10674 = and i32 %10671, %10669
  %10675 = or i32 %10674, %10673
  %10676 = add i64 %10667, 16
  %10677 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10676
  %10678 = load i32, i32* %10677, align 4
  %10679 = icmp eq i64 %10621, %10676
  %10680 = sext i1 %10679 to i32
  %10681 = xor i32 %10680, -1
  %10682 = and i32 %10681, %10675
  %10683 = and i32 %10680, %10678
  %10684 = or i32 %10683, %10682
  %10685 = add i64 %10676, 16
  %10686 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10685
  %10687 = load i32, i32* %10686, align 4
  %10688 = icmp eq i64 %10621, %10685
  %10689 = sext i1 %10688 to i32
  %10690 = xor i32 %10689, -1
  %10691 = and i32 %10690, %10684
  %10692 = and i32 %10689, %10687
  %10693 = or i32 %10692, %10691
  %10694 = add i64 %10685, 16
  %10695 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10694
  %10696 = load i32, i32* %10695, align 4
  %10697 = icmp eq i64 %10621, %10694
  %10698 = sext i1 %10697 to i32
  %10699 = xor i32 %10698, -1
  %10700 = and i32 %10699, %10693
  %10701 = and i32 %10698, %10696
  %10702 = or i32 %10701, %10700
  %10703 = add i64 %10694, 16
  %10704 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10703
  %10705 = load i32, i32* %10704, align 4
  %10706 = icmp eq i64 %10621, %10703
  %10707 = sext i1 %10706 to i32
  %10708 = xor i32 %10707, -1
  %10709 = and i32 %10708, %10702
  %10710 = and i32 %10707, %10705
  %10711 = or i32 %10710, %10709
  %10712 = add i64 %10703, 16
  %10713 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10712
  %10714 = load i32, i32* %10713, align 4
  %10715 = icmp eq i64 %10621, %10712
  %10716 = sext i1 %10715 to i32
  %10717 = xor i32 %10716, -1
  %10718 = and i32 %10717, %10711
  %10719 = and i32 %10716, %10714
  %10720 = or i32 %10719, %10718
  %10721 = add i64 %10712, 16
  %10722 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10721
  %10723 = load i32, i32* %10722, align 4
  %10724 = icmp eq i64 %10621, %10721
  %10725 = sext i1 %10724 to i32
  %10726 = xor i32 %10725, -1
  %10727 = and i32 %10726, %10720
  %10728 = and i32 %10725, %10723
  %10729 = or i32 %10728, %10727
  %10730 = add i64 %10721, 16
  %10731 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10730
  %10732 = load i32, i32* %10731, align 4
  %10733 = icmp eq i64 %10621, %10730
  %10734 = sext i1 %10733 to i32
  %10735 = xor i32 %10734, -1
  %10736 = and i32 %10735, %10729
  %10737 = and i32 %10734, %10732
  %10738 = or i32 %10737, %10736
  %10739 = add i64 %10730, 16
  %10740 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10739
  %10741 = load i32, i32* %10740, align 4
  %10742 = icmp eq i64 %10621, %10739
  %10743 = sext i1 %10742 to i32
  %10744 = xor i32 %10743, -1
  %10745 = and i32 %10744, %10738
  %10746 = and i32 %10743, %10741
  %10747 = or i32 %10746, %10745
  %10748 = add i64 %10739, 16
  %10749 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10748
  %10750 = load i32, i32* %10749, align 4
  %10751 = icmp eq i64 %10621, %10748
  %10752 = sext i1 %10751 to i32
  %10753 = xor i32 %10752, -1
  %10754 = and i32 %10753, %10747
  %10755 = and i32 %10752, %10750
  %10756 = or i32 %10755, %10754
  %10757 = add i64 %10748, 16
  %10758 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %10757
  %10759 = load i32, i32* %10758, align 4
  %10760 = icmp eq i64 %10621, %10757
  %10761 = sext i1 %10760 to i32
  %10762 = xor i32 %10761, -1
  %10763 = and i32 %10762, %10756
  %10764 = and i32 %10761, %10759
  %Mitigated99 = or i32 %10764, %10763
  %10765 = xor i32 %Mitigated97, %Mitigated99
  %10766 = add nsw i32 %.18, 1
  %10767 = sext i32 %10766 to i64
  %10768 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %10767
  %10769 = load i8, i8* %10768, align 1
  %10770 = zext i8 %10769 to i32
  %10771 = getelementptr inbounds i8, i8* %0, i64 14
  %10772 = load i8, i8* %10771, align 1
  %10773 = zext i8 %10772 to i32
  %10774 = xor i32 %10770, %10773
  %10775 = sext i32 %10774 to i64
  %10776 = srem i64 %10775, 64
  %10777 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10776
  %10778 = load i8, i8* %10777, align 1
  %10779 = icmp eq i64 %10775, %10776
  %10780 = sext i1 %10779 to i8
  %10781 = xor i8 %10780, -1
  %10782 = and i8 %10781, 0
  %10783 = and i8 %10780, %10778
  %10784 = or i8 %10783, %10782
  %10785 = add i64 %10776, 64
  %10786 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10785
  %10787 = load i8, i8* %10786, align 1
  %10788 = icmp eq i64 %10775, %10785
  %10789 = sext i1 %10788 to i8
  %10790 = xor i8 %10789, -1
  %10791 = and i8 %10790, %10784
  %10792 = and i8 %10789, %10787
  %10793 = or i8 %10792, %10791
  %10794 = add i64 %10785, 64
  %10795 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10794
  %10796 = load i8, i8* %10795, align 1
  %10797 = icmp eq i64 %10775, %10794
  %10798 = sext i1 %10797 to i8
  %10799 = xor i8 %10798, -1
  %10800 = and i8 %10799, %10793
  %10801 = and i8 %10798, %10796
  %10802 = or i8 %10801, %10800
  %10803 = add i64 %10794, 64
  %10804 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10803
  %10805 = load i8, i8* %10804, align 1
  %10806 = icmp eq i64 %10775, %10803
  %10807 = sext i1 %10806 to i8
  %10808 = xor i8 %10807, -1
  %10809 = and i8 %10808, %10802
  %10810 = and i8 %10807, %10805
  %Mitigated100 = or i8 %10810, %10809
  %10811 = zext i8 %Mitigated100 to i32
  %10812 = getelementptr inbounds i8, i8* %0, i64 6
  %10813 = load i8, i8* %10812, align 1
  %10814 = zext i8 %10813 to i32
  %10815 = xor i32 %10811, %10814
  %10816 = sext i32 %10815 to i64
  %10817 = srem i64 %10816, 16
  %10818 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10817
  %10819 = load i32, i32* %10818, align 4
  %10820 = icmp eq i64 %10816, %10817
  %10821 = sext i1 %10820 to i32
  %10822 = xor i32 %10821, -1
  %10823 = and i32 %10822, 0
  %10824 = and i32 %10821, %10819
  %10825 = or i32 %10824, %10823
  %10826 = add i64 %10817, 16
  %10827 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10826
  %10828 = load i32, i32* %10827, align 4
  %10829 = icmp eq i64 %10816, %10826
  %10830 = sext i1 %10829 to i32
  %10831 = xor i32 %10830, -1
  %10832 = and i32 %10831, %10825
  %10833 = and i32 %10830, %10828
  %10834 = or i32 %10833, %10832
  %10835 = add i64 %10826, 16
  %10836 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10835
  %10837 = load i32, i32* %10836, align 4
  %10838 = icmp eq i64 %10816, %10835
  %10839 = sext i1 %10838 to i32
  %10840 = xor i32 %10839, -1
  %10841 = and i32 %10840, %10834
  %10842 = and i32 %10839, %10837
  %10843 = or i32 %10842, %10841
  %10844 = add i64 %10835, 16
  %10845 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10844
  %10846 = load i32, i32* %10845, align 4
  %10847 = icmp eq i64 %10816, %10844
  %10848 = sext i1 %10847 to i32
  %10849 = xor i32 %10848, -1
  %10850 = and i32 %10849, %10843
  %10851 = and i32 %10848, %10846
  %10852 = or i32 %10851, %10850
  %10853 = add i64 %10844, 16
  %10854 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10853
  %10855 = load i32, i32* %10854, align 4
  %10856 = icmp eq i64 %10816, %10853
  %10857 = sext i1 %10856 to i32
  %10858 = xor i32 %10857, -1
  %10859 = and i32 %10858, %10852
  %10860 = and i32 %10857, %10855
  %10861 = or i32 %10860, %10859
  %10862 = add i64 %10853, 16
  %10863 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10862
  %10864 = load i32, i32* %10863, align 4
  %10865 = icmp eq i64 %10816, %10862
  %10866 = sext i1 %10865 to i32
  %10867 = xor i32 %10866, -1
  %10868 = and i32 %10867, %10861
  %10869 = and i32 %10866, %10864
  %10870 = or i32 %10869, %10868
  %10871 = add i64 %10862, 16
  %10872 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10871
  %10873 = load i32, i32* %10872, align 4
  %10874 = icmp eq i64 %10816, %10871
  %10875 = sext i1 %10874 to i32
  %10876 = xor i32 %10875, -1
  %10877 = and i32 %10876, %10870
  %10878 = and i32 %10875, %10873
  %10879 = or i32 %10878, %10877
  %10880 = add i64 %10871, 16
  %10881 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10880
  %10882 = load i32, i32* %10881, align 4
  %10883 = icmp eq i64 %10816, %10880
  %10884 = sext i1 %10883 to i32
  %10885 = xor i32 %10884, -1
  %10886 = and i32 %10885, %10879
  %10887 = and i32 %10884, %10882
  %10888 = or i32 %10887, %10886
  %10889 = add i64 %10880, 16
  %10890 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10889
  %10891 = load i32, i32* %10890, align 4
  %10892 = icmp eq i64 %10816, %10889
  %10893 = sext i1 %10892 to i32
  %10894 = xor i32 %10893, -1
  %10895 = and i32 %10894, %10888
  %10896 = and i32 %10893, %10891
  %10897 = or i32 %10896, %10895
  %10898 = add i64 %10889, 16
  %10899 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10898
  %10900 = load i32, i32* %10899, align 4
  %10901 = icmp eq i64 %10816, %10898
  %10902 = sext i1 %10901 to i32
  %10903 = xor i32 %10902, -1
  %10904 = and i32 %10903, %10897
  %10905 = and i32 %10902, %10900
  %10906 = or i32 %10905, %10904
  %10907 = add i64 %10898, 16
  %10908 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10907
  %10909 = load i32, i32* %10908, align 4
  %10910 = icmp eq i64 %10816, %10907
  %10911 = sext i1 %10910 to i32
  %10912 = xor i32 %10911, -1
  %10913 = and i32 %10912, %10906
  %10914 = and i32 %10911, %10909
  %10915 = or i32 %10914, %10913
  %10916 = add i64 %10907, 16
  %10917 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10916
  %10918 = load i32, i32* %10917, align 4
  %10919 = icmp eq i64 %10816, %10916
  %10920 = sext i1 %10919 to i32
  %10921 = xor i32 %10920, -1
  %10922 = and i32 %10921, %10915
  %10923 = and i32 %10920, %10918
  %10924 = or i32 %10923, %10922
  %10925 = add i64 %10916, 16
  %10926 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10925
  %10927 = load i32, i32* %10926, align 4
  %10928 = icmp eq i64 %10816, %10925
  %10929 = sext i1 %10928 to i32
  %10930 = xor i32 %10929, -1
  %10931 = and i32 %10930, %10924
  %10932 = and i32 %10929, %10927
  %10933 = or i32 %10932, %10931
  %10934 = add i64 %10925, 16
  %10935 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10934
  %10936 = load i32, i32* %10935, align 4
  %10937 = icmp eq i64 %10816, %10934
  %10938 = sext i1 %10937 to i32
  %10939 = xor i32 %10938, -1
  %10940 = and i32 %10939, %10933
  %10941 = and i32 %10938, %10936
  %10942 = or i32 %10941, %10940
  %10943 = add i64 %10934, 16
  %10944 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10943
  %10945 = load i32, i32* %10944, align 4
  %10946 = icmp eq i64 %10816, %10943
  %10947 = sext i1 %10946 to i32
  %10948 = xor i32 %10947, -1
  %10949 = and i32 %10948, %10942
  %10950 = and i32 %10947, %10945
  %10951 = or i32 %10950, %10949
  %10952 = add i64 %10943, 16
  %10953 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %10952
  %10954 = load i32, i32* %10953, align 4
  %10955 = icmp eq i64 %10816, %10952
  %10956 = sext i1 %10955 to i32
  %10957 = xor i32 %10956, -1
  %10958 = and i32 %10957, %10951
  %10959 = and i32 %10956, %10954
  %Mitigated101 = or i32 %10959, %10958
  %10960 = xor i32 %10765, %Mitigated101
  %10961 = add nsw i32 %.18, 1
  %10962 = sext i32 %10961 to i64
  %10963 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10962
  %10964 = load i8, i8* %10963, align 1
  %10965 = zext i8 %10964 to i32
  %10966 = getelementptr inbounds i8, i8* %0, i64 15
  %10967 = load i8, i8* %10966, align 1
  %10968 = zext i8 %10967 to i32
  %10969 = xor i32 %10965, %10968
  %10970 = sext i32 %10969 to i64
  %10971 = srem i64 %10970, 64
  %10972 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10971
  %10973 = load i8, i8* %10972, align 1
  %10974 = icmp eq i64 %10970, %10971
  %10975 = sext i1 %10974 to i8
  %10976 = xor i8 %10975, -1
  %10977 = and i8 %10976, 0
  %10978 = and i8 %10975, %10973
  %10979 = or i8 %10978, %10977
  %10980 = add i64 %10971, 64
  %10981 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10980
  %10982 = load i8, i8* %10981, align 1
  %10983 = icmp eq i64 %10970, %10980
  %10984 = sext i1 %10983 to i8
  %10985 = xor i8 %10984, -1
  %10986 = and i8 %10985, %10979
  %10987 = and i8 %10984, %10982
  %10988 = or i8 %10987, %10986
  %10989 = add i64 %10980, 64
  %10990 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10989
  %10991 = load i8, i8* %10990, align 1
  %10992 = icmp eq i64 %10970, %10989
  %10993 = sext i1 %10992 to i8
  %10994 = xor i8 %10993, -1
  %10995 = and i8 %10994, %10988
  %10996 = and i8 %10993, %10991
  %10997 = or i8 %10996, %10995
  %10998 = add i64 %10989, 64
  %10999 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %10998
  %11000 = load i8, i8* %10999, align 1
  %11001 = icmp eq i64 %10970, %10998
  %11002 = sext i1 %11001 to i8
  %11003 = xor i8 %11002, -1
  %11004 = and i8 %11003, %10997
  %11005 = and i8 %11002, %11000
  %Mitigated102 = or i8 %11005, %11004
  %11006 = zext i8 %Mitigated102 to i32
  %11007 = getelementptr inbounds i8, i8* %0, i64 7
  %11008 = load i8, i8* %11007, align 1
  %11009 = zext i8 %11008 to i32
  %11010 = xor i32 %11006, %11009
  %11011 = sext i32 %11010 to i64
  %11012 = srem i64 %11011, 16
  %11013 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11012
  %11014 = load i32, i32* %11013, align 4
  %11015 = icmp eq i64 %11011, %11012
  %11016 = sext i1 %11015 to i32
  %11017 = xor i32 %11016, -1
  %11018 = and i32 %11017, 0
  %11019 = and i32 %11016, %11014
  %11020 = or i32 %11019, %11018
  %11021 = add i64 %11012, 16
  %11022 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11021
  %11023 = load i32, i32* %11022, align 4
  %11024 = icmp eq i64 %11011, %11021
  %11025 = sext i1 %11024 to i32
  %11026 = xor i32 %11025, -1
  %11027 = and i32 %11026, %11020
  %11028 = and i32 %11025, %11023
  %11029 = or i32 %11028, %11027
  %11030 = add i64 %11021, 16
  %11031 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11030
  %11032 = load i32, i32* %11031, align 4
  %11033 = icmp eq i64 %11011, %11030
  %11034 = sext i1 %11033 to i32
  %11035 = xor i32 %11034, -1
  %11036 = and i32 %11035, %11029
  %11037 = and i32 %11034, %11032
  %11038 = or i32 %11037, %11036
  %11039 = add i64 %11030, 16
  %11040 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11039
  %11041 = load i32, i32* %11040, align 4
  %11042 = icmp eq i64 %11011, %11039
  %11043 = sext i1 %11042 to i32
  %11044 = xor i32 %11043, -1
  %11045 = and i32 %11044, %11038
  %11046 = and i32 %11043, %11041
  %11047 = or i32 %11046, %11045
  %11048 = add i64 %11039, 16
  %11049 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11048
  %11050 = load i32, i32* %11049, align 4
  %11051 = icmp eq i64 %11011, %11048
  %11052 = sext i1 %11051 to i32
  %11053 = xor i32 %11052, -1
  %11054 = and i32 %11053, %11047
  %11055 = and i32 %11052, %11050
  %11056 = or i32 %11055, %11054
  %11057 = add i64 %11048, 16
  %11058 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11057
  %11059 = load i32, i32* %11058, align 4
  %11060 = icmp eq i64 %11011, %11057
  %11061 = sext i1 %11060 to i32
  %11062 = xor i32 %11061, -1
  %11063 = and i32 %11062, %11056
  %11064 = and i32 %11061, %11059
  %11065 = or i32 %11064, %11063
  %11066 = add i64 %11057, 16
  %11067 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11066
  %11068 = load i32, i32* %11067, align 4
  %11069 = icmp eq i64 %11011, %11066
  %11070 = sext i1 %11069 to i32
  %11071 = xor i32 %11070, -1
  %11072 = and i32 %11071, %11065
  %11073 = and i32 %11070, %11068
  %11074 = or i32 %11073, %11072
  %11075 = add i64 %11066, 16
  %11076 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11075
  %11077 = load i32, i32* %11076, align 4
  %11078 = icmp eq i64 %11011, %11075
  %11079 = sext i1 %11078 to i32
  %11080 = xor i32 %11079, -1
  %11081 = and i32 %11080, %11074
  %11082 = and i32 %11079, %11077
  %11083 = or i32 %11082, %11081
  %11084 = add i64 %11075, 16
  %11085 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11084
  %11086 = load i32, i32* %11085, align 4
  %11087 = icmp eq i64 %11011, %11084
  %11088 = sext i1 %11087 to i32
  %11089 = xor i32 %11088, -1
  %11090 = and i32 %11089, %11083
  %11091 = and i32 %11088, %11086
  %11092 = or i32 %11091, %11090
  %11093 = add i64 %11084, 16
  %11094 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11093
  %11095 = load i32, i32* %11094, align 4
  %11096 = icmp eq i64 %11011, %11093
  %11097 = sext i1 %11096 to i32
  %11098 = xor i32 %11097, -1
  %11099 = and i32 %11098, %11092
  %11100 = and i32 %11097, %11095
  %11101 = or i32 %11100, %11099
  %11102 = add i64 %11093, 16
  %11103 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11102
  %11104 = load i32, i32* %11103, align 4
  %11105 = icmp eq i64 %11011, %11102
  %11106 = sext i1 %11105 to i32
  %11107 = xor i32 %11106, -1
  %11108 = and i32 %11107, %11101
  %11109 = and i32 %11106, %11104
  %11110 = or i32 %11109, %11108
  %11111 = add i64 %11102, 16
  %11112 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11111
  %11113 = load i32, i32* %11112, align 4
  %11114 = icmp eq i64 %11011, %11111
  %11115 = sext i1 %11114 to i32
  %11116 = xor i32 %11115, -1
  %11117 = and i32 %11116, %11110
  %11118 = and i32 %11115, %11113
  %11119 = or i32 %11118, %11117
  %11120 = add i64 %11111, 16
  %11121 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11120
  %11122 = load i32, i32* %11121, align 4
  %11123 = icmp eq i64 %11011, %11120
  %11124 = sext i1 %11123 to i32
  %11125 = xor i32 %11124, -1
  %11126 = and i32 %11125, %11119
  %11127 = and i32 %11124, %11122
  %11128 = or i32 %11127, %11126
  %11129 = add i64 %11120, 16
  %11130 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11129
  %11131 = load i32, i32* %11130, align 4
  %11132 = icmp eq i64 %11011, %11129
  %11133 = sext i1 %11132 to i32
  %11134 = xor i32 %11133, -1
  %11135 = and i32 %11134, %11128
  %11136 = and i32 %11133, %11131
  %11137 = or i32 %11136, %11135
  %11138 = add i64 %11129, 16
  %11139 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11138
  %11140 = load i32, i32* %11139, align 4
  %11141 = icmp eq i64 %11011, %11138
  %11142 = sext i1 %11141 to i32
  %11143 = xor i32 %11142, -1
  %11144 = and i32 %11143, %11137
  %11145 = and i32 %11142, %11140
  %11146 = or i32 %11145, %11144
  %11147 = add i64 %11138, 16
  %11148 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11147
  %11149 = load i32, i32* %11148, align 4
  %11150 = icmp eq i64 %11011, %11147
  %11151 = sext i1 %11150 to i32
  %11152 = xor i32 %11151, -1
  %11153 = and i32 %11152, %11146
  %11154 = and i32 %11151, %11149
  %Mitigated103 = or i32 %11154, %11153
  %11155 = xor i32 %10960, %Mitigated103
  %11156 = shl i32 %11155, 8
  %11157 = lshr i32 %11155, 24
  %11158 = add i32 %11156, %11157
  %11159 = add i32 %10376, %11158
  %11160 = add i32 %11158, %11159
  %11161 = sext i32 %.18 to i64
  %11162 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 1
  %11163 = getelementptr inbounds [8 x i32], [8 x i32]* %11162, i64 0, i64 %11161
  store i32 %11159, i32* %11163, align 4
  %11164 = shl i32 %11160, 9
  %11165 = lshr i32 %11160, 23
  %11166 = add i32 %11164, %11165
  %11167 = add nsw i32 %.18, 1
  %11168 = sext i32 %11167 to i64
  %11169 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 1
  %11170 = getelementptr inbounds [8 x i32], [8 x i32]* %11169, i64 0, i64 %11168
  store i32 %11166, i32* %11170, align 4
  %11171 = add nsw i32 %.18, 2
  %11172 = icmp slt i32 %11171, 8
  br i1 %11172, label %9601, label %.preheader

; <label>:11173:                                  ; preds = %.preheader, %11173
  %.27 = phi i32 [ %.2.ph, %.preheader ], [ %12744, %11173 ]
  %.136 = phi i32 [ %.13.ph, %.preheader ], [ %12743, %11173 ]
  %11174 = sext i32 %.27 to i64
  %11175 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11174
  %11176 = load i8, i8* %11175, align 1
  %11177 = zext i8 %11176 to i32
  %11178 = getelementptr inbounds i8, i8* %0, i64 8
  %11179 = load i8, i8* %11178, align 1
  %11180 = zext i8 %11179 to i32
  %11181 = xor i32 %11177, %11180
  %11182 = sext i32 %11181 to i64
  %11183 = srem i64 %11182, 64
  %11184 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11183
  %11185 = load i8, i8* %11184, align 1
  %11186 = icmp eq i64 %11182, %11183
  %11187 = sext i1 %11186 to i8
  %11188 = xor i8 %11187, -1
  %11189 = and i8 %11188, 0
  %11190 = and i8 %11187, %11185
  %11191 = or i8 %11190, %11189
  %11192 = add i64 %11183, 64
  %11193 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11192
  %11194 = load i8, i8* %11193, align 1
  %11195 = icmp eq i64 %11182, %11192
  %11196 = sext i1 %11195 to i8
  %11197 = xor i8 %11196, -1
  %11198 = and i8 %11197, %11191
  %11199 = and i8 %11196, %11194
  %11200 = or i8 %11199, %11198
  %11201 = add i64 %11192, 64
  %11202 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11201
  %11203 = load i8, i8* %11202, align 1
  %11204 = icmp eq i64 %11182, %11201
  %11205 = sext i1 %11204 to i8
  %11206 = xor i8 %11205, -1
  %11207 = and i8 %11206, %11200
  %11208 = and i8 %11205, %11203
  %11209 = or i8 %11208, %11207
  %11210 = add i64 %11201, 64
  %11211 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11210
  %11212 = load i8, i8* %11211, align 1
  %11213 = icmp eq i64 %11182, %11210
  %11214 = sext i1 %11213 to i8
  %11215 = xor i8 %11214, -1
  %11216 = and i8 %11215, %11209
  %11217 = and i8 %11214, %11212
  %Mitigated104 = or i8 %11217, %11216
  %11218 = zext i8 %Mitigated104 to i32
  %11219 = getelementptr inbounds i8, i8* %0, i64 0
  %11220 = load i8, i8* %11219, align 1
  %11221 = zext i8 %11220 to i32
  %11222 = xor i32 %11218, %11221
  %11223 = sext i32 %11222 to i64
  %11224 = srem i64 %11223, 16
  %11225 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11224
  %11226 = load i32, i32* %11225, align 4
  %11227 = icmp eq i64 %11223, %11224
  %11228 = sext i1 %11227 to i32
  %11229 = xor i32 %11228, -1
  %11230 = and i32 %11229, 0
  %11231 = and i32 %11228, %11226
  %11232 = or i32 %11231, %11230
  %11233 = add i64 %11224, 16
  %11234 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11233
  %11235 = load i32, i32* %11234, align 4
  %11236 = icmp eq i64 %11223, %11233
  %11237 = sext i1 %11236 to i32
  %11238 = xor i32 %11237, -1
  %11239 = and i32 %11238, %11232
  %11240 = and i32 %11237, %11235
  %11241 = or i32 %11240, %11239
  %11242 = add i64 %11233, 16
  %11243 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11242
  %11244 = load i32, i32* %11243, align 4
  %11245 = icmp eq i64 %11223, %11242
  %11246 = sext i1 %11245 to i32
  %11247 = xor i32 %11246, -1
  %11248 = and i32 %11247, %11241
  %11249 = and i32 %11246, %11244
  %11250 = or i32 %11249, %11248
  %11251 = add i64 %11242, 16
  %11252 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11251
  %11253 = load i32, i32* %11252, align 4
  %11254 = icmp eq i64 %11223, %11251
  %11255 = sext i1 %11254 to i32
  %11256 = xor i32 %11255, -1
  %11257 = and i32 %11256, %11250
  %11258 = and i32 %11255, %11253
  %11259 = or i32 %11258, %11257
  %11260 = add i64 %11251, 16
  %11261 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11260
  %11262 = load i32, i32* %11261, align 4
  %11263 = icmp eq i64 %11223, %11260
  %11264 = sext i1 %11263 to i32
  %11265 = xor i32 %11264, -1
  %11266 = and i32 %11265, %11259
  %11267 = and i32 %11264, %11262
  %11268 = or i32 %11267, %11266
  %11269 = add i64 %11260, 16
  %11270 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11269
  %11271 = load i32, i32* %11270, align 4
  %11272 = icmp eq i64 %11223, %11269
  %11273 = sext i1 %11272 to i32
  %11274 = xor i32 %11273, -1
  %11275 = and i32 %11274, %11268
  %11276 = and i32 %11273, %11271
  %11277 = or i32 %11276, %11275
  %11278 = add i64 %11269, 16
  %11279 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11278
  %11280 = load i32, i32* %11279, align 4
  %11281 = icmp eq i64 %11223, %11278
  %11282 = sext i1 %11281 to i32
  %11283 = xor i32 %11282, -1
  %11284 = and i32 %11283, %11277
  %11285 = and i32 %11282, %11280
  %11286 = or i32 %11285, %11284
  %11287 = add i64 %11278, 16
  %11288 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11287
  %11289 = load i32, i32* %11288, align 4
  %11290 = icmp eq i64 %11223, %11287
  %11291 = sext i1 %11290 to i32
  %11292 = xor i32 %11291, -1
  %11293 = and i32 %11292, %11286
  %11294 = and i32 %11291, %11289
  %11295 = or i32 %11294, %11293
  %11296 = add i64 %11287, 16
  %11297 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11296
  %11298 = load i32, i32* %11297, align 4
  %11299 = icmp eq i64 %11223, %11296
  %11300 = sext i1 %11299 to i32
  %11301 = xor i32 %11300, -1
  %11302 = and i32 %11301, %11295
  %11303 = and i32 %11300, %11298
  %11304 = or i32 %11303, %11302
  %11305 = add i64 %11296, 16
  %11306 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11305
  %11307 = load i32, i32* %11306, align 4
  %11308 = icmp eq i64 %11223, %11305
  %11309 = sext i1 %11308 to i32
  %11310 = xor i32 %11309, -1
  %11311 = and i32 %11310, %11304
  %11312 = and i32 %11309, %11307
  %11313 = or i32 %11312, %11311
  %11314 = add i64 %11305, 16
  %11315 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11314
  %11316 = load i32, i32* %11315, align 4
  %11317 = icmp eq i64 %11223, %11314
  %11318 = sext i1 %11317 to i32
  %11319 = xor i32 %11318, -1
  %11320 = and i32 %11319, %11313
  %11321 = and i32 %11318, %11316
  %11322 = or i32 %11321, %11320
  %11323 = add i64 %11314, 16
  %11324 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11323
  %11325 = load i32, i32* %11324, align 4
  %11326 = icmp eq i64 %11223, %11323
  %11327 = sext i1 %11326 to i32
  %11328 = xor i32 %11327, -1
  %11329 = and i32 %11328, %11322
  %11330 = and i32 %11327, %11325
  %11331 = or i32 %11330, %11329
  %11332 = add i64 %11323, 16
  %11333 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11332
  %11334 = load i32, i32* %11333, align 4
  %11335 = icmp eq i64 %11223, %11332
  %11336 = sext i1 %11335 to i32
  %11337 = xor i32 %11336, -1
  %11338 = and i32 %11337, %11331
  %11339 = and i32 %11336, %11334
  %11340 = or i32 %11339, %11338
  %11341 = add i64 %11332, 16
  %11342 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11341
  %11343 = load i32, i32* %11342, align 4
  %11344 = icmp eq i64 %11223, %11341
  %11345 = sext i1 %11344 to i32
  %11346 = xor i32 %11345, -1
  %11347 = and i32 %11346, %11340
  %11348 = and i32 %11345, %11343
  %11349 = or i32 %11348, %11347
  %11350 = add i64 %11341, 16
  %11351 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11350
  %11352 = load i32, i32* %11351, align 4
  %11353 = icmp eq i64 %11223, %11350
  %11354 = sext i1 %11353 to i32
  %11355 = xor i32 %11354, -1
  %11356 = and i32 %11355, %11349
  %11357 = and i32 %11354, %11352
  %11358 = or i32 %11357, %11356
  %11359 = add i64 %11350, 16
  %11360 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %11359
  %11361 = load i32, i32* %11360, align 4
  %11362 = icmp eq i64 %11223, %11359
  %11363 = sext i1 %11362 to i32
  %11364 = xor i32 %11363, -1
  %11365 = and i32 %11364, %11358
  %11366 = and i32 %11363, %11361
  %Mitigated105 = or i32 %11366, %11365
  %11367 = sext i32 %.27 to i64
  %11368 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11367
  %11369 = load i8, i8* %11368, align 1
  %11370 = zext i8 %11369 to i32
  %11371 = getelementptr inbounds i8, i8* %0, i64 9
  %11372 = load i8, i8* %11371, align 1
  %11373 = zext i8 %11372 to i32
  %11374 = xor i32 %11370, %11373
  %11375 = sext i32 %11374 to i64
  %11376 = srem i64 %11375, 64
  %11377 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11376
  %11378 = load i8, i8* %11377, align 1
  %11379 = icmp eq i64 %11375, %11376
  %11380 = sext i1 %11379 to i8
  %11381 = xor i8 %11380, -1
  %11382 = and i8 %11381, 0
  %11383 = and i8 %11380, %11378
  %11384 = or i8 %11383, %11382
  %11385 = add i64 %11376, 64
  %11386 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11385
  %11387 = load i8, i8* %11386, align 1
  %11388 = icmp eq i64 %11375, %11385
  %11389 = sext i1 %11388 to i8
  %11390 = xor i8 %11389, -1
  %11391 = and i8 %11390, %11384
  %11392 = and i8 %11389, %11387
  %11393 = or i8 %11392, %11391
  %11394 = add i64 %11385, 64
  %11395 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11394
  %11396 = load i8, i8* %11395, align 1
  %11397 = icmp eq i64 %11375, %11394
  %11398 = sext i1 %11397 to i8
  %11399 = xor i8 %11398, -1
  %11400 = and i8 %11399, %11393
  %11401 = and i8 %11398, %11396
  %11402 = or i8 %11401, %11400
  %11403 = add i64 %11394, 64
  %11404 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11403
  %11405 = load i8, i8* %11404, align 1
  %11406 = icmp eq i64 %11375, %11403
  %11407 = sext i1 %11406 to i8
  %11408 = xor i8 %11407, -1
  %11409 = and i8 %11408, %11402
  %11410 = and i8 %11407, %11405
  %Mitigated106 = or i8 %11410, %11409
  %11411 = zext i8 %Mitigated106 to i32
  %11412 = getelementptr inbounds i8, i8* %0, i64 1
  %11413 = load i8, i8* %11412, align 1
  %11414 = zext i8 %11413 to i32
  %11415 = xor i32 %11411, %11414
  %11416 = sext i32 %11415 to i64
  %11417 = srem i64 %11416, 16
  %11418 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11417
  %11419 = load i32, i32* %11418, align 4
  %11420 = icmp eq i64 %11416, %11417
  %11421 = sext i1 %11420 to i32
  %11422 = xor i32 %11421, -1
  %11423 = and i32 %11422, 0
  %11424 = and i32 %11421, %11419
  %11425 = or i32 %11424, %11423
  %11426 = add i64 %11417, 16
  %11427 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11426
  %11428 = load i32, i32* %11427, align 4
  %11429 = icmp eq i64 %11416, %11426
  %11430 = sext i1 %11429 to i32
  %11431 = xor i32 %11430, -1
  %11432 = and i32 %11431, %11425
  %11433 = and i32 %11430, %11428
  %11434 = or i32 %11433, %11432
  %11435 = add i64 %11426, 16
  %11436 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11435
  %11437 = load i32, i32* %11436, align 4
  %11438 = icmp eq i64 %11416, %11435
  %11439 = sext i1 %11438 to i32
  %11440 = xor i32 %11439, -1
  %11441 = and i32 %11440, %11434
  %11442 = and i32 %11439, %11437
  %11443 = or i32 %11442, %11441
  %11444 = add i64 %11435, 16
  %11445 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11444
  %11446 = load i32, i32* %11445, align 4
  %11447 = icmp eq i64 %11416, %11444
  %11448 = sext i1 %11447 to i32
  %11449 = xor i32 %11448, -1
  %11450 = and i32 %11449, %11443
  %11451 = and i32 %11448, %11446
  %11452 = or i32 %11451, %11450
  %11453 = add i64 %11444, 16
  %11454 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11453
  %11455 = load i32, i32* %11454, align 4
  %11456 = icmp eq i64 %11416, %11453
  %11457 = sext i1 %11456 to i32
  %11458 = xor i32 %11457, -1
  %11459 = and i32 %11458, %11452
  %11460 = and i32 %11457, %11455
  %11461 = or i32 %11460, %11459
  %11462 = add i64 %11453, 16
  %11463 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11462
  %11464 = load i32, i32* %11463, align 4
  %11465 = icmp eq i64 %11416, %11462
  %11466 = sext i1 %11465 to i32
  %11467 = xor i32 %11466, -1
  %11468 = and i32 %11467, %11461
  %11469 = and i32 %11466, %11464
  %11470 = or i32 %11469, %11468
  %11471 = add i64 %11462, 16
  %11472 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11471
  %11473 = load i32, i32* %11472, align 4
  %11474 = icmp eq i64 %11416, %11471
  %11475 = sext i1 %11474 to i32
  %11476 = xor i32 %11475, -1
  %11477 = and i32 %11476, %11470
  %11478 = and i32 %11475, %11473
  %11479 = or i32 %11478, %11477
  %11480 = add i64 %11471, 16
  %11481 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11480
  %11482 = load i32, i32* %11481, align 4
  %11483 = icmp eq i64 %11416, %11480
  %11484 = sext i1 %11483 to i32
  %11485 = xor i32 %11484, -1
  %11486 = and i32 %11485, %11479
  %11487 = and i32 %11484, %11482
  %11488 = or i32 %11487, %11486
  %11489 = add i64 %11480, 16
  %11490 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11489
  %11491 = load i32, i32* %11490, align 4
  %11492 = icmp eq i64 %11416, %11489
  %11493 = sext i1 %11492 to i32
  %11494 = xor i32 %11493, -1
  %11495 = and i32 %11494, %11488
  %11496 = and i32 %11493, %11491
  %11497 = or i32 %11496, %11495
  %11498 = add i64 %11489, 16
  %11499 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11498
  %11500 = load i32, i32* %11499, align 4
  %11501 = icmp eq i64 %11416, %11498
  %11502 = sext i1 %11501 to i32
  %11503 = xor i32 %11502, -1
  %11504 = and i32 %11503, %11497
  %11505 = and i32 %11502, %11500
  %11506 = or i32 %11505, %11504
  %11507 = add i64 %11498, 16
  %11508 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11507
  %11509 = load i32, i32* %11508, align 4
  %11510 = icmp eq i64 %11416, %11507
  %11511 = sext i1 %11510 to i32
  %11512 = xor i32 %11511, -1
  %11513 = and i32 %11512, %11506
  %11514 = and i32 %11511, %11509
  %11515 = or i32 %11514, %11513
  %11516 = add i64 %11507, 16
  %11517 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11516
  %11518 = load i32, i32* %11517, align 4
  %11519 = icmp eq i64 %11416, %11516
  %11520 = sext i1 %11519 to i32
  %11521 = xor i32 %11520, -1
  %11522 = and i32 %11521, %11515
  %11523 = and i32 %11520, %11518
  %11524 = or i32 %11523, %11522
  %11525 = add i64 %11516, 16
  %11526 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11525
  %11527 = load i32, i32* %11526, align 4
  %11528 = icmp eq i64 %11416, %11525
  %11529 = sext i1 %11528 to i32
  %11530 = xor i32 %11529, -1
  %11531 = and i32 %11530, %11524
  %11532 = and i32 %11529, %11527
  %11533 = or i32 %11532, %11531
  %11534 = add i64 %11525, 16
  %11535 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11534
  %11536 = load i32, i32* %11535, align 4
  %11537 = icmp eq i64 %11416, %11534
  %11538 = sext i1 %11537 to i32
  %11539 = xor i32 %11538, -1
  %11540 = and i32 %11539, %11533
  %11541 = and i32 %11538, %11536
  %11542 = or i32 %11541, %11540
  %11543 = add i64 %11534, 16
  %11544 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11543
  %11545 = load i32, i32* %11544, align 4
  %11546 = icmp eq i64 %11416, %11543
  %11547 = sext i1 %11546 to i32
  %11548 = xor i32 %11547, -1
  %11549 = and i32 %11548, %11542
  %11550 = and i32 %11547, %11545
  %11551 = or i32 %11550, %11549
  %11552 = add i64 %11543, 16
  %11553 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %11552
  %11554 = load i32, i32* %11553, align 4
  %11555 = icmp eq i64 %11416, %11552
  %11556 = sext i1 %11555 to i32
  %11557 = xor i32 %11556, -1
  %11558 = and i32 %11557, %11551
  %11559 = and i32 %11556, %11554
  %Mitigated107 = or i32 %11559, %11558
  %11560 = xor i32 %Mitigated105, %Mitigated107
  %11561 = sext i32 %.27 to i64
  %11562 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11561
  %11563 = load i8, i8* %11562, align 1
  %11564 = zext i8 %11563 to i32
  %11565 = getelementptr inbounds i8, i8* %0, i64 10
  %11566 = load i8, i8* %11565, align 1
  %11567 = zext i8 %11566 to i32
  %11568 = xor i32 %11564, %11567
  %11569 = sext i32 %11568 to i64
  %11570 = srem i64 %11569, 64
  %11571 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11570
  %11572 = load i8, i8* %11571, align 1
  %11573 = icmp eq i64 %11569, %11570
  %11574 = sext i1 %11573 to i8
  %11575 = xor i8 %11574, -1
  %11576 = and i8 %11575, 0
  %11577 = and i8 %11574, %11572
  %11578 = or i8 %11577, %11576
  %11579 = add i64 %11570, 64
  %11580 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11579
  %11581 = load i8, i8* %11580, align 1
  %11582 = icmp eq i64 %11569, %11579
  %11583 = sext i1 %11582 to i8
  %11584 = xor i8 %11583, -1
  %11585 = and i8 %11584, %11578
  %11586 = and i8 %11583, %11581
  %11587 = or i8 %11586, %11585
  %11588 = add i64 %11579, 64
  %11589 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11588
  %11590 = load i8, i8* %11589, align 1
  %11591 = icmp eq i64 %11569, %11588
  %11592 = sext i1 %11591 to i8
  %11593 = xor i8 %11592, -1
  %11594 = and i8 %11593, %11587
  %11595 = and i8 %11592, %11590
  %11596 = or i8 %11595, %11594
  %11597 = add i64 %11588, 64
  %11598 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11597
  %11599 = load i8, i8* %11598, align 1
  %11600 = icmp eq i64 %11569, %11597
  %11601 = sext i1 %11600 to i8
  %11602 = xor i8 %11601, -1
  %11603 = and i8 %11602, %11596
  %11604 = and i8 %11601, %11599
  %Mitigated108 = or i8 %11604, %11603
  %11605 = zext i8 %Mitigated108 to i32
  %11606 = getelementptr inbounds i8, i8* %0, i64 2
  %11607 = load i8, i8* %11606, align 1
  %11608 = zext i8 %11607 to i32
  %11609 = xor i32 %11605, %11608
  %11610 = sext i32 %11609 to i64
  %11611 = srem i64 %11610, 16
  %11612 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11611
  %11613 = load i32, i32* %11612, align 4
  %11614 = icmp eq i64 %11610, %11611
  %11615 = sext i1 %11614 to i32
  %11616 = xor i32 %11615, -1
  %11617 = and i32 %11616, 0
  %11618 = and i32 %11615, %11613
  %11619 = or i32 %11618, %11617
  %11620 = add i64 %11611, 16
  %11621 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11620
  %11622 = load i32, i32* %11621, align 4
  %11623 = icmp eq i64 %11610, %11620
  %11624 = sext i1 %11623 to i32
  %11625 = xor i32 %11624, -1
  %11626 = and i32 %11625, %11619
  %11627 = and i32 %11624, %11622
  %11628 = or i32 %11627, %11626
  %11629 = add i64 %11620, 16
  %11630 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11629
  %11631 = load i32, i32* %11630, align 4
  %11632 = icmp eq i64 %11610, %11629
  %11633 = sext i1 %11632 to i32
  %11634 = xor i32 %11633, -1
  %11635 = and i32 %11634, %11628
  %11636 = and i32 %11633, %11631
  %11637 = or i32 %11636, %11635
  %11638 = add i64 %11629, 16
  %11639 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11638
  %11640 = load i32, i32* %11639, align 4
  %11641 = icmp eq i64 %11610, %11638
  %11642 = sext i1 %11641 to i32
  %11643 = xor i32 %11642, -1
  %11644 = and i32 %11643, %11637
  %11645 = and i32 %11642, %11640
  %11646 = or i32 %11645, %11644
  %11647 = add i64 %11638, 16
  %11648 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11647
  %11649 = load i32, i32* %11648, align 4
  %11650 = icmp eq i64 %11610, %11647
  %11651 = sext i1 %11650 to i32
  %11652 = xor i32 %11651, -1
  %11653 = and i32 %11652, %11646
  %11654 = and i32 %11651, %11649
  %11655 = or i32 %11654, %11653
  %11656 = add i64 %11647, 16
  %11657 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11656
  %11658 = load i32, i32* %11657, align 4
  %11659 = icmp eq i64 %11610, %11656
  %11660 = sext i1 %11659 to i32
  %11661 = xor i32 %11660, -1
  %11662 = and i32 %11661, %11655
  %11663 = and i32 %11660, %11658
  %11664 = or i32 %11663, %11662
  %11665 = add i64 %11656, 16
  %11666 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11665
  %11667 = load i32, i32* %11666, align 4
  %11668 = icmp eq i64 %11610, %11665
  %11669 = sext i1 %11668 to i32
  %11670 = xor i32 %11669, -1
  %11671 = and i32 %11670, %11664
  %11672 = and i32 %11669, %11667
  %11673 = or i32 %11672, %11671
  %11674 = add i64 %11665, 16
  %11675 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11674
  %11676 = load i32, i32* %11675, align 4
  %11677 = icmp eq i64 %11610, %11674
  %11678 = sext i1 %11677 to i32
  %11679 = xor i32 %11678, -1
  %11680 = and i32 %11679, %11673
  %11681 = and i32 %11678, %11676
  %11682 = or i32 %11681, %11680
  %11683 = add i64 %11674, 16
  %11684 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11683
  %11685 = load i32, i32* %11684, align 4
  %11686 = icmp eq i64 %11610, %11683
  %11687 = sext i1 %11686 to i32
  %11688 = xor i32 %11687, -1
  %11689 = and i32 %11688, %11682
  %11690 = and i32 %11687, %11685
  %11691 = or i32 %11690, %11689
  %11692 = add i64 %11683, 16
  %11693 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11692
  %11694 = load i32, i32* %11693, align 4
  %11695 = icmp eq i64 %11610, %11692
  %11696 = sext i1 %11695 to i32
  %11697 = xor i32 %11696, -1
  %11698 = and i32 %11697, %11691
  %11699 = and i32 %11696, %11694
  %11700 = or i32 %11699, %11698
  %11701 = add i64 %11692, 16
  %11702 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11701
  %11703 = load i32, i32* %11702, align 4
  %11704 = icmp eq i64 %11610, %11701
  %11705 = sext i1 %11704 to i32
  %11706 = xor i32 %11705, -1
  %11707 = and i32 %11706, %11700
  %11708 = and i32 %11705, %11703
  %11709 = or i32 %11708, %11707
  %11710 = add i64 %11701, 16
  %11711 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11710
  %11712 = load i32, i32* %11711, align 4
  %11713 = icmp eq i64 %11610, %11710
  %11714 = sext i1 %11713 to i32
  %11715 = xor i32 %11714, -1
  %11716 = and i32 %11715, %11709
  %11717 = and i32 %11714, %11712
  %11718 = or i32 %11717, %11716
  %11719 = add i64 %11710, 16
  %11720 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11719
  %11721 = load i32, i32* %11720, align 4
  %11722 = icmp eq i64 %11610, %11719
  %11723 = sext i1 %11722 to i32
  %11724 = xor i32 %11723, -1
  %11725 = and i32 %11724, %11718
  %11726 = and i32 %11723, %11721
  %11727 = or i32 %11726, %11725
  %11728 = add i64 %11719, 16
  %11729 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11728
  %11730 = load i32, i32* %11729, align 4
  %11731 = icmp eq i64 %11610, %11728
  %11732 = sext i1 %11731 to i32
  %11733 = xor i32 %11732, -1
  %11734 = and i32 %11733, %11727
  %11735 = and i32 %11732, %11730
  %11736 = or i32 %11735, %11734
  %11737 = add i64 %11728, 16
  %11738 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11737
  %11739 = load i32, i32* %11738, align 4
  %11740 = icmp eq i64 %11610, %11737
  %11741 = sext i1 %11740 to i32
  %11742 = xor i32 %11741, -1
  %11743 = and i32 %11742, %11736
  %11744 = and i32 %11741, %11739
  %11745 = or i32 %11744, %11743
  %11746 = add i64 %11737, 16
  %11747 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %11746
  %11748 = load i32, i32* %11747, align 4
  %11749 = icmp eq i64 %11610, %11746
  %11750 = sext i1 %11749 to i32
  %11751 = xor i32 %11750, -1
  %11752 = and i32 %11751, %11745
  %11753 = and i32 %11750, %11748
  %Mitigated109 = or i32 %11753, %11752
  %11754 = xor i32 %11560, %Mitigated109
  %11755 = sext i32 %.27 to i64
  %11756 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11755
  %11757 = load i8, i8* %11756, align 1
  %11758 = zext i8 %11757 to i32
  %11759 = getelementptr inbounds i8, i8* %0, i64 11
  %11760 = load i8, i8* %11759, align 1
  %11761 = zext i8 %11760 to i32
  %11762 = xor i32 %11758, %11761
  %11763 = sext i32 %11762 to i64
  %11764 = srem i64 %11763, 64
  %11765 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11764
  %11766 = load i8, i8* %11765, align 1
  %11767 = icmp eq i64 %11763, %11764
  %11768 = sext i1 %11767 to i8
  %11769 = xor i8 %11768, -1
  %11770 = and i8 %11769, 0
  %11771 = and i8 %11768, %11766
  %11772 = or i8 %11771, %11770
  %11773 = add i64 %11764, 64
  %11774 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11773
  %11775 = load i8, i8* %11774, align 1
  %11776 = icmp eq i64 %11763, %11773
  %11777 = sext i1 %11776 to i8
  %11778 = xor i8 %11777, -1
  %11779 = and i8 %11778, %11772
  %11780 = and i8 %11777, %11775
  %11781 = or i8 %11780, %11779
  %11782 = add i64 %11773, 64
  %11783 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11782
  %11784 = load i8, i8* %11783, align 1
  %11785 = icmp eq i64 %11763, %11782
  %11786 = sext i1 %11785 to i8
  %11787 = xor i8 %11786, -1
  %11788 = and i8 %11787, %11781
  %11789 = and i8 %11786, %11784
  %11790 = or i8 %11789, %11788
  %11791 = add i64 %11782, 64
  %11792 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %11791
  %11793 = load i8, i8* %11792, align 1
  %11794 = icmp eq i64 %11763, %11791
  %11795 = sext i1 %11794 to i8
  %11796 = xor i8 %11795, -1
  %11797 = and i8 %11796, %11790
  %11798 = and i8 %11795, %11793
  %Mitigated110 = or i8 %11798, %11797
  %11799 = zext i8 %Mitigated110 to i32
  %11800 = getelementptr inbounds i8, i8* %0, i64 3
  %11801 = load i8, i8* %11800, align 1
  %11802 = zext i8 %11801 to i32
  %11803 = xor i32 %11799, %11802
  %11804 = sext i32 %11803 to i64
  %11805 = srem i64 %11804, 16
  %11806 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11805
  %11807 = load i32, i32* %11806, align 4
  %11808 = icmp eq i64 %11804, %11805
  %11809 = sext i1 %11808 to i32
  %11810 = xor i32 %11809, -1
  %11811 = and i32 %11810, 0
  %11812 = and i32 %11809, %11807
  %11813 = or i32 %11812, %11811
  %11814 = add i64 %11805, 16
  %11815 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11814
  %11816 = load i32, i32* %11815, align 4
  %11817 = icmp eq i64 %11804, %11814
  %11818 = sext i1 %11817 to i32
  %11819 = xor i32 %11818, -1
  %11820 = and i32 %11819, %11813
  %11821 = and i32 %11818, %11816
  %11822 = or i32 %11821, %11820
  %11823 = add i64 %11814, 16
  %11824 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11823
  %11825 = load i32, i32* %11824, align 4
  %11826 = icmp eq i64 %11804, %11823
  %11827 = sext i1 %11826 to i32
  %11828 = xor i32 %11827, -1
  %11829 = and i32 %11828, %11822
  %11830 = and i32 %11827, %11825
  %11831 = or i32 %11830, %11829
  %11832 = add i64 %11823, 16
  %11833 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11832
  %11834 = load i32, i32* %11833, align 4
  %11835 = icmp eq i64 %11804, %11832
  %11836 = sext i1 %11835 to i32
  %11837 = xor i32 %11836, -1
  %11838 = and i32 %11837, %11831
  %11839 = and i32 %11836, %11834
  %11840 = or i32 %11839, %11838
  %11841 = add i64 %11832, 16
  %11842 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11841
  %11843 = load i32, i32* %11842, align 4
  %11844 = icmp eq i64 %11804, %11841
  %11845 = sext i1 %11844 to i32
  %11846 = xor i32 %11845, -1
  %11847 = and i32 %11846, %11840
  %11848 = and i32 %11845, %11843
  %11849 = or i32 %11848, %11847
  %11850 = add i64 %11841, 16
  %11851 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11850
  %11852 = load i32, i32* %11851, align 4
  %11853 = icmp eq i64 %11804, %11850
  %11854 = sext i1 %11853 to i32
  %11855 = xor i32 %11854, -1
  %11856 = and i32 %11855, %11849
  %11857 = and i32 %11854, %11852
  %11858 = or i32 %11857, %11856
  %11859 = add i64 %11850, 16
  %11860 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11859
  %11861 = load i32, i32* %11860, align 4
  %11862 = icmp eq i64 %11804, %11859
  %11863 = sext i1 %11862 to i32
  %11864 = xor i32 %11863, -1
  %11865 = and i32 %11864, %11858
  %11866 = and i32 %11863, %11861
  %11867 = or i32 %11866, %11865
  %11868 = add i64 %11859, 16
  %11869 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11868
  %11870 = load i32, i32* %11869, align 4
  %11871 = icmp eq i64 %11804, %11868
  %11872 = sext i1 %11871 to i32
  %11873 = xor i32 %11872, -1
  %11874 = and i32 %11873, %11867
  %11875 = and i32 %11872, %11870
  %11876 = or i32 %11875, %11874
  %11877 = add i64 %11868, 16
  %11878 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11877
  %11879 = load i32, i32* %11878, align 4
  %11880 = icmp eq i64 %11804, %11877
  %11881 = sext i1 %11880 to i32
  %11882 = xor i32 %11881, -1
  %11883 = and i32 %11882, %11876
  %11884 = and i32 %11881, %11879
  %11885 = or i32 %11884, %11883
  %11886 = add i64 %11877, 16
  %11887 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11886
  %11888 = load i32, i32* %11887, align 4
  %11889 = icmp eq i64 %11804, %11886
  %11890 = sext i1 %11889 to i32
  %11891 = xor i32 %11890, -1
  %11892 = and i32 %11891, %11885
  %11893 = and i32 %11890, %11888
  %11894 = or i32 %11893, %11892
  %11895 = add i64 %11886, 16
  %11896 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11895
  %11897 = load i32, i32* %11896, align 4
  %11898 = icmp eq i64 %11804, %11895
  %11899 = sext i1 %11898 to i32
  %11900 = xor i32 %11899, -1
  %11901 = and i32 %11900, %11894
  %11902 = and i32 %11899, %11897
  %11903 = or i32 %11902, %11901
  %11904 = add i64 %11895, 16
  %11905 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11904
  %11906 = load i32, i32* %11905, align 4
  %11907 = icmp eq i64 %11804, %11904
  %11908 = sext i1 %11907 to i32
  %11909 = xor i32 %11908, -1
  %11910 = and i32 %11909, %11903
  %11911 = and i32 %11908, %11906
  %11912 = or i32 %11911, %11910
  %11913 = add i64 %11904, 16
  %11914 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11913
  %11915 = load i32, i32* %11914, align 4
  %11916 = icmp eq i64 %11804, %11913
  %11917 = sext i1 %11916 to i32
  %11918 = xor i32 %11917, -1
  %11919 = and i32 %11918, %11912
  %11920 = and i32 %11917, %11915
  %11921 = or i32 %11920, %11919
  %11922 = add i64 %11913, 16
  %11923 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11922
  %11924 = load i32, i32* %11923, align 4
  %11925 = icmp eq i64 %11804, %11922
  %11926 = sext i1 %11925 to i32
  %11927 = xor i32 %11926, -1
  %11928 = and i32 %11927, %11921
  %11929 = and i32 %11926, %11924
  %11930 = or i32 %11929, %11928
  %11931 = add i64 %11922, 16
  %11932 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11931
  %11933 = load i32, i32* %11932, align 4
  %11934 = icmp eq i64 %11804, %11931
  %11935 = sext i1 %11934 to i32
  %11936 = xor i32 %11935, -1
  %11937 = and i32 %11936, %11930
  %11938 = and i32 %11935, %11933
  %11939 = or i32 %11938, %11937
  %11940 = add i64 %11931, 16
  %11941 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %11940
  %11942 = load i32, i32* %11941, align 4
  %11943 = icmp eq i64 %11804, %11940
  %11944 = sext i1 %11943 to i32
  %11945 = xor i32 %11944, -1
  %11946 = and i32 %11945, %11939
  %11947 = and i32 %11944, %11942
  %Mitigated111 = or i32 %11947, %11946
  %11948 = xor i32 %11754, %Mitigated111
  %11949 = add nsw i32 %.27, 1
  %11950 = sext i32 %11949 to i64
  %11951 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11950
  %11952 = load i8, i8* %11951, align 1
  %11953 = zext i8 %11952 to i32
  %11954 = getelementptr inbounds i8, i8* %0, i64 12
  %11955 = load i8, i8* %11954, align 1
  %11956 = zext i8 %11955 to i32
  %11957 = xor i32 %11953, %11956
  %11958 = sext i32 %11957 to i64
  %11959 = srem i64 %11958, 64
  %11960 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11959
  %11961 = load i8, i8* %11960, align 1
  %11962 = icmp eq i64 %11958, %11959
  %11963 = sext i1 %11962 to i8
  %11964 = xor i8 %11963, -1
  %11965 = and i8 %11964, 0
  %11966 = and i8 %11963, %11961
  %11967 = or i8 %11966, %11965
  %11968 = add i64 %11959, 64
  %11969 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11968
  %11970 = load i8, i8* %11969, align 1
  %11971 = icmp eq i64 %11958, %11968
  %11972 = sext i1 %11971 to i8
  %11973 = xor i8 %11972, -1
  %11974 = and i8 %11973, %11967
  %11975 = and i8 %11972, %11970
  %11976 = or i8 %11975, %11974
  %11977 = add i64 %11968, 64
  %11978 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11977
  %11979 = load i8, i8* %11978, align 1
  %11980 = icmp eq i64 %11958, %11977
  %11981 = sext i1 %11980 to i8
  %11982 = xor i8 %11981, -1
  %11983 = and i8 %11982, %11976
  %11984 = and i8 %11981, %11979
  %11985 = or i8 %11984, %11983
  %11986 = add i64 %11977, 64
  %11987 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %11986
  %11988 = load i8, i8* %11987, align 1
  %11989 = icmp eq i64 %11958, %11986
  %11990 = sext i1 %11989 to i8
  %11991 = xor i8 %11990, -1
  %11992 = and i8 %11991, %11985
  %11993 = and i8 %11990, %11988
  %Mitigated112 = or i8 %11993, %11992
  %11994 = zext i8 %Mitigated112 to i32
  %11995 = getelementptr inbounds i8, i8* %0, i64 4
  %11996 = load i8, i8* %11995, align 1
  %11997 = zext i8 %11996 to i32
  %11998 = xor i32 %11994, %11997
  %11999 = sext i32 %11998 to i64
  %12000 = srem i64 %11999, 16
  %12001 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12000
  %12002 = load i32, i32* %12001, align 4
  %12003 = icmp eq i64 %11999, %12000
  %12004 = sext i1 %12003 to i32
  %12005 = xor i32 %12004, -1
  %12006 = and i32 %12005, 0
  %12007 = and i32 %12004, %12002
  %12008 = or i32 %12007, %12006
  %12009 = add i64 %12000, 16
  %12010 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12009
  %12011 = load i32, i32* %12010, align 4
  %12012 = icmp eq i64 %11999, %12009
  %12013 = sext i1 %12012 to i32
  %12014 = xor i32 %12013, -1
  %12015 = and i32 %12014, %12008
  %12016 = and i32 %12013, %12011
  %12017 = or i32 %12016, %12015
  %12018 = add i64 %12009, 16
  %12019 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12018
  %12020 = load i32, i32* %12019, align 4
  %12021 = icmp eq i64 %11999, %12018
  %12022 = sext i1 %12021 to i32
  %12023 = xor i32 %12022, -1
  %12024 = and i32 %12023, %12017
  %12025 = and i32 %12022, %12020
  %12026 = or i32 %12025, %12024
  %12027 = add i64 %12018, 16
  %12028 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12027
  %12029 = load i32, i32* %12028, align 4
  %12030 = icmp eq i64 %11999, %12027
  %12031 = sext i1 %12030 to i32
  %12032 = xor i32 %12031, -1
  %12033 = and i32 %12032, %12026
  %12034 = and i32 %12031, %12029
  %12035 = or i32 %12034, %12033
  %12036 = add i64 %12027, 16
  %12037 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12036
  %12038 = load i32, i32* %12037, align 4
  %12039 = icmp eq i64 %11999, %12036
  %12040 = sext i1 %12039 to i32
  %12041 = xor i32 %12040, -1
  %12042 = and i32 %12041, %12035
  %12043 = and i32 %12040, %12038
  %12044 = or i32 %12043, %12042
  %12045 = add i64 %12036, 16
  %12046 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12045
  %12047 = load i32, i32* %12046, align 4
  %12048 = icmp eq i64 %11999, %12045
  %12049 = sext i1 %12048 to i32
  %12050 = xor i32 %12049, -1
  %12051 = and i32 %12050, %12044
  %12052 = and i32 %12049, %12047
  %12053 = or i32 %12052, %12051
  %12054 = add i64 %12045, 16
  %12055 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12054
  %12056 = load i32, i32* %12055, align 4
  %12057 = icmp eq i64 %11999, %12054
  %12058 = sext i1 %12057 to i32
  %12059 = xor i32 %12058, -1
  %12060 = and i32 %12059, %12053
  %12061 = and i32 %12058, %12056
  %12062 = or i32 %12061, %12060
  %12063 = add i64 %12054, 16
  %12064 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12063
  %12065 = load i32, i32* %12064, align 4
  %12066 = icmp eq i64 %11999, %12063
  %12067 = sext i1 %12066 to i32
  %12068 = xor i32 %12067, -1
  %12069 = and i32 %12068, %12062
  %12070 = and i32 %12067, %12065
  %12071 = or i32 %12070, %12069
  %12072 = add i64 %12063, 16
  %12073 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12072
  %12074 = load i32, i32* %12073, align 4
  %12075 = icmp eq i64 %11999, %12072
  %12076 = sext i1 %12075 to i32
  %12077 = xor i32 %12076, -1
  %12078 = and i32 %12077, %12071
  %12079 = and i32 %12076, %12074
  %12080 = or i32 %12079, %12078
  %12081 = add i64 %12072, 16
  %12082 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12081
  %12083 = load i32, i32* %12082, align 4
  %12084 = icmp eq i64 %11999, %12081
  %12085 = sext i1 %12084 to i32
  %12086 = xor i32 %12085, -1
  %12087 = and i32 %12086, %12080
  %12088 = and i32 %12085, %12083
  %12089 = or i32 %12088, %12087
  %12090 = add i64 %12081, 16
  %12091 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12090
  %12092 = load i32, i32* %12091, align 4
  %12093 = icmp eq i64 %11999, %12090
  %12094 = sext i1 %12093 to i32
  %12095 = xor i32 %12094, -1
  %12096 = and i32 %12095, %12089
  %12097 = and i32 %12094, %12092
  %12098 = or i32 %12097, %12096
  %12099 = add i64 %12090, 16
  %12100 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12099
  %12101 = load i32, i32* %12100, align 4
  %12102 = icmp eq i64 %11999, %12099
  %12103 = sext i1 %12102 to i32
  %12104 = xor i32 %12103, -1
  %12105 = and i32 %12104, %12098
  %12106 = and i32 %12103, %12101
  %12107 = or i32 %12106, %12105
  %12108 = add i64 %12099, 16
  %12109 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12108
  %12110 = load i32, i32* %12109, align 4
  %12111 = icmp eq i64 %11999, %12108
  %12112 = sext i1 %12111 to i32
  %12113 = xor i32 %12112, -1
  %12114 = and i32 %12113, %12107
  %12115 = and i32 %12112, %12110
  %12116 = or i32 %12115, %12114
  %12117 = add i64 %12108, 16
  %12118 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12117
  %12119 = load i32, i32* %12118, align 4
  %12120 = icmp eq i64 %11999, %12117
  %12121 = sext i1 %12120 to i32
  %12122 = xor i32 %12121, -1
  %12123 = and i32 %12122, %12116
  %12124 = and i32 %12121, %12119
  %12125 = or i32 %12124, %12123
  %12126 = add i64 %12117, 16
  %12127 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12126
  %12128 = load i32, i32* %12127, align 4
  %12129 = icmp eq i64 %11999, %12126
  %12130 = sext i1 %12129 to i32
  %12131 = xor i32 %12130, -1
  %12132 = and i32 %12131, %12125
  %12133 = and i32 %12130, %12128
  %12134 = or i32 %12133, %12132
  %12135 = add i64 %12126, 16
  %12136 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 0), i64 0, i64 %12135
  %12137 = load i32, i32* %12136, align 4
  %12138 = icmp eq i64 %11999, %12135
  %12139 = sext i1 %12138 to i32
  %12140 = xor i32 %12139, -1
  %12141 = and i32 %12140, %12134
  %12142 = and i32 %12139, %12137
  %Mitigated113 = or i32 %12142, %12141
  %12143 = add nsw i32 %.27, 1
  %12144 = sext i32 %12143 to i64
  %12145 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12144
  %12146 = load i8, i8* %12145, align 1
  %12147 = zext i8 %12146 to i32
  %12148 = getelementptr inbounds i8, i8* %0, i64 13
  %12149 = load i8, i8* %12148, align 1
  %12150 = zext i8 %12149 to i32
  %12151 = xor i32 %12147, %12150
  %12152 = sext i32 %12151 to i64
  %12153 = srem i64 %12152, 64
  %12154 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %12153
  %12155 = load i8, i8* %12154, align 1
  %12156 = icmp eq i64 %12152, %12153
  %12157 = sext i1 %12156 to i8
  %12158 = xor i8 %12157, -1
  %12159 = and i8 %12158, 0
  %12160 = and i8 %12157, %12155
  %12161 = or i8 %12160, %12159
  %12162 = add i64 %12153, 64
  %12163 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %12162
  %12164 = load i8, i8* %12163, align 1
  %12165 = icmp eq i64 %12152, %12162
  %12166 = sext i1 %12165 to i8
  %12167 = xor i8 %12166, -1
  %12168 = and i8 %12167, %12161
  %12169 = and i8 %12166, %12164
  %12170 = or i8 %12169, %12168
  %12171 = add i64 %12162, 64
  %12172 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %12171
  %12173 = load i8, i8* %12172, align 1
  %12174 = icmp eq i64 %12152, %12171
  %12175 = sext i1 %12174 to i8
  %12176 = xor i8 %12175, -1
  %12177 = and i8 %12176, %12170
  %12178 = and i8 %12175, %12173
  %12179 = or i8 %12178, %12177
  %12180 = add i64 %12171, 64
  %12181 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %12180
  %12182 = load i8, i8* %12181, align 1
  %12183 = icmp eq i64 %12152, %12180
  %12184 = sext i1 %12183 to i8
  %12185 = xor i8 %12184, -1
  %12186 = and i8 %12185, %12179
  %12187 = and i8 %12184, %12182
  %Mitigated114 = or i8 %12187, %12186
  %12188 = zext i8 %Mitigated114 to i32
  %12189 = getelementptr inbounds i8, i8* %0, i64 5
  %12190 = load i8, i8* %12189, align 1
  %12191 = zext i8 %12190 to i32
  %12192 = xor i32 %12188, %12191
  %12193 = sext i32 %12192 to i64
  %12194 = srem i64 %12193, 16
  %12195 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12194
  %12196 = load i32, i32* %12195, align 4
  %12197 = icmp eq i64 %12193, %12194
  %12198 = sext i1 %12197 to i32
  %12199 = xor i32 %12198, -1
  %12200 = and i32 %12199, 0
  %12201 = and i32 %12198, %12196
  %12202 = or i32 %12201, %12200
  %12203 = add i64 %12194, 16
  %12204 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12203
  %12205 = load i32, i32* %12204, align 4
  %12206 = icmp eq i64 %12193, %12203
  %12207 = sext i1 %12206 to i32
  %12208 = xor i32 %12207, -1
  %12209 = and i32 %12208, %12202
  %12210 = and i32 %12207, %12205
  %12211 = or i32 %12210, %12209
  %12212 = add i64 %12203, 16
  %12213 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12212
  %12214 = load i32, i32* %12213, align 4
  %12215 = icmp eq i64 %12193, %12212
  %12216 = sext i1 %12215 to i32
  %12217 = xor i32 %12216, -1
  %12218 = and i32 %12217, %12211
  %12219 = and i32 %12216, %12214
  %12220 = or i32 %12219, %12218
  %12221 = add i64 %12212, 16
  %12222 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12221
  %12223 = load i32, i32* %12222, align 4
  %12224 = icmp eq i64 %12193, %12221
  %12225 = sext i1 %12224 to i32
  %12226 = xor i32 %12225, -1
  %12227 = and i32 %12226, %12220
  %12228 = and i32 %12225, %12223
  %12229 = or i32 %12228, %12227
  %12230 = add i64 %12221, 16
  %12231 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12230
  %12232 = load i32, i32* %12231, align 4
  %12233 = icmp eq i64 %12193, %12230
  %12234 = sext i1 %12233 to i32
  %12235 = xor i32 %12234, -1
  %12236 = and i32 %12235, %12229
  %12237 = and i32 %12234, %12232
  %12238 = or i32 %12237, %12236
  %12239 = add i64 %12230, 16
  %12240 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12239
  %12241 = load i32, i32* %12240, align 4
  %12242 = icmp eq i64 %12193, %12239
  %12243 = sext i1 %12242 to i32
  %12244 = xor i32 %12243, -1
  %12245 = and i32 %12244, %12238
  %12246 = and i32 %12243, %12241
  %12247 = or i32 %12246, %12245
  %12248 = add i64 %12239, 16
  %12249 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12248
  %12250 = load i32, i32* %12249, align 4
  %12251 = icmp eq i64 %12193, %12248
  %12252 = sext i1 %12251 to i32
  %12253 = xor i32 %12252, -1
  %12254 = and i32 %12253, %12247
  %12255 = and i32 %12252, %12250
  %12256 = or i32 %12255, %12254
  %12257 = add i64 %12248, 16
  %12258 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12257
  %12259 = load i32, i32* %12258, align 4
  %12260 = icmp eq i64 %12193, %12257
  %12261 = sext i1 %12260 to i32
  %12262 = xor i32 %12261, -1
  %12263 = and i32 %12262, %12256
  %12264 = and i32 %12261, %12259
  %12265 = or i32 %12264, %12263
  %12266 = add i64 %12257, 16
  %12267 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12266
  %12268 = load i32, i32* %12267, align 4
  %12269 = icmp eq i64 %12193, %12266
  %12270 = sext i1 %12269 to i32
  %12271 = xor i32 %12270, -1
  %12272 = and i32 %12271, %12265
  %12273 = and i32 %12270, %12268
  %12274 = or i32 %12273, %12272
  %12275 = add i64 %12266, 16
  %12276 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12275
  %12277 = load i32, i32* %12276, align 4
  %12278 = icmp eq i64 %12193, %12275
  %12279 = sext i1 %12278 to i32
  %12280 = xor i32 %12279, -1
  %12281 = and i32 %12280, %12274
  %12282 = and i32 %12279, %12277
  %12283 = or i32 %12282, %12281
  %12284 = add i64 %12275, 16
  %12285 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12284
  %12286 = load i32, i32* %12285, align 4
  %12287 = icmp eq i64 %12193, %12284
  %12288 = sext i1 %12287 to i32
  %12289 = xor i32 %12288, -1
  %12290 = and i32 %12289, %12283
  %12291 = and i32 %12288, %12286
  %12292 = or i32 %12291, %12290
  %12293 = add i64 %12284, 16
  %12294 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12293
  %12295 = load i32, i32* %12294, align 4
  %12296 = icmp eq i64 %12193, %12293
  %12297 = sext i1 %12296 to i32
  %12298 = xor i32 %12297, -1
  %12299 = and i32 %12298, %12292
  %12300 = and i32 %12297, %12295
  %12301 = or i32 %12300, %12299
  %12302 = add i64 %12293, 16
  %12303 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12302
  %12304 = load i32, i32* %12303, align 4
  %12305 = icmp eq i64 %12193, %12302
  %12306 = sext i1 %12305 to i32
  %12307 = xor i32 %12306, -1
  %12308 = and i32 %12307, %12301
  %12309 = and i32 %12306, %12304
  %12310 = or i32 %12309, %12308
  %12311 = add i64 %12302, 16
  %12312 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12311
  %12313 = load i32, i32* %12312, align 4
  %12314 = icmp eq i64 %12193, %12311
  %12315 = sext i1 %12314 to i32
  %12316 = xor i32 %12315, -1
  %12317 = and i32 %12316, %12310
  %12318 = and i32 %12315, %12313
  %12319 = or i32 %12318, %12317
  %12320 = add i64 %12311, 16
  %12321 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12320
  %12322 = load i32, i32* %12321, align 4
  %12323 = icmp eq i64 %12193, %12320
  %12324 = sext i1 %12323 to i32
  %12325 = xor i32 %12324, -1
  %12326 = and i32 %12325, %12319
  %12327 = and i32 %12324, %12322
  %12328 = or i32 %12327, %12326
  %12329 = add i64 %12320, 16
  %12330 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 1), i64 0, i64 %12329
  %12331 = load i32, i32* %12330, align 4
  %12332 = icmp eq i64 %12193, %12329
  %12333 = sext i1 %12332 to i32
  %12334 = xor i32 %12333, -1
  %12335 = and i32 %12334, %12328
  %12336 = and i32 %12333, %12331
  %Mitigated115 = or i32 %12336, %12335
  %12337 = xor i32 %Mitigated113, %Mitigated115
  %12338 = add nsw i32 %.27, 1
  %12339 = sext i32 %12338 to i64
  %12340 = getelementptr inbounds [256 x i8], [256 x i8]* @q0, i64 0, i64 %12339
  %12341 = load i8, i8* %12340, align 1
  %12342 = zext i8 %12341 to i32
  %12343 = getelementptr inbounds i8, i8* %0, i64 14
  %12344 = load i8, i8* %12343, align 1
  %12345 = zext i8 %12344 to i32
  %12346 = xor i32 %12342, %12345
  %12347 = sext i32 %12346 to i64
  %12348 = srem i64 %12347, 64
  %12349 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12348
  %12350 = load i8, i8* %12349, align 1
  %12351 = icmp eq i64 %12347, %12348
  %12352 = sext i1 %12351 to i8
  %12353 = xor i8 %12352, -1
  %12354 = and i8 %12353, 0
  %12355 = and i8 %12352, %12350
  %12356 = or i8 %12355, %12354
  %12357 = add i64 %12348, 64
  %12358 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12357
  %12359 = load i8, i8* %12358, align 1
  %12360 = icmp eq i64 %12347, %12357
  %12361 = sext i1 %12360 to i8
  %12362 = xor i8 %12361, -1
  %12363 = and i8 %12362, %12356
  %12364 = and i8 %12361, %12359
  %12365 = or i8 %12364, %12363
  %12366 = add i64 %12357, 64
  %12367 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12366
  %12368 = load i8, i8* %12367, align 1
  %12369 = icmp eq i64 %12347, %12366
  %12370 = sext i1 %12369 to i8
  %12371 = xor i8 %12370, -1
  %12372 = and i8 %12371, %12365
  %12373 = and i8 %12370, %12368
  %12374 = or i8 %12373, %12372
  %12375 = add i64 %12366, 64
  %12376 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12375
  %12377 = load i8, i8* %12376, align 1
  %12378 = icmp eq i64 %12347, %12375
  %12379 = sext i1 %12378 to i8
  %12380 = xor i8 %12379, -1
  %12381 = and i8 %12380, %12374
  %12382 = and i8 %12379, %12377
  %Mitigated116 = or i8 %12382, %12381
  %12383 = zext i8 %Mitigated116 to i32
  %12384 = getelementptr inbounds i8, i8* %0, i64 6
  %12385 = load i8, i8* %12384, align 1
  %12386 = zext i8 %12385 to i32
  %12387 = xor i32 %12383, %12386
  %12388 = sext i32 %12387 to i64
  %12389 = srem i64 %12388, 16
  %12390 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12389
  %12391 = load i32, i32* %12390, align 4
  %12392 = icmp eq i64 %12388, %12389
  %12393 = sext i1 %12392 to i32
  %12394 = xor i32 %12393, -1
  %12395 = and i32 %12394, 0
  %12396 = and i32 %12393, %12391
  %12397 = or i32 %12396, %12395
  %12398 = add i64 %12389, 16
  %12399 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12398
  %12400 = load i32, i32* %12399, align 4
  %12401 = icmp eq i64 %12388, %12398
  %12402 = sext i1 %12401 to i32
  %12403 = xor i32 %12402, -1
  %12404 = and i32 %12403, %12397
  %12405 = and i32 %12402, %12400
  %12406 = or i32 %12405, %12404
  %12407 = add i64 %12398, 16
  %12408 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12407
  %12409 = load i32, i32* %12408, align 4
  %12410 = icmp eq i64 %12388, %12407
  %12411 = sext i1 %12410 to i32
  %12412 = xor i32 %12411, -1
  %12413 = and i32 %12412, %12406
  %12414 = and i32 %12411, %12409
  %12415 = or i32 %12414, %12413
  %12416 = add i64 %12407, 16
  %12417 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12416
  %12418 = load i32, i32* %12417, align 4
  %12419 = icmp eq i64 %12388, %12416
  %12420 = sext i1 %12419 to i32
  %12421 = xor i32 %12420, -1
  %12422 = and i32 %12421, %12415
  %12423 = and i32 %12420, %12418
  %12424 = or i32 %12423, %12422
  %12425 = add i64 %12416, 16
  %12426 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12425
  %12427 = load i32, i32* %12426, align 4
  %12428 = icmp eq i64 %12388, %12425
  %12429 = sext i1 %12428 to i32
  %12430 = xor i32 %12429, -1
  %12431 = and i32 %12430, %12424
  %12432 = and i32 %12429, %12427
  %12433 = or i32 %12432, %12431
  %12434 = add i64 %12425, 16
  %12435 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12434
  %12436 = load i32, i32* %12435, align 4
  %12437 = icmp eq i64 %12388, %12434
  %12438 = sext i1 %12437 to i32
  %12439 = xor i32 %12438, -1
  %12440 = and i32 %12439, %12433
  %12441 = and i32 %12438, %12436
  %12442 = or i32 %12441, %12440
  %12443 = add i64 %12434, 16
  %12444 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12443
  %12445 = load i32, i32* %12444, align 4
  %12446 = icmp eq i64 %12388, %12443
  %12447 = sext i1 %12446 to i32
  %12448 = xor i32 %12447, -1
  %12449 = and i32 %12448, %12442
  %12450 = and i32 %12447, %12445
  %12451 = or i32 %12450, %12449
  %12452 = add i64 %12443, 16
  %12453 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12452
  %12454 = load i32, i32* %12453, align 4
  %12455 = icmp eq i64 %12388, %12452
  %12456 = sext i1 %12455 to i32
  %12457 = xor i32 %12456, -1
  %12458 = and i32 %12457, %12451
  %12459 = and i32 %12456, %12454
  %12460 = or i32 %12459, %12458
  %12461 = add i64 %12452, 16
  %12462 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12461
  %12463 = load i32, i32* %12462, align 4
  %12464 = icmp eq i64 %12388, %12461
  %12465 = sext i1 %12464 to i32
  %12466 = xor i32 %12465, -1
  %12467 = and i32 %12466, %12460
  %12468 = and i32 %12465, %12463
  %12469 = or i32 %12468, %12467
  %12470 = add i64 %12461, 16
  %12471 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12470
  %12472 = load i32, i32* %12471, align 4
  %12473 = icmp eq i64 %12388, %12470
  %12474 = sext i1 %12473 to i32
  %12475 = xor i32 %12474, -1
  %12476 = and i32 %12475, %12469
  %12477 = and i32 %12474, %12472
  %12478 = or i32 %12477, %12476
  %12479 = add i64 %12470, 16
  %12480 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12479
  %12481 = load i32, i32* %12480, align 4
  %12482 = icmp eq i64 %12388, %12479
  %12483 = sext i1 %12482 to i32
  %12484 = xor i32 %12483, -1
  %12485 = and i32 %12484, %12478
  %12486 = and i32 %12483, %12481
  %12487 = or i32 %12486, %12485
  %12488 = add i64 %12479, 16
  %12489 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12488
  %12490 = load i32, i32* %12489, align 4
  %12491 = icmp eq i64 %12388, %12488
  %12492 = sext i1 %12491 to i32
  %12493 = xor i32 %12492, -1
  %12494 = and i32 %12493, %12487
  %12495 = and i32 %12492, %12490
  %12496 = or i32 %12495, %12494
  %12497 = add i64 %12488, 16
  %12498 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12497
  %12499 = load i32, i32* %12498, align 4
  %12500 = icmp eq i64 %12388, %12497
  %12501 = sext i1 %12500 to i32
  %12502 = xor i32 %12501, -1
  %12503 = and i32 %12502, %12496
  %12504 = and i32 %12501, %12499
  %12505 = or i32 %12504, %12503
  %12506 = add i64 %12497, 16
  %12507 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12506
  %12508 = load i32, i32* %12507, align 4
  %12509 = icmp eq i64 %12388, %12506
  %12510 = sext i1 %12509 to i32
  %12511 = xor i32 %12510, -1
  %12512 = and i32 %12511, %12505
  %12513 = and i32 %12510, %12508
  %12514 = or i32 %12513, %12512
  %12515 = add i64 %12506, 16
  %12516 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12515
  %12517 = load i32, i32* %12516, align 4
  %12518 = icmp eq i64 %12388, %12515
  %12519 = sext i1 %12518 to i32
  %12520 = xor i32 %12519, -1
  %12521 = and i32 %12520, %12514
  %12522 = and i32 %12519, %12517
  %12523 = or i32 %12522, %12521
  %12524 = add i64 %12515, 16
  %12525 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 2), i64 0, i64 %12524
  %12526 = load i32, i32* %12525, align 4
  %12527 = icmp eq i64 %12388, %12524
  %12528 = sext i1 %12527 to i32
  %12529 = xor i32 %12528, -1
  %12530 = and i32 %12529, %12523
  %12531 = and i32 %12528, %12526
  %Mitigated117 = or i32 %12531, %12530
  %12532 = xor i32 %12337, %Mitigated117
  %12533 = add nsw i32 %.27, 1
  %12534 = sext i32 %12533 to i64
  %12535 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12534
  %12536 = load i8, i8* %12535, align 1
  %12537 = zext i8 %12536 to i32
  %12538 = getelementptr inbounds i8, i8* %0, i64 15
  %12539 = load i8, i8* %12538, align 1
  %12540 = zext i8 %12539 to i32
  %12541 = xor i32 %12537, %12540
  %12542 = sext i32 %12541 to i64
  %12543 = srem i64 %12542, 64
  %12544 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12543
  %12545 = load i8, i8* %12544, align 1
  %12546 = icmp eq i64 %12542, %12543
  %12547 = sext i1 %12546 to i8
  %12548 = xor i8 %12547, -1
  %12549 = and i8 %12548, 0
  %12550 = and i8 %12547, %12545
  %12551 = or i8 %12550, %12549
  %12552 = add i64 %12543, 64
  %12553 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12552
  %12554 = load i8, i8* %12553, align 1
  %12555 = icmp eq i64 %12542, %12552
  %12556 = sext i1 %12555 to i8
  %12557 = xor i8 %12556, -1
  %12558 = and i8 %12557, %12551
  %12559 = and i8 %12556, %12554
  %12560 = or i8 %12559, %12558
  %12561 = add i64 %12552, 64
  %12562 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12561
  %12563 = load i8, i8* %12562, align 1
  %12564 = icmp eq i64 %12542, %12561
  %12565 = sext i1 %12564 to i8
  %12566 = xor i8 %12565, -1
  %12567 = and i8 %12566, %12560
  %12568 = and i8 %12565, %12563
  %12569 = or i8 %12568, %12567
  %12570 = add i64 %12561, 64
  %12571 = getelementptr inbounds [256 x i8], [256 x i8]* @q1, i64 0, i64 %12570
  %12572 = load i8, i8* %12571, align 1
  %12573 = icmp eq i64 %12542, %12570
  %12574 = sext i1 %12573 to i8
  %12575 = xor i8 %12574, -1
  %12576 = and i8 %12575, %12569
  %12577 = and i8 %12574, %12572
  %Mitigated118 = or i8 %12577, %12576
  %12578 = zext i8 %Mitigated118 to i32
  %12579 = getelementptr inbounds i8, i8* %0, i64 7
  %12580 = load i8, i8* %12579, align 1
  %12581 = zext i8 %12580 to i32
  %12582 = xor i32 %12578, %12581
  %12583 = sext i32 %12582 to i64
  %12584 = srem i64 %12583, 16
  %12585 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12584
  %12586 = load i32, i32* %12585, align 4
  %12587 = icmp eq i64 %12583, %12584
  %12588 = sext i1 %12587 to i32
  %12589 = xor i32 %12588, -1
  %12590 = and i32 %12589, 0
  %12591 = and i32 %12588, %12586
  %12592 = or i32 %12591, %12590
  %12593 = add i64 %12584, 16
  %12594 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12593
  %12595 = load i32, i32* %12594, align 4
  %12596 = icmp eq i64 %12583, %12593
  %12597 = sext i1 %12596 to i32
  %12598 = xor i32 %12597, -1
  %12599 = and i32 %12598, %12592
  %12600 = and i32 %12597, %12595
  %12601 = or i32 %12600, %12599
  %12602 = add i64 %12593, 16
  %12603 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12602
  %12604 = load i32, i32* %12603, align 4
  %12605 = icmp eq i64 %12583, %12602
  %12606 = sext i1 %12605 to i32
  %12607 = xor i32 %12606, -1
  %12608 = and i32 %12607, %12601
  %12609 = and i32 %12606, %12604
  %12610 = or i32 %12609, %12608
  %12611 = add i64 %12602, 16
  %12612 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12611
  %12613 = load i32, i32* %12612, align 4
  %12614 = icmp eq i64 %12583, %12611
  %12615 = sext i1 %12614 to i32
  %12616 = xor i32 %12615, -1
  %12617 = and i32 %12616, %12610
  %12618 = and i32 %12615, %12613
  %12619 = or i32 %12618, %12617
  %12620 = add i64 %12611, 16
  %12621 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12620
  %12622 = load i32, i32* %12621, align 4
  %12623 = icmp eq i64 %12583, %12620
  %12624 = sext i1 %12623 to i32
  %12625 = xor i32 %12624, -1
  %12626 = and i32 %12625, %12619
  %12627 = and i32 %12624, %12622
  %12628 = or i32 %12627, %12626
  %12629 = add i64 %12620, 16
  %12630 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12629
  %12631 = load i32, i32* %12630, align 4
  %12632 = icmp eq i64 %12583, %12629
  %12633 = sext i1 %12632 to i32
  %12634 = xor i32 %12633, -1
  %12635 = and i32 %12634, %12628
  %12636 = and i32 %12633, %12631
  %12637 = or i32 %12636, %12635
  %12638 = add i64 %12629, 16
  %12639 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12638
  %12640 = load i32, i32* %12639, align 4
  %12641 = icmp eq i64 %12583, %12638
  %12642 = sext i1 %12641 to i32
  %12643 = xor i32 %12642, -1
  %12644 = and i32 %12643, %12637
  %12645 = and i32 %12642, %12640
  %12646 = or i32 %12645, %12644
  %12647 = add i64 %12638, 16
  %12648 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12647
  %12649 = load i32, i32* %12648, align 4
  %12650 = icmp eq i64 %12583, %12647
  %12651 = sext i1 %12650 to i32
  %12652 = xor i32 %12651, -1
  %12653 = and i32 %12652, %12646
  %12654 = and i32 %12651, %12649
  %12655 = or i32 %12654, %12653
  %12656 = add i64 %12647, 16
  %12657 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12656
  %12658 = load i32, i32* %12657, align 4
  %12659 = icmp eq i64 %12583, %12656
  %12660 = sext i1 %12659 to i32
  %12661 = xor i32 %12660, -1
  %12662 = and i32 %12661, %12655
  %12663 = and i32 %12660, %12658
  %12664 = or i32 %12663, %12662
  %12665 = add i64 %12656, 16
  %12666 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12665
  %12667 = load i32, i32* %12666, align 4
  %12668 = icmp eq i64 %12583, %12665
  %12669 = sext i1 %12668 to i32
  %12670 = xor i32 %12669, -1
  %12671 = and i32 %12670, %12664
  %12672 = and i32 %12669, %12667
  %12673 = or i32 %12672, %12671
  %12674 = add i64 %12665, 16
  %12675 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12674
  %12676 = load i32, i32* %12675, align 4
  %12677 = icmp eq i64 %12583, %12674
  %12678 = sext i1 %12677 to i32
  %12679 = xor i32 %12678, -1
  %12680 = and i32 %12679, %12673
  %12681 = and i32 %12678, %12676
  %12682 = or i32 %12681, %12680
  %12683 = add i64 %12674, 16
  %12684 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12683
  %12685 = load i32, i32* %12684, align 4
  %12686 = icmp eq i64 %12583, %12683
  %12687 = sext i1 %12686 to i32
  %12688 = xor i32 %12687, -1
  %12689 = and i32 %12688, %12682
  %12690 = and i32 %12687, %12685
  %12691 = or i32 %12690, %12689
  %12692 = add i64 %12683, 16
  %12693 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12692
  %12694 = load i32, i32* %12693, align 4
  %12695 = icmp eq i64 %12583, %12692
  %12696 = sext i1 %12695 to i32
  %12697 = xor i32 %12696, -1
  %12698 = and i32 %12697, %12691
  %12699 = and i32 %12696, %12694
  %12700 = or i32 %12699, %12698
  %12701 = add i64 %12692, 16
  %12702 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12701
  %12703 = load i32, i32* %12702, align 4
  %12704 = icmp eq i64 %12583, %12701
  %12705 = sext i1 %12704 to i32
  %12706 = xor i32 %12705, -1
  %12707 = and i32 %12706, %12700
  %12708 = and i32 %12705, %12703
  %12709 = or i32 %12708, %12707
  %12710 = add i64 %12701, 16
  %12711 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12710
  %12712 = load i32, i32* %12711, align 4
  %12713 = icmp eq i64 %12583, %12710
  %12714 = sext i1 %12713 to i32
  %12715 = xor i32 %12714, -1
  %12716 = and i32 %12715, %12709
  %12717 = and i32 %12714, %12712
  %12718 = or i32 %12717, %12716
  %12719 = add i64 %12710, 16
  %12720 = getelementptr inbounds [256 x i32], [256 x i32]* getelementptr inbounds ([4 x [256 x i32]], [4 x [256 x i32]]* @mds, i64 0, i64 3), i64 0, i64 %12719
  %12721 = load i32, i32* %12720, align 4
  %12722 = icmp eq i64 %12583, %12719
  %12723 = sext i1 %12722 to i32
  %12724 = xor i32 %12723, -1
  %12725 = and i32 %12724, %12718
  %12726 = and i32 %12723, %12721
  %Mitigated119 = or i32 %12726, %12725
  %12727 = xor i32 %12532, %Mitigated119
  %12728 = shl i32 %12727, 8
  %12729 = lshr i32 %12727, 24
  %12730 = add i32 %12728, %12729
  %12731 = add i32 %11948, %12730
  %12732 = add i32 %12730, %12731
  %12733 = sext i32 %.136 to i64
  %12734 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 2
  %12735 = getelementptr inbounds [32 x i32], [32 x i32]* %12734, i64 0, i64 %12733
  store i32 %12731, i32* %12735, align 4
  %12736 = shl i32 %12732, 9
  %12737 = lshr i32 %12732, 23
  %12738 = add i32 %12736, %12737
  %12739 = add nsw i32 %.136, 1
  %12740 = sext i32 %12739 to i64
  %12741 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %1, i32 0, i32 2
  %12742 = getelementptr inbounds [32 x i32], [32 x i32]* %12741, i64 0, i64 %12740
  store i32 %12738, i32* %12742, align 4
  %12743 = add nsw i32 %.136, 2
  %12744 = add nsw i32 %.27, 2
  %12745 = icmp slt i32 %12743, 32
  br i1 %12745, label %11173, label %.loopexit

.loopexit:                                        ; preds = %11173
  %.0.ph = phi i32 [ 0, %11173 ]
  br label %12746

; <label>:12746:                                  ; preds = %.loopexit, %3
  %.0 = phi i32 [ 2, %3 ], [ %.0.ph, %.loopexit ]
  ret i32 %.0
}

; Function Attrs: nounwind uwtable
define internal void @do_twofish_encrypt(%struct.TWOFISH_context*, i8*, i8*) #0 {
  %4 = getelementptr inbounds i8, i8* %2, i64 0
  %5 = getelementptr inbounds i8, i8* %4, i64 3
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl i32 %7, 24
  %9 = getelementptr inbounds i8, i8* %4, i64 2
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = shl i32 %11, 16
  %13 = or i32 %8, %12
  %14 = getelementptr inbounds i8, i8* %4, i64 1
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = shl i32 %16, 8
  %18 = or i32 %13, %17
  %19 = load i8, i8* %4, align 1
  %20 = zext i8 %19 to i32
  %21 = or i32 %18, %20
  %22 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %23 = getelementptr inbounds [8 x i32], [8 x i32]* %22, i64 0, i64 0
  %24 = load i32, i32* %23, align 4
  %25 = xor i32 %21, %24
  %26 = getelementptr inbounds i8, i8* %2, i64 4
  %27 = getelementptr inbounds i8, i8* %26, i64 3
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = shl i32 %29, 24
  %31 = getelementptr inbounds i8, i8* %26, i64 2
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = shl i32 %33, 16
  %35 = or i32 %30, %34
  %36 = getelementptr inbounds i8, i8* %26, i64 1
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = shl i32 %38, 8
  %40 = or i32 %35, %39
  %41 = load i8, i8* %26, align 1
  %42 = zext i8 %41 to i32
  %43 = or i32 %40, %42
  %44 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %45 = getelementptr inbounds [8 x i32], [8 x i32]* %44, i64 0, i64 1
  %46 = load i32, i32* %45, align 4
  %47 = xor i32 %43, %46
  %48 = getelementptr inbounds i8, i8* %2, i64 8
  %49 = getelementptr inbounds i8, i8* %48, i64 3
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = shl i32 %51, 24
  %53 = getelementptr inbounds i8, i8* %48, i64 2
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = shl i32 %55, 16
  %57 = or i32 %52, %56
  %58 = getelementptr inbounds i8, i8* %48, i64 1
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = shl i32 %60, 8
  %62 = or i32 %57, %61
  %63 = load i8, i8* %48, align 1
  %64 = zext i8 %63 to i32
  %65 = or i32 %62, %64
  %66 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %67 = getelementptr inbounds [8 x i32], [8 x i32]* %66, i64 0, i64 2
  %68 = load i32, i32* %67, align 4
  %69 = xor i32 %65, %68
  %70 = getelementptr inbounds i8, i8* %2, i64 12
  %71 = getelementptr inbounds i8, i8* %70, i64 3
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = shl i32 %73, 24
  %75 = getelementptr inbounds i8, i8* %70, i64 2
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = shl i32 %77, 16
  %79 = or i32 %74, %78
  %80 = getelementptr inbounds i8, i8* %70, i64 1
  %81 = load i8, i8* %80, align 1
  %82 = zext i8 %81 to i32
  %83 = shl i32 %82, 8
  %84 = or i32 %79, %83
  %85 = load i8, i8* %70, align 1
  %86 = zext i8 %85 to i32
  %87 = or i32 %84, %86
  %88 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %89 = getelementptr inbounds [8 x i32], [8 x i32]* %88, i64 0, i64 3
  %90 = load i32, i32* %89, align 4
  %91 = xor i32 %87, %90
  %92 = and i32 %25, 255
  %93 = zext i32 %92 to i64
  %94 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %95 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %94, i64 0, i64 0
  %96 = srem i64 %93, 16
  %97 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %96
  %98 = load i32, i32* %97, align 4
  %99 = icmp eq i64 %93, %96
  %100 = sext i1 %99 to i32
  %101 = xor i32 %100, -1
  %102 = and i32 %101, 0
  %103 = and i32 %100, %98
  %104 = or i32 %103, %102
  %105 = add i64 %96, 16
  %106 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %105
  %107 = load i32, i32* %106, align 4
  %108 = icmp eq i64 %93, %105
  %109 = sext i1 %108 to i32
  %110 = xor i32 %109, -1
  %111 = and i32 %110, %104
  %112 = and i32 %109, %107
  %113 = or i32 %112, %111
  %114 = add i64 %105, 16
  %115 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %114
  %116 = load i32, i32* %115, align 4
  %117 = icmp eq i64 %93, %114
  %118 = sext i1 %117 to i32
  %119 = xor i32 %118, -1
  %120 = and i32 %119, %113
  %121 = and i32 %118, %116
  %122 = or i32 %121, %120
  %123 = add i64 %114, 16
  %124 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %123
  %125 = load i32, i32* %124, align 4
  %126 = icmp eq i64 %93, %123
  %127 = sext i1 %126 to i32
  %128 = xor i32 %127, -1
  %129 = and i32 %128, %122
  %130 = and i32 %127, %125
  %131 = or i32 %130, %129
  %132 = add i64 %123, 16
  %133 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %132
  %134 = load i32, i32* %133, align 4
  %135 = icmp eq i64 %93, %132
  %136 = sext i1 %135 to i32
  %137 = xor i32 %136, -1
  %138 = and i32 %137, %131
  %139 = and i32 %136, %134
  %140 = or i32 %139, %138
  %141 = add i64 %132, 16
  %142 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %141
  %143 = load i32, i32* %142, align 4
  %144 = icmp eq i64 %93, %141
  %145 = sext i1 %144 to i32
  %146 = xor i32 %145, -1
  %147 = and i32 %146, %140
  %148 = and i32 %145, %143
  %149 = or i32 %148, %147
  %150 = add i64 %141, 16
  %151 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %150
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i64 %93, %150
  %154 = sext i1 %153 to i32
  %155 = xor i32 %154, -1
  %156 = and i32 %155, %149
  %157 = and i32 %154, %152
  %158 = or i32 %157, %156
  %159 = add i64 %150, 16
  %160 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %159
  %161 = load i32, i32* %160, align 4
  %162 = icmp eq i64 %93, %159
  %163 = sext i1 %162 to i32
  %164 = xor i32 %163, -1
  %165 = and i32 %164, %158
  %166 = and i32 %163, %161
  %167 = or i32 %166, %165
  %168 = add i64 %159, 16
  %169 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %168
  %170 = load i32, i32* %169, align 4
  %171 = icmp eq i64 %93, %168
  %172 = sext i1 %171 to i32
  %173 = xor i32 %172, -1
  %174 = and i32 %173, %167
  %175 = and i32 %172, %170
  %176 = or i32 %175, %174
  %177 = add i64 %168, 16
  %178 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %177
  %179 = load i32, i32* %178, align 4
  %180 = icmp eq i64 %93, %177
  %181 = sext i1 %180 to i32
  %182 = xor i32 %181, -1
  %183 = and i32 %182, %176
  %184 = and i32 %181, %179
  %185 = or i32 %184, %183
  %186 = add i64 %177, 16
  %187 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %186
  %188 = load i32, i32* %187, align 4
  %189 = icmp eq i64 %93, %186
  %190 = sext i1 %189 to i32
  %191 = xor i32 %190, -1
  %192 = and i32 %191, %185
  %193 = and i32 %190, %188
  %194 = or i32 %193, %192
  %195 = add i64 %186, 16
  %196 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %195
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i64 %93, %195
  %199 = sext i1 %198 to i32
  %200 = xor i32 %199, -1
  %201 = and i32 %200, %194
  %202 = and i32 %199, %197
  %203 = or i32 %202, %201
  %204 = add i64 %195, 16
  %205 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %204
  %206 = load i32, i32* %205, align 4
  %207 = icmp eq i64 %93, %204
  %208 = sext i1 %207 to i32
  %209 = xor i32 %208, -1
  %210 = and i32 %209, %203
  %211 = and i32 %208, %206
  %212 = or i32 %211, %210
  %213 = add i64 %204, 16
  %214 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %213
  %215 = load i32, i32* %214, align 4
  %216 = icmp eq i64 %93, %213
  %217 = sext i1 %216 to i32
  %218 = xor i32 %217, -1
  %219 = and i32 %218, %212
  %220 = and i32 %217, %215
  %221 = or i32 %220, %219
  %222 = add i64 %213, 16
  %223 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %222
  %224 = load i32, i32* %223, align 4
  %225 = icmp eq i64 %93, %222
  %226 = sext i1 %225 to i32
  %227 = xor i32 %226, -1
  %228 = and i32 %227, %221
  %229 = and i32 %226, %224
  %230 = or i32 %229, %228
  %231 = add i64 %222, 16
  %232 = getelementptr inbounds [256 x i32], [256 x i32]* %95, i64 0, i64 %231
  %233 = load i32, i32* %232, align 4
  %234 = icmp eq i64 %93, %231
  %235 = sext i1 %234 to i32
  %236 = xor i32 %235, -1
  %237 = and i32 %236, %230
  %238 = and i32 %235, %233
  %Mitigated = or i32 %238, %237
  %239 = lshr i32 %25, 8
  %240 = and i32 %239, 255
  %241 = zext i32 %240 to i64
  %242 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %243 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %242, i64 0, i64 1
  %244 = srem i64 %241, 16
  %245 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %244
  %246 = load i32, i32* %245, align 4
  %247 = icmp eq i64 %241, %244
  %248 = sext i1 %247 to i32
  %249 = xor i32 %248, -1
  %250 = and i32 %249, 0
  %251 = and i32 %248, %246
  %252 = or i32 %251, %250
  %253 = add i64 %244, 16
  %254 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %253
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i64 %241, %253
  %257 = sext i1 %256 to i32
  %258 = xor i32 %257, -1
  %259 = and i32 %258, %252
  %260 = and i32 %257, %255
  %261 = or i32 %260, %259
  %262 = add i64 %253, 16
  %263 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %262
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i64 %241, %262
  %266 = sext i1 %265 to i32
  %267 = xor i32 %266, -1
  %268 = and i32 %267, %261
  %269 = and i32 %266, %264
  %270 = or i32 %269, %268
  %271 = add i64 %262, 16
  %272 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %271
  %273 = load i32, i32* %272, align 4
  %274 = icmp eq i64 %241, %271
  %275 = sext i1 %274 to i32
  %276 = xor i32 %275, -1
  %277 = and i32 %276, %270
  %278 = and i32 %275, %273
  %279 = or i32 %278, %277
  %280 = add i64 %271, 16
  %281 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %280
  %282 = load i32, i32* %281, align 4
  %283 = icmp eq i64 %241, %280
  %284 = sext i1 %283 to i32
  %285 = xor i32 %284, -1
  %286 = and i32 %285, %279
  %287 = and i32 %284, %282
  %288 = or i32 %287, %286
  %289 = add i64 %280, 16
  %290 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %289
  %291 = load i32, i32* %290, align 4
  %292 = icmp eq i64 %241, %289
  %293 = sext i1 %292 to i32
  %294 = xor i32 %293, -1
  %295 = and i32 %294, %288
  %296 = and i32 %293, %291
  %297 = or i32 %296, %295
  %298 = add i64 %289, 16
  %299 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %298
  %300 = load i32, i32* %299, align 4
  %301 = icmp eq i64 %241, %298
  %302 = sext i1 %301 to i32
  %303 = xor i32 %302, -1
  %304 = and i32 %303, %297
  %305 = and i32 %302, %300
  %306 = or i32 %305, %304
  %307 = add i64 %298, 16
  %308 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %307
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i64 %241, %307
  %311 = sext i1 %310 to i32
  %312 = xor i32 %311, -1
  %313 = and i32 %312, %306
  %314 = and i32 %311, %309
  %315 = or i32 %314, %313
  %316 = add i64 %307, 16
  %317 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %316
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i64 %241, %316
  %320 = sext i1 %319 to i32
  %321 = xor i32 %320, -1
  %322 = and i32 %321, %315
  %323 = and i32 %320, %318
  %324 = or i32 %323, %322
  %325 = add i64 %316, 16
  %326 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %325
  %327 = load i32, i32* %326, align 4
  %328 = icmp eq i64 %241, %325
  %329 = sext i1 %328 to i32
  %330 = xor i32 %329, -1
  %331 = and i32 %330, %324
  %332 = and i32 %329, %327
  %333 = or i32 %332, %331
  %334 = add i64 %325, 16
  %335 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %334
  %336 = load i32, i32* %335, align 4
  %337 = icmp eq i64 %241, %334
  %338 = sext i1 %337 to i32
  %339 = xor i32 %338, -1
  %340 = and i32 %339, %333
  %341 = and i32 %338, %336
  %342 = or i32 %341, %340
  %343 = add i64 %334, 16
  %344 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %343
  %345 = load i32, i32* %344, align 4
  %346 = icmp eq i64 %241, %343
  %347 = sext i1 %346 to i32
  %348 = xor i32 %347, -1
  %349 = and i32 %348, %342
  %350 = and i32 %347, %345
  %351 = or i32 %350, %349
  %352 = add i64 %343, 16
  %353 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %352
  %354 = load i32, i32* %353, align 4
  %355 = icmp eq i64 %241, %352
  %356 = sext i1 %355 to i32
  %357 = xor i32 %356, -1
  %358 = and i32 %357, %351
  %359 = and i32 %356, %354
  %360 = or i32 %359, %358
  %361 = add i64 %352, 16
  %362 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %361
  %363 = load i32, i32* %362, align 4
  %364 = icmp eq i64 %241, %361
  %365 = sext i1 %364 to i32
  %366 = xor i32 %365, -1
  %367 = and i32 %366, %360
  %368 = and i32 %365, %363
  %369 = or i32 %368, %367
  %370 = add i64 %361, 16
  %371 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %370
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i64 %241, %370
  %374 = sext i1 %373 to i32
  %375 = xor i32 %374, -1
  %376 = and i32 %375, %369
  %377 = and i32 %374, %372
  %378 = or i32 %377, %376
  %379 = add i64 %370, 16
  %380 = getelementptr inbounds [256 x i32], [256 x i32]* %243, i64 0, i64 %379
  %381 = load i32, i32* %380, align 4
  %382 = icmp eq i64 %241, %379
  %383 = sext i1 %382 to i32
  %384 = xor i32 %383, -1
  %385 = and i32 %384, %378
  %386 = and i32 %383, %381
  %Mitigated1 = or i32 %386, %385
  %387 = xor i32 %Mitigated, %Mitigated1
  %388 = lshr i32 %25, 16
  %389 = and i32 %388, 255
  %390 = zext i32 %389 to i64
  %391 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %392 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %391, i64 0, i64 2
  %393 = srem i64 %390, 16
  %394 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %393
  %395 = load i32, i32* %394, align 4
  %396 = icmp eq i64 %390, %393
  %397 = sext i1 %396 to i32
  %398 = xor i32 %397, -1
  %399 = and i32 %398, 0
  %400 = and i32 %397, %395
  %401 = or i32 %400, %399
  %402 = add i64 %393, 16
  %403 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %402
  %404 = load i32, i32* %403, align 4
  %405 = icmp eq i64 %390, %402
  %406 = sext i1 %405 to i32
  %407 = xor i32 %406, -1
  %408 = and i32 %407, %401
  %409 = and i32 %406, %404
  %410 = or i32 %409, %408
  %411 = add i64 %402, 16
  %412 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %411
  %413 = load i32, i32* %412, align 4
  %414 = icmp eq i64 %390, %411
  %415 = sext i1 %414 to i32
  %416 = xor i32 %415, -1
  %417 = and i32 %416, %410
  %418 = and i32 %415, %413
  %419 = or i32 %418, %417
  %420 = add i64 %411, 16
  %421 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %420
  %422 = load i32, i32* %421, align 4
  %423 = icmp eq i64 %390, %420
  %424 = sext i1 %423 to i32
  %425 = xor i32 %424, -1
  %426 = and i32 %425, %419
  %427 = and i32 %424, %422
  %428 = or i32 %427, %426
  %429 = add i64 %420, 16
  %430 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %429
  %431 = load i32, i32* %430, align 4
  %432 = icmp eq i64 %390, %429
  %433 = sext i1 %432 to i32
  %434 = xor i32 %433, -1
  %435 = and i32 %434, %428
  %436 = and i32 %433, %431
  %437 = or i32 %436, %435
  %438 = add i64 %429, 16
  %439 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %438
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i64 %390, %438
  %442 = sext i1 %441 to i32
  %443 = xor i32 %442, -1
  %444 = and i32 %443, %437
  %445 = and i32 %442, %440
  %446 = or i32 %445, %444
  %447 = add i64 %438, 16
  %448 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %447
  %449 = load i32, i32* %448, align 4
  %450 = icmp eq i64 %390, %447
  %451 = sext i1 %450 to i32
  %452 = xor i32 %451, -1
  %453 = and i32 %452, %446
  %454 = and i32 %451, %449
  %455 = or i32 %454, %453
  %456 = add i64 %447, 16
  %457 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %456
  %458 = load i32, i32* %457, align 4
  %459 = icmp eq i64 %390, %456
  %460 = sext i1 %459 to i32
  %461 = xor i32 %460, -1
  %462 = and i32 %461, %455
  %463 = and i32 %460, %458
  %464 = or i32 %463, %462
  %465 = add i64 %456, 16
  %466 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %465
  %467 = load i32, i32* %466, align 4
  %468 = icmp eq i64 %390, %465
  %469 = sext i1 %468 to i32
  %470 = xor i32 %469, -1
  %471 = and i32 %470, %464
  %472 = and i32 %469, %467
  %473 = or i32 %472, %471
  %474 = add i64 %465, 16
  %475 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %474
  %476 = load i32, i32* %475, align 4
  %477 = icmp eq i64 %390, %474
  %478 = sext i1 %477 to i32
  %479 = xor i32 %478, -1
  %480 = and i32 %479, %473
  %481 = and i32 %478, %476
  %482 = or i32 %481, %480
  %483 = add i64 %474, 16
  %484 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %483
  %485 = load i32, i32* %484, align 4
  %486 = icmp eq i64 %390, %483
  %487 = sext i1 %486 to i32
  %488 = xor i32 %487, -1
  %489 = and i32 %488, %482
  %490 = and i32 %487, %485
  %491 = or i32 %490, %489
  %492 = add i64 %483, 16
  %493 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %492
  %494 = load i32, i32* %493, align 4
  %495 = icmp eq i64 %390, %492
  %496 = sext i1 %495 to i32
  %497 = xor i32 %496, -1
  %498 = and i32 %497, %491
  %499 = and i32 %496, %494
  %500 = or i32 %499, %498
  %501 = add i64 %492, 16
  %502 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %501
  %503 = load i32, i32* %502, align 4
  %504 = icmp eq i64 %390, %501
  %505 = sext i1 %504 to i32
  %506 = xor i32 %505, -1
  %507 = and i32 %506, %500
  %508 = and i32 %505, %503
  %509 = or i32 %508, %507
  %510 = add i64 %501, 16
  %511 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %510
  %512 = load i32, i32* %511, align 4
  %513 = icmp eq i64 %390, %510
  %514 = sext i1 %513 to i32
  %515 = xor i32 %514, -1
  %516 = and i32 %515, %509
  %517 = and i32 %514, %512
  %518 = or i32 %517, %516
  %519 = add i64 %510, 16
  %520 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %519
  %521 = load i32, i32* %520, align 4
  %522 = icmp eq i64 %390, %519
  %523 = sext i1 %522 to i32
  %524 = xor i32 %523, -1
  %525 = and i32 %524, %518
  %526 = and i32 %523, %521
  %527 = or i32 %526, %525
  %528 = add i64 %519, 16
  %529 = getelementptr inbounds [256 x i32], [256 x i32]* %392, i64 0, i64 %528
  %530 = load i32, i32* %529, align 4
  %531 = icmp eq i64 %390, %528
  %532 = sext i1 %531 to i32
  %533 = xor i32 %532, -1
  %534 = and i32 %533, %527
  %535 = and i32 %532, %530
  %Mitigated2 = or i32 %535, %534
  %536 = xor i32 %387, %Mitigated2
  %537 = lshr i32 %25, 24
  %538 = zext i32 %537 to i64
  %539 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %540 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %539, i64 0, i64 3
  %541 = srem i64 %538, 16
  %542 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %541
  %543 = load i32, i32* %542, align 4
  %544 = icmp eq i64 %538, %541
  %545 = sext i1 %544 to i32
  %546 = xor i32 %545, -1
  %547 = and i32 %546, 0
  %548 = and i32 %545, %543
  %549 = or i32 %548, %547
  %550 = add i64 %541, 16
  %551 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %550
  %552 = load i32, i32* %551, align 4
  %553 = icmp eq i64 %538, %550
  %554 = sext i1 %553 to i32
  %555 = xor i32 %554, -1
  %556 = and i32 %555, %549
  %557 = and i32 %554, %552
  %558 = or i32 %557, %556
  %559 = add i64 %550, 16
  %560 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %559
  %561 = load i32, i32* %560, align 4
  %562 = icmp eq i64 %538, %559
  %563 = sext i1 %562 to i32
  %564 = xor i32 %563, -1
  %565 = and i32 %564, %558
  %566 = and i32 %563, %561
  %567 = or i32 %566, %565
  %568 = add i64 %559, 16
  %569 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %568
  %570 = load i32, i32* %569, align 4
  %571 = icmp eq i64 %538, %568
  %572 = sext i1 %571 to i32
  %573 = xor i32 %572, -1
  %574 = and i32 %573, %567
  %575 = and i32 %572, %570
  %576 = or i32 %575, %574
  %577 = add i64 %568, 16
  %578 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %577
  %579 = load i32, i32* %578, align 4
  %580 = icmp eq i64 %538, %577
  %581 = sext i1 %580 to i32
  %582 = xor i32 %581, -1
  %583 = and i32 %582, %576
  %584 = and i32 %581, %579
  %585 = or i32 %584, %583
  %586 = add i64 %577, 16
  %587 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %586
  %588 = load i32, i32* %587, align 4
  %589 = icmp eq i64 %538, %586
  %590 = sext i1 %589 to i32
  %591 = xor i32 %590, -1
  %592 = and i32 %591, %585
  %593 = and i32 %590, %588
  %594 = or i32 %593, %592
  %595 = add i64 %586, 16
  %596 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %595
  %597 = load i32, i32* %596, align 4
  %598 = icmp eq i64 %538, %595
  %599 = sext i1 %598 to i32
  %600 = xor i32 %599, -1
  %601 = and i32 %600, %594
  %602 = and i32 %599, %597
  %603 = or i32 %602, %601
  %604 = add i64 %595, 16
  %605 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %604
  %606 = load i32, i32* %605, align 4
  %607 = icmp eq i64 %538, %604
  %608 = sext i1 %607 to i32
  %609 = xor i32 %608, -1
  %610 = and i32 %609, %603
  %611 = and i32 %608, %606
  %612 = or i32 %611, %610
  %613 = add i64 %604, 16
  %614 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %613
  %615 = load i32, i32* %614, align 4
  %616 = icmp eq i64 %538, %613
  %617 = sext i1 %616 to i32
  %618 = xor i32 %617, -1
  %619 = and i32 %618, %612
  %620 = and i32 %617, %615
  %621 = or i32 %620, %619
  %622 = add i64 %613, 16
  %623 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %622
  %624 = load i32, i32* %623, align 4
  %625 = icmp eq i64 %538, %622
  %626 = sext i1 %625 to i32
  %627 = xor i32 %626, -1
  %628 = and i32 %627, %621
  %629 = and i32 %626, %624
  %630 = or i32 %629, %628
  %631 = add i64 %622, 16
  %632 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %631
  %633 = load i32, i32* %632, align 4
  %634 = icmp eq i64 %538, %631
  %635 = sext i1 %634 to i32
  %636 = xor i32 %635, -1
  %637 = and i32 %636, %630
  %638 = and i32 %635, %633
  %639 = or i32 %638, %637
  %640 = add i64 %631, 16
  %641 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %640
  %642 = load i32, i32* %641, align 4
  %643 = icmp eq i64 %538, %640
  %644 = sext i1 %643 to i32
  %645 = xor i32 %644, -1
  %646 = and i32 %645, %639
  %647 = and i32 %644, %642
  %648 = or i32 %647, %646
  %649 = add i64 %640, 16
  %650 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %649
  %651 = load i32, i32* %650, align 4
  %652 = icmp eq i64 %538, %649
  %653 = sext i1 %652 to i32
  %654 = xor i32 %653, -1
  %655 = and i32 %654, %648
  %656 = and i32 %653, %651
  %657 = or i32 %656, %655
  %658 = add i64 %649, 16
  %659 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %658
  %660 = load i32, i32* %659, align 4
  %661 = icmp eq i64 %538, %658
  %662 = sext i1 %661 to i32
  %663 = xor i32 %662, -1
  %664 = and i32 %663, %657
  %665 = and i32 %662, %660
  %666 = or i32 %665, %664
  %667 = add i64 %658, 16
  %668 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %667
  %669 = load i32, i32* %668, align 4
  %670 = icmp eq i64 %538, %667
  %671 = sext i1 %670 to i32
  %672 = xor i32 %671, -1
  %673 = and i32 %672, %666
  %674 = and i32 %671, %669
  %675 = or i32 %674, %673
  %676 = add i64 %667, 16
  %677 = getelementptr inbounds [256 x i32], [256 x i32]* %540, i64 0, i64 %676
  %678 = load i32, i32* %677, align 4
  %679 = icmp eq i64 %538, %676
  %680 = sext i1 %679 to i32
  %681 = xor i32 %680, -1
  %682 = and i32 %681, %675
  %683 = and i32 %680, %678
  %Mitigated3 = or i32 %683, %682
  %684 = xor i32 %536, %Mitigated3
  %685 = and i32 %47, 255
  %686 = zext i32 %685 to i64
  %687 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %688 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %687, i64 0, i64 1
  %689 = srem i64 %686, 16
  %690 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %689
  %691 = load i32, i32* %690, align 4
  %692 = icmp eq i64 %686, %689
  %693 = sext i1 %692 to i32
  %694 = xor i32 %693, -1
  %695 = and i32 %694, 0
  %696 = and i32 %693, %691
  %697 = or i32 %696, %695
  %698 = add i64 %689, 16
  %699 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %698
  %700 = load i32, i32* %699, align 4
  %701 = icmp eq i64 %686, %698
  %702 = sext i1 %701 to i32
  %703 = xor i32 %702, -1
  %704 = and i32 %703, %697
  %705 = and i32 %702, %700
  %706 = or i32 %705, %704
  %707 = add i64 %698, 16
  %708 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %707
  %709 = load i32, i32* %708, align 4
  %710 = icmp eq i64 %686, %707
  %711 = sext i1 %710 to i32
  %712 = xor i32 %711, -1
  %713 = and i32 %712, %706
  %714 = and i32 %711, %709
  %715 = or i32 %714, %713
  %716 = add i64 %707, 16
  %717 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %716
  %718 = load i32, i32* %717, align 4
  %719 = icmp eq i64 %686, %716
  %720 = sext i1 %719 to i32
  %721 = xor i32 %720, -1
  %722 = and i32 %721, %715
  %723 = and i32 %720, %718
  %724 = or i32 %723, %722
  %725 = add i64 %716, 16
  %726 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %725
  %727 = load i32, i32* %726, align 4
  %728 = icmp eq i64 %686, %725
  %729 = sext i1 %728 to i32
  %730 = xor i32 %729, -1
  %731 = and i32 %730, %724
  %732 = and i32 %729, %727
  %733 = or i32 %732, %731
  %734 = add i64 %725, 16
  %735 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %734
  %736 = load i32, i32* %735, align 4
  %737 = icmp eq i64 %686, %734
  %738 = sext i1 %737 to i32
  %739 = xor i32 %738, -1
  %740 = and i32 %739, %733
  %741 = and i32 %738, %736
  %742 = or i32 %741, %740
  %743 = add i64 %734, 16
  %744 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %743
  %745 = load i32, i32* %744, align 4
  %746 = icmp eq i64 %686, %743
  %747 = sext i1 %746 to i32
  %748 = xor i32 %747, -1
  %749 = and i32 %748, %742
  %750 = and i32 %747, %745
  %751 = or i32 %750, %749
  %752 = add i64 %743, 16
  %753 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %752
  %754 = load i32, i32* %753, align 4
  %755 = icmp eq i64 %686, %752
  %756 = sext i1 %755 to i32
  %757 = xor i32 %756, -1
  %758 = and i32 %757, %751
  %759 = and i32 %756, %754
  %760 = or i32 %759, %758
  %761 = add i64 %752, 16
  %762 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %761
  %763 = load i32, i32* %762, align 4
  %764 = icmp eq i64 %686, %761
  %765 = sext i1 %764 to i32
  %766 = xor i32 %765, -1
  %767 = and i32 %766, %760
  %768 = and i32 %765, %763
  %769 = or i32 %768, %767
  %770 = add i64 %761, 16
  %771 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %770
  %772 = load i32, i32* %771, align 4
  %773 = icmp eq i64 %686, %770
  %774 = sext i1 %773 to i32
  %775 = xor i32 %774, -1
  %776 = and i32 %775, %769
  %777 = and i32 %774, %772
  %778 = or i32 %777, %776
  %779 = add i64 %770, 16
  %780 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %779
  %781 = load i32, i32* %780, align 4
  %782 = icmp eq i64 %686, %779
  %783 = sext i1 %782 to i32
  %784 = xor i32 %783, -1
  %785 = and i32 %784, %778
  %786 = and i32 %783, %781
  %787 = or i32 %786, %785
  %788 = add i64 %779, 16
  %789 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %788
  %790 = load i32, i32* %789, align 4
  %791 = icmp eq i64 %686, %788
  %792 = sext i1 %791 to i32
  %793 = xor i32 %792, -1
  %794 = and i32 %793, %787
  %795 = and i32 %792, %790
  %796 = or i32 %795, %794
  %797 = add i64 %788, 16
  %798 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %797
  %799 = load i32, i32* %798, align 4
  %800 = icmp eq i64 %686, %797
  %801 = sext i1 %800 to i32
  %802 = xor i32 %801, -1
  %803 = and i32 %802, %796
  %804 = and i32 %801, %799
  %805 = or i32 %804, %803
  %806 = add i64 %797, 16
  %807 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %806
  %808 = load i32, i32* %807, align 4
  %809 = icmp eq i64 %686, %806
  %810 = sext i1 %809 to i32
  %811 = xor i32 %810, -1
  %812 = and i32 %811, %805
  %813 = and i32 %810, %808
  %814 = or i32 %813, %812
  %815 = add i64 %806, 16
  %816 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %815
  %817 = load i32, i32* %816, align 4
  %818 = icmp eq i64 %686, %815
  %819 = sext i1 %818 to i32
  %820 = xor i32 %819, -1
  %821 = and i32 %820, %814
  %822 = and i32 %819, %817
  %823 = or i32 %822, %821
  %824 = add i64 %815, 16
  %825 = getelementptr inbounds [256 x i32], [256 x i32]* %688, i64 0, i64 %824
  %826 = load i32, i32* %825, align 4
  %827 = icmp eq i64 %686, %824
  %828 = sext i1 %827 to i32
  %829 = xor i32 %828, -1
  %830 = and i32 %829, %823
  %831 = and i32 %828, %826
  %Mitigated4 = or i32 %831, %830
  %832 = lshr i32 %47, 8
  %833 = and i32 %832, 255
  %834 = zext i32 %833 to i64
  %835 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %836 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %835, i64 0, i64 2
  %837 = srem i64 %834, 16
  %838 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %837
  %839 = load i32, i32* %838, align 4
  %840 = icmp eq i64 %834, %837
  %841 = sext i1 %840 to i32
  %842 = xor i32 %841, -1
  %843 = and i32 %842, 0
  %844 = and i32 %841, %839
  %845 = or i32 %844, %843
  %846 = add i64 %837, 16
  %847 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %846
  %848 = load i32, i32* %847, align 4
  %849 = icmp eq i64 %834, %846
  %850 = sext i1 %849 to i32
  %851 = xor i32 %850, -1
  %852 = and i32 %851, %845
  %853 = and i32 %850, %848
  %854 = or i32 %853, %852
  %855 = add i64 %846, 16
  %856 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %855
  %857 = load i32, i32* %856, align 4
  %858 = icmp eq i64 %834, %855
  %859 = sext i1 %858 to i32
  %860 = xor i32 %859, -1
  %861 = and i32 %860, %854
  %862 = and i32 %859, %857
  %863 = or i32 %862, %861
  %864 = add i64 %855, 16
  %865 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %864
  %866 = load i32, i32* %865, align 4
  %867 = icmp eq i64 %834, %864
  %868 = sext i1 %867 to i32
  %869 = xor i32 %868, -1
  %870 = and i32 %869, %863
  %871 = and i32 %868, %866
  %872 = or i32 %871, %870
  %873 = add i64 %864, 16
  %874 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %873
  %875 = load i32, i32* %874, align 4
  %876 = icmp eq i64 %834, %873
  %877 = sext i1 %876 to i32
  %878 = xor i32 %877, -1
  %879 = and i32 %878, %872
  %880 = and i32 %877, %875
  %881 = or i32 %880, %879
  %882 = add i64 %873, 16
  %883 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %882
  %884 = load i32, i32* %883, align 4
  %885 = icmp eq i64 %834, %882
  %886 = sext i1 %885 to i32
  %887 = xor i32 %886, -1
  %888 = and i32 %887, %881
  %889 = and i32 %886, %884
  %890 = or i32 %889, %888
  %891 = add i64 %882, 16
  %892 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %891
  %893 = load i32, i32* %892, align 4
  %894 = icmp eq i64 %834, %891
  %895 = sext i1 %894 to i32
  %896 = xor i32 %895, -1
  %897 = and i32 %896, %890
  %898 = and i32 %895, %893
  %899 = or i32 %898, %897
  %900 = add i64 %891, 16
  %901 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %900
  %902 = load i32, i32* %901, align 4
  %903 = icmp eq i64 %834, %900
  %904 = sext i1 %903 to i32
  %905 = xor i32 %904, -1
  %906 = and i32 %905, %899
  %907 = and i32 %904, %902
  %908 = or i32 %907, %906
  %909 = add i64 %900, 16
  %910 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %909
  %911 = load i32, i32* %910, align 4
  %912 = icmp eq i64 %834, %909
  %913 = sext i1 %912 to i32
  %914 = xor i32 %913, -1
  %915 = and i32 %914, %908
  %916 = and i32 %913, %911
  %917 = or i32 %916, %915
  %918 = add i64 %909, 16
  %919 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %918
  %920 = load i32, i32* %919, align 4
  %921 = icmp eq i64 %834, %918
  %922 = sext i1 %921 to i32
  %923 = xor i32 %922, -1
  %924 = and i32 %923, %917
  %925 = and i32 %922, %920
  %926 = or i32 %925, %924
  %927 = add i64 %918, 16
  %928 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %927
  %929 = load i32, i32* %928, align 4
  %930 = icmp eq i64 %834, %927
  %931 = sext i1 %930 to i32
  %932 = xor i32 %931, -1
  %933 = and i32 %932, %926
  %934 = and i32 %931, %929
  %935 = or i32 %934, %933
  %936 = add i64 %927, 16
  %937 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %936
  %938 = load i32, i32* %937, align 4
  %939 = icmp eq i64 %834, %936
  %940 = sext i1 %939 to i32
  %941 = xor i32 %940, -1
  %942 = and i32 %941, %935
  %943 = and i32 %940, %938
  %944 = or i32 %943, %942
  %945 = add i64 %936, 16
  %946 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %945
  %947 = load i32, i32* %946, align 4
  %948 = icmp eq i64 %834, %945
  %949 = sext i1 %948 to i32
  %950 = xor i32 %949, -1
  %951 = and i32 %950, %944
  %952 = and i32 %949, %947
  %953 = or i32 %952, %951
  %954 = add i64 %945, 16
  %955 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %954
  %956 = load i32, i32* %955, align 4
  %957 = icmp eq i64 %834, %954
  %958 = sext i1 %957 to i32
  %959 = xor i32 %958, -1
  %960 = and i32 %959, %953
  %961 = and i32 %958, %956
  %962 = or i32 %961, %960
  %963 = add i64 %954, 16
  %964 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %963
  %965 = load i32, i32* %964, align 4
  %966 = icmp eq i64 %834, %963
  %967 = sext i1 %966 to i32
  %968 = xor i32 %967, -1
  %969 = and i32 %968, %962
  %970 = and i32 %967, %965
  %971 = or i32 %970, %969
  %972 = add i64 %963, 16
  %973 = getelementptr inbounds [256 x i32], [256 x i32]* %836, i64 0, i64 %972
  %974 = load i32, i32* %973, align 4
  %975 = icmp eq i64 %834, %972
  %976 = sext i1 %975 to i32
  %977 = xor i32 %976, -1
  %978 = and i32 %977, %971
  %979 = and i32 %976, %974
  %Mitigated5 = or i32 %979, %978
  %980 = xor i32 %Mitigated4, %Mitigated5
  %981 = lshr i32 %47, 16
  %982 = and i32 %981, 255
  %983 = zext i32 %982 to i64
  %984 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %985 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %984, i64 0, i64 3
  %986 = srem i64 %983, 16
  %987 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %986
  %988 = load i32, i32* %987, align 4
  %989 = icmp eq i64 %983, %986
  %990 = sext i1 %989 to i32
  %991 = xor i32 %990, -1
  %992 = and i32 %991, 0
  %993 = and i32 %990, %988
  %994 = or i32 %993, %992
  %995 = add i64 %986, 16
  %996 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %995
  %997 = load i32, i32* %996, align 4
  %998 = icmp eq i64 %983, %995
  %999 = sext i1 %998 to i32
  %1000 = xor i32 %999, -1
  %1001 = and i32 %1000, %994
  %1002 = and i32 %999, %997
  %1003 = or i32 %1002, %1001
  %1004 = add i64 %995, 16
  %1005 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1004
  %1006 = load i32, i32* %1005, align 4
  %1007 = icmp eq i64 %983, %1004
  %1008 = sext i1 %1007 to i32
  %1009 = xor i32 %1008, -1
  %1010 = and i32 %1009, %1003
  %1011 = and i32 %1008, %1006
  %1012 = or i32 %1011, %1010
  %1013 = add i64 %1004, 16
  %1014 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1013
  %1015 = load i32, i32* %1014, align 4
  %1016 = icmp eq i64 %983, %1013
  %1017 = sext i1 %1016 to i32
  %1018 = xor i32 %1017, -1
  %1019 = and i32 %1018, %1012
  %1020 = and i32 %1017, %1015
  %1021 = or i32 %1020, %1019
  %1022 = add i64 %1013, 16
  %1023 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1022
  %1024 = load i32, i32* %1023, align 4
  %1025 = icmp eq i64 %983, %1022
  %1026 = sext i1 %1025 to i32
  %1027 = xor i32 %1026, -1
  %1028 = and i32 %1027, %1021
  %1029 = and i32 %1026, %1024
  %1030 = or i32 %1029, %1028
  %1031 = add i64 %1022, 16
  %1032 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1031
  %1033 = load i32, i32* %1032, align 4
  %1034 = icmp eq i64 %983, %1031
  %1035 = sext i1 %1034 to i32
  %1036 = xor i32 %1035, -1
  %1037 = and i32 %1036, %1030
  %1038 = and i32 %1035, %1033
  %1039 = or i32 %1038, %1037
  %1040 = add i64 %1031, 16
  %1041 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1040
  %1042 = load i32, i32* %1041, align 4
  %1043 = icmp eq i64 %983, %1040
  %1044 = sext i1 %1043 to i32
  %1045 = xor i32 %1044, -1
  %1046 = and i32 %1045, %1039
  %1047 = and i32 %1044, %1042
  %1048 = or i32 %1047, %1046
  %1049 = add i64 %1040, 16
  %1050 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1049
  %1051 = load i32, i32* %1050, align 4
  %1052 = icmp eq i64 %983, %1049
  %1053 = sext i1 %1052 to i32
  %1054 = xor i32 %1053, -1
  %1055 = and i32 %1054, %1048
  %1056 = and i32 %1053, %1051
  %1057 = or i32 %1056, %1055
  %1058 = add i64 %1049, 16
  %1059 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1058
  %1060 = load i32, i32* %1059, align 4
  %1061 = icmp eq i64 %983, %1058
  %1062 = sext i1 %1061 to i32
  %1063 = xor i32 %1062, -1
  %1064 = and i32 %1063, %1057
  %1065 = and i32 %1062, %1060
  %1066 = or i32 %1065, %1064
  %1067 = add i64 %1058, 16
  %1068 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1067
  %1069 = load i32, i32* %1068, align 4
  %1070 = icmp eq i64 %983, %1067
  %1071 = sext i1 %1070 to i32
  %1072 = xor i32 %1071, -1
  %1073 = and i32 %1072, %1066
  %1074 = and i32 %1071, %1069
  %1075 = or i32 %1074, %1073
  %1076 = add i64 %1067, 16
  %1077 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1076
  %1078 = load i32, i32* %1077, align 4
  %1079 = icmp eq i64 %983, %1076
  %1080 = sext i1 %1079 to i32
  %1081 = xor i32 %1080, -1
  %1082 = and i32 %1081, %1075
  %1083 = and i32 %1080, %1078
  %1084 = or i32 %1083, %1082
  %1085 = add i64 %1076, 16
  %1086 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1085
  %1087 = load i32, i32* %1086, align 4
  %1088 = icmp eq i64 %983, %1085
  %1089 = sext i1 %1088 to i32
  %1090 = xor i32 %1089, -1
  %1091 = and i32 %1090, %1084
  %1092 = and i32 %1089, %1087
  %1093 = or i32 %1092, %1091
  %1094 = add i64 %1085, 16
  %1095 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1094
  %1096 = load i32, i32* %1095, align 4
  %1097 = icmp eq i64 %983, %1094
  %1098 = sext i1 %1097 to i32
  %1099 = xor i32 %1098, -1
  %1100 = and i32 %1099, %1093
  %1101 = and i32 %1098, %1096
  %1102 = or i32 %1101, %1100
  %1103 = add i64 %1094, 16
  %1104 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1103
  %1105 = load i32, i32* %1104, align 4
  %1106 = icmp eq i64 %983, %1103
  %1107 = sext i1 %1106 to i32
  %1108 = xor i32 %1107, -1
  %1109 = and i32 %1108, %1102
  %1110 = and i32 %1107, %1105
  %1111 = or i32 %1110, %1109
  %1112 = add i64 %1103, 16
  %1113 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1112
  %1114 = load i32, i32* %1113, align 4
  %1115 = icmp eq i64 %983, %1112
  %1116 = sext i1 %1115 to i32
  %1117 = xor i32 %1116, -1
  %1118 = and i32 %1117, %1111
  %1119 = and i32 %1116, %1114
  %1120 = or i32 %1119, %1118
  %1121 = add i64 %1112, 16
  %1122 = getelementptr inbounds [256 x i32], [256 x i32]* %985, i64 0, i64 %1121
  %1123 = load i32, i32* %1122, align 4
  %1124 = icmp eq i64 %983, %1121
  %1125 = sext i1 %1124 to i32
  %1126 = xor i32 %1125, -1
  %1127 = and i32 %1126, %1120
  %1128 = and i32 %1125, %1123
  %Mitigated6 = or i32 %1128, %1127
  %1129 = xor i32 %980, %Mitigated6
  %1130 = lshr i32 %47, 24
  %1131 = zext i32 %1130 to i64
  %1132 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1133 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1132, i64 0, i64 0
  %1134 = srem i64 %1131, 16
  %1135 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1134
  %1136 = load i32, i32* %1135, align 4
  %1137 = icmp eq i64 %1131, %1134
  %1138 = sext i1 %1137 to i32
  %1139 = xor i32 %1138, -1
  %1140 = and i32 %1139, 0
  %1141 = and i32 %1138, %1136
  %1142 = or i32 %1141, %1140
  %1143 = add i64 %1134, 16
  %1144 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1143
  %1145 = load i32, i32* %1144, align 4
  %1146 = icmp eq i64 %1131, %1143
  %1147 = sext i1 %1146 to i32
  %1148 = xor i32 %1147, -1
  %1149 = and i32 %1148, %1142
  %1150 = and i32 %1147, %1145
  %1151 = or i32 %1150, %1149
  %1152 = add i64 %1143, 16
  %1153 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1152
  %1154 = load i32, i32* %1153, align 4
  %1155 = icmp eq i64 %1131, %1152
  %1156 = sext i1 %1155 to i32
  %1157 = xor i32 %1156, -1
  %1158 = and i32 %1157, %1151
  %1159 = and i32 %1156, %1154
  %1160 = or i32 %1159, %1158
  %1161 = add i64 %1152, 16
  %1162 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1161
  %1163 = load i32, i32* %1162, align 4
  %1164 = icmp eq i64 %1131, %1161
  %1165 = sext i1 %1164 to i32
  %1166 = xor i32 %1165, -1
  %1167 = and i32 %1166, %1160
  %1168 = and i32 %1165, %1163
  %1169 = or i32 %1168, %1167
  %1170 = add i64 %1161, 16
  %1171 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1170
  %1172 = load i32, i32* %1171, align 4
  %1173 = icmp eq i64 %1131, %1170
  %1174 = sext i1 %1173 to i32
  %1175 = xor i32 %1174, -1
  %1176 = and i32 %1175, %1169
  %1177 = and i32 %1174, %1172
  %1178 = or i32 %1177, %1176
  %1179 = add i64 %1170, 16
  %1180 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1179
  %1181 = load i32, i32* %1180, align 4
  %1182 = icmp eq i64 %1131, %1179
  %1183 = sext i1 %1182 to i32
  %1184 = xor i32 %1183, -1
  %1185 = and i32 %1184, %1178
  %1186 = and i32 %1183, %1181
  %1187 = or i32 %1186, %1185
  %1188 = add i64 %1179, 16
  %1189 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1188
  %1190 = load i32, i32* %1189, align 4
  %1191 = icmp eq i64 %1131, %1188
  %1192 = sext i1 %1191 to i32
  %1193 = xor i32 %1192, -1
  %1194 = and i32 %1193, %1187
  %1195 = and i32 %1192, %1190
  %1196 = or i32 %1195, %1194
  %1197 = add i64 %1188, 16
  %1198 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1197
  %1199 = load i32, i32* %1198, align 4
  %1200 = icmp eq i64 %1131, %1197
  %1201 = sext i1 %1200 to i32
  %1202 = xor i32 %1201, -1
  %1203 = and i32 %1202, %1196
  %1204 = and i32 %1201, %1199
  %1205 = or i32 %1204, %1203
  %1206 = add i64 %1197, 16
  %1207 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1206
  %1208 = load i32, i32* %1207, align 4
  %1209 = icmp eq i64 %1131, %1206
  %1210 = sext i1 %1209 to i32
  %1211 = xor i32 %1210, -1
  %1212 = and i32 %1211, %1205
  %1213 = and i32 %1210, %1208
  %1214 = or i32 %1213, %1212
  %1215 = add i64 %1206, 16
  %1216 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1215
  %1217 = load i32, i32* %1216, align 4
  %1218 = icmp eq i64 %1131, %1215
  %1219 = sext i1 %1218 to i32
  %1220 = xor i32 %1219, -1
  %1221 = and i32 %1220, %1214
  %1222 = and i32 %1219, %1217
  %1223 = or i32 %1222, %1221
  %1224 = add i64 %1215, 16
  %1225 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1224
  %1226 = load i32, i32* %1225, align 4
  %1227 = icmp eq i64 %1131, %1224
  %1228 = sext i1 %1227 to i32
  %1229 = xor i32 %1228, -1
  %1230 = and i32 %1229, %1223
  %1231 = and i32 %1228, %1226
  %1232 = or i32 %1231, %1230
  %1233 = add i64 %1224, 16
  %1234 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1233
  %1235 = load i32, i32* %1234, align 4
  %1236 = icmp eq i64 %1131, %1233
  %1237 = sext i1 %1236 to i32
  %1238 = xor i32 %1237, -1
  %1239 = and i32 %1238, %1232
  %1240 = and i32 %1237, %1235
  %1241 = or i32 %1240, %1239
  %1242 = add i64 %1233, 16
  %1243 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1242
  %1244 = load i32, i32* %1243, align 4
  %1245 = icmp eq i64 %1131, %1242
  %1246 = sext i1 %1245 to i32
  %1247 = xor i32 %1246, -1
  %1248 = and i32 %1247, %1241
  %1249 = and i32 %1246, %1244
  %1250 = or i32 %1249, %1248
  %1251 = add i64 %1242, 16
  %1252 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1251
  %1253 = load i32, i32* %1252, align 4
  %1254 = icmp eq i64 %1131, %1251
  %1255 = sext i1 %1254 to i32
  %1256 = xor i32 %1255, -1
  %1257 = and i32 %1256, %1250
  %1258 = and i32 %1255, %1253
  %1259 = or i32 %1258, %1257
  %1260 = add i64 %1251, 16
  %1261 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1260
  %1262 = load i32, i32* %1261, align 4
  %1263 = icmp eq i64 %1131, %1260
  %1264 = sext i1 %1263 to i32
  %1265 = xor i32 %1264, -1
  %1266 = and i32 %1265, %1259
  %1267 = and i32 %1264, %1262
  %1268 = or i32 %1267, %1266
  %1269 = add i64 %1260, 16
  %1270 = getelementptr inbounds [256 x i32], [256 x i32]* %1133, i64 0, i64 %1269
  %1271 = load i32, i32* %1270, align 4
  %1272 = icmp eq i64 %1131, %1269
  %1273 = sext i1 %1272 to i32
  %1274 = xor i32 %1273, -1
  %1275 = and i32 %1274, %1268
  %1276 = and i32 %1273, %1271
  %Mitigated7 = or i32 %1276, %1275
  %1277 = xor i32 %1129, %Mitigated7
  %1278 = add i32 %684, %1277
  %1279 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %1280 = getelementptr inbounds [32 x i32], [32 x i32]* %1279, i64 0, i64 1
  %1281 = load i32, i32* %1280, align 4
  %1282 = add i32 %1278, %1281
  %1283 = add i32 %1277, %1282
  %1284 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %1285 = getelementptr inbounds [32 x i32], [32 x i32]* %1284, i64 0, i64 0
  %1286 = load i32, i32* %1285, align 4
  %1287 = add i32 %1278, %1286
  %1288 = xor i32 %69, %1287
  %1289 = lshr i32 %1288, 1
  %1290 = shl i32 %1288, 31
  %1291 = add i32 %1289, %1290
  %1292 = shl i32 %91, 1
  %1293 = lshr i32 %91, 31
  %1294 = add i32 %1292, %1293
  %1295 = xor i32 %1294, %1283
  %1296 = and i32 %1291, 255
  %1297 = zext i32 %1296 to i64
  %1298 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1299 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1298, i64 0, i64 0
  %1300 = srem i64 %1297, 16
  %1301 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1300
  %1302 = load i32, i32* %1301, align 4
  %1303 = icmp eq i64 %1297, %1300
  %1304 = sext i1 %1303 to i32
  %1305 = xor i32 %1304, -1
  %1306 = and i32 %1305, 0
  %1307 = and i32 %1304, %1302
  %1308 = or i32 %1307, %1306
  %1309 = add i64 %1300, 16
  %1310 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1309
  %1311 = load i32, i32* %1310, align 4
  %1312 = icmp eq i64 %1297, %1309
  %1313 = sext i1 %1312 to i32
  %1314 = xor i32 %1313, -1
  %1315 = and i32 %1314, %1308
  %1316 = and i32 %1313, %1311
  %1317 = or i32 %1316, %1315
  %1318 = add i64 %1309, 16
  %1319 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1318
  %1320 = load i32, i32* %1319, align 4
  %1321 = icmp eq i64 %1297, %1318
  %1322 = sext i1 %1321 to i32
  %1323 = xor i32 %1322, -1
  %1324 = and i32 %1323, %1317
  %1325 = and i32 %1322, %1320
  %1326 = or i32 %1325, %1324
  %1327 = add i64 %1318, 16
  %1328 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1327
  %1329 = load i32, i32* %1328, align 4
  %1330 = icmp eq i64 %1297, %1327
  %1331 = sext i1 %1330 to i32
  %1332 = xor i32 %1331, -1
  %1333 = and i32 %1332, %1326
  %1334 = and i32 %1331, %1329
  %1335 = or i32 %1334, %1333
  %1336 = add i64 %1327, 16
  %1337 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1336
  %1338 = load i32, i32* %1337, align 4
  %1339 = icmp eq i64 %1297, %1336
  %1340 = sext i1 %1339 to i32
  %1341 = xor i32 %1340, -1
  %1342 = and i32 %1341, %1335
  %1343 = and i32 %1340, %1338
  %1344 = or i32 %1343, %1342
  %1345 = add i64 %1336, 16
  %1346 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1345
  %1347 = load i32, i32* %1346, align 4
  %1348 = icmp eq i64 %1297, %1345
  %1349 = sext i1 %1348 to i32
  %1350 = xor i32 %1349, -1
  %1351 = and i32 %1350, %1344
  %1352 = and i32 %1349, %1347
  %1353 = or i32 %1352, %1351
  %1354 = add i64 %1345, 16
  %1355 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1354
  %1356 = load i32, i32* %1355, align 4
  %1357 = icmp eq i64 %1297, %1354
  %1358 = sext i1 %1357 to i32
  %1359 = xor i32 %1358, -1
  %1360 = and i32 %1359, %1353
  %1361 = and i32 %1358, %1356
  %1362 = or i32 %1361, %1360
  %1363 = add i64 %1354, 16
  %1364 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1363
  %1365 = load i32, i32* %1364, align 4
  %1366 = icmp eq i64 %1297, %1363
  %1367 = sext i1 %1366 to i32
  %1368 = xor i32 %1367, -1
  %1369 = and i32 %1368, %1362
  %1370 = and i32 %1367, %1365
  %1371 = or i32 %1370, %1369
  %1372 = add i64 %1363, 16
  %1373 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1372
  %1374 = load i32, i32* %1373, align 4
  %1375 = icmp eq i64 %1297, %1372
  %1376 = sext i1 %1375 to i32
  %1377 = xor i32 %1376, -1
  %1378 = and i32 %1377, %1371
  %1379 = and i32 %1376, %1374
  %1380 = or i32 %1379, %1378
  %1381 = add i64 %1372, 16
  %1382 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1381
  %1383 = load i32, i32* %1382, align 4
  %1384 = icmp eq i64 %1297, %1381
  %1385 = sext i1 %1384 to i32
  %1386 = xor i32 %1385, -1
  %1387 = and i32 %1386, %1380
  %1388 = and i32 %1385, %1383
  %1389 = or i32 %1388, %1387
  %1390 = add i64 %1381, 16
  %1391 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1390
  %1392 = load i32, i32* %1391, align 4
  %1393 = icmp eq i64 %1297, %1390
  %1394 = sext i1 %1393 to i32
  %1395 = xor i32 %1394, -1
  %1396 = and i32 %1395, %1389
  %1397 = and i32 %1394, %1392
  %1398 = or i32 %1397, %1396
  %1399 = add i64 %1390, 16
  %1400 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1399
  %1401 = load i32, i32* %1400, align 4
  %1402 = icmp eq i64 %1297, %1399
  %1403 = sext i1 %1402 to i32
  %1404 = xor i32 %1403, -1
  %1405 = and i32 %1404, %1398
  %1406 = and i32 %1403, %1401
  %1407 = or i32 %1406, %1405
  %1408 = add i64 %1399, 16
  %1409 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1408
  %1410 = load i32, i32* %1409, align 4
  %1411 = icmp eq i64 %1297, %1408
  %1412 = sext i1 %1411 to i32
  %1413 = xor i32 %1412, -1
  %1414 = and i32 %1413, %1407
  %1415 = and i32 %1412, %1410
  %1416 = or i32 %1415, %1414
  %1417 = add i64 %1408, 16
  %1418 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1417
  %1419 = load i32, i32* %1418, align 4
  %1420 = icmp eq i64 %1297, %1417
  %1421 = sext i1 %1420 to i32
  %1422 = xor i32 %1421, -1
  %1423 = and i32 %1422, %1416
  %1424 = and i32 %1421, %1419
  %1425 = or i32 %1424, %1423
  %1426 = add i64 %1417, 16
  %1427 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1426
  %1428 = load i32, i32* %1427, align 4
  %1429 = icmp eq i64 %1297, %1426
  %1430 = sext i1 %1429 to i32
  %1431 = xor i32 %1430, -1
  %1432 = and i32 %1431, %1425
  %1433 = and i32 %1430, %1428
  %1434 = or i32 %1433, %1432
  %1435 = add i64 %1426, 16
  %1436 = getelementptr inbounds [256 x i32], [256 x i32]* %1299, i64 0, i64 %1435
  %1437 = load i32, i32* %1436, align 4
  %1438 = icmp eq i64 %1297, %1435
  %1439 = sext i1 %1438 to i32
  %1440 = xor i32 %1439, -1
  %1441 = and i32 %1440, %1434
  %1442 = and i32 %1439, %1437
  %Mitigated8 = or i32 %1442, %1441
  %1443 = lshr i32 %1291, 8
  %1444 = and i32 %1443, 255
  %1445 = zext i32 %1444 to i64
  %1446 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1447 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1446, i64 0, i64 1
  %1448 = srem i64 %1445, 16
  %1449 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1448
  %1450 = load i32, i32* %1449, align 4
  %1451 = icmp eq i64 %1445, %1448
  %1452 = sext i1 %1451 to i32
  %1453 = xor i32 %1452, -1
  %1454 = and i32 %1453, 0
  %1455 = and i32 %1452, %1450
  %1456 = or i32 %1455, %1454
  %1457 = add i64 %1448, 16
  %1458 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1457
  %1459 = load i32, i32* %1458, align 4
  %1460 = icmp eq i64 %1445, %1457
  %1461 = sext i1 %1460 to i32
  %1462 = xor i32 %1461, -1
  %1463 = and i32 %1462, %1456
  %1464 = and i32 %1461, %1459
  %1465 = or i32 %1464, %1463
  %1466 = add i64 %1457, 16
  %1467 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1466
  %1468 = load i32, i32* %1467, align 4
  %1469 = icmp eq i64 %1445, %1466
  %1470 = sext i1 %1469 to i32
  %1471 = xor i32 %1470, -1
  %1472 = and i32 %1471, %1465
  %1473 = and i32 %1470, %1468
  %1474 = or i32 %1473, %1472
  %1475 = add i64 %1466, 16
  %1476 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1475
  %1477 = load i32, i32* %1476, align 4
  %1478 = icmp eq i64 %1445, %1475
  %1479 = sext i1 %1478 to i32
  %1480 = xor i32 %1479, -1
  %1481 = and i32 %1480, %1474
  %1482 = and i32 %1479, %1477
  %1483 = or i32 %1482, %1481
  %1484 = add i64 %1475, 16
  %1485 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1484
  %1486 = load i32, i32* %1485, align 4
  %1487 = icmp eq i64 %1445, %1484
  %1488 = sext i1 %1487 to i32
  %1489 = xor i32 %1488, -1
  %1490 = and i32 %1489, %1483
  %1491 = and i32 %1488, %1486
  %1492 = or i32 %1491, %1490
  %1493 = add i64 %1484, 16
  %1494 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1493
  %1495 = load i32, i32* %1494, align 4
  %1496 = icmp eq i64 %1445, %1493
  %1497 = sext i1 %1496 to i32
  %1498 = xor i32 %1497, -1
  %1499 = and i32 %1498, %1492
  %1500 = and i32 %1497, %1495
  %1501 = or i32 %1500, %1499
  %1502 = add i64 %1493, 16
  %1503 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1502
  %1504 = load i32, i32* %1503, align 4
  %1505 = icmp eq i64 %1445, %1502
  %1506 = sext i1 %1505 to i32
  %1507 = xor i32 %1506, -1
  %1508 = and i32 %1507, %1501
  %1509 = and i32 %1506, %1504
  %1510 = or i32 %1509, %1508
  %1511 = add i64 %1502, 16
  %1512 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1511
  %1513 = load i32, i32* %1512, align 4
  %1514 = icmp eq i64 %1445, %1511
  %1515 = sext i1 %1514 to i32
  %1516 = xor i32 %1515, -1
  %1517 = and i32 %1516, %1510
  %1518 = and i32 %1515, %1513
  %1519 = or i32 %1518, %1517
  %1520 = add i64 %1511, 16
  %1521 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1520
  %1522 = load i32, i32* %1521, align 4
  %1523 = icmp eq i64 %1445, %1520
  %1524 = sext i1 %1523 to i32
  %1525 = xor i32 %1524, -1
  %1526 = and i32 %1525, %1519
  %1527 = and i32 %1524, %1522
  %1528 = or i32 %1527, %1526
  %1529 = add i64 %1520, 16
  %1530 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1529
  %1531 = load i32, i32* %1530, align 4
  %1532 = icmp eq i64 %1445, %1529
  %1533 = sext i1 %1532 to i32
  %1534 = xor i32 %1533, -1
  %1535 = and i32 %1534, %1528
  %1536 = and i32 %1533, %1531
  %1537 = or i32 %1536, %1535
  %1538 = add i64 %1529, 16
  %1539 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1538
  %1540 = load i32, i32* %1539, align 4
  %1541 = icmp eq i64 %1445, %1538
  %1542 = sext i1 %1541 to i32
  %1543 = xor i32 %1542, -1
  %1544 = and i32 %1543, %1537
  %1545 = and i32 %1542, %1540
  %1546 = or i32 %1545, %1544
  %1547 = add i64 %1538, 16
  %1548 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1547
  %1549 = load i32, i32* %1548, align 4
  %1550 = icmp eq i64 %1445, %1547
  %1551 = sext i1 %1550 to i32
  %1552 = xor i32 %1551, -1
  %1553 = and i32 %1552, %1546
  %1554 = and i32 %1551, %1549
  %1555 = or i32 %1554, %1553
  %1556 = add i64 %1547, 16
  %1557 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1556
  %1558 = load i32, i32* %1557, align 4
  %1559 = icmp eq i64 %1445, %1556
  %1560 = sext i1 %1559 to i32
  %1561 = xor i32 %1560, -1
  %1562 = and i32 %1561, %1555
  %1563 = and i32 %1560, %1558
  %1564 = or i32 %1563, %1562
  %1565 = add i64 %1556, 16
  %1566 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1565
  %1567 = load i32, i32* %1566, align 4
  %1568 = icmp eq i64 %1445, %1565
  %1569 = sext i1 %1568 to i32
  %1570 = xor i32 %1569, -1
  %1571 = and i32 %1570, %1564
  %1572 = and i32 %1569, %1567
  %1573 = or i32 %1572, %1571
  %1574 = add i64 %1565, 16
  %1575 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1574
  %1576 = load i32, i32* %1575, align 4
  %1577 = icmp eq i64 %1445, %1574
  %1578 = sext i1 %1577 to i32
  %1579 = xor i32 %1578, -1
  %1580 = and i32 %1579, %1573
  %1581 = and i32 %1578, %1576
  %1582 = or i32 %1581, %1580
  %1583 = add i64 %1574, 16
  %1584 = getelementptr inbounds [256 x i32], [256 x i32]* %1447, i64 0, i64 %1583
  %1585 = load i32, i32* %1584, align 4
  %1586 = icmp eq i64 %1445, %1583
  %1587 = sext i1 %1586 to i32
  %1588 = xor i32 %1587, -1
  %1589 = and i32 %1588, %1582
  %1590 = and i32 %1587, %1585
  %Mitigated9 = or i32 %1590, %1589
  %1591 = xor i32 %Mitigated8, %Mitigated9
  %1592 = lshr i32 %1291, 16
  %1593 = and i32 %1592, 255
  %1594 = zext i32 %1593 to i64
  %1595 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1596 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1595, i64 0, i64 2
  %1597 = srem i64 %1594, 16
  %1598 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1597
  %1599 = load i32, i32* %1598, align 4
  %1600 = icmp eq i64 %1594, %1597
  %1601 = sext i1 %1600 to i32
  %1602 = xor i32 %1601, -1
  %1603 = and i32 %1602, 0
  %1604 = and i32 %1601, %1599
  %1605 = or i32 %1604, %1603
  %1606 = add i64 %1597, 16
  %1607 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1606
  %1608 = load i32, i32* %1607, align 4
  %1609 = icmp eq i64 %1594, %1606
  %1610 = sext i1 %1609 to i32
  %1611 = xor i32 %1610, -1
  %1612 = and i32 %1611, %1605
  %1613 = and i32 %1610, %1608
  %1614 = or i32 %1613, %1612
  %1615 = add i64 %1606, 16
  %1616 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1615
  %1617 = load i32, i32* %1616, align 4
  %1618 = icmp eq i64 %1594, %1615
  %1619 = sext i1 %1618 to i32
  %1620 = xor i32 %1619, -1
  %1621 = and i32 %1620, %1614
  %1622 = and i32 %1619, %1617
  %1623 = or i32 %1622, %1621
  %1624 = add i64 %1615, 16
  %1625 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1624
  %1626 = load i32, i32* %1625, align 4
  %1627 = icmp eq i64 %1594, %1624
  %1628 = sext i1 %1627 to i32
  %1629 = xor i32 %1628, -1
  %1630 = and i32 %1629, %1623
  %1631 = and i32 %1628, %1626
  %1632 = or i32 %1631, %1630
  %1633 = add i64 %1624, 16
  %1634 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1633
  %1635 = load i32, i32* %1634, align 4
  %1636 = icmp eq i64 %1594, %1633
  %1637 = sext i1 %1636 to i32
  %1638 = xor i32 %1637, -1
  %1639 = and i32 %1638, %1632
  %1640 = and i32 %1637, %1635
  %1641 = or i32 %1640, %1639
  %1642 = add i64 %1633, 16
  %1643 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1642
  %1644 = load i32, i32* %1643, align 4
  %1645 = icmp eq i64 %1594, %1642
  %1646 = sext i1 %1645 to i32
  %1647 = xor i32 %1646, -1
  %1648 = and i32 %1647, %1641
  %1649 = and i32 %1646, %1644
  %1650 = or i32 %1649, %1648
  %1651 = add i64 %1642, 16
  %1652 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1651
  %1653 = load i32, i32* %1652, align 4
  %1654 = icmp eq i64 %1594, %1651
  %1655 = sext i1 %1654 to i32
  %1656 = xor i32 %1655, -1
  %1657 = and i32 %1656, %1650
  %1658 = and i32 %1655, %1653
  %1659 = or i32 %1658, %1657
  %1660 = add i64 %1651, 16
  %1661 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1660
  %1662 = load i32, i32* %1661, align 4
  %1663 = icmp eq i64 %1594, %1660
  %1664 = sext i1 %1663 to i32
  %1665 = xor i32 %1664, -1
  %1666 = and i32 %1665, %1659
  %1667 = and i32 %1664, %1662
  %1668 = or i32 %1667, %1666
  %1669 = add i64 %1660, 16
  %1670 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1669
  %1671 = load i32, i32* %1670, align 4
  %1672 = icmp eq i64 %1594, %1669
  %1673 = sext i1 %1672 to i32
  %1674 = xor i32 %1673, -1
  %1675 = and i32 %1674, %1668
  %1676 = and i32 %1673, %1671
  %1677 = or i32 %1676, %1675
  %1678 = add i64 %1669, 16
  %1679 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1678
  %1680 = load i32, i32* %1679, align 4
  %1681 = icmp eq i64 %1594, %1678
  %1682 = sext i1 %1681 to i32
  %1683 = xor i32 %1682, -1
  %1684 = and i32 %1683, %1677
  %1685 = and i32 %1682, %1680
  %1686 = or i32 %1685, %1684
  %1687 = add i64 %1678, 16
  %1688 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1687
  %1689 = load i32, i32* %1688, align 4
  %1690 = icmp eq i64 %1594, %1687
  %1691 = sext i1 %1690 to i32
  %1692 = xor i32 %1691, -1
  %1693 = and i32 %1692, %1686
  %1694 = and i32 %1691, %1689
  %1695 = or i32 %1694, %1693
  %1696 = add i64 %1687, 16
  %1697 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1696
  %1698 = load i32, i32* %1697, align 4
  %1699 = icmp eq i64 %1594, %1696
  %1700 = sext i1 %1699 to i32
  %1701 = xor i32 %1700, -1
  %1702 = and i32 %1701, %1695
  %1703 = and i32 %1700, %1698
  %1704 = or i32 %1703, %1702
  %1705 = add i64 %1696, 16
  %1706 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1705
  %1707 = load i32, i32* %1706, align 4
  %1708 = icmp eq i64 %1594, %1705
  %1709 = sext i1 %1708 to i32
  %1710 = xor i32 %1709, -1
  %1711 = and i32 %1710, %1704
  %1712 = and i32 %1709, %1707
  %1713 = or i32 %1712, %1711
  %1714 = add i64 %1705, 16
  %1715 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1714
  %1716 = load i32, i32* %1715, align 4
  %1717 = icmp eq i64 %1594, %1714
  %1718 = sext i1 %1717 to i32
  %1719 = xor i32 %1718, -1
  %1720 = and i32 %1719, %1713
  %1721 = and i32 %1718, %1716
  %1722 = or i32 %1721, %1720
  %1723 = add i64 %1714, 16
  %1724 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1723
  %1725 = load i32, i32* %1724, align 4
  %1726 = icmp eq i64 %1594, %1723
  %1727 = sext i1 %1726 to i32
  %1728 = xor i32 %1727, -1
  %1729 = and i32 %1728, %1722
  %1730 = and i32 %1727, %1725
  %1731 = or i32 %1730, %1729
  %1732 = add i64 %1723, 16
  %1733 = getelementptr inbounds [256 x i32], [256 x i32]* %1596, i64 0, i64 %1732
  %1734 = load i32, i32* %1733, align 4
  %1735 = icmp eq i64 %1594, %1732
  %1736 = sext i1 %1735 to i32
  %1737 = xor i32 %1736, -1
  %1738 = and i32 %1737, %1731
  %1739 = and i32 %1736, %1734
  %Mitigated10 = or i32 %1739, %1738
  %1740 = xor i32 %1591, %Mitigated10
  %1741 = lshr i32 %1291, 24
  %1742 = zext i32 %1741 to i64
  %1743 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1744 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1743, i64 0, i64 3
  %1745 = srem i64 %1742, 16
  %1746 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1745
  %1747 = load i32, i32* %1746, align 4
  %1748 = icmp eq i64 %1742, %1745
  %1749 = sext i1 %1748 to i32
  %1750 = xor i32 %1749, -1
  %1751 = and i32 %1750, 0
  %1752 = and i32 %1749, %1747
  %1753 = or i32 %1752, %1751
  %1754 = add i64 %1745, 16
  %1755 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1754
  %1756 = load i32, i32* %1755, align 4
  %1757 = icmp eq i64 %1742, %1754
  %1758 = sext i1 %1757 to i32
  %1759 = xor i32 %1758, -1
  %1760 = and i32 %1759, %1753
  %1761 = and i32 %1758, %1756
  %1762 = or i32 %1761, %1760
  %1763 = add i64 %1754, 16
  %1764 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1763
  %1765 = load i32, i32* %1764, align 4
  %1766 = icmp eq i64 %1742, %1763
  %1767 = sext i1 %1766 to i32
  %1768 = xor i32 %1767, -1
  %1769 = and i32 %1768, %1762
  %1770 = and i32 %1767, %1765
  %1771 = or i32 %1770, %1769
  %1772 = add i64 %1763, 16
  %1773 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1772
  %1774 = load i32, i32* %1773, align 4
  %1775 = icmp eq i64 %1742, %1772
  %1776 = sext i1 %1775 to i32
  %1777 = xor i32 %1776, -1
  %1778 = and i32 %1777, %1771
  %1779 = and i32 %1776, %1774
  %1780 = or i32 %1779, %1778
  %1781 = add i64 %1772, 16
  %1782 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1781
  %1783 = load i32, i32* %1782, align 4
  %1784 = icmp eq i64 %1742, %1781
  %1785 = sext i1 %1784 to i32
  %1786 = xor i32 %1785, -1
  %1787 = and i32 %1786, %1780
  %1788 = and i32 %1785, %1783
  %1789 = or i32 %1788, %1787
  %1790 = add i64 %1781, 16
  %1791 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1790
  %1792 = load i32, i32* %1791, align 4
  %1793 = icmp eq i64 %1742, %1790
  %1794 = sext i1 %1793 to i32
  %1795 = xor i32 %1794, -1
  %1796 = and i32 %1795, %1789
  %1797 = and i32 %1794, %1792
  %1798 = or i32 %1797, %1796
  %1799 = add i64 %1790, 16
  %1800 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1799
  %1801 = load i32, i32* %1800, align 4
  %1802 = icmp eq i64 %1742, %1799
  %1803 = sext i1 %1802 to i32
  %1804 = xor i32 %1803, -1
  %1805 = and i32 %1804, %1798
  %1806 = and i32 %1803, %1801
  %1807 = or i32 %1806, %1805
  %1808 = add i64 %1799, 16
  %1809 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1808
  %1810 = load i32, i32* %1809, align 4
  %1811 = icmp eq i64 %1742, %1808
  %1812 = sext i1 %1811 to i32
  %1813 = xor i32 %1812, -1
  %1814 = and i32 %1813, %1807
  %1815 = and i32 %1812, %1810
  %1816 = or i32 %1815, %1814
  %1817 = add i64 %1808, 16
  %1818 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1817
  %1819 = load i32, i32* %1818, align 4
  %1820 = icmp eq i64 %1742, %1817
  %1821 = sext i1 %1820 to i32
  %1822 = xor i32 %1821, -1
  %1823 = and i32 %1822, %1816
  %1824 = and i32 %1821, %1819
  %1825 = or i32 %1824, %1823
  %1826 = add i64 %1817, 16
  %1827 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1826
  %1828 = load i32, i32* %1827, align 4
  %1829 = icmp eq i64 %1742, %1826
  %1830 = sext i1 %1829 to i32
  %1831 = xor i32 %1830, -1
  %1832 = and i32 %1831, %1825
  %1833 = and i32 %1830, %1828
  %1834 = or i32 %1833, %1832
  %1835 = add i64 %1826, 16
  %1836 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1835
  %1837 = load i32, i32* %1836, align 4
  %1838 = icmp eq i64 %1742, %1835
  %1839 = sext i1 %1838 to i32
  %1840 = xor i32 %1839, -1
  %1841 = and i32 %1840, %1834
  %1842 = and i32 %1839, %1837
  %1843 = or i32 %1842, %1841
  %1844 = add i64 %1835, 16
  %1845 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1844
  %1846 = load i32, i32* %1845, align 4
  %1847 = icmp eq i64 %1742, %1844
  %1848 = sext i1 %1847 to i32
  %1849 = xor i32 %1848, -1
  %1850 = and i32 %1849, %1843
  %1851 = and i32 %1848, %1846
  %1852 = or i32 %1851, %1850
  %1853 = add i64 %1844, 16
  %1854 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1853
  %1855 = load i32, i32* %1854, align 4
  %1856 = icmp eq i64 %1742, %1853
  %1857 = sext i1 %1856 to i32
  %1858 = xor i32 %1857, -1
  %1859 = and i32 %1858, %1852
  %1860 = and i32 %1857, %1855
  %1861 = or i32 %1860, %1859
  %1862 = add i64 %1853, 16
  %1863 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1862
  %1864 = load i32, i32* %1863, align 4
  %1865 = icmp eq i64 %1742, %1862
  %1866 = sext i1 %1865 to i32
  %1867 = xor i32 %1866, -1
  %1868 = and i32 %1867, %1861
  %1869 = and i32 %1866, %1864
  %1870 = or i32 %1869, %1868
  %1871 = add i64 %1862, 16
  %1872 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1871
  %1873 = load i32, i32* %1872, align 4
  %1874 = icmp eq i64 %1742, %1871
  %1875 = sext i1 %1874 to i32
  %1876 = xor i32 %1875, -1
  %1877 = and i32 %1876, %1870
  %1878 = and i32 %1875, %1873
  %1879 = or i32 %1878, %1877
  %1880 = add i64 %1871, 16
  %1881 = getelementptr inbounds [256 x i32], [256 x i32]* %1744, i64 0, i64 %1880
  %1882 = load i32, i32* %1881, align 4
  %1883 = icmp eq i64 %1742, %1880
  %1884 = sext i1 %1883 to i32
  %1885 = xor i32 %1884, -1
  %1886 = and i32 %1885, %1879
  %1887 = and i32 %1884, %1882
  %Mitigated11 = or i32 %1887, %1886
  %1888 = xor i32 %1740, %Mitigated11
  %1889 = and i32 %1295, 255
  %1890 = zext i32 %1889 to i64
  %1891 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %1892 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %1891, i64 0, i64 1
  %1893 = srem i64 %1890, 16
  %1894 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1893
  %1895 = load i32, i32* %1894, align 4
  %1896 = icmp eq i64 %1890, %1893
  %1897 = sext i1 %1896 to i32
  %1898 = xor i32 %1897, -1
  %1899 = and i32 %1898, 0
  %1900 = and i32 %1897, %1895
  %1901 = or i32 %1900, %1899
  %1902 = add i64 %1893, 16
  %1903 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1902
  %1904 = load i32, i32* %1903, align 4
  %1905 = icmp eq i64 %1890, %1902
  %1906 = sext i1 %1905 to i32
  %1907 = xor i32 %1906, -1
  %1908 = and i32 %1907, %1901
  %1909 = and i32 %1906, %1904
  %1910 = or i32 %1909, %1908
  %1911 = add i64 %1902, 16
  %1912 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1911
  %1913 = load i32, i32* %1912, align 4
  %1914 = icmp eq i64 %1890, %1911
  %1915 = sext i1 %1914 to i32
  %1916 = xor i32 %1915, -1
  %1917 = and i32 %1916, %1910
  %1918 = and i32 %1915, %1913
  %1919 = or i32 %1918, %1917
  %1920 = add i64 %1911, 16
  %1921 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1920
  %1922 = load i32, i32* %1921, align 4
  %1923 = icmp eq i64 %1890, %1920
  %1924 = sext i1 %1923 to i32
  %1925 = xor i32 %1924, -1
  %1926 = and i32 %1925, %1919
  %1927 = and i32 %1924, %1922
  %1928 = or i32 %1927, %1926
  %1929 = add i64 %1920, 16
  %1930 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1929
  %1931 = load i32, i32* %1930, align 4
  %1932 = icmp eq i64 %1890, %1929
  %1933 = sext i1 %1932 to i32
  %1934 = xor i32 %1933, -1
  %1935 = and i32 %1934, %1928
  %1936 = and i32 %1933, %1931
  %1937 = or i32 %1936, %1935
  %1938 = add i64 %1929, 16
  %1939 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1938
  %1940 = load i32, i32* %1939, align 4
  %1941 = icmp eq i64 %1890, %1938
  %1942 = sext i1 %1941 to i32
  %1943 = xor i32 %1942, -1
  %1944 = and i32 %1943, %1937
  %1945 = and i32 %1942, %1940
  %1946 = or i32 %1945, %1944
  %1947 = add i64 %1938, 16
  %1948 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1947
  %1949 = load i32, i32* %1948, align 4
  %1950 = icmp eq i64 %1890, %1947
  %1951 = sext i1 %1950 to i32
  %1952 = xor i32 %1951, -1
  %1953 = and i32 %1952, %1946
  %1954 = and i32 %1951, %1949
  %1955 = or i32 %1954, %1953
  %1956 = add i64 %1947, 16
  %1957 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1956
  %1958 = load i32, i32* %1957, align 4
  %1959 = icmp eq i64 %1890, %1956
  %1960 = sext i1 %1959 to i32
  %1961 = xor i32 %1960, -1
  %1962 = and i32 %1961, %1955
  %1963 = and i32 %1960, %1958
  %1964 = or i32 %1963, %1962
  %1965 = add i64 %1956, 16
  %1966 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1965
  %1967 = load i32, i32* %1966, align 4
  %1968 = icmp eq i64 %1890, %1965
  %1969 = sext i1 %1968 to i32
  %1970 = xor i32 %1969, -1
  %1971 = and i32 %1970, %1964
  %1972 = and i32 %1969, %1967
  %1973 = or i32 %1972, %1971
  %1974 = add i64 %1965, 16
  %1975 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1974
  %1976 = load i32, i32* %1975, align 4
  %1977 = icmp eq i64 %1890, %1974
  %1978 = sext i1 %1977 to i32
  %1979 = xor i32 %1978, -1
  %1980 = and i32 %1979, %1973
  %1981 = and i32 %1978, %1976
  %1982 = or i32 %1981, %1980
  %1983 = add i64 %1974, 16
  %1984 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1983
  %1985 = load i32, i32* %1984, align 4
  %1986 = icmp eq i64 %1890, %1983
  %1987 = sext i1 %1986 to i32
  %1988 = xor i32 %1987, -1
  %1989 = and i32 %1988, %1982
  %1990 = and i32 %1987, %1985
  %1991 = or i32 %1990, %1989
  %1992 = add i64 %1983, 16
  %1993 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %1992
  %1994 = load i32, i32* %1993, align 4
  %1995 = icmp eq i64 %1890, %1992
  %1996 = sext i1 %1995 to i32
  %1997 = xor i32 %1996, -1
  %1998 = and i32 %1997, %1991
  %1999 = and i32 %1996, %1994
  %2000 = or i32 %1999, %1998
  %2001 = add i64 %1992, 16
  %2002 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %2001
  %2003 = load i32, i32* %2002, align 4
  %2004 = icmp eq i64 %1890, %2001
  %2005 = sext i1 %2004 to i32
  %2006 = xor i32 %2005, -1
  %2007 = and i32 %2006, %2000
  %2008 = and i32 %2005, %2003
  %2009 = or i32 %2008, %2007
  %2010 = add i64 %2001, 16
  %2011 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %2010
  %2012 = load i32, i32* %2011, align 4
  %2013 = icmp eq i64 %1890, %2010
  %2014 = sext i1 %2013 to i32
  %2015 = xor i32 %2014, -1
  %2016 = and i32 %2015, %2009
  %2017 = and i32 %2014, %2012
  %2018 = or i32 %2017, %2016
  %2019 = add i64 %2010, 16
  %2020 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %2019
  %2021 = load i32, i32* %2020, align 4
  %2022 = icmp eq i64 %1890, %2019
  %2023 = sext i1 %2022 to i32
  %2024 = xor i32 %2023, -1
  %2025 = and i32 %2024, %2018
  %2026 = and i32 %2023, %2021
  %2027 = or i32 %2026, %2025
  %2028 = add i64 %2019, 16
  %2029 = getelementptr inbounds [256 x i32], [256 x i32]* %1892, i64 0, i64 %2028
  %2030 = load i32, i32* %2029, align 4
  %2031 = icmp eq i64 %1890, %2028
  %2032 = sext i1 %2031 to i32
  %2033 = xor i32 %2032, -1
  %2034 = and i32 %2033, %2027
  %2035 = and i32 %2032, %2030
  %Mitigated12 = or i32 %2035, %2034
  %2036 = lshr i32 %1295, 8
  %2037 = and i32 %2036, 255
  %2038 = zext i32 %2037 to i64
  %2039 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2040 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2039, i64 0, i64 2
  %2041 = srem i64 %2038, 16
  %2042 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2041
  %2043 = load i32, i32* %2042, align 4
  %2044 = icmp eq i64 %2038, %2041
  %2045 = sext i1 %2044 to i32
  %2046 = xor i32 %2045, -1
  %2047 = and i32 %2046, 0
  %2048 = and i32 %2045, %2043
  %2049 = or i32 %2048, %2047
  %2050 = add i64 %2041, 16
  %2051 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2050
  %2052 = load i32, i32* %2051, align 4
  %2053 = icmp eq i64 %2038, %2050
  %2054 = sext i1 %2053 to i32
  %2055 = xor i32 %2054, -1
  %2056 = and i32 %2055, %2049
  %2057 = and i32 %2054, %2052
  %2058 = or i32 %2057, %2056
  %2059 = add i64 %2050, 16
  %2060 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2059
  %2061 = load i32, i32* %2060, align 4
  %2062 = icmp eq i64 %2038, %2059
  %2063 = sext i1 %2062 to i32
  %2064 = xor i32 %2063, -1
  %2065 = and i32 %2064, %2058
  %2066 = and i32 %2063, %2061
  %2067 = or i32 %2066, %2065
  %2068 = add i64 %2059, 16
  %2069 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2068
  %2070 = load i32, i32* %2069, align 4
  %2071 = icmp eq i64 %2038, %2068
  %2072 = sext i1 %2071 to i32
  %2073 = xor i32 %2072, -1
  %2074 = and i32 %2073, %2067
  %2075 = and i32 %2072, %2070
  %2076 = or i32 %2075, %2074
  %2077 = add i64 %2068, 16
  %2078 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2077
  %2079 = load i32, i32* %2078, align 4
  %2080 = icmp eq i64 %2038, %2077
  %2081 = sext i1 %2080 to i32
  %2082 = xor i32 %2081, -1
  %2083 = and i32 %2082, %2076
  %2084 = and i32 %2081, %2079
  %2085 = or i32 %2084, %2083
  %2086 = add i64 %2077, 16
  %2087 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2086
  %2088 = load i32, i32* %2087, align 4
  %2089 = icmp eq i64 %2038, %2086
  %2090 = sext i1 %2089 to i32
  %2091 = xor i32 %2090, -1
  %2092 = and i32 %2091, %2085
  %2093 = and i32 %2090, %2088
  %2094 = or i32 %2093, %2092
  %2095 = add i64 %2086, 16
  %2096 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2095
  %2097 = load i32, i32* %2096, align 4
  %2098 = icmp eq i64 %2038, %2095
  %2099 = sext i1 %2098 to i32
  %2100 = xor i32 %2099, -1
  %2101 = and i32 %2100, %2094
  %2102 = and i32 %2099, %2097
  %2103 = or i32 %2102, %2101
  %2104 = add i64 %2095, 16
  %2105 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2104
  %2106 = load i32, i32* %2105, align 4
  %2107 = icmp eq i64 %2038, %2104
  %2108 = sext i1 %2107 to i32
  %2109 = xor i32 %2108, -1
  %2110 = and i32 %2109, %2103
  %2111 = and i32 %2108, %2106
  %2112 = or i32 %2111, %2110
  %2113 = add i64 %2104, 16
  %2114 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2113
  %2115 = load i32, i32* %2114, align 4
  %2116 = icmp eq i64 %2038, %2113
  %2117 = sext i1 %2116 to i32
  %2118 = xor i32 %2117, -1
  %2119 = and i32 %2118, %2112
  %2120 = and i32 %2117, %2115
  %2121 = or i32 %2120, %2119
  %2122 = add i64 %2113, 16
  %2123 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2122
  %2124 = load i32, i32* %2123, align 4
  %2125 = icmp eq i64 %2038, %2122
  %2126 = sext i1 %2125 to i32
  %2127 = xor i32 %2126, -1
  %2128 = and i32 %2127, %2121
  %2129 = and i32 %2126, %2124
  %2130 = or i32 %2129, %2128
  %2131 = add i64 %2122, 16
  %2132 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2131
  %2133 = load i32, i32* %2132, align 4
  %2134 = icmp eq i64 %2038, %2131
  %2135 = sext i1 %2134 to i32
  %2136 = xor i32 %2135, -1
  %2137 = and i32 %2136, %2130
  %2138 = and i32 %2135, %2133
  %2139 = or i32 %2138, %2137
  %2140 = add i64 %2131, 16
  %2141 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2140
  %2142 = load i32, i32* %2141, align 4
  %2143 = icmp eq i64 %2038, %2140
  %2144 = sext i1 %2143 to i32
  %2145 = xor i32 %2144, -1
  %2146 = and i32 %2145, %2139
  %2147 = and i32 %2144, %2142
  %2148 = or i32 %2147, %2146
  %2149 = add i64 %2140, 16
  %2150 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2149
  %2151 = load i32, i32* %2150, align 4
  %2152 = icmp eq i64 %2038, %2149
  %2153 = sext i1 %2152 to i32
  %2154 = xor i32 %2153, -1
  %2155 = and i32 %2154, %2148
  %2156 = and i32 %2153, %2151
  %2157 = or i32 %2156, %2155
  %2158 = add i64 %2149, 16
  %2159 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2158
  %2160 = load i32, i32* %2159, align 4
  %2161 = icmp eq i64 %2038, %2158
  %2162 = sext i1 %2161 to i32
  %2163 = xor i32 %2162, -1
  %2164 = and i32 %2163, %2157
  %2165 = and i32 %2162, %2160
  %2166 = or i32 %2165, %2164
  %2167 = add i64 %2158, 16
  %2168 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2167
  %2169 = load i32, i32* %2168, align 4
  %2170 = icmp eq i64 %2038, %2167
  %2171 = sext i1 %2170 to i32
  %2172 = xor i32 %2171, -1
  %2173 = and i32 %2172, %2166
  %2174 = and i32 %2171, %2169
  %2175 = or i32 %2174, %2173
  %2176 = add i64 %2167, 16
  %2177 = getelementptr inbounds [256 x i32], [256 x i32]* %2040, i64 0, i64 %2176
  %2178 = load i32, i32* %2177, align 4
  %2179 = icmp eq i64 %2038, %2176
  %2180 = sext i1 %2179 to i32
  %2181 = xor i32 %2180, -1
  %2182 = and i32 %2181, %2175
  %2183 = and i32 %2180, %2178
  %Mitigated13 = or i32 %2183, %2182
  %2184 = xor i32 %Mitigated12, %Mitigated13
  %2185 = lshr i32 %1295, 16
  %2186 = and i32 %2185, 255
  %2187 = zext i32 %2186 to i64
  %2188 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2189 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2188, i64 0, i64 3
  %2190 = srem i64 %2187, 16
  %2191 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2190
  %2192 = load i32, i32* %2191, align 4
  %2193 = icmp eq i64 %2187, %2190
  %2194 = sext i1 %2193 to i32
  %2195 = xor i32 %2194, -1
  %2196 = and i32 %2195, 0
  %2197 = and i32 %2194, %2192
  %2198 = or i32 %2197, %2196
  %2199 = add i64 %2190, 16
  %2200 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2199
  %2201 = load i32, i32* %2200, align 4
  %2202 = icmp eq i64 %2187, %2199
  %2203 = sext i1 %2202 to i32
  %2204 = xor i32 %2203, -1
  %2205 = and i32 %2204, %2198
  %2206 = and i32 %2203, %2201
  %2207 = or i32 %2206, %2205
  %2208 = add i64 %2199, 16
  %2209 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2208
  %2210 = load i32, i32* %2209, align 4
  %2211 = icmp eq i64 %2187, %2208
  %2212 = sext i1 %2211 to i32
  %2213 = xor i32 %2212, -1
  %2214 = and i32 %2213, %2207
  %2215 = and i32 %2212, %2210
  %2216 = or i32 %2215, %2214
  %2217 = add i64 %2208, 16
  %2218 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2217
  %2219 = load i32, i32* %2218, align 4
  %2220 = icmp eq i64 %2187, %2217
  %2221 = sext i1 %2220 to i32
  %2222 = xor i32 %2221, -1
  %2223 = and i32 %2222, %2216
  %2224 = and i32 %2221, %2219
  %2225 = or i32 %2224, %2223
  %2226 = add i64 %2217, 16
  %2227 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2226
  %2228 = load i32, i32* %2227, align 4
  %2229 = icmp eq i64 %2187, %2226
  %2230 = sext i1 %2229 to i32
  %2231 = xor i32 %2230, -1
  %2232 = and i32 %2231, %2225
  %2233 = and i32 %2230, %2228
  %2234 = or i32 %2233, %2232
  %2235 = add i64 %2226, 16
  %2236 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2235
  %2237 = load i32, i32* %2236, align 4
  %2238 = icmp eq i64 %2187, %2235
  %2239 = sext i1 %2238 to i32
  %2240 = xor i32 %2239, -1
  %2241 = and i32 %2240, %2234
  %2242 = and i32 %2239, %2237
  %2243 = or i32 %2242, %2241
  %2244 = add i64 %2235, 16
  %2245 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2244
  %2246 = load i32, i32* %2245, align 4
  %2247 = icmp eq i64 %2187, %2244
  %2248 = sext i1 %2247 to i32
  %2249 = xor i32 %2248, -1
  %2250 = and i32 %2249, %2243
  %2251 = and i32 %2248, %2246
  %2252 = or i32 %2251, %2250
  %2253 = add i64 %2244, 16
  %2254 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2253
  %2255 = load i32, i32* %2254, align 4
  %2256 = icmp eq i64 %2187, %2253
  %2257 = sext i1 %2256 to i32
  %2258 = xor i32 %2257, -1
  %2259 = and i32 %2258, %2252
  %2260 = and i32 %2257, %2255
  %2261 = or i32 %2260, %2259
  %2262 = add i64 %2253, 16
  %2263 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2262
  %2264 = load i32, i32* %2263, align 4
  %2265 = icmp eq i64 %2187, %2262
  %2266 = sext i1 %2265 to i32
  %2267 = xor i32 %2266, -1
  %2268 = and i32 %2267, %2261
  %2269 = and i32 %2266, %2264
  %2270 = or i32 %2269, %2268
  %2271 = add i64 %2262, 16
  %2272 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2271
  %2273 = load i32, i32* %2272, align 4
  %2274 = icmp eq i64 %2187, %2271
  %2275 = sext i1 %2274 to i32
  %2276 = xor i32 %2275, -1
  %2277 = and i32 %2276, %2270
  %2278 = and i32 %2275, %2273
  %2279 = or i32 %2278, %2277
  %2280 = add i64 %2271, 16
  %2281 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2280
  %2282 = load i32, i32* %2281, align 4
  %2283 = icmp eq i64 %2187, %2280
  %2284 = sext i1 %2283 to i32
  %2285 = xor i32 %2284, -1
  %2286 = and i32 %2285, %2279
  %2287 = and i32 %2284, %2282
  %2288 = or i32 %2287, %2286
  %2289 = add i64 %2280, 16
  %2290 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2289
  %2291 = load i32, i32* %2290, align 4
  %2292 = icmp eq i64 %2187, %2289
  %2293 = sext i1 %2292 to i32
  %2294 = xor i32 %2293, -1
  %2295 = and i32 %2294, %2288
  %2296 = and i32 %2293, %2291
  %2297 = or i32 %2296, %2295
  %2298 = add i64 %2289, 16
  %2299 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2298
  %2300 = load i32, i32* %2299, align 4
  %2301 = icmp eq i64 %2187, %2298
  %2302 = sext i1 %2301 to i32
  %2303 = xor i32 %2302, -1
  %2304 = and i32 %2303, %2297
  %2305 = and i32 %2302, %2300
  %2306 = or i32 %2305, %2304
  %2307 = add i64 %2298, 16
  %2308 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2307
  %2309 = load i32, i32* %2308, align 4
  %2310 = icmp eq i64 %2187, %2307
  %2311 = sext i1 %2310 to i32
  %2312 = xor i32 %2311, -1
  %2313 = and i32 %2312, %2306
  %2314 = and i32 %2311, %2309
  %2315 = or i32 %2314, %2313
  %2316 = add i64 %2307, 16
  %2317 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2316
  %2318 = load i32, i32* %2317, align 4
  %2319 = icmp eq i64 %2187, %2316
  %2320 = sext i1 %2319 to i32
  %2321 = xor i32 %2320, -1
  %2322 = and i32 %2321, %2315
  %2323 = and i32 %2320, %2318
  %2324 = or i32 %2323, %2322
  %2325 = add i64 %2316, 16
  %2326 = getelementptr inbounds [256 x i32], [256 x i32]* %2189, i64 0, i64 %2325
  %2327 = load i32, i32* %2326, align 4
  %2328 = icmp eq i64 %2187, %2325
  %2329 = sext i1 %2328 to i32
  %2330 = xor i32 %2329, -1
  %2331 = and i32 %2330, %2324
  %2332 = and i32 %2329, %2327
  %Mitigated14 = or i32 %2332, %2331
  %2333 = xor i32 %2184, %Mitigated14
  %2334 = lshr i32 %1295, 24
  %2335 = zext i32 %2334 to i64
  %2336 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2337 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2336, i64 0, i64 0
  %2338 = srem i64 %2335, 16
  %2339 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2338
  %2340 = load i32, i32* %2339, align 4
  %2341 = icmp eq i64 %2335, %2338
  %2342 = sext i1 %2341 to i32
  %2343 = xor i32 %2342, -1
  %2344 = and i32 %2343, 0
  %2345 = and i32 %2342, %2340
  %2346 = or i32 %2345, %2344
  %2347 = add i64 %2338, 16
  %2348 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2347
  %2349 = load i32, i32* %2348, align 4
  %2350 = icmp eq i64 %2335, %2347
  %2351 = sext i1 %2350 to i32
  %2352 = xor i32 %2351, -1
  %2353 = and i32 %2352, %2346
  %2354 = and i32 %2351, %2349
  %2355 = or i32 %2354, %2353
  %2356 = add i64 %2347, 16
  %2357 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2356
  %2358 = load i32, i32* %2357, align 4
  %2359 = icmp eq i64 %2335, %2356
  %2360 = sext i1 %2359 to i32
  %2361 = xor i32 %2360, -1
  %2362 = and i32 %2361, %2355
  %2363 = and i32 %2360, %2358
  %2364 = or i32 %2363, %2362
  %2365 = add i64 %2356, 16
  %2366 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2365
  %2367 = load i32, i32* %2366, align 4
  %2368 = icmp eq i64 %2335, %2365
  %2369 = sext i1 %2368 to i32
  %2370 = xor i32 %2369, -1
  %2371 = and i32 %2370, %2364
  %2372 = and i32 %2369, %2367
  %2373 = or i32 %2372, %2371
  %2374 = add i64 %2365, 16
  %2375 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2374
  %2376 = load i32, i32* %2375, align 4
  %2377 = icmp eq i64 %2335, %2374
  %2378 = sext i1 %2377 to i32
  %2379 = xor i32 %2378, -1
  %2380 = and i32 %2379, %2373
  %2381 = and i32 %2378, %2376
  %2382 = or i32 %2381, %2380
  %2383 = add i64 %2374, 16
  %2384 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2383
  %2385 = load i32, i32* %2384, align 4
  %2386 = icmp eq i64 %2335, %2383
  %2387 = sext i1 %2386 to i32
  %2388 = xor i32 %2387, -1
  %2389 = and i32 %2388, %2382
  %2390 = and i32 %2387, %2385
  %2391 = or i32 %2390, %2389
  %2392 = add i64 %2383, 16
  %2393 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2392
  %2394 = load i32, i32* %2393, align 4
  %2395 = icmp eq i64 %2335, %2392
  %2396 = sext i1 %2395 to i32
  %2397 = xor i32 %2396, -1
  %2398 = and i32 %2397, %2391
  %2399 = and i32 %2396, %2394
  %2400 = or i32 %2399, %2398
  %2401 = add i64 %2392, 16
  %2402 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2401
  %2403 = load i32, i32* %2402, align 4
  %2404 = icmp eq i64 %2335, %2401
  %2405 = sext i1 %2404 to i32
  %2406 = xor i32 %2405, -1
  %2407 = and i32 %2406, %2400
  %2408 = and i32 %2405, %2403
  %2409 = or i32 %2408, %2407
  %2410 = add i64 %2401, 16
  %2411 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2410
  %2412 = load i32, i32* %2411, align 4
  %2413 = icmp eq i64 %2335, %2410
  %2414 = sext i1 %2413 to i32
  %2415 = xor i32 %2414, -1
  %2416 = and i32 %2415, %2409
  %2417 = and i32 %2414, %2412
  %2418 = or i32 %2417, %2416
  %2419 = add i64 %2410, 16
  %2420 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2419
  %2421 = load i32, i32* %2420, align 4
  %2422 = icmp eq i64 %2335, %2419
  %2423 = sext i1 %2422 to i32
  %2424 = xor i32 %2423, -1
  %2425 = and i32 %2424, %2418
  %2426 = and i32 %2423, %2421
  %2427 = or i32 %2426, %2425
  %2428 = add i64 %2419, 16
  %2429 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2428
  %2430 = load i32, i32* %2429, align 4
  %2431 = icmp eq i64 %2335, %2428
  %2432 = sext i1 %2431 to i32
  %2433 = xor i32 %2432, -1
  %2434 = and i32 %2433, %2427
  %2435 = and i32 %2432, %2430
  %2436 = or i32 %2435, %2434
  %2437 = add i64 %2428, 16
  %2438 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2437
  %2439 = load i32, i32* %2438, align 4
  %2440 = icmp eq i64 %2335, %2437
  %2441 = sext i1 %2440 to i32
  %2442 = xor i32 %2441, -1
  %2443 = and i32 %2442, %2436
  %2444 = and i32 %2441, %2439
  %2445 = or i32 %2444, %2443
  %2446 = add i64 %2437, 16
  %2447 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2446
  %2448 = load i32, i32* %2447, align 4
  %2449 = icmp eq i64 %2335, %2446
  %2450 = sext i1 %2449 to i32
  %2451 = xor i32 %2450, -1
  %2452 = and i32 %2451, %2445
  %2453 = and i32 %2450, %2448
  %2454 = or i32 %2453, %2452
  %2455 = add i64 %2446, 16
  %2456 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2455
  %2457 = load i32, i32* %2456, align 4
  %2458 = icmp eq i64 %2335, %2455
  %2459 = sext i1 %2458 to i32
  %2460 = xor i32 %2459, -1
  %2461 = and i32 %2460, %2454
  %2462 = and i32 %2459, %2457
  %2463 = or i32 %2462, %2461
  %2464 = add i64 %2455, 16
  %2465 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2464
  %2466 = load i32, i32* %2465, align 4
  %2467 = icmp eq i64 %2335, %2464
  %2468 = sext i1 %2467 to i32
  %2469 = xor i32 %2468, -1
  %2470 = and i32 %2469, %2463
  %2471 = and i32 %2468, %2466
  %2472 = or i32 %2471, %2470
  %2473 = add i64 %2464, 16
  %2474 = getelementptr inbounds [256 x i32], [256 x i32]* %2337, i64 0, i64 %2473
  %2475 = load i32, i32* %2474, align 4
  %2476 = icmp eq i64 %2335, %2473
  %2477 = sext i1 %2476 to i32
  %2478 = xor i32 %2477, -1
  %2479 = and i32 %2478, %2472
  %2480 = and i32 %2477, %2475
  %Mitigated15 = or i32 %2480, %2479
  %2481 = xor i32 %2333, %Mitigated15
  %2482 = add i32 %1888, %2481
  %2483 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %2484 = getelementptr inbounds [32 x i32], [32 x i32]* %2483, i64 0, i64 3
  %2485 = load i32, i32* %2484, align 4
  %2486 = add i32 %2482, %2485
  %2487 = add i32 %2481, %2486
  %2488 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %2489 = getelementptr inbounds [32 x i32], [32 x i32]* %2488, i64 0, i64 2
  %2490 = load i32, i32* %2489, align 4
  %2491 = add i32 %2482, %2490
  %2492 = xor i32 %25, %2491
  %2493 = lshr i32 %2492, 1
  %2494 = shl i32 %2492, 31
  %2495 = add i32 %2493, %2494
  %2496 = shl i32 %47, 1
  %2497 = lshr i32 %47, 31
  %2498 = add i32 %2496, %2497
  %2499 = xor i32 %2498, %2487
  %2500 = and i32 %2495, 255
  %2501 = zext i32 %2500 to i64
  %2502 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2503 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2502, i64 0, i64 0
  %2504 = srem i64 %2501, 16
  %2505 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2504
  %2506 = load i32, i32* %2505, align 4
  %2507 = icmp eq i64 %2501, %2504
  %2508 = sext i1 %2507 to i32
  %2509 = xor i32 %2508, -1
  %2510 = and i32 %2509, 0
  %2511 = and i32 %2508, %2506
  %2512 = or i32 %2511, %2510
  %2513 = add i64 %2504, 16
  %2514 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2513
  %2515 = load i32, i32* %2514, align 4
  %2516 = icmp eq i64 %2501, %2513
  %2517 = sext i1 %2516 to i32
  %2518 = xor i32 %2517, -1
  %2519 = and i32 %2518, %2512
  %2520 = and i32 %2517, %2515
  %2521 = or i32 %2520, %2519
  %2522 = add i64 %2513, 16
  %2523 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2522
  %2524 = load i32, i32* %2523, align 4
  %2525 = icmp eq i64 %2501, %2522
  %2526 = sext i1 %2525 to i32
  %2527 = xor i32 %2526, -1
  %2528 = and i32 %2527, %2521
  %2529 = and i32 %2526, %2524
  %2530 = or i32 %2529, %2528
  %2531 = add i64 %2522, 16
  %2532 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2531
  %2533 = load i32, i32* %2532, align 4
  %2534 = icmp eq i64 %2501, %2531
  %2535 = sext i1 %2534 to i32
  %2536 = xor i32 %2535, -1
  %2537 = and i32 %2536, %2530
  %2538 = and i32 %2535, %2533
  %2539 = or i32 %2538, %2537
  %2540 = add i64 %2531, 16
  %2541 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2540
  %2542 = load i32, i32* %2541, align 4
  %2543 = icmp eq i64 %2501, %2540
  %2544 = sext i1 %2543 to i32
  %2545 = xor i32 %2544, -1
  %2546 = and i32 %2545, %2539
  %2547 = and i32 %2544, %2542
  %2548 = or i32 %2547, %2546
  %2549 = add i64 %2540, 16
  %2550 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2549
  %2551 = load i32, i32* %2550, align 4
  %2552 = icmp eq i64 %2501, %2549
  %2553 = sext i1 %2552 to i32
  %2554 = xor i32 %2553, -1
  %2555 = and i32 %2554, %2548
  %2556 = and i32 %2553, %2551
  %2557 = or i32 %2556, %2555
  %2558 = add i64 %2549, 16
  %2559 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2558
  %2560 = load i32, i32* %2559, align 4
  %2561 = icmp eq i64 %2501, %2558
  %2562 = sext i1 %2561 to i32
  %2563 = xor i32 %2562, -1
  %2564 = and i32 %2563, %2557
  %2565 = and i32 %2562, %2560
  %2566 = or i32 %2565, %2564
  %2567 = add i64 %2558, 16
  %2568 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2567
  %2569 = load i32, i32* %2568, align 4
  %2570 = icmp eq i64 %2501, %2567
  %2571 = sext i1 %2570 to i32
  %2572 = xor i32 %2571, -1
  %2573 = and i32 %2572, %2566
  %2574 = and i32 %2571, %2569
  %2575 = or i32 %2574, %2573
  %2576 = add i64 %2567, 16
  %2577 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2576
  %2578 = load i32, i32* %2577, align 4
  %2579 = icmp eq i64 %2501, %2576
  %2580 = sext i1 %2579 to i32
  %2581 = xor i32 %2580, -1
  %2582 = and i32 %2581, %2575
  %2583 = and i32 %2580, %2578
  %2584 = or i32 %2583, %2582
  %2585 = add i64 %2576, 16
  %2586 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2585
  %2587 = load i32, i32* %2586, align 4
  %2588 = icmp eq i64 %2501, %2585
  %2589 = sext i1 %2588 to i32
  %2590 = xor i32 %2589, -1
  %2591 = and i32 %2590, %2584
  %2592 = and i32 %2589, %2587
  %2593 = or i32 %2592, %2591
  %2594 = add i64 %2585, 16
  %2595 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2594
  %2596 = load i32, i32* %2595, align 4
  %2597 = icmp eq i64 %2501, %2594
  %2598 = sext i1 %2597 to i32
  %2599 = xor i32 %2598, -1
  %2600 = and i32 %2599, %2593
  %2601 = and i32 %2598, %2596
  %2602 = or i32 %2601, %2600
  %2603 = add i64 %2594, 16
  %2604 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2603
  %2605 = load i32, i32* %2604, align 4
  %2606 = icmp eq i64 %2501, %2603
  %2607 = sext i1 %2606 to i32
  %2608 = xor i32 %2607, -1
  %2609 = and i32 %2608, %2602
  %2610 = and i32 %2607, %2605
  %2611 = or i32 %2610, %2609
  %2612 = add i64 %2603, 16
  %2613 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2612
  %2614 = load i32, i32* %2613, align 4
  %2615 = icmp eq i64 %2501, %2612
  %2616 = sext i1 %2615 to i32
  %2617 = xor i32 %2616, -1
  %2618 = and i32 %2617, %2611
  %2619 = and i32 %2616, %2614
  %2620 = or i32 %2619, %2618
  %2621 = add i64 %2612, 16
  %2622 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2621
  %2623 = load i32, i32* %2622, align 4
  %2624 = icmp eq i64 %2501, %2621
  %2625 = sext i1 %2624 to i32
  %2626 = xor i32 %2625, -1
  %2627 = and i32 %2626, %2620
  %2628 = and i32 %2625, %2623
  %2629 = or i32 %2628, %2627
  %2630 = add i64 %2621, 16
  %2631 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2630
  %2632 = load i32, i32* %2631, align 4
  %2633 = icmp eq i64 %2501, %2630
  %2634 = sext i1 %2633 to i32
  %2635 = xor i32 %2634, -1
  %2636 = and i32 %2635, %2629
  %2637 = and i32 %2634, %2632
  %2638 = or i32 %2637, %2636
  %2639 = add i64 %2630, 16
  %2640 = getelementptr inbounds [256 x i32], [256 x i32]* %2503, i64 0, i64 %2639
  %2641 = load i32, i32* %2640, align 4
  %2642 = icmp eq i64 %2501, %2639
  %2643 = sext i1 %2642 to i32
  %2644 = xor i32 %2643, -1
  %2645 = and i32 %2644, %2638
  %2646 = and i32 %2643, %2641
  %Mitigated16 = or i32 %2646, %2645
  %2647 = lshr i32 %2495, 8
  %2648 = and i32 %2647, 255
  %2649 = zext i32 %2648 to i64
  %2650 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2651 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2650, i64 0, i64 1
  %2652 = srem i64 %2649, 16
  %2653 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2652
  %2654 = load i32, i32* %2653, align 4
  %2655 = icmp eq i64 %2649, %2652
  %2656 = sext i1 %2655 to i32
  %2657 = xor i32 %2656, -1
  %2658 = and i32 %2657, 0
  %2659 = and i32 %2656, %2654
  %2660 = or i32 %2659, %2658
  %2661 = add i64 %2652, 16
  %2662 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2661
  %2663 = load i32, i32* %2662, align 4
  %2664 = icmp eq i64 %2649, %2661
  %2665 = sext i1 %2664 to i32
  %2666 = xor i32 %2665, -1
  %2667 = and i32 %2666, %2660
  %2668 = and i32 %2665, %2663
  %2669 = or i32 %2668, %2667
  %2670 = add i64 %2661, 16
  %2671 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2670
  %2672 = load i32, i32* %2671, align 4
  %2673 = icmp eq i64 %2649, %2670
  %2674 = sext i1 %2673 to i32
  %2675 = xor i32 %2674, -1
  %2676 = and i32 %2675, %2669
  %2677 = and i32 %2674, %2672
  %2678 = or i32 %2677, %2676
  %2679 = add i64 %2670, 16
  %2680 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2679
  %2681 = load i32, i32* %2680, align 4
  %2682 = icmp eq i64 %2649, %2679
  %2683 = sext i1 %2682 to i32
  %2684 = xor i32 %2683, -1
  %2685 = and i32 %2684, %2678
  %2686 = and i32 %2683, %2681
  %2687 = or i32 %2686, %2685
  %2688 = add i64 %2679, 16
  %2689 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2688
  %2690 = load i32, i32* %2689, align 4
  %2691 = icmp eq i64 %2649, %2688
  %2692 = sext i1 %2691 to i32
  %2693 = xor i32 %2692, -1
  %2694 = and i32 %2693, %2687
  %2695 = and i32 %2692, %2690
  %2696 = or i32 %2695, %2694
  %2697 = add i64 %2688, 16
  %2698 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2697
  %2699 = load i32, i32* %2698, align 4
  %2700 = icmp eq i64 %2649, %2697
  %2701 = sext i1 %2700 to i32
  %2702 = xor i32 %2701, -1
  %2703 = and i32 %2702, %2696
  %2704 = and i32 %2701, %2699
  %2705 = or i32 %2704, %2703
  %2706 = add i64 %2697, 16
  %2707 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2706
  %2708 = load i32, i32* %2707, align 4
  %2709 = icmp eq i64 %2649, %2706
  %2710 = sext i1 %2709 to i32
  %2711 = xor i32 %2710, -1
  %2712 = and i32 %2711, %2705
  %2713 = and i32 %2710, %2708
  %2714 = or i32 %2713, %2712
  %2715 = add i64 %2706, 16
  %2716 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2715
  %2717 = load i32, i32* %2716, align 4
  %2718 = icmp eq i64 %2649, %2715
  %2719 = sext i1 %2718 to i32
  %2720 = xor i32 %2719, -1
  %2721 = and i32 %2720, %2714
  %2722 = and i32 %2719, %2717
  %2723 = or i32 %2722, %2721
  %2724 = add i64 %2715, 16
  %2725 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2724
  %2726 = load i32, i32* %2725, align 4
  %2727 = icmp eq i64 %2649, %2724
  %2728 = sext i1 %2727 to i32
  %2729 = xor i32 %2728, -1
  %2730 = and i32 %2729, %2723
  %2731 = and i32 %2728, %2726
  %2732 = or i32 %2731, %2730
  %2733 = add i64 %2724, 16
  %2734 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2733
  %2735 = load i32, i32* %2734, align 4
  %2736 = icmp eq i64 %2649, %2733
  %2737 = sext i1 %2736 to i32
  %2738 = xor i32 %2737, -1
  %2739 = and i32 %2738, %2732
  %2740 = and i32 %2737, %2735
  %2741 = or i32 %2740, %2739
  %2742 = add i64 %2733, 16
  %2743 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2742
  %2744 = load i32, i32* %2743, align 4
  %2745 = icmp eq i64 %2649, %2742
  %2746 = sext i1 %2745 to i32
  %2747 = xor i32 %2746, -1
  %2748 = and i32 %2747, %2741
  %2749 = and i32 %2746, %2744
  %2750 = or i32 %2749, %2748
  %2751 = add i64 %2742, 16
  %2752 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2751
  %2753 = load i32, i32* %2752, align 4
  %2754 = icmp eq i64 %2649, %2751
  %2755 = sext i1 %2754 to i32
  %2756 = xor i32 %2755, -1
  %2757 = and i32 %2756, %2750
  %2758 = and i32 %2755, %2753
  %2759 = or i32 %2758, %2757
  %2760 = add i64 %2751, 16
  %2761 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2760
  %2762 = load i32, i32* %2761, align 4
  %2763 = icmp eq i64 %2649, %2760
  %2764 = sext i1 %2763 to i32
  %2765 = xor i32 %2764, -1
  %2766 = and i32 %2765, %2759
  %2767 = and i32 %2764, %2762
  %2768 = or i32 %2767, %2766
  %2769 = add i64 %2760, 16
  %2770 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2769
  %2771 = load i32, i32* %2770, align 4
  %2772 = icmp eq i64 %2649, %2769
  %2773 = sext i1 %2772 to i32
  %2774 = xor i32 %2773, -1
  %2775 = and i32 %2774, %2768
  %2776 = and i32 %2773, %2771
  %2777 = or i32 %2776, %2775
  %2778 = add i64 %2769, 16
  %2779 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2778
  %2780 = load i32, i32* %2779, align 4
  %2781 = icmp eq i64 %2649, %2778
  %2782 = sext i1 %2781 to i32
  %2783 = xor i32 %2782, -1
  %2784 = and i32 %2783, %2777
  %2785 = and i32 %2782, %2780
  %2786 = or i32 %2785, %2784
  %2787 = add i64 %2778, 16
  %2788 = getelementptr inbounds [256 x i32], [256 x i32]* %2651, i64 0, i64 %2787
  %2789 = load i32, i32* %2788, align 4
  %2790 = icmp eq i64 %2649, %2787
  %2791 = sext i1 %2790 to i32
  %2792 = xor i32 %2791, -1
  %2793 = and i32 %2792, %2786
  %2794 = and i32 %2791, %2789
  %Mitigated17 = or i32 %2794, %2793
  %2795 = xor i32 %Mitigated16, %Mitigated17
  %2796 = lshr i32 %2495, 16
  %2797 = and i32 %2796, 255
  %2798 = zext i32 %2797 to i64
  %2799 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2800 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2799, i64 0, i64 2
  %2801 = srem i64 %2798, 16
  %2802 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2801
  %2803 = load i32, i32* %2802, align 4
  %2804 = icmp eq i64 %2798, %2801
  %2805 = sext i1 %2804 to i32
  %2806 = xor i32 %2805, -1
  %2807 = and i32 %2806, 0
  %2808 = and i32 %2805, %2803
  %2809 = or i32 %2808, %2807
  %2810 = add i64 %2801, 16
  %2811 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2810
  %2812 = load i32, i32* %2811, align 4
  %2813 = icmp eq i64 %2798, %2810
  %2814 = sext i1 %2813 to i32
  %2815 = xor i32 %2814, -1
  %2816 = and i32 %2815, %2809
  %2817 = and i32 %2814, %2812
  %2818 = or i32 %2817, %2816
  %2819 = add i64 %2810, 16
  %2820 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2819
  %2821 = load i32, i32* %2820, align 4
  %2822 = icmp eq i64 %2798, %2819
  %2823 = sext i1 %2822 to i32
  %2824 = xor i32 %2823, -1
  %2825 = and i32 %2824, %2818
  %2826 = and i32 %2823, %2821
  %2827 = or i32 %2826, %2825
  %2828 = add i64 %2819, 16
  %2829 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2828
  %2830 = load i32, i32* %2829, align 4
  %2831 = icmp eq i64 %2798, %2828
  %2832 = sext i1 %2831 to i32
  %2833 = xor i32 %2832, -1
  %2834 = and i32 %2833, %2827
  %2835 = and i32 %2832, %2830
  %2836 = or i32 %2835, %2834
  %2837 = add i64 %2828, 16
  %2838 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2837
  %2839 = load i32, i32* %2838, align 4
  %2840 = icmp eq i64 %2798, %2837
  %2841 = sext i1 %2840 to i32
  %2842 = xor i32 %2841, -1
  %2843 = and i32 %2842, %2836
  %2844 = and i32 %2841, %2839
  %2845 = or i32 %2844, %2843
  %2846 = add i64 %2837, 16
  %2847 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2846
  %2848 = load i32, i32* %2847, align 4
  %2849 = icmp eq i64 %2798, %2846
  %2850 = sext i1 %2849 to i32
  %2851 = xor i32 %2850, -1
  %2852 = and i32 %2851, %2845
  %2853 = and i32 %2850, %2848
  %2854 = or i32 %2853, %2852
  %2855 = add i64 %2846, 16
  %2856 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2855
  %2857 = load i32, i32* %2856, align 4
  %2858 = icmp eq i64 %2798, %2855
  %2859 = sext i1 %2858 to i32
  %2860 = xor i32 %2859, -1
  %2861 = and i32 %2860, %2854
  %2862 = and i32 %2859, %2857
  %2863 = or i32 %2862, %2861
  %2864 = add i64 %2855, 16
  %2865 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2864
  %2866 = load i32, i32* %2865, align 4
  %2867 = icmp eq i64 %2798, %2864
  %2868 = sext i1 %2867 to i32
  %2869 = xor i32 %2868, -1
  %2870 = and i32 %2869, %2863
  %2871 = and i32 %2868, %2866
  %2872 = or i32 %2871, %2870
  %2873 = add i64 %2864, 16
  %2874 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2873
  %2875 = load i32, i32* %2874, align 4
  %2876 = icmp eq i64 %2798, %2873
  %2877 = sext i1 %2876 to i32
  %2878 = xor i32 %2877, -1
  %2879 = and i32 %2878, %2872
  %2880 = and i32 %2877, %2875
  %2881 = or i32 %2880, %2879
  %2882 = add i64 %2873, 16
  %2883 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2882
  %2884 = load i32, i32* %2883, align 4
  %2885 = icmp eq i64 %2798, %2882
  %2886 = sext i1 %2885 to i32
  %2887 = xor i32 %2886, -1
  %2888 = and i32 %2887, %2881
  %2889 = and i32 %2886, %2884
  %2890 = or i32 %2889, %2888
  %2891 = add i64 %2882, 16
  %2892 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2891
  %2893 = load i32, i32* %2892, align 4
  %2894 = icmp eq i64 %2798, %2891
  %2895 = sext i1 %2894 to i32
  %2896 = xor i32 %2895, -1
  %2897 = and i32 %2896, %2890
  %2898 = and i32 %2895, %2893
  %2899 = or i32 %2898, %2897
  %2900 = add i64 %2891, 16
  %2901 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2900
  %2902 = load i32, i32* %2901, align 4
  %2903 = icmp eq i64 %2798, %2900
  %2904 = sext i1 %2903 to i32
  %2905 = xor i32 %2904, -1
  %2906 = and i32 %2905, %2899
  %2907 = and i32 %2904, %2902
  %2908 = or i32 %2907, %2906
  %2909 = add i64 %2900, 16
  %2910 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2909
  %2911 = load i32, i32* %2910, align 4
  %2912 = icmp eq i64 %2798, %2909
  %2913 = sext i1 %2912 to i32
  %2914 = xor i32 %2913, -1
  %2915 = and i32 %2914, %2908
  %2916 = and i32 %2913, %2911
  %2917 = or i32 %2916, %2915
  %2918 = add i64 %2909, 16
  %2919 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2918
  %2920 = load i32, i32* %2919, align 4
  %2921 = icmp eq i64 %2798, %2918
  %2922 = sext i1 %2921 to i32
  %2923 = xor i32 %2922, -1
  %2924 = and i32 %2923, %2917
  %2925 = and i32 %2922, %2920
  %2926 = or i32 %2925, %2924
  %2927 = add i64 %2918, 16
  %2928 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2927
  %2929 = load i32, i32* %2928, align 4
  %2930 = icmp eq i64 %2798, %2927
  %2931 = sext i1 %2930 to i32
  %2932 = xor i32 %2931, -1
  %2933 = and i32 %2932, %2926
  %2934 = and i32 %2931, %2929
  %2935 = or i32 %2934, %2933
  %2936 = add i64 %2927, 16
  %2937 = getelementptr inbounds [256 x i32], [256 x i32]* %2800, i64 0, i64 %2936
  %2938 = load i32, i32* %2937, align 4
  %2939 = icmp eq i64 %2798, %2936
  %2940 = sext i1 %2939 to i32
  %2941 = xor i32 %2940, -1
  %2942 = and i32 %2941, %2935
  %2943 = and i32 %2940, %2938
  %Mitigated18 = or i32 %2943, %2942
  %2944 = xor i32 %2795, %Mitigated18
  %2945 = lshr i32 %2495, 24
  %2946 = zext i32 %2945 to i64
  %2947 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %2948 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %2947, i64 0, i64 3
  %2949 = srem i64 %2946, 16
  %2950 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2949
  %2951 = load i32, i32* %2950, align 4
  %2952 = icmp eq i64 %2946, %2949
  %2953 = sext i1 %2952 to i32
  %2954 = xor i32 %2953, -1
  %2955 = and i32 %2954, 0
  %2956 = and i32 %2953, %2951
  %2957 = or i32 %2956, %2955
  %2958 = add i64 %2949, 16
  %2959 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2958
  %2960 = load i32, i32* %2959, align 4
  %2961 = icmp eq i64 %2946, %2958
  %2962 = sext i1 %2961 to i32
  %2963 = xor i32 %2962, -1
  %2964 = and i32 %2963, %2957
  %2965 = and i32 %2962, %2960
  %2966 = or i32 %2965, %2964
  %2967 = add i64 %2958, 16
  %2968 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2967
  %2969 = load i32, i32* %2968, align 4
  %2970 = icmp eq i64 %2946, %2967
  %2971 = sext i1 %2970 to i32
  %2972 = xor i32 %2971, -1
  %2973 = and i32 %2972, %2966
  %2974 = and i32 %2971, %2969
  %2975 = or i32 %2974, %2973
  %2976 = add i64 %2967, 16
  %2977 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2976
  %2978 = load i32, i32* %2977, align 4
  %2979 = icmp eq i64 %2946, %2976
  %2980 = sext i1 %2979 to i32
  %2981 = xor i32 %2980, -1
  %2982 = and i32 %2981, %2975
  %2983 = and i32 %2980, %2978
  %2984 = or i32 %2983, %2982
  %2985 = add i64 %2976, 16
  %2986 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2985
  %2987 = load i32, i32* %2986, align 4
  %2988 = icmp eq i64 %2946, %2985
  %2989 = sext i1 %2988 to i32
  %2990 = xor i32 %2989, -1
  %2991 = and i32 %2990, %2984
  %2992 = and i32 %2989, %2987
  %2993 = or i32 %2992, %2991
  %2994 = add i64 %2985, 16
  %2995 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %2994
  %2996 = load i32, i32* %2995, align 4
  %2997 = icmp eq i64 %2946, %2994
  %2998 = sext i1 %2997 to i32
  %2999 = xor i32 %2998, -1
  %3000 = and i32 %2999, %2993
  %3001 = and i32 %2998, %2996
  %3002 = or i32 %3001, %3000
  %3003 = add i64 %2994, 16
  %3004 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3003
  %3005 = load i32, i32* %3004, align 4
  %3006 = icmp eq i64 %2946, %3003
  %3007 = sext i1 %3006 to i32
  %3008 = xor i32 %3007, -1
  %3009 = and i32 %3008, %3002
  %3010 = and i32 %3007, %3005
  %3011 = or i32 %3010, %3009
  %3012 = add i64 %3003, 16
  %3013 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3012
  %3014 = load i32, i32* %3013, align 4
  %3015 = icmp eq i64 %2946, %3012
  %3016 = sext i1 %3015 to i32
  %3017 = xor i32 %3016, -1
  %3018 = and i32 %3017, %3011
  %3019 = and i32 %3016, %3014
  %3020 = or i32 %3019, %3018
  %3021 = add i64 %3012, 16
  %3022 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3021
  %3023 = load i32, i32* %3022, align 4
  %3024 = icmp eq i64 %2946, %3021
  %3025 = sext i1 %3024 to i32
  %3026 = xor i32 %3025, -1
  %3027 = and i32 %3026, %3020
  %3028 = and i32 %3025, %3023
  %3029 = or i32 %3028, %3027
  %3030 = add i64 %3021, 16
  %3031 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3030
  %3032 = load i32, i32* %3031, align 4
  %3033 = icmp eq i64 %2946, %3030
  %3034 = sext i1 %3033 to i32
  %3035 = xor i32 %3034, -1
  %3036 = and i32 %3035, %3029
  %3037 = and i32 %3034, %3032
  %3038 = or i32 %3037, %3036
  %3039 = add i64 %3030, 16
  %3040 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3039
  %3041 = load i32, i32* %3040, align 4
  %3042 = icmp eq i64 %2946, %3039
  %3043 = sext i1 %3042 to i32
  %3044 = xor i32 %3043, -1
  %3045 = and i32 %3044, %3038
  %3046 = and i32 %3043, %3041
  %3047 = or i32 %3046, %3045
  %3048 = add i64 %3039, 16
  %3049 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3048
  %3050 = load i32, i32* %3049, align 4
  %3051 = icmp eq i64 %2946, %3048
  %3052 = sext i1 %3051 to i32
  %3053 = xor i32 %3052, -1
  %3054 = and i32 %3053, %3047
  %3055 = and i32 %3052, %3050
  %3056 = or i32 %3055, %3054
  %3057 = add i64 %3048, 16
  %3058 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3057
  %3059 = load i32, i32* %3058, align 4
  %3060 = icmp eq i64 %2946, %3057
  %3061 = sext i1 %3060 to i32
  %3062 = xor i32 %3061, -1
  %3063 = and i32 %3062, %3056
  %3064 = and i32 %3061, %3059
  %3065 = or i32 %3064, %3063
  %3066 = add i64 %3057, 16
  %3067 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3066
  %3068 = load i32, i32* %3067, align 4
  %3069 = icmp eq i64 %2946, %3066
  %3070 = sext i1 %3069 to i32
  %3071 = xor i32 %3070, -1
  %3072 = and i32 %3071, %3065
  %3073 = and i32 %3070, %3068
  %3074 = or i32 %3073, %3072
  %3075 = add i64 %3066, 16
  %3076 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3075
  %3077 = load i32, i32* %3076, align 4
  %3078 = icmp eq i64 %2946, %3075
  %3079 = sext i1 %3078 to i32
  %3080 = xor i32 %3079, -1
  %3081 = and i32 %3080, %3074
  %3082 = and i32 %3079, %3077
  %3083 = or i32 %3082, %3081
  %3084 = add i64 %3075, 16
  %3085 = getelementptr inbounds [256 x i32], [256 x i32]* %2948, i64 0, i64 %3084
  %3086 = load i32, i32* %3085, align 4
  %3087 = icmp eq i64 %2946, %3084
  %3088 = sext i1 %3087 to i32
  %3089 = xor i32 %3088, -1
  %3090 = and i32 %3089, %3083
  %3091 = and i32 %3088, %3086
  %Mitigated19 = or i32 %3091, %3090
  %3092 = xor i32 %2944, %Mitigated19
  %3093 = and i32 %2499, 255
  %3094 = zext i32 %3093 to i64
  %3095 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3096 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3095, i64 0, i64 1
  %3097 = srem i64 %3094, 16
  %3098 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3097
  %3099 = load i32, i32* %3098, align 4
  %3100 = icmp eq i64 %3094, %3097
  %3101 = sext i1 %3100 to i32
  %3102 = xor i32 %3101, -1
  %3103 = and i32 %3102, 0
  %3104 = and i32 %3101, %3099
  %3105 = or i32 %3104, %3103
  %3106 = add i64 %3097, 16
  %3107 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3106
  %3108 = load i32, i32* %3107, align 4
  %3109 = icmp eq i64 %3094, %3106
  %3110 = sext i1 %3109 to i32
  %3111 = xor i32 %3110, -1
  %3112 = and i32 %3111, %3105
  %3113 = and i32 %3110, %3108
  %3114 = or i32 %3113, %3112
  %3115 = add i64 %3106, 16
  %3116 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3115
  %3117 = load i32, i32* %3116, align 4
  %3118 = icmp eq i64 %3094, %3115
  %3119 = sext i1 %3118 to i32
  %3120 = xor i32 %3119, -1
  %3121 = and i32 %3120, %3114
  %3122 = and i32 %3119, %3117
  %3123 = or i32 %3122, %3121
  %3124 = add i64 %3115, 16
  %3125 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3124
  %3126 = load i32, i32* %3125, align 4
  %3127 = icmp eq i64 %3094, %3124
  %3128 = sext i1 %3127 to i32
  %3129 = xor i32 %3128, -1
  %3130 = and i32 %3129, %3123
  %3131 = and i32 %3128, %3126
  %3132 = or i32 %3131, %3130
  %3133 = add i64 %3124, 16
  %3134 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3133
  %3135 = load i32, i32* %3134, align 4
  %3136 = icmp eq i64 %3094, %3133
  %3137 = sext i1 %3136 to i32
  %3138 = xor i32 %3137, -1
  %3139 = and i32 %3138, %3132
  %3140 = and i32 %3137, %3135
  %3141 = or i32 %3140, %3139
  %3142 = add i64 %3133, 16
  %3143 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3142
  %3144 = load i32, i32* %3143, align 4
  %3145 = icmp eq i64 %3094, %3142
  %3146 = sext i1 %3145 to i32
  %3147 = xor i32 %3146, -1
  %3148 = and i32 %3147, %3141
  %3149 = and i32 %3146, %3144
  %3150 = or i32 %3149, %3148
  %3151 = add i64 %3142, 16
  %3152 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3151
  %3153 = load i32, i32* %3152, align 4
  %3154 = icmp eq i64 %3094, %3151
  %3155 = sext i1 %3154 to i32
  %3156 = xor i32 %3155, -1
  %3157 = and i32 %3156, %3150
  %3158 = and i32 %3155, %3153
  %3159 = or i32 %3158, %3157
  %3160 = add i64 %3151, 16
  %3161 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3160
  %3162 = load i32, i32* %3161, align 4
  %3163 = icmp eq i64 %3094, %3160
  %3164 = sext i1 %3163 to i32
  %3165 = xor i32 %3164, -1
  %3166 = and i32 %3165, %3159
  %3167 = and i32 %3164, %3162
  %3168 = or i32 %3167, %3166
  %3169 = add i64 %3160, 16
  %3170 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3169
  %3171 = load i32, i32* %3170, align 4
  %3172 = icmp eq i64 %3094, %3169
  %3173 = sext i1 %3172 to i32
  %3174 = xor i32 %3173, -1
  %3175 = and i32 %3174, %3168
  %3176 = and i32 %3173, %3171
  %3177 = or i32 %3176, %3175
  %3178 = add i64 %3169, 16
  %3179 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3178
  %3180 = load i32, i32* %3179, align 4
  %3181 = icmp eq i64 %3094, %3178
  %3182 = sext i1 %3181 to i32
  %3183 = xor i32 %3182, -1
  %3184 = and i32 %3183, %3177
  %3185 = and i32 %3182, %3180
  %3186 = or i32 %3185, %3184
  %3187 = add i64 %3178, 16
  %3188 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3187
  %3189 = load i32, i32* %3188, align 4
  %3190 = icmp eq i64 %3094, %3187
  %3191 = sext i1 %3190 to i32
  %3192 = xor i32 %3191, -1
  %3193 = and i32 %3192, %3186
  %3194 = and i32 %3191, %3189
  %3195 = or i32 %3194, %3193
  %3196 = add i64 %3187, 16
  %3197 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3196
  %3198 = load i32, i32* %3197, align 4
  %3199 = icmp eq i64 %3094, %3196
  %3200 = sext i1 %3199 to i32
  %3201 = xor i32 %3200, -1
  %3202 = and i32 %3201, %3195
  %3203 = and i32 %3200, %3198
  %3204 = or i32 %3203, %3202
  %3205 = add i64 %3196, 16
  %3206 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3205
  %3207 = load i32, i32* %3206, align 4
  %3208 = icmp eq i64 %3094, %3205
  %3209 = sext i1 %3208 to i32
  %3210 = xor i32 %3209, -1
  %3211 = and i32 %3210, %3204
  %3212 = and i32 %3209, %3207
  %3213 = or i32 %3212, %3211
  %3214 = add i64 %3205, 16
  %3215 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3214
  %3216 = load i32, i32* %3215, align 4
  %3217 = icmp eq i64 %3094, %3214
  %3218 = sext i1 %3217 to i32
  %3219 = xor i32 %3218, -1
  %3220 = and i32 %3219, %3213
  %3221 = and i32 %3218, %3216
  %3222 = or i32 %3221, %3220
  %3223 = add i64 %3214, 16
  %3224 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3223
  %3225 = load i32, i32* %3224, align 4
  %3226 = icmp eq i64 %3094, %3223
  %3227 = sext i1 %3226 to i32
  %3228 = xor i32 %3227, -1
  %3229 = and i32 %3228, %3222
  %3230 = and i32 %3227, %3225
  %3231 = or i32 %3230, %3229
  %3232 = add i64 %3223, 16
  %3233 = getelementptr inbounds [256 x i32], [256 x i32]* %3096, i64 0, i64 %3232
  %3234 = load i32, i32* %3233, align 4
  %3235 = icmp eq i64 %3094, %3232
  %3236 = sext i1 %3235 to i32
  %3237 = xor i32 %3236, -1
  %3238 = and i32 %3237, %3231
  %3239 = and i32 %3236, %3234
  %Mitigated20 = or i32 %3239, %3238
  %3240 = lshr i32 %2499, 8
  %3241 = and i32 %3240, 255
  %3242 = zext i32 %3241 to i64
  %3243 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3244 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3243, i64 0, i64 2
  %3245 = srem i64 %3242, 16
  %3246 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3245
  %3247 = load i32, i32* %3246, align 4
  %3248 = icmp eq i64 %3242, %3245
  %3249 = sext i1 %3248 to i32
  %3250 = xor i32 %3249, -1
  %3251 = and i32 %3250, 0
  %3252 = and i32 %3249, %3247
  %3253 = or i32 %3252, %3251
  %3254 = add i64 %3245, 16
  %3255 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3254
  %3256 = load i32, i32* %3255, align 4
  %3257 = icmp eq i64 %3242, %3254
  %3258 = sext i1 %3257 to i32
  %3259 = xor i32 %3258, -1
  %3260 = and i32 %3259, %3253
  %3261 = and i32 %3258, %3256
  %3262 = or i32 %3261, %3260
  %3263 = add i64 %3254, 16
  %3264 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3263
  %3265 = load i32, i32* %3264, align 4
  %3266 = icmp eq i64 %3242, %3263
  %3267 = sext i1 %3266 to i32
  %3268 = xor i32 %3267, -1
  %3269 = and i32 %3268, %3262
  %3270 = and i32 %3267, %3265
  %3271 = or i32 %3270, %3269
  %3272 = add i64 %3263, 16
  %3273 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3272
  %3274 = load i32, i32* %3273, align 4
  %3275 = icmp eq i64 %3242, %3272
  %3276 = sext i1 %3275 to i32
  %3277 = xor i32 %3276, -1
  %3278 = and i32 %3277, %3271
  %3279 = and i32 %3276, %3274
  %3280 = or i32 %3279, %3278
  %3281 = add i64 %3272, 16
  %3282 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3281
  %3283 = load i32, i32* %3282, align 4
  %3284 = icmp eq i64 %3242, %3281
  %3285 = sext i1 %3284 to i32
  %3286 = xor i32 %3285, -1
  %3287 = and i32 %3286, %3280
  %3288 = and i32 %3285, %3283
  %3289 = or i32 %3288, %3287
  %3290 = add i64 %3281, 16
  %3291 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3290
  %3292 = load i32, i32* %3291, align 4
  %3293 = icmp eq i64 %3242, %3290
  %3294 = sext i1 %3293 to i32
  %3295 = xor i32 %3294, -1
  %3296 = and i32 %3295, %3289
  %3297 = and i32 %3294, %3292
  %3298 = or i32 %3297, %3296
  %3299 = add i64 %3290, 16
  %3300 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3299
  %3301 = load i32, i32* %3300, align 4
  %3302 = icmp eq i64 %3242, %3299
  %3303 = sext i1 %3302 to i32
  %3304 = xor i32 %3303, -1
  %3305 = and i32 %3304, %3298
  %3306 = and i32 %3303, %3301
  %3307 = or i32 %3306, %3305
  %3308 = add i64 %3299, 16
  %3309 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3308
  %3310 = load i32, i32* %3309, align 4
  %3311 = icmp eq i64 %3242, %3308
  %3312 = sext i1 %3311 to i32
  %3313 = xor i32 %3312, -1
  %3314 = and i32 %3313, %3307
  %3315 = and i32 %3312, %3310
  %3316 = or i32 %3315, %3314
  %3317 = add i64 %3308, 16
  %3318 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3317
  %3319 = load i32, i32* %3318, align 4
  %3320 = icmp eq i64 %3242, %3317
  %3321 = sext i1 %3320 to i32
  %3322 = xor i32 %3321, -1
  %3323 = and i32 %3322, %3316
  %3324 = and i32 %3321, %3319
  %3325 = or i32 %3324, %3323
  %3326 = add i64 %3317, 16
  %3327 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3326
  %3328 = load i32, i32* %3327, align 4
  %3329 = icmp eq i64 %3242, %3326
  %3330 = sext i1 %3329 to i32
  %3331 = xor i32 %3330, -1
  %3332 = and i32 %3331, %3325
  %3333 = and i32 %3330, %3328
  %3334 = or i32 %3333, %3332
  %3335 = add i64 %3326, 16
  %3336 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3335
  %3337 = load i32, i32* %3336, align 4
  %3338 = icmp eq i64 %3242, %3335
  %3339 = sext i1 %3338 to i32
  %3340 = xor i32 %3339, -1
  %3341 = and i32 %3340, %3334
  %3342 = and i32 %3339, %3337
  %3343 = or i32 %3342, %3341
  %3344 = add i64 %3335, 16
  %3345 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3344
  %3346 = load i32, i32* %3345, align 4
  %3347 = icmp eq i64 %3242, %3344
  %3348 = sext i1 %3347 to i32
  %3349 = xor i32 %3348, -1
  %3350 = and i32 %3349, %3343
  %3351 = and i32 %3348, %3346
  %3352 = or i32 %3351, %3350
  %3353 = add i64 %3344, 16
  %3354 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3353
  %3355 = load i32, i32* %3354, align 4
  %3356 = icmp eq i64 %3242, %3353
  %3357 = sext i1 %3356 to i32
  %3358 = xor i32 %3357, -1
  %3359 = and i32 %3358, %3352
  %3360 = and i32 %3357, %3355
  %3361 = or i32 %3360, %3359
  %3362 = add i64 %3353, 16
  %3363 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3362
  %3364 = load i32, i32* %3363, align 4
  %3365 = icmp eq i64 %3242, %3362
  %3366 = sext i1 %3365 to i32
  %3367 = xor i32 %3366, -1
  %3368 = and i32 %3367, %3361
  %3369 = and i32 %3366, %3364
  %3370 = or i32 %3369, %3368
  %3371 = add i64 %3362, 16
  %3372 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3371
  %3373 = load i32, i32* %3372, align 4
  %3374 = icmp eq i64 %3242, %3371
  %3375 = sext i1 %3374 to i32
  %3376 = xor i32 %3375, -1
  %3377 = and i32 %3376, %3370
  %3378 = and i32 %3375, %3373
  %3379 = or i32 %3378, %3377
  %3380 = add i64 %3371, 16
  %3381 = getelementptr inbounds [256 x i32], [256 x i32]* %3244, i64 0, i64 %3380
  %3382 = load i32, i32* %3381, align 4
  %3383 = icmp eq i64 %3242, %3380
  %3384 = sext i1 %3383 to i32
  %3385 = xor i32 %3384, -1
  %3386 = and i32 %3385, %3379
  %3387 = and i32 %3384, %3382
  %Mitigated21 = or i32 %3387, %3386
  %3388 = xor i32 %Mitigated20, %Mitigated21
  %3389 = lshr i32 %2499, 16
  %3390 = and i32 %3389, 255
  %3391 = zext i32 %3390 to i64
  %3392 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3393 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3392, i64 0, i64 3
  %3394 = srem i64 %3391, 16
  %3395 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3394
  %3396 = load i32, i32* %3395, align 4
  %3397 = icmp eq i64 %3391, %3394
  %3398 = sext i1 %3397 to i32
  %3399 = xor i32 %3398, -1
  %3400 = and i32 %3399, 0
  %3401 = and i32 %3398, %3396
  %3402 = or i32 %3401, %3400
  %3403 = add i64 %3394, 16
  %3404 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3403
  %3405 = load i32, i32* %3404, align 4
  %3406 = icmp eq i64 %3391, %3403
  %3407 = sext i1 %3406 to i32
  %3408 = xor i32 %3407, -1
  %3409 = and i32 %3408, %3402
  %3410 = and i32 %3407, %3405
  %3411 = or i32 %3410, %3409
  %3412 = add i64 %3403, 16
  %3413 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3412
  %3414 = load i32, i32* %3413, align 4
  %3415 = icmp eq i64 %3391, %3412
  %3416 = sext i1 %3415 to i32
  %3417 = xor i32 %3416, -1
  %3418 = and i32 %3417, %3411
  %3419 = and i32 %3416, %3414
  %3420 = or i32 %3419, %3418
  %3421 = add i64 %3412, 16
  %3422 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3421
  %3423 = load i32, i32* %3422, align 4
  %3424 = icmp eq i64 %3391, %3421
  %3425 = sext i1 %3424 to i32
  %3426 = xor i32 %3425, -1
  %3427 = and i32 %3426, %3420
  %3428 = and i32 %3425, %3423
  %3429 = or i32 %3428, %3427
  %3430 = add i64 %3421, 16
  %3431 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3430
  %3432 = load i32, i32* %3431, align 4
  %3433 = icmp eq i64 %3391, %3430
  %3434 = sext i1 %3433 to i32
  %3435 = xor i32 %3434, -1
  %3436 = and i32 %3435, %3429
  %3437 = and i32 %3434, %3432
  %3438 = or i32 %3437, %3436
  %3439 = add i64 %3430, 16
  %3440 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3439
  %3441 = load i32, i32* %3440, align 4
  %3442 = icmp eq i64 %3391, %3439
  %3443 = sext i1 %3442 to i32
  %3444 = xor i32 %3443, -1
  %3445 = and i32 %3444, %3438
  %3446 = and i32 %3443, %3441
  %3447 = or i32 %3446, %3445
  %3448 = add i64 %3439, 16
  %3449 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3448
  %3450 = load i32, i32* %3449, align 4
  %3451 = icmp eq i64 %3391, %3448
  %3452 = sext i1 %3451 to i32
  %3453 = xor i32 %3452, -1
  %3454 = and i32 %3453, %3447
  %3455 = and i32 %3452, %3450
  %3456 = or i32 %3455, %3454
  %3457 = add i64 %3448, 16
  %3458 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3457
  %3459 = load i32, i32* %3458, align 4
  %3460 = icmp eq i64 %3391, %3457
  %3461 = sext i1 %3460 to i32
  %3462 = xor i32 %3461, -1
  %3463 = and i32 %3462, %3456
  %3464 = and i32 %3461, %3459
  %3465 = or i32 %3464, %3463
  %3466 = add i64 %3457, 16
  %3467 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3466
  %3468 = load i32, i32* %3467, align 4
  %3469 = icmp eq i64 %3391, %3466
  %3470 = sext i1 %3469 to i32
  %3471 = xor i32 %3470, -1
  %3472 = and i32 %3471, %3465
  %3473 = and i32 %3470, %3468
  %3474 = or i32 %3473, %3472
  %3475 = add i64 %3466, 16
  %3476 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3475
  %3477 = load i32, i32* %3476, align 4
  %3478 = icmp eq i64 %3391, %3475
  %3479 = sext i1 %3478 to i32
  %3480 = xor i32 %3479, -1
  %3481 = and i32 %3480, %3474
  %3482 = and i32 %3479, %3477
  %3483 = or i32 %3482, %3481
  %3484 = add i64 %3475, 16
  %3485 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3484
  %3486 = load i32, i32* %3485, align 4
  %3487 = icmp eq i64 %3391, %3484
  %3488 = sext i1 %3487 to i32
  %3489 = xor i32 %3488, -1
  %3490 = and i32 %3489, %3483
  %3491 = and i32 %3488, %3486
  %3492 = or i32 %3491, %3490
  %3493 = add i64 %3484, 16
  %3494 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3493
  %3495 = load i32, i32* %3494, align 4
  %3496 = icmp eq i64 %3391, %3493
  %3497 = sext i1 %3496 to i32
  %3498 = xor i32 %3497, -1
  %3499 = and i32 %3498, %3492
  %3500 = and i32 %3497, %3495
  %3501 = or i32 %3500, %3499
  %3502 = add i64 %3493, 16
  %3503 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3502
  %3504 = load i32, i32* %3503, align 4
  %3505 = icmp eq i64 %3391, %3502
  %3506 = sext i1 %3505 to i32
  %3507 = xor i32 %3506, -1
  %3508 = and i32 %3507, %3501
  %3509 = and i32 %3506, %3504
  %3510 = or i32 %3509, %3508
  %3511 = add i64 %3502, 16
  %3512 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3511
  %3513 = load i32, i32* %3512, align 4
  %3514 = icmp eq i64 %3391, %3511
  %3515 = sext i1 %3514 to i32
  %3516 = xor i32 %3515, -1
  %3517 = and i32 %3516, %3510
  %3518 = and i32 %3515, %3513
  %3519 = or i32 %3518, %3517
  %3520 = add i64 %3511, 16
  %3521 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3520
  %3522 = load i32, i32* %3521, align 4
  %3523 = icmp eq i64 %3391, %3520
  %3524 = sext i1 %3523 to i32
  %3525 = xor i32 %3524, -1
  %3526 = and i32 %3525, %3519
  %3527 = and i32 %3524, %3522
  %3528 = or i32 %3527, %3526
  %3529 = add i64 %3520, 16
  %3530 = getelementptr inbounds [256 x i32], [256 x i32]* %3393, i64 0, i64 %3529
  %3531 = load i32, i32* %3530, align 4
  %3532 = icmp eq i64 %3391, %3529
  %3533 = sext i1 %3532 to i32
  %3534 = xor i32 %3533, -1
  %3535 = and i32 %3534, %3528
  %3536 = and i32 %3533, %3531
  %Mitigated22 = or i32 %3536, %3535
  %3537 = xor i32 %3388, %Mitigated22
  %3538 = lshr i32 %2499, 24
  %3539 = zext i32 %3538 to i64
  %3540 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3541 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3540, i64 0, i64 0
  %3542 = srem i64 %3539, 16
  %3543 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3542
  %3544 = load i32, i32* %3543, align 4
  %3545 = icmp eq i64 %3539, %3542
  %3546 = sext i1 %3545 to i32
  %3547 = xor i32 %3546, -1
  %3548 = and i32 %3547, 0
  %3549 = and i32 %3546, %3544
  %3550 = or i32 %3549, %3548
  %3551 = add i64 %3542, 16
  %3552 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3551
  %3553 = load i32, i32* %3552, align 4
  %3554 = icmp eq i64 %3539, %3551
  %3555 = sext i1 %3554 to i32
  %3556 = xor i32 %3555, -1
  %3557 = and i32 %3556, %3550
  %3558 = and i32 %3555, %3553
  %3559 = or i32 %3558, %3557
  %3560 = add i64 %3551, 16
  %3561 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3560
  %3562 = load i32, i32* %3561, align 4
  %3563 = icmp eq i64 %3539, %3560
  %3564 = sext i1 %3563 to i32
  %3565 = xor i32 %3564, -1
  %3566 = and i32 %3565, %3559
  %3567 = and i32 %3564, %3562
  %3568 = or i32 %3567, %3566
  %3569 = add i64 %3560, 16
  %3570 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3569
  %3571 = load i32, i32* %3570, align 4
  %3572 = icmp eq i64 %3539, %3569
  %3573 = sext i1 %3572 to i32
  %3574 = xor i32 %3573, -1
  %3575 = and i32 %3574, %3568
  %3576 = and i32 %3573, %3571
  %3577 = or i32 %3576, %3575
  %3578 = add i64 %3569, 16
  %3579 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3578
  %3580 = load i32, i32* %3579, align 4
  %3581 = icmp eq i64 %3539, %3578
  %3582 = sext i1 %3581 to i32
  %3583 = xor i32 %3582, -1
  %3584 = and i32 %3583, %3577
  %3585 = and i32 %3582, %3580
  %3586 = or i32 %3585, %3584
  %3587 = add i64 %3578, 16
  %3588 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3587
  %3589 = load i32, i32* %3588, align 4
  %3590 = icmp eq i64 %3539, %3587
  %3591 = sext i1 %3590 to i32
  %3592 = xor i32 %3591, -1
  %3593 = and i32 %3592, %3586
  %3594 = and i32 %3591, %3589
  %3595 = or i32 %3594, %3593
  %3596 = add i64 %3587, 16
  %3597 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3596
  %3598 = load i32, i32* %3597, align 4
  %3599 = icmp eq i64 %3539, %3596
  %3600 = sext i1 %3599 to i32
  %3601 = xor i32 %3600, -1
  %3602 = and i32 %3601, %3595
  %3603 = and i32 %3600, %3598
  %3604 = or i32 %3603, %3602
  %3605 = add i64 %3596, 16
  %3606 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3605
  %3607 = load i32, i32* %3606, align 4
  %3608 = icmp eq i64 %3539, %3605
  %3609 = sext i1 %3608 to i32
  %3610 = xor i32 %3609, -1
  %3611 = and i32 %3610, %3604
  %3612 = and i32 %3609, %3607
  %3613 = or i32 %3612, %3611
  %3614 = add i64 %3605, 16
  %3615 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3614
  %3616 = load i32, i32* %3615, align 4
  %3617 = icmp eq i64 %3539, %3614
  %3618 = sext i1 %3617 to i32
  %3619 = xor i32 %3618, -1
  %3620 = and i32 %3619, %3613
  %3621 = and i32 %3618, %3616
  %3622 = or i32 %3621, %3620
  %3623 = add i64 %3614, 16
  %3624 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3623
  %3625 = load i32, i32* %3624, align 4
  %3626 = icmp eq i64 %3539, %3623
  %3627 = sext i1 %3626 to i32
  %3628 = xor i32 %3627, -1
  %3629 = and i32 %3628, %3622
  %3630 = and i32 %3627, %3625
  %3631 = or i32 %3630, %3629
  %3632 = add i64 %3623, 16
  %3633 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3632
  %3634 = load i32, i32* %3633, align 4
  %3635 = icmp eq i64 %3539, %3632
  %3636 = sext i1 %3635 to i32
  %3637 = xor i32 %3636, -1
  %3638 = and i32 %3637, %3631
  %3639 = and i32 %3636, %3634
  %3640 = or i32 %3639, %3638
  %3641 = add i64 %3632, 16
  %3642 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3641
  %3643 = load i32, i32* %3642, align 4
  %3644 = icmp eq i64 %3539, %3641
  %3645 = sext i1 %3644 to i32
  %3646 = xor i32 %3645, -1
  %3647 = and i32 %3646, %3640
  %3648 = and i32 %3645, %3643
  %3649 = or i32 %3648, %3647
  %3650 = add i64 %3641, 16
  %3651 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3650
  %3652 = load i32, i32* %3651, align 4
  %3653 = icmp eq i64 %3539, %3650
  %3654 = sext i1 %3653 to i32
  %3655 = xor i32 %3654, -1
  %3656 = and i32 %3655, %3649
  %3657 = and i32 %3654, %3652
  %3658 = or i32 %3657, %3656
  %3659 = add i64 %3650, 16
  %3660 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3659
  %3661 = load i32, i32* %3660, align 4
  %3662 = icmp eq i64 %3539, %3659
  %3663 = sext i1 %3662 to i32
  %3664 = xor i32 %3663, -1
  %3665 = and i32 %3664, %3658
  %3666 = and i32 %3663, %3661
  %3667 = or i32 %3666, %3665
  %3668 = add i64 %3659, 16
  %3669 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3668
  %3670 = load i32, i32* %3669, align 4
  %3671 = icmp eq i64 %3539, %3668
  %3672 = sext i1 %3671 to i32
  %3673 = xor i32 %3672, -1
  %3674 = and i32 %3673, %3667
  %3675 = and i32 %3672, %3670
  %3676 = or i32 %3675, %3674
  %3677 = add i64 %3668, 16
  %3678 = getelementptr inbounds [256 x i32], [256 x i32]* %3541, i64 0, i64 %3677
  %3679 = load i32, i32* %3678, align 4
  %3680 = icmp eq i64 %3539, %3677
  %3681 = sext i1 %3680 to i32
  %3682 = xor i32 %3681, -1
  %3683 = and i32 %3682, %3676
  %3684 = and i32 %3681, %3679
  %Mitigated23 = or i32 %3684, %3683
  %3685 = xor i32 %3537, %Mitigated23
  %3686 = add i32 %3092, %3685
  %3687 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %3688 = getelementptr inbounds [32 x i32], [32 x i32]* %3687, i64 0, i64 5
  %3689 = load i32, i32* %3688, align 4
  %3690 = add i32 %3686, %3689
  %3691 = add i32 %3685, %3690
  %3692 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %3693 = getelementptr inbounds [32 x i32], [32 x i32]* %3692, i64 0, i64 4
  %3694 = load i32, i32* %3693, align 4
  %3695 = add i32 %3686, %3694
  %3696 = xor i32 %1291, %3695
  %3697 = lshr i32 %3696, 1
  %3698 = shl i32 %3696, 31
  %3699 = add i32 %3697, %3698
  %3700 = shl i32 %1295, 1
  %3701 = lshr i32 %1295, 31
  %3702 = add i32 %3700, %3701
  %3703 = xor i32 %3702, %3691
  %3704 = and i32 %3699, 255
  %3705 = zext i32 %3704 to i64
  %3706 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3707 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3706, i64 0, i64 0
  %3708 = srem i64 %3705, 16
  %3709 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3708
  %3710 = load i32, i32* %3709, align 4
  %3711 = icmp eq i64 %3705, %3708
  %3712 = sext i1 %3711 to i32
  %3713 = xor i32 %3712, -1
  %3714 = and i32 %3713, 0
  %3715 = and i32 %3712, %3710
  %3716 = or i32 %3715, %3714
  %3717 = add i64 %3708, 16
  %3718 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3717
  %3719 = load i32, i32* %3718, align 4
  %3720 = icmp eq i64 %3705, %3717
  %3721 = sext i1 %3720 to i32
  %3722 = xor i32 %3721, -1
  %3723 = and i32 %3722, %3716
  %3724 = and i32 %3721, %3719
  %3725 = or i32 %3724, %3723
  %3726 = add i64 %3717, 16
  %3727 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3726
  %3728 = load i32, i32* %3727, align 4
  %3729 = icmp eq i64 %3705, %3726
  %3730 = sext i1 %3729 to i32
  %3731 = xor i32 %3730, -1
  %3732 = and i32 %3731, %3725
  %3733 = and i32 %3730, %3728
  %3734 = or i32 %3733, %3732
  %3735 = add i64 %3726, 16
  %3736 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3735
  %3737 = load i32, i32* %3736, align 4
  %3738 = icmp eq i64 %3705, %3735
  %3739 = sext i1 %3738 to i32
  %3740 = xor i32 %3739, -1
  %3741 = and i32 %3740, %3734
  %3742 = and i32 %3739, %3737
  %3743 = or i32 %3742, %3741
  %3744 = add i64 %3735, 16
  %3745 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3744
  %3746 = load i32, i32* %3745, align 4
  %3747 = icmp eq i64 %3705, %3744
  %3748 = sext i1 %3747 to i32
  %3749 = xor i32 %3748, -1
  %3750 = and i32 %3749, %3743
  %3751 = and i32 %3748, %3746
  %3752 = or i32 %3751, %3750
  %3753 = add i64 %3744, 16
  %3754 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3753
  %3755 = load i32, i32* %3754, align 4
  %3756 = icmp eq i64 %3705, %3753
  %3757 = sext i1 %3756 to i32
  %3758 = xor i32 %3757, -1
  %3759 = and i32 %3758, %3752
  %3760 = and i32 %3757, %3755
  %3761 = or i32 %3760, %3759
  %3762 = add i64 %3753, 16
  %3763 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3762
  %3764 = load i32, i32* %3763, align 4
  %3765 = icmp eq i64 %3705, %3762
  %3766 = sext i1 %3765 to i32
  %3767 = xor i32 %3766, -1
  %3768 = and i32 %3767, %3761
  %3769 = and i32 %3766, %3764
  %3770 = or i32 %3769, %3768
  %3771 = add i64 %3762, 16
  %3772 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3771
  %3773 = load i32, i32* %3772, align 4
  %3774 = icmp eq i64 %3705, %3771
  %3775 = sext i1 %3774 to i32
  %3776 = xor i32 %3775, -1
  %3777 = and i32 %3776, %3770
  %3778 = and i32 %3775, %3773
  %3779 = or i32 %3778, %3777
  %3780 = add i64 %3771, 16
  %3781 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3780
  %3782 = load i32, i32* %3781, align 4
  %3783 = icmp eq i64 %3705, %3780
  %3784 = sext i1 %3783 to i32
  %3785 = xor i32 %3784, -1
  %3786 = and i32 %3785, %3779
  %3787 = and i32 %3784, %3782
  %3788 = or i32 %3787, %3786
  %3789 = add i64 %3780, 16
  %3790 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3789
  %3791 = load i32, i32* %3790, align 4
  %3792 = icmp eq i64 %3705, %3789
  %3793 = sext i1 %3792 to i32
  %3794 = xor i32 %3793, -1
  %3795 = and i32 %3794, %3788
  %3796 = and i32 %3793, %3791
  %3797 = or i32 %3796, %3795
  %3798 = add i64 %3789, 16
  %3799 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3798
  %3800 = load i32, i32* %3799, align 4
  %3801 = icmp eq i64 %3705, %3798
  %3802 = sext i1 %3801 to i32
  %3803 = xor i32 %3802, -1
  %3804 = and i32 %3803, %3797
  %3805 = and i32 %3802, %3800
  %3806 = or i32 %3805, %3804
  %3807 = add i64 %3798, 16
  %3808 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3807
  %3809 = load i32, i32* %3808, align 4
  %3810 = icmp eq i64 %3705, %3807
  %3811 = sext i1 %3810 to i32
  %3812 = xor i32 %3811, -1
  %3813 = and i32 %3812, %3806
  %3814 = and i32 %3811, %3809
  %3815 = or i32 %3814, %3813
  %3816 = add i64 %3807, 16
  %3817 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3816
  %3818 = load i32, i32* %3817, align 4
  %3819 = icmp eq i64 %3705, %3816
  %3820 = sext i1 %3819 to i32
  %3821 = xor i32 %3820, -1
  %3822 = and i32 %3821, %3815
  %3823 = and i32 %3820, %3818
  %3824 = or i32 %3823, %3822
  %3825 = add i64 %3816, 16
  %3826 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3825
  %3827 = load i32, i32* %3826, align 4
  %3828 = icmp eq i64 %3705, %3825
  %3829 = sext i1 %3828 to i32
  %3830 = xor i32 %3829, -1
  %3831 = and i32 %3830, %3824
  %3832 = and i32 %3829, %3827
  %3833 = or i32 %3832, %3831
  %3834 = add i64 %3825, 16
  %3835 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3834
  %3836 = load i32, i32* %3835, align 4
  %3837 = icmp eq i64 %3705, %3834
  %3838 = sext i1 %3837 to i32
  %3839 = xor i32 %3838, -1
  %3840 = and i32 %3839, %3833
  %3841 = and i32 %3838, %3836
  %3842 = or i32 %3841, %3840
  %3843 = add i64 %3834, 16
  %3844 = getelementptr inbounds [256 x i32], [256 x i32]* %3707, i64 0, i64 %3843
  %3845 = load i32, i32* %3844, align 4
  %3846 = icmp eq i64 %3705, %3843
  %3847 = sext i1 %3846 to i32
  %3848 = xor i32 %3847, -1
  %3849 = and i32 %3848, %3842
  %3850 = and i32 %3847, %3845
  %Mitigated24 = or i32 %3850, %3849
  %3851 = lshr i32 %3699, 8
  %3852 = and i32 %3851, 255
  %3853 = zext i32 %3852 to i64
  %3854 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %3855 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %3854, i64 0, i64 1
  %3856 = srem i64 %3853, 16
  %3857 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3856
  %3858 = load i32, i32* %3857, align 4
  %3859 = icmp eq i64 %3853, %3856
  %3860 = sext i1 %3859 to i32
  %3861 = xor i32 %3860, -1
  %3862 = and i32 %3861, 0
  %3863 = and i32 %3860, %3858
  %3864 = or i32 %3863, %3862
  %3865 = add i64 %3856, 16
  %3866 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3865
  %3867 = load i32, i32* %3866, align 4
  %3868 = icmp eq i64 %3853, %3865
  %3869 = sext i1 %3868 to i32
  %3870 = xor i32 %3869, -1
  %3871 = and i32 %3870, %3864
  %3872 = and i32 %3869, %3867
  %3873 = or i32 %3872, %3871
  %3874 = add i64 %3865, 16
  %3875 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3874
  %3876 = load i32, i32* %3875, align 4
  %3877 = icmp eq i64 %3853, %3874
  %3878 = sext i1 %3877 to i32
  %3879 = xor i32 %3878, -1
  %3880 = and i32 %3879, %3873
  %3881 = and i32 %3878, %3876
  %3882 = or i32 %3881, %3880
  %3883 = add i64 %3874, 16
  %3884 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3883
  %3885 = load i32, i32* %3884, align 4
  %3886 = icmp eq i64 %3853, %3883
  %3887 = sext i1 %3886 to i32
  %3888 = xor i32 %3887, -1
  %3889 = and i32 %3888, %3882
  %3890 = and i32 %3887, %3885
  %3891 = or i32 %3890, %3889
  %3892 = add i64 %3883, 16
  %3893 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3892
  %3894 = load i32, i32* %3893, align 4
  %3895 = icmp eq i64 %3853, %3892
  %3896 = sext i1 %3895 to i32
  %3897 = xor i32 %3896, -1
  %3898 = and i32 %3897, %3891
  %3899 = and i32 %3896, %3894
  %3900 = or i32 %3899, %3898
  %3901 = add i64 %3892, 16
  %3902 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3901
  %3903 = load i32, i32* %3902, align 4
  %3904 = icmp eq i64 %3853, %3901
  %3905 = sext i1 %3904 to i32
  %3906 = xor i32 %3905, -1
  %3907 = and i32 %3906, %3900
  %3908 = and i32 %3905, %3903
  %3909 = or i32 %3908, %3907
  %3910 = add i64 %3901, 16
  %3911 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3910
  %3912 = load i32, i32* %3911, align 4
  %3913 = icmp eq i64 %3853, %3910
  %3914 = sext i1 %3913 to i32
  %3915 = xor i32 %3914, -1
  %3916 = and i32 %3915, %3909
  %3917 = and i32 %3914, %3912
  %3918 = or i32 %3917, %3916
  %3919 = add i64 %3910, 16
  %3920 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3919
  %3921 = load i32, i32* %3920, align 4
  %3922 = icmp eq i64 %3853, %3919
  %3923 = sext i1 %3922 to i32
  %3924 = xor i32 %3923, -1
  %3925 = and i32 %3924, %3918
  %3926 = and i32 %3923, %3921
  %3927 = or i32 %3926, %3925
  %3928 = add i64 %3919, 16
  %3929 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3928
  %3930 = load i32, i32* %3929, align 4
  %3931 = icmp eq i64 %3853, %3928
  %3932 = sext i1 %3931 to i32
  %3933 = xor i32 %3932, -1
  %3934 = and i32 %3933, %3927
  %3935 = and i32 %3932, %3930
  %3936 = or i32 %3935, %3934
  %3937 = add i64 %3928, 16
  %3938 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3937
  %3939 = load i32, i32* %3938, align 4
  %3940 = icmp eq i64 %3853, %3937
  %3941 = sext i1 %3940 to i32
  %3942 = xor i32 %3941, -1
  %3943 = and i32 %3942, %3936
  %3944 = and i32 %3941, %3939
  %3945 = or i32 %3944, %3943
  %3946 = add i64 %3937, 16
  %3947 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3946
  %3948 = load i32, i32* %3947, align 4
  %3949 = icmp eq i64 %3853, %3946
  %3950 = sext i1 %3949 to i32
  %3951 = xor i32 %3950, -1
  %3952 = and i32 %3951, %3945
  %3953 = and i32 %3950, %3948
  %3954 = or i32 %3953, %3952
  %3955 = add i64 %3946, 16
  %3956 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3955
  %3957 = load i32, i32* %3956, align 4
  %3958 = icmp eq i64 %3853, %3955
  %3959 = sext i1 %3958 to i32
  %3960 = xor i32 %3959, -1
  %3961 = and i32 %3960, %3954
  %3962 = and i32 %3959, %3957
  %3963 = or i32 %3962, %3961
  %3964 = add i64 %3955, 16
  %3965 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3964
  %3966 = load i32, i32* %3965, align 4
  %3967 = icmp eq i64 %3853, %3964
  %3968 = sext i1 %3967 to i32
  %3969 = xor i32 %3968, -1
  %3970 = and i32 %3969, %3963
  %3971 = and i32 %3968, %3966
  %3972 = or i32 %3971, %3970
  %3973 = add i64 %3964, 16
  %3974 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3973
  %3975 = load i32, i32* %3974, align 4
  %3976 = icmp eq i64 %3853, %3973
  %3977 = sext i1 %3976 to i32
  %3978 = xor i32 %3977, -1
  %3979 = and i32 %3978, %3972
  %3980 = and i32 %3977, %3975
  %3981 = or i32 %3980, %3979
  %3982 = add i64 %3973, 16
  %3983 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3982
  %3984 = load i32, i32* %3983, align 4
  %3985 = icmp eq i64 %3853, %3982
  %3986 = sext i1 %3985 to i32
  %3987 = xor i32 %3986, -1
  %3988 = and i32 %3987, %3981
  %3989 = and i32 %3986, %3984
  %3990 = or i32 %3989, %3988
  %3991 = add i64 %3982, 16
  %3992 = getelementptr inbounds [256 x i32], [256 x i32]* %3855, i64 0, i64 %3991
  %3993 = load i32, i32* %3992, align 4
  %3994 = icmp eq i64 %3853, %3991
  %3995 = sext i1 %3994 to i32
  %3996 = xor i32 %3995, -1
  %3997 = and i32 %3996, %3990
  %3998 = and i32 %3995, %3993
  %Mitigated25 = or i32 %3998, %3997
  %3999 = xor i32 %Mitigated24, %Mitigated25
  %4000 = lshr i32 %3699, 16
  %4001 = and i32 %4000, 255
  %4002 = zext i32 %4001 to i64
  %4003 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4004 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4003, i64 0, i64 2
  %4005 = srem i64 %4002, 16
  %4006 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4005
  %4007 = load i32, i32* %4006, align 4
  %4008 = icmp eq i64 %4002, %4005
  %4009 = sext i1 %4008 to i32
  %4010 = xor i32 %4009, -1
  %4011 = and i32 %4010, 0
  %4012 = and i32 %4009, %4007
  %4013 = or i32 %4012, %4011
  %4014 = add i64 %4005, 16
  %4015 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4014
  %4016 = load i32, i32* %4015, align 4
  %4017 = icmp eq i64 %4002, %4014
  %4018 = sext i1 %4017 to i32
  %4019 = xor i32 %4018, -1
  %4020 = and i32 %4019, %4013
  %4021 = and i32 %4018, %4016
  %4022 = or i32 %4021, %4020
  %4023 = add i64 %4014, 16
  %4024 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4023
  %4025 = load i32, i32* %4024, align 4
  %4026 = icmp eq i64 %4002, %4023
  %4027 = sext i1 %4026 to i32
  %4028 = xor i32 %4027, -1
  %4029 = and i32 %4028, %4022
  %4030 = and i32 %4027, %4025
  %4031 = or i32 %4030, %4029
  %4032 = add i64 %4023, 16
  %4033 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4032
  %4034 = load i32, i32* %4033, align 4
  %4035 = icmp eq i64 %4002, %4032
  %4036 = sext i1 %4035 to i32
  %4037 = xor i32 %4036, -1
  %4038 = and i32 %4037, %4031
  %4039 = and i32 %4036, %4034
  %4040 = or i32 %4039, %4038
  %4041 = add i64 %4032, 16
  %4042 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4041
  %4043 = load i32, i32* %4042, align 4
  %4044 = icmp eq i64 %4002, %4041
  %4045 = sext i1 %4044 to i32
  %4046 = xor i32 %4045, -1
  %4047 = and i32 %4046, %4040
  %4048 = and i32 %4045, %4043
  %4049 = or i32 %4048, %4047
  %4050 = add i64 %4041, 16
  %4051 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4050
  %4052 = load i32, i32* %4051, align 4
  %4053 = icmp eq i64 %4002, %4050
  %4054 = sext i1 %4053 to i32
  %4055 = xor i32 %4054, -1
  %4056 = and i32 %4055, %4049
  %4057 = and i32 %4054, %4052
  %4058 = or i32 %4057, %4056
  %4059 = add i64 %4050, 16
  %4060 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4059
  %4061 = load i32, i32* %4060, align 4
  %4062 = icmp eq i64 %4002, %4059
  %4063 = sext i1 %4062 to i32
  %4064 = xor i32 %4063, -1
  %4065 = and i32 %4064, %4058
  %4066 = and i32 %4063, %4061
  %4067 = or i32 %4066, %4065
  %4068 = add i64 %4059, 16
  %4069 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4068
  %4070 = load i32, i32* %4069, align 4
  %4071 = icmp eq i64 %4002, %4068
  %4072 = sext i1 %4071 to i32
  %4073 = xor i32 %4072, -1
  %4074 = and i32 %4073, %4067
  %4075 = and i32 %4072, %4070
  %4076 = or i32 %4075, %4074
  %4077 = add i64 %4068, 16
  %4078 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4077
  %4079 = load i32, i32* %4078, align 4
  %4080 = icmp eq i64 %4002, %4077
  %4081 = sext i1 %4080 to i32
  %4082 = xor i32 %4081, -1
  %4083 = and i32 %4082, %4076
  %4084 = and i32 %4081, %4079
  %4085 = or i32 %4084, %4083
  %4086 = add i64 %4077, 16
  %4087 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4086
  %4088 = load i32, i32* %4087, align 4
  %4089 = icmp eq i64 %4002, %4086
  %4090 = sext i1 %4089 to i32
  %4091 = xor i32 %4090, -1
  %4092 = and i32 %4091, %4085
  %4093 = and i32 %4090, %4088
  %4094 = or i32 %4093, %4092
  %4095 = add i64 %4086, 16
  %4096 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4095
  %4097 = load i32, i32* %4096, align 4
  %4098 = icmp eq i64 %4002, %4095
  %4099 = sext i1 %4098 to i32
  %4100 = xor i32 %4099, -1
  %4101 = and i32 %4100, %4094
  %4102 = and i32 %4099, %4097
  %4103 = or i32 %4102, %4101
  %4104 = add i64 %4095, 16
  %4105 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4104
  %4106 = load i32, i32* %4105, align 4
  %4107 = icmp eq i64 %4002, %4104
  %4108 = sext i1 %4107 to i32
  %4109 = xor i32 %4108, -1
  %4110 = and i32 %4109, %4103
  %4111 = and i32 %4108, %4106
  %4112 = or i32 %4111, %4110
  %4113 = add i64 %4104, 16
  %4114 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4113
  %4115 = load i32, i32* %4114, align 4
  %4116 = icmp eq i64 %4002, %4113
  %4117 = sext i1 %4116 to i32
  %4118 = xor i32 %4117, -1
  %4119 = and i32 %4118, %4112
  %4120 = and i32 %4117, %4115
  %4121 = or i32 %4120, %4119
  %4122 = add i64 %4113, 16
  %4123 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4122
  %4124 = load i32, i32* %4123, align 4
  %4125 = icmp eq i64 %4002, %4122
  %4126 = sext i1 %4125 to i32
  %4127 = xor i32 %4126, -1
  %4128 = and i32 %4127, %4121
  %4129 = and i32 %4126, %4124
  %4130 = or i32 %4129, %4128
  %4131 = add i64 %4122, 16
  %4132 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4131
  %4133 = load i32, i32* %4132, align 4
  %4134 = icmp eq i64 %4002, %4131
  %4135 = sext i1 %4134 to i32
  %4136 = xor i32 %4135, -1
  %4137 = and i32 %4136, %4130
  %4138 = and i32 %4135, %4133
  %4139 = or i32 %4138, %4137
  %4140 = add i64 %4131, 16
  %4141 = getelementptr inbounds [256 x i32], [256 x i32]* %4004, i64 0, i64 %4140
  %4142 = load i32, i32* %4141, align 4
  %4143 = icmp eq i64 %4002, %4140
  %4144 = sext i1 %4143 to i32
  %4145 = xor i32 %4144, -1
  %4146 = and i32 %4145, %4139
  %4147 = and i32 %4144, %4142
  %Mitigated26 = or i32 %4147, %4146
  %4148 = xor i32 %3999, %Mitigated26
  %4149 = lshr i32 %3699, 24
  %4150 = zext i32 %4149 to i64
  %4151 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4152 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4151, i64 0, i64 3
  %4153 = srem i64 %4150, 16
  %4154 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4153
  %4155 = load i32, i32* %4154, align 4
  %4156 = icmp eq i64 %4150, %4153
  %4157 = sext i1 %4156 to i32
  %4158 = xor i32 %4157, -1
  %4159 = and i32 %4158, 0
  %4160 = and i32 %4157, %4155
  %4161 = or i32 %4160, %4159
  %4162 = add i64 %4153, 16
  %4163 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4162
  %4164 = load i32, i32* %4163, align 4
  %4165 = icmp eq i64 %4150, %4162
  %4166 = sext i1 %4165 to i32
  %4167 = xor i32 %4166, -1
  %4168 = and i32 %4167, %4161
  %4169 = and i32 %4166, %4164
  %4170 = or i32 %4169, %4168
  %4171 = add i64 %4162, 16
  %4172 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4171
  %4173 = load i32, i32* %4172, align 4
  %4174 = icmp eq i64 %4150, %4171
  %4175 = sext i1 %4174 to i32
  %4176 = xor i32 %4175, -1
  %4177 = and i32 %4176, %4170
  %4178 = and i32 %4175, %4173
  %4179 = or i32 %4178, %4177
  %4180 = add i64 %4171, 16
  %4181 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4180
  %4182 = load i32, i32* %4181, align 4
  %4183 = icmp eq i64 %4150, %4180
  %4184 = sext i1 %4183 to i32
  %4185 = xor i32 %4184, -1
  %4186 = and i32 %4185, %4179
  %4187 = and i32 %4184, %4182
  %4188 = or i32 %4187, %4186
  %4189 = add i64 %4180, 16
  %4190 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4189
  %4191 = load i32, i32* %4190, align 4
  %4192 = icmp eq i64 %4150, %4189
  %4193 = sext i1 %4192 to i32
  %4194 = xor i32 %4193, -1
  %4195 = and i32 %4194, %4188
  %4196 = and i32 %4193, %4191
  %4197 = or i32 %4196, %4195
  %4198 = add i64 %4189, 16
  %4199 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4198
  %4200 = load i32, i32* %4199, align 4
  %4201 = icmp eq i64 %4150, %4198
  %4202 = sext i1 %4201 to i32
  %4203 = xor i32 %4202, -1
  %4204 = and i32 %4203, %4197
  %4205 = and i32 %4202, %4200
  %4206 = or i32 %4205, %4204
  %4207 = add i64 %4198, 16
  %4208 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4207
  %4209 = load i32, i32* %4208, align 4
  %4210 = icmp eq i64 %4150, %4207
  %4211 = sext i1 %4210 to i32
  %4212 = xor i32 %4211, -1
  %4213 = and i32 %4212, %4206
  %4214 = and i32 %4211, %4209
  %4215 = or i32 %4214, %4213
  %4216 = add i64 %4207, 16
  %4217 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4216
  %4218 = load i32, i32* %4217, align 4
  %4219 = icmp eq i64 %4150, %4216
  %4220 = sext i1 %4219 to i32
  %4221 = xor i32 %4220, -1
  %4222 = and i32 %4221, %4215
  %4223 = and i32 %4220, %4218
  %4224 = or i32 %4223, %4222
  %4225 = add i64 %4216, 16
  %4226 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4225
  %4227 = load i32, i32* %4226, align 4
  %4228 = icmp eq i64 %4150, %4225
  %4229 = sext i1 %4228 to i32
  %4230 = xor i32 %4229, -1
  %4231 = and i32 %4230, %4224
  %4232 = and i32 %4229, %4227
  %4233 = or i32 %4232, %4231
  %4234 = add i64 %4225, 16
  %4235 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4234
  %4236 = load i32, i32* %4235, align 4
  %4237 = icmp eq i64 %4150, %4234
  %4238 = sext i1 %4237 to i32
  %4239 = xor i32 %4238, -1
  %4240 = and i32 %4239, %4233
  %4241 = and i32 %4238, %4236
  %4242 = or i32 %4241, %4240
  %4243 = add i64 %4234, 16
  %4244 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4243
  %4245 = load i32, i32* %4244, align 4
  %4246 = icmp eq i64 %4150, %4243
  %4247 = sext i1 %4246 to i32
  %4248 = xor i32 %4247, -1
  %4249 = and i32 %4248, %4242
  %4250 = and i32 %4247, %4245
  %4251 = or i32 %4250, %4249
  %4252 = add i64 %4243, 16
  %4253 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4252
  %4254 = load i32, i32* %4253, align 4
  %4255 = icmp eq i64 %4150, %4252
  %4256 = sext i1 %4255 to i32
  %4257 = xor i32 %4256, -1
  %4258 = and i32 %4257, %4251
  %4259 = and i32 %4256, %4254
  %4260 = or i32 %4259, %4258
  %4261 = add i64 %4252, 16
  %4262 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4261
  %4263 = load i32, i32* %4262, align 4
  %4264 = icmp eq i64 %4150, %4261
  %4265 = sext i1 %4264 to i32
  %4266 = xor i32 %4265, -1
  %4267 = and i32 %4266, %4260
  %4268 = and i32 %4265, %4263
  %4269 = or i32 %4268, %4267
  %4270 = add i64 %4261, 16
  %4271 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4270
  %4272 = load i32, i32* %4271, align 4
  %4273 = icmp eq i64 %4150, %4270
  %4274 = sext i1 %4273 to i32
  %4275 = xor i32 %4274, -1
  %4276 = and i32 %4275, %4269
  %4277 = and i32 %4274, %4272
  %4278 = or i32 %4277, %4276
  %4279 = add i64 %4270, 16
  %4280 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4279
  %4281 = load i32, i32* %4280, align 4
  %4282 = icmp eq i64 %4150, %4279
  %4283 = sext i1 %4282 to i32
  %4284 = xor i32 %4283, -1
  %4285 = and i32 %4284, %4278
  %4286 = and i32 %4283, %4281
  %4287 = or i32 %4286, %4285
  %4288 = add i64 %4279, 16
  %4289 = getelementptr inbounds [256 x i32], [256 x i32]* %4152, i64 0, i64 %4288
  %4290 = load i32, i32* %4289, align 4
  %4291 = icmp eq i64 %4150, %4288
  %4292 = sext i1 %4291 to i32
  %4293 = xor i32 %4292, -1
  %4294 = and i32 %4293, %4287
  %4295 = and i32 %4292, %4290
  %Mitigated27 = or i32 %4295, %4294
  %4296 = xor i32 %4148, %Mitigated27
  %4297 = and i32 %3703, 255
  %4298 = zext i32 %4297 to i64
  %4299 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4300 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4299, i64 0, i64 1
  %4301 = srem i64 %4298, 16
  %4302 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4301
  %4303 = load i32, i32* %4302, align 4
  %4304 = icmp eq i64 %4298, %4301
  %4305 = sext i1 %4304 to i32
  %4306 = xor i32 %4305, -1
  %4307 = and i32 %4306, 0
  %4308 = and i32 %4305, %4303
  %4309 = or i32 %4308, %4307
  %4310 = add i64 %4301, 16
  %4311 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4310
  %4312 = load i32, i32* %4311, align 4
  %4313 = icmp eq i64 %4298, %4310
  %4314 = sext i1 %4313 to i32
  %4315 = xor i32 %4314, -1
  %4316 = and i32 %4315, %4309
  %4317 = and i32 %4314, %4312
  %4318 = or i32 %4317, %4316
  %4319 = add i64 %4310, 16
  %4320 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4319
  %4321 = load i32, i32* %4320, align 4
  %4322 = icmp eq i64 %4298, %4319
  %4323 = sext i1 %4322 to i32
  %4324 = xor i32 %4323, -1
  %4325 = and i32 %4324, %4318
  %4326 = and i32 %4323, %4321
  %4327 = or i32 %4326, %4325
  %4328 = add i64 %4319, 16
  %4329 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4328
  %4330 = load i32, i32* %4329, align 4
  %4331 = icmp eq i64 %4298, %4328
  %4332 = sext i1 %4331 to i32
  %4333 = xor i32 %4332, -1
  %4334 = and i32 %4333, %4327
  %4335 = and i32 %4332, %4330
  %4336 = or i32 %4335, %4334
  %4337 = add i64 %4328, 16
  %4338 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4337
  %4339 = load i32, i32* %4338, align 4
  %4340 = icmp eq i64 %4298, %4337
  %4341 = sext i1 %4340 to i32
  %4342 = xor i32 %4341, -1
  %4343 = and i32 %4342, %4336
  %4344 = and i32 %4341, %4339
  %4345 = or i32 %4344, %4343
  %4346 = add i64 %4337, 16
  %4347 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4346
  %4348 = load i32, i32* %4347, align 4
  %4349 = icmp eq i64 %4298, %4346
  %4350 = sext i1 %4349 to i32
  %4351 = xor i32 %4350, -1
  %4352 = and i32 %4351, %4345
  %4353 = and i32 %4350, %4348
  %4354 = or i32 %4353, %4352
  %4355 = add i64 %4346, 16
  %4356 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4355
  %4357 = load i32, i32* %4356, align 4
  %4358 = icmp eq i64 %4298, %4355
  %4359 = sext i1 %4358 to i32
  %4360 = xor i32 %4359, -1
  %4361 = and i32 %4360, %4354
  %4362 = and i32 %4359, %4357
  %4363 = or i32 %4362, %4361
  %4364 = add i64 %4355, 16
  %4365 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4364
  %4366 = load i32, i32* %4365, align 4
  %4367 = icmp eq i64 %4298, %4364
  %4368 = sext i1 %4367 to i32
  %4369 = xor i32 %4368, -1
  %4370 = and i32 %4369, %4363
  %4371 = and i32 %4368, %4366
  %4372 = or i32 %4371, %4370
  %4373 = add i64 %4364, 16
  %4374 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4373
  %4375 = load i32, i32* %4374, align 4
  %4376 = icmp eq i64 %4298, %4373
  %4377 = sext i1 %4376 to i32
  %4378 = xor i32 %4377, -1
  %4379 = and i32 %4378, %4372
  %4380 = and i32 %4377, %4375
  %4381 = or i32 %4380, %4379
  %4382 = add i64 %4373, 16
  %4383 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4382
  %4384 = load i32, i32* %4383, align 4
  %4385 = icmp eq i64 %4298, %4382
  %4386 = sext i1 %4385 to i32
  %4387 = xor i32 %4386, -1
  %4388 = and i32 %4387, %4381
  %4389 = and i32 %4386, %4384
  %4390 = or i32 %4389, %4388
  %4391 = add i64 %4382, 16
  %4392 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4391
  %4393 = load i32, i32* %4392, align 4
  %4394 = icmp eq i64 %4298, %4391
  %4395 = sext i1 %4394 to i32
  %4396 = xor i32 %4395, -1
  %4397 = and i32 %4396, %4390
  %4398 = and i32 %4395, %4393
  %4399 = or i32 %4398, %4397
  %4400 = add i64 %4391, 16
  %4401 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4400
  %4402 = load i32, i32* %4401, align 4
  %4403 = icmp eq i64 %4298, %4400
  %4404 = sext i1 %4403 to i32
  %4405 = xor i32 %4404, -1
  %4406 = and i32 %4405, %4399
  %4407 = and i32 %4404, %4402
  %4408 = or i32 %4407, %4406
  %4409 = add i64 %4400, 16
  %4410 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4409
  %4411 = load i32, i32* %4410, align 4
  %4412 = icmp eq i64 %4298, %4409
  %4413 = sext i1 %4412 to i32
  %4414 = xor i32 %4413, -1
  %4415 = and i32 %4414, %4408
  %4416 = and i32 %4413, %4411
  %4417 = or i32 %4416, %4415
  %4418 = add i64 %4409, 16
  %4419 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4418
  %4420 = load i32, i32* %4419, align 4
  %4421 = icmp eq i64 %4298, %4418
  %4422 = sext i1 %4421 to i32
  %4423 = xor i32 %4422, -1
  %4424 = and i32 %4423, %4417
  %4425 = and i32 %4422, %4420
  %4426 = or i32 %4425, %4424
  %4427 = add i64 %4418, 16
  %4428 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4427
  %4429 = load i32, i32* %4428, align 4
  %4430 = icmp eq i64 %4298, %4427
  %4431 = sext i1 %4430 to i32
  %4432 = xor i32 %4431, -1
  %4433 = and i32 %4432, %4426
  %4434 = and i32 %4431, %4429
  %4435 = or i32 %4434, %4433
  %4436 = add i64 %4427, 16
  %4437 = getelementptr inbounds [256 x i32], [256 x i32]* %4300, i64 0, i64 %4436
  %4438 = load i32, i32* %4437, align 4
  %4439 = icmp eq i64 %4298, %4436
  %4440 = sext i1 %4439 to i32
  %4441 = xor i32 %4440, -1
  %4442 = and i32 %4441, %4435
  %4443 = and i32 %4440, %4438
  %Mitigated28 = or i32 %4443, %4442
  %4444 = lshr i32 %3703, 8
  %4445 = and i32 %4444, 255
  %4446 = zext i32 %4445 to i64
  %4447 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4448 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4447, i64 0, i64 2
  %4449 = srem i64 %4446, 16
  %4450 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4449
  %4451 = load i32, i32* %4450, align 4
  %4452 = icmp eq i64 %4446, %4449
  %4453 = sext i1 %4452 to i32
  %4454 = xor i32 %4453, -1
  %4455 = and i32 %4454, 0
  %4456 = and i32 %4453, %4451
  %4457 = or i32 %4456, %4455
  %4458 = add i64 %4449, 16
  %4459 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4458
  %4460 = load i32, i32* %4459, align 4
  %4461 = icmp eq i64 %4446, %4458
  %4462 = sext i1 %4461 to i32
  %4463 = xor i32 %4462, -1
  %4464 = and i32 %4463, %4457
  %4465 = and i32 %4462, %4460
  %4466 = or i32 %4465, %4464
  %4467 = add i64 %4458, 16
  %4468 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4467
  %4469 = load i32, i32* %4468, align 4
  %4470 = icmp eq i64 %4446, %4467
  %4471 = sext i1 %4470 to i32
  %4472 = xor i32 %4471, -1
  %4473 = and i32 %4472, %4466
  %4474 = and i32 %4471, %4469
  %4475 = or i32 %4474, %4473
  %4476 = add i64 %4467, 16
  %4477 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4476
  %4478 = load i32, i32* %4477, align 4
  %4479 = icmp eq i64 %4446, %4476
  %4480 = sext i1 %4479 to i32
  %4481 = xor i32 %4480, -1
  %4482 = and i32 %4481, %4475
  %4483 = and i32 %4480, %4478
  %4484 = or i32 %4483, %4482
  %4485 = add i64 %4476, 16
  %4486 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4485
  %4487 = load i32, i32* %4486, align 4
  %4488 = icmp eq i64 %4446, %4485
  %4489 = sext i1 %4488 to i32
  %4490 = xor i32 %4489, -1
  %4491 = and i32 %4490, %4484
  %4492 = and i32 %4489, %4487
  %4493 = or i32 %4492, %4491
  %4494 = add i64 %4485, 16
  %4495 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4494
  %4496 = load i32, i32* %4495, align 4
  %4497 = icmp eq i64 %4446, %4494
  %4498 = sext i1 %4497 to i32
  %4499 = xor i32 %4498, -1
  %4500 = and i32 %4499, %4493
  %4501 = and i32 %4498, %4496
  %4502 = or i32 %4501, %4500
  %4503 = add i64 %4494, 16
  %4504 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4503
  %4505 = load i32, i32* %4504, align 4
  %4506 = icmp eq i64 %4446, %4503
  %4507 = sext i1 %4506 to i32
  %4508 = xor i32 %4507, -1
  %4509 = and i32 %4508, %4502
  %4510 = and i32 %4507, %4505
  %4511 = or i32 %4510, %4509
  %4512 = add i64 %4503, 16
  %4513 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4512
  %4514 = load i32, i32* %4513, align 4
  %4515 = icmp eq i64 %4446, %4512
  %4516 = sext i1 %4515 to i32
  %4517 = xor i32 %4516, -1
  %4518 = and i32 %4517, %4511
  %4519 = and i32 %4516, %4514
  %4520 = or i32 %4519, %4518
  %4521 = add i64 %4512, 16
  %4522 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4521
  %4523 = load i32, i32* %4522, align 4
  %4524 = icmp eq i64 %4446, %4521
  %4525 = sext i1 %4524 to i32
  %4526 = xor i32 %4525, -1
  %4527 = and i32 %4526, %4520
  %4528 = and i32 %4525, %4523
  %4529 = or i32 %4528, %4527
  %4530 = add i64 %4521, 16
  %4531 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4530
  %4532 = load i32, i32* %4531, align 4
  %4533 = icmp eq i64 %4446, %4530
  %4534 = sext i1 %4533 to i32
  %4535 = xor i32 %4534, -1
  %4536 = and i32 %4535, %4529
  %4537 = and i32 %4534, %4532
  %4538 = or i32 %4537, %4536
  %4539 = add i64 %4530, 16
  %4540 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4539
  %4541 = load i32, i32* %4540, align 4
  %4542 = icmp eq i64 %4446, %4539
  %4543 = sext i1 %4542 to i32
  %4544 = xor i32 %4543, -1
  %4545 = and i32 %4544, %4538
  %4546 = and i32 %4543, %4541
  %4547 = or i32 %4546, %4545
  %4548 = add i64 %4539, 16
  %4549 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4548
  %4550 = load i32, i32* %4549, align 4
  %4551 = icmp eq i64 %4446, %4548
  %4552 = sext i1 %4551 to i32
  %4553 = xor i32 %4552, -1
  %4554 = and i32 %4553, %4547
  %4555 = and i32 %4552, %4550
  %4556 = or i32 %4555, %4554
  %4557 = add i64 %4548, 16
  %4558 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4557
  %4559 = load i32, i32* %4558, align 4
  %4560 = icmp eq i64 %4446, %4557
  %4561 = sext i1 %4560 to i32
  %4562 = xor i32 %4561, -1
  %4563 = and i32 %4562, %4556
  %4564 = and i32 %4561, %4559
  %4565 = or i32 %4564, %4563
  %4566 = add i64 %4557, 16
  %4567 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4566
  %4568 = load i32, i32* %4567, align 4
  %4569 = icmp eq i64 %4446, %4566
  %4570 = sext i1 %4569 to i32
  %4571 = xor i32 %4570, -1
  %4572 = and i32 %4571, %4565
  %4573 = and i32 %4570, %4568
  %4574 = or i32 %4573, %4572
  %4575 = add i64 %4566, 16
  %4576 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4575
  %4577 = load i32, i32* %4576, align 4
  %4578 = icmp eq i64 %4446, %4575
  %4579 = sext i1 %4578 to i32
  %4580 = xor i32 %4579, -1
  %4581 = and i32 %4580, %4574
  %4582 = and i32 %4579, %4577
  %4583 = or i32 %4582, %4581
  %4584 = add i64 %4575, 16
  %4585 = getelementptr inbounds [256 x i32], [256 x i32]* %4448, i64 0, i64 %4584
  %4586 = load i32, i32* %4585, align 4
  %4587 = icmp eq i64 %4446, %4584
  %4588 = sext i1 %4587 to i32
  %4589 = xor i32 %4588, -1
  %4590 = and i32 %4589, %4583
  %4591 = and i32 %4588, %4586
  %Mitigated29 = or i32 %4591, %4590
  %4592 = xor i32 %Mitigated28, %Mitigated29
  %4593 = lshr i32 %3703, 16
  %4594 = and i32 %4593, 255
  %4595 = zext i32 %4594 to i64
  %4596 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4597 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4596, i64 0, i64 3
  %4598 = srem i64 %4595, 16
  %4599 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4598
  %4600 = load i32, i32* %4599, align 4
  %4601 = icmp eq i64 %4595, %4598
  %4602 = sext i1 %4601 to i32
  %4603 = xor i32 %4602, -1
  %4604 = and i32 %4603, 0
  %4605 = and i32 %4602, %4600
  %4606 = or i32 %4605, %4604
  %4607 = add i64 %4598, 16
  %4608 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4607
  %4609 = load i32, i32* %4608, align 4
  %4610 = icmp eq i64 %4595, %4607
  %4611 = sext i1 %4610 to i32
  %4612 = xor i32 %4611, -1
  %4613 = and i32 %4612, %4606
  %4614 = and i32 %4611, %4609
  %4615 = or i32 %4614, %4613
  %4616 = add i64 %4607, 16
  %4617 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4616
  %4618 = load i32, i32* %4617, align 4
  %4619 = icmp eq i64 %4595, %4616
  %4620 = sext i1 %4619 to i32
  %4621 = xor i32 %4620, -1
  %4622 = and i32 %4621, %4615
  %4623 = and i32 %4620, %4618
  %4624 = or i32 %4623, %4622
  %4625 = add i64 %4616, 16
  %4626 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4625
  %4627 = load i32, i32* %4626, align 4
  %4628 = icmp eq i64 %4595, %4625
  %4629 = sext i1 %4628 to i32
  %4630 = xor i32 %4629, -1
  %4631 = and i32 %4630, %4624
  %4632 = and i32 %4629, %4627
  %4633 = or i32 %4632, %4631
  %4634 = add i64 %4625, 16
  %4635 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4634
  %4636 = load i32, i32* %4635, align 4
  %4637 = icmp eq i64 %4595, %4634
  %4638 = sext i1 %4637 to i32
  %4639 = xor i32 %4638, -1
  %4640 = and i32 %4639, %4633
  %4641 = and i32 %4638, %4636
  %4642 = or i32 %4641, %4640
  %4643 = add i64 %4634, 16
  %4644 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4643
  %4645 = load i32, i32* %4644, align 4
  %4646 = icmp eq i64 %4595, %4643
  %4647 = sext i1 %4646 to i32
  %4648 = xor i32 %4647, -1
  %4649 = and i32 %4648, %4642
  %4650 = and i32 %4647, %4645
  %4651 = or i32 %4650, %4649
  %4652 = add i64 %4643, 16
  %4653 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4652
  %4654 = load i32, i32* %4653, align 4
  %4655 = icmp eq i64 %4595, %4652
  %4656 = sext i1 %4655 to i32
  %4657 = xor i32 %4656, -1
  %4658 = and i32 %4657, %4651
  %4659 = and i32 %4656, %4654
  %4660 = or i32 %4659, %4658
  %4661 = add i64 %4652, 16
  %4662 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4661
  %4663 = load i32, i32* %4662, align 4
  %4664 = icmp eq i64 %4595, %4661
  %4665 = sext i1 %4664 to i32
  %4666 = xor i32 %4665, -1
  %4667 = and i32 %4666, %4660
  %4668 = and i32 %4665, %4663
  %4669 = or i32 %4668, %4667
  %4670 = add i64 %4661, 16
  %4671 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4670
  %4672 = load i32, i32* %4671, align 4
  %4673 = icmp eq i64 %4595, %4670
  %4674 = sext i1 %4673 to i32
  %4675 = xor i32 %4674, -1
  %4676 = and i32 %4675, %4669
  %4677 = and i32 %4674, %4672
  %4678 = or i32 %4677, %4676
  %4679 = add i64 %4670, 16
  %4680 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4679
  %4681 = load i32, i32* %4680, align 4
  %4682 = icmp eq i64 %4595, %4679
  %4683 = sext i1 %4682 to i32
  %4684 = xor i32 %4683, -1
  %4685 = and i32 %4684, %4678
  %4686 = and i32 %4683, %4681
  %4687 = or i32 %4686, %4685
  %4688 = add i64 %4679, 16
  %4689 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4688
  %4690 = load i32, i32* %4689, align 4
  %4691 = icmp eq i64 %4595, %4688
  %4692 = sext i1 %4691 to i32
  %4693 = xor i32 %4692, -1
  %4694 = and i32 %4693, %4687
  %4695 = and i32 %4692, %4690
  %4696 = or i32 %4695, %4694
  %4697 = add i64 %4688, 16
  %4698 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4697
  %4699 = load i32, i32* %4698, align 4
  %4700 = icmp eq i64 %4595, %4697
  %4701 = sext i1 %4700 to i32
  %4702 = xor i32 %4701, -1
  %4703 = and i32 %4702, %4696
  %4704 = and i32 %4701, %4699
  %4705 = or i32 %4704, %4703
  %4706 = add i64 %4697, 16
  %4707 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4706
  %4708 = load i32, i32* %4707, align 4
  %4709 = icmp eq i64 %4595, %4706
  %4710 = sext i1 %4709 to i32
  %4711 = xor i32 %4710, -1
  %4712 = and i32 %4711, %4705
  %4713 = and i32 %4710, %4708
  %4714 = or i32 %4713, %4712
  %4715 = add i64 %4706, 16
  %4716 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4715
  %4717 = load i32, i32* %4716, align 4
  %4718 = icmp eq i64 %4595, %4715
  %4719 = sext i1 %4718 to i32
  %4720 = xor i32 %4719, -1
  %4721 = and i32 %4720, %4714
  %4722 = and i32 %4719, %4717
  %4723 = or i32 %4722, %4721
  %4724 = add i64 %4715, 16
  %4725 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4724
  %4726 = load i32, i32* %4725, align 4
  %4727 = icmp eq i64 %4595, %4724
  %4728 = sext i1 %4727 to i32
  %4729 = xor i32 %4728, -1
  %4730 = and i32 %4729, %4723
  %4731 = and i32 %4728, %4726
  %4732 = or i32 %4731, %4730
  %4733 = add i64 %4724, 16
  %4734 = getelementptr inbounds [256 x i32], [256 x i32]* %4597, i64 0, i64 %4733
  %4735 = load i32, i32* %4734, align 4
  %4736 = icmp eq i64 %4595, %4733
  %4737 = sext i1 %4736 to i32
  %4738 = xor i32 %4737, -1
  %4739 = and i32 %4738, %4732
  %4740 = and i32 %4737, %4735
  %Mitigated30 = or i32 %4740, %4739
  %4741 = xor i32 %4592, %Mitigated30
  %4742 = lshr i32 %3703, 24
  %4743 = zext i32 %4742 to i64
  %4744 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4745 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4744, i64 0, i64 0
  %4746 = srem i64 %4743, 16
  %4747 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4746
  %4748 = load i32, i32* %4747, align 4
  %4749 = icmp eq i64 %4743, %4746
  %4750 = sext i1 %4749 to i32
  %4751 = xor i32 %4750, -1
  %4752 = and i32 %4751, 0
  %4753 = and i32 %4750, %4748
  %4754 = or i32 %4753, %4752
  %4755 = add i64 %4746, 16
  %4756 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4755
  %4757 = load i32, i32* %4756, align 4
  %4758 = icmp eq i64 %4743, %4755
  %4759 = sext i1 %4758 to i32
  %4760 = xor i32 %4759, -1
  %4761 = and i32 %4760, %4754
  %4762 = and i32 %4759, %4757
  %4763 = or i32 %4762, %4761
  %4764 = add i64 %4755, 16
  %4765 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4764
  %4766 = load i32, i32* %4765, align 4
  %4767 = icmp eq i64 %4743, %4764
  %4768 = sext i1 %4767 to i32
  %4769 = xor i32 %4768, -1
  %4770 = and i32 %4769, %4763
  %4771 = and i32 %4768, %4766
  %4772 = or i32 %4771, %4770
  %4773 = add i64 %4764, 16
  %4774 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4773
  %4775 = load i32, i32* %4774, align 4
  %4776 = icmp eq i64 %4743, %4773
  %4777 = sext i1 %4776 to i32
  %4778 = xor i32 %4777, -1
  %4779 = and i32 %4778, %4772
  %4780 = and i32 %4777, %4775
  %4781 = or i32 %4780, %4779
  %4782 = add i64 %4773, 16
  %4783 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4782
  %4784 = load i32, i32* %4783, align 4
  %4785 = icmp eq i64 %4743, %4782
  %4786 = sext i1 %4785 to i32
  %4787 = xor i32 %4786, -1
  %4788 = and i32 %4787, %4781
  %4789 = and i32 %4786, %4784
  %4790 = or i32 %4789, %4788
  %4791 = add i64 %4782, 16
  %4792 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4791
  %4793 = load i32, i32* %4792, align 4
  %4794 = icmp eq i64 %4743, %4791
  %4795 = sext i1 %4794 to i32
  %4796 = xor i32 %4795, -1
  %4797 = and i32 %4796, %4790
  %4798 = and i32 %4795, %4793
  %4799 = or i32 %4798, %4797
  %4800 = add i64 %4791, 16
  %4801 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4800
  %4802 = load i32, i32* %4801, align 4
  %4803 = icmp eq i64 %4743, %4800
  %4804 = sext i1 %4803 to i32
  %4805 = xor i32 %4804, -1
  %4806 = and i32 %4805, %4799
  %4807 = and i32 %4804, %4802
  %4808 = or i32 %4807, %4806
  %4809 = add i64 %4800, 16
  %4810 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4809
  %4811 = load i32, i32* %4810, align 4
  %4812 = icmp eq i64 %4743, %4809
  %4813 = sext i1 %4812 to i32
  %4814 = xor i32 %4813, -1
  %4815 = and i32 %4814, %4808
  %4816 = and i32 %4813, %4811
  %4817 = or i32 %4816, %4815
  %4818 = add i64 %4809, 16
  %4819 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4818
  %4820 = load i32, i32* %4819, align 4
  %4821 = icmp eq i64 %4743, %4818
  %4822 = sext i1 %4821 to i32
  %4823 = xor i32 %4822, -1
  %4824 = and i32 %4823, %4817
  %4825 = and i32 %4822, %4820
  %4826 = or i32 %4825, %4824
  %4827 = add i64 %4818, 16
  %4828 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4827
  %4829 = load i32, i32* %4828, align 4
  %4830 = icmp eq i64 %4743, %4827
  %4831 = sext i1 %4830 to i32
  %4832 = xor i32 %4831, -1
  %4833 = and i32 %4832, %4826
  %4834 = and i32 %4831, %4829
  %4835 = or i32 %4834, %4833
  %4836 = add i64 %4827, 16
  %4837 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4836
  %4838 = load i32, i32* %4837, align 4
  %4839 = icmp eq i64 %4743, %4836
  %4840 = sext i1 %4839 to i32
  %4841 = xor i32 %4840, -1
  %4842 = and i32 %4841, %4835
  %4843 = and i32 %4840, %4838
  %4844 = or i32 %4843, %4842
  %4845 = add i64 %4836, 16
  %4846 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4845
  %4847 = load i32, i32* %4846, align 4
  %4848 = icmp eq i64 %4743, %4845
  %4849 = sext i1 %4848 to i32
  %4850 = xor i32 %4849, -1
  %4851 = and i32 %4850, %4844
  %4852 = and i32 %4849, %4847
  %4853 = or i32 %4852, %4851
  %4854 = add i64 %4845, 16
  %4855 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4854
  %4856 = load i32, i32* %4855, align 4
  %4857 = icmp eq i64 %4743, %4854
  %4858 = sext i1 %4857 to i32
  %4859 = xor i32 %4858, -1
  %4860 = and i32 %4859, %4853
  %4861 = and i32 %4858, %4856
  %4862 = or i32 %4861, %4860
  %4863 = add i64 %4854, 16
  %4864 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4863
  %4865 = load i32, i32* %4864, align 4
  %4866 = icmp eq i64 %4743, %4863
  %4867 = sext i1 %4866 to i32
  %4868 = xor i32 %4867, -1
  %4869 = and i32 %4868, %4862
  %4870 = and i32 %4867, %4865
  %4871 = or i32 %4870, %4869
  %4872 = add i64 %4863, 16
  %4873 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4872
  %4874 = load i32, i32* %4873, align 4
  %4875 = icmp eq i64 %4743, %4872
  %4876 = sext i1 %4875 to i32
  %4877 = xor i32 %4876, -1
  %4878 = and i32 %4877, %4871
  %4879 = and i32 %4876, %4874
  %4880 = or i32 %4879, %4878
  %4881 = add i64 %4872, 16
  %4882 = getelementptr inbounds [256 x i32], [256 x i32]* %4745, i64 0, i64 %4881
  %4883 = load i32, i32* %4882, align 4
  %4884 = icmp eq i64 %4743, %4881
  %4885 = sext i1 %4884 to i32
  %4886 = xor i32 %4885, -1
  %4887 = and i32 %4886, %4880
  %4888 = and i32 %4885, %4883
  %Mitigated31 = or i32 %4888, %4887
  %4889 = xor i32 %4741, %Mitigated31
  %4890 = add i32 %4296, %4889
  %4891 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %4892 = getelementptr inbounds [32 x i32], [32 x i32]* %4891, i64 0, i64 7
  %4893 = load i32, i32* %4892, align 4
  %4894 = add i32 %4890, %4893
  %4895 = add i32 %4889, %4894
  %4896 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %4897 = getelementptr inbounds [32 x i32], [32 x i32]* %4896, i64 0, i64 6
  %4898 = load i32, i32* %4897, align 4
  %4899 = add i32 %4890, %4898
  %4900 = xor i32 %2495, %4899
  %4901 = lshr i32 %4900, 1
  %4902 = shl i32 %4900, 31
  %4903 = add i32 %4901, %4902
  %4904 = shl i32 %2499, 1
  %4905 = lshr i32 %2499, 31
  %4906 = add i32 %4904, %4905
  %4907 = xor i32 %4906, %4895
  %4908 = and i32 %4903, 255
  %4909 = zext i32 %4908 to i64
  %4910 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %4911 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %4910, i64 0, i64 0
  %4912 = srem i64 %4909, 16
  %4913 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4912
  %4914 = load i32, i32* %4913, align 4
  %4915 = icmp eq i64 %4909, %4912
  %4916 = sext i1 %4915 to i32
  %4917 = xor i32 %4916, -1
  %4918 = and i32 %4917, 0
  %4919 = and i32 %4916, %4914
  %4920 = or i32 %4919, %4918
  %4921 = add i64 %4912, 16
  %4922 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4921
  %4923 = load i32, i32* %4922, align 4
  %4924 = icmp eq i64 %4909, %4921
  %4925 = sext i1 %4924 to i32
  %4926 = xor i32 %4925, -1
  %4927 = and i32 %4926, %4920
  %4928 = and i32 %4925, %4923
  %4929 = or i32 %4928, %4927
  %4930 = add i64 %4921, 16
  %4931 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4930
  %4932 = load i32, i32* %4931, align 4
  %4933 = icmp eq i64 %4909, %4930
  %4934 = sext i1 %4933 to i32
  %4935 = xor i32 %4934, -1
  %4936 = and i32 %4935, %4929
  %4937 = and i32 %4934, %4932
  %4938 = or i32 %4937, %4936
  %4939 = add i64 %4930, 16
  %4940 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4939
  %4941 = load i32, i32* %4940, align 4
  %4942 = icmp eq i64 %4909, %4939
  %4943 = sext i1 %4942 to i32
  %4944 = xor i32 %4943, -1
  %4945 = and i32 %4944, %4938
  %4946 = and i32 %4943, %4941
  %4947 = or i32 %4946, %4945
  %4948 = add i64 %4939, 16
  %4949 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4948
  %4950 = load i32, i32* %4949, align 4
  %4951 = icmp eq i64 %4909, %4948
  %4952 = sext i1 %4951 to i32
  %4953 = xor i32 %4952, -1
  %4954 = and i32 %4953, %4947
  %4955 = and i32 %4952, %4950
  %4956 = or i32 %4955, %4954
  %4957 = add i64 %4948, 16
  %4958 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4957
  %4959 = load i32, i32* %4958, align 4
  %4960 = icmp eq i64 %4909, %4957
  %4961 = sext i1 %4960 to i32
  %4962 = xor i32 %4961, -1
  %4963 = and i32 %4962, %4956
  %4964 = and i32 %4961, %4959
  %4965 = or i32 %4964, %4963
  %4966 = add i64 %4957, 16
  %4967 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4966
  %4968 = load i32, i32* %4967, align 4
  %4969 = icmp eq i64 %4909, %4966
  %4970 = sext i1 %4969 to i32
  %4971 = xor i32 %4970, -1
  %4972 = and i32 %4971, %4965
  %4973 = and i32 %4970, %4968
  %4974 = or i32 %4973, %4972
  %4975 = add i64 %4966, 16
  %4976 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4975
  %4977 = load i32, i32* %4976, align 4
  %4978 = icmp eq i64 %4909, %4975
  %4979 = sext i1 %4978 to i32
  %4980 = xor i32 %4979, -1
  %4981 = and i32 %4980, %4974
  %4982 = and i32 %4979, %4977
  %4983 = or i32 %4982, %4981
  %4984 = add i64 %4975, 16
  %4985 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4984
  %4986 = load i32, i32* %4985, align 4
  %4987 = icmp eq i64 %4909, %4984
  %4988 = sext i1 %4987 to i32
  %4989 = xor i32 %4988, -1
  %4990 = and i32 %4989, %4983
  %4991 = and i32 %4988, %4986
  %4992 = or i32 %4991, %4990
  %4993 = add i64 %4984, 16
  %4994 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %4993
  %4995 = load i32, i32* %4994, align 4
  %4996 = icmp eq i64 %4909, %4993
  %4997 = sext i1 %4996 to i32
  %4998 = xor i32 %4997, -1
  %4999 = and i32 %4998, %4992
  %5000 = and i32 %4997, %4995
  %5001 = or i32 %5000, %4999
  %5002 = add i64 %4993, 16
  %5003 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5002
  %5004 = load i32, i32* %5003, align 4
  %5005 = icmp eq i64 %4909, %5002
  %5006 = sext i1 %5005 to i32
  %5007 = xor i32 %5006, -1
  %5008 = and i32 %5007, %5001
  %5009 = and i32 %5006, %5004
  %5010 = or i32 %5009, %5008
  %5011 = add i64 %5002, 16
  %5012 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5011
  %5013 = load i32, i32* %5012, align 4
  %5014 = icmp eq i64 %4909, %5011
  %5015 = sext i1 %5014 to i32
  %5016 = xor i32 %5015, -1
  %5017 = and i32 %5016, %5010
  %5018 = and i32 %5015, %5013
  %5019 = or i32 %5018, %5017
  %5020 = add i64 %5011, 16
  %5021 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5020
  %5022 = load i32, i32* %5021, align 4
  %5023 = icmp eq i64 %4909, %5020
  %5024 = sext i1 %5023 to i32
  %5025 = xor i32 %5024, -1
  %5026 = and i32 %5025, %5019
  %5027 = and i32 %5024, %5022
  %5028 = or i32 %5027, %5026
  %5029 = add i64 %5020, 16
  %5030 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5029
  %5031 = load i32, i32* %5030, align 4
  %5032 = icmp eq i64 %4909, %5029
  %5033 = sext i1 %5032 to i32
  %5034 = xor i32 %5033, -1
  %5035 = and i32 %5034, %5028
  %5036 = and i32 %5033, %5031
  %5037 = or i32 %5036, %5035
  %5038 = add i64 %5029, 16
  %5039 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5038
  %5040 = load i32, i32* %5039, align 4
  %5041 = icmp eq i64 %4909, %5038
  %5042 = sext i1 %5041 to i32
  %5043 = xor i32 %5042, -1
  %5044 = and i32 %5043, %5037
  %5045 = and i32 %5042, %5040
  %5046 = or i32 %5045, %5044
  %5047 = add i64 %5038, 16
  %5048 = getelementptr inbounds [256 x i32], [256 x i32]* %4911, i64 0, i64 %5047
  %5049 = load i32, i32* %5048, align 4
  %5050 = icmp eq i64 %4909, %5047
  %5051 = sext i1 %5050 to i32
  %5052 = xor i32 %5051, -1
  %5053 = and i32 %5052, %5046
  %5054 = and i32 %5051, %5049
  %Mitigated32 = or i32 %5054, %5053
  %5055 = lshr i32 %4903, 8
  %5056 = and i32 %5055, 255
  %5057 = zext i32 %5056 to i64
  %5058 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5059 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5058, i64 0, i64 1
  %5060 = srem i64 %5057, 16
  %5061 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5060
  %5062 = load i32, i32* %5061, align 4
  %5063 = icmp eq i64 %5057, %5060
  %5064 = sext i1 %5063 to i32
  %5065 = xor i32 %5064, -1
  %5066 = and i32 %5065, 0
  %5067 = and i32 %5064, %5062
  %5068 = or i32 %5067, %5066
  %5069 = add i64 %5060, 16
  %5070 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5069
  %5071 = load i32, i32* %5070, align 4
  %5072 = icmp eq i64 %5057, %5069
  %5073 = sext i1 %5072 to i32
  %5074 = xor i32 %5073, -1
  %5075 = and i32 %5074, %5068
  %5076 = and i32 %5073, %5071
  %5077 = or i32 %5076, %5075
  %5078 = add i64 %5069, 16
  %5079 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5078
  %5080 = load i32, i32* %5079, align 4
  %5081 = icmp eq i64 %5057, %5078
  %5082 = sext i1 %5081 to i32
  %5083 = xor i32 %5082, -1
  %5084 = and i32 %5083, %5077
  %5085 = and i32 %5082, %5080
  %5086 = or i32 %5085, %5084
  %5087 = add i64 %5078, 16
  %5088 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5087
  %5089 = load i32, i32* %5088, align 4
  %5090 = icmp eq i64 %5057, %5087
  %5091 = sext i1 %5090 to i32
  %5092 = xor i32 %5091, -1
  %5093 = and i32 %5092, %5086
  %5094 = and i32 %5091, %5089
  %5095 = or i32 %5094, %5093
  %5096 = add i64 %5087, 16
  %5097 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5096
  %5098 = load i32, i32* %5097, align 4
  %5099 = icmp eq i64 %5057, %5096
  %5100 = sext i1 %5099 to i32
  %5101 = xor i32 %5100, -1
  %5102 = and i32 %5101, %5095
  %5103 = and i32 %5100, %5098
  %5104 = or i32 %5103, %5102
  %5105 = add i64 %5096, 16
  %5106 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5105
  %5107 = load i32, i32* %5106, align 4
  %5108 = icmp eq i64 %5057, %5105
  %5109 = sext i1 %5108 to i32
  %5110 = xor i32 %5109, -1
  %5111 = and i32 %5110, %5104
  %5112 = and i32 %5109, %5107
  %5113 = or i32 %5112, %5111
  %5114 = add i64 %5105, 16
  %5115 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5114
  %5116 = load i32, i32* %5115, align 4
  %5117 = icmp eq i64 %5057, %5114
  %5118 = sext i1 %5117 to i32
  %5119 = xor i32 %5118, -1
  %5120 = and i32 %5119, %5113
  %5121 = and i32 %5118, %5116
  %5122 = or i32 %5121, %5120
  %5123 = add i64 %5114, 16
  %5124 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5123
  %5125 = load i32, i32* %5124, align 4
  %5126 = icmp eq i64 %5057, %5123
  %5127 = sext i1 %5126 to i32
  %5128 = xor i32 %5127, -1
  %5129 = and i32 %5128, %5122
  %5130 = and i32 %5127, %5125
  %5131 = or i32 %5130, %5129
  %5132 = add i64 %5123, 16
  %5133 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5132
  %5134 = load i32, i32* %5133, align 4
  %5135 = icmp eq i64 %5057, %5132
  %5136 = sext i1 %5135 to i32
  %5137 = xor i32 %5136, -1
  %5138 = and i32 %5137, %5131
  %5139 = and i32 %5136, %5134
  %5140 = or i32 %5139, %5138
  %5141 = add i64 %5132, 16
  %5142 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5141
  %5143 = load i32, i32* %5142, align 4
  %5144 = icmp eq i64 %5057, %5141
  %5145 = sext i1 %5144 to i32
  %5146 = xor i32 %5145, -1
  %5147 = and i32 %5146, %5140
  %5148 = and i32 %5145, %5143
  %5149 = or i32 %5148, %5147
  %5150 = add i64 %5141, 16
  %5151 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5150
  %5152 = load i32, i32* %5151, align 4
  %5153 = icmp eq i64 %5057, %5150
  %5154 = sext i1 %5153 to i32
  %5155 = xor i32 %5154, -1
  %5156 = and i32 %5155, %5149
  %5157 = and i32 %5154, %5152
  %5158 = or i32 %5157, %5156
  %5159 = add i64 %5150, 16
  %5160 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5159
  %5161 = load i32, i32* %5160, align 4
  %5162 = icmp eq i64 %5057, %5159
  %5163 = sext i1 %5162 to i32
  %5164 = xor i32 %5163, -1
  %5165 = and i32 %5164, %5158
  %5166 = and i32 %5163, %5161
  %5167 = or i32 %5166, %5165
  %5168 = add i64 %5159, 16
  %5169 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5168
  %5170 = load i32, i32* %5169, align 4
  %5171 = icmp eq i64 %5057, %5168
  %5172 = sext i1 %5171 to i32
  %5173 = xor i32 %5172, -1
  %5174 = and i32 %5173, %5167
  %5175 = and i32 %5172, %5170
  %5176 = or i32 %5175, %5174
  %5177 = add i64 %5168, 16
  %5178 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5177
  %5179 = load i32, i32* %5178, align 4
  %5180 = icmp eq i64 %5057, %5177
  %5181 = sext i1 %5180 to i32
  %5182 = xor i32 %5181, -1
  %5183 = and i32 %5182, %5176
  %5184 = and i32 %5181, %5179
  %5185 = or i32 %5184, %5183
  %5186 = add i64 %5177, 16
  %5187 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5186
  %5188 = load i32, i32* %5187, align 4
  %5189 = icmp eq i64 %5057, %5186
  %5190 = sext i1 %5189 to i32
  %5191 = xor i32 %5190, -1
  %5192 = and i32 %5191, %5185
  %5193 = and i32 %5190, %5188
  %5194 = or i32 %5193, %5192
  %5195 = add i64 %5186, 16
  %5196 = getelementptr inbounds [256 x i32], [256 x i32]* %5059, i64 0, i64 %5195
  %5197 = load i32, i32* %5196, align 4
  %5198 = icmp eq i64 %5057, %5195
  %5199 = sext i1 %5198 to i32
  %5200 = xor i32 %5199, -1
  %5201 = and i32 %5200, %5194
  %5202 = and i32 %5199, %5197
  %Mitigated33 = or i32 %5202, %5201
  %5203 = xor i32 %Mitigated32, %Mitigated33
  %5204 = lshr i32 %4903, 16
  %5205 = and i32 %5204, 255
  %5206 = zext i32 %5205 to i64
  %5207 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5208 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5207, i64 0, i64 2
  %5209 = srem i64 %5206, 16
  %5210 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5209
  %5211 = load i32, i32* %5210, align 4
  %5212 = icmp eq i64 %5206, %5209
  %5213 = sext i1 %5212 to i32
  %5214 = xor i32 %5213, -1
  %5215 = and i32 %5214, 0
  %5216 = and i32 %5213, %5211
  %5217 = or i32 %5216, %5215
  %5218 = add i64 %5209, 16
  %5219 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5218
  %5220 = load i32, i32* %5219, align 4
  %5221 = icmp eq i64 %5206, %5218
  %5222 = sext i1 %5221 to i32
  %5223 = xor i32 %5222, -1
  %5224 = and i32 %5223, %5217
  %5225 = and i32 %5222, %5220
  %5226 = or i32 %5225, %5224
  %5227 = add i64 %5218, 16
  %5228 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5227
  %5229 = load i32, i32* %5228, align 4
  %5230 = icmp eq i64 %5206, %5227
  %5231 = sext i1 %5230 to i32
  %5232 = xor i32 %5231, -1
  %5233 = and i32 %5232, %5226
  %5234 = and i32 %5231, %5229
  %5235 = or i32 %5234, %5233
  %5236 = add i64 %5227, 16
  %5237 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5236
  %5238 = load i32, i32* %5237, align 4
  %5239 = icmp eq i64 %5206, %5236
  %5240 = sext i1 %5239 to i32
  %5241 = xor i32 %5240, -1
  %5242 = and i32 %5241, %5235
  %5243 = and i32 %5240, %5238
  %5244 = or i32 %5243, %5242
  %5245 = add i64 %5236, 16
  %5246 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5245
  %5247 = load i32, i32* %5246, align 4
  %5248 = icmp eq i64 %5206, %5245
  %5249 = sext i1 %5248 to i32
  %5250 = xor i32 %5249, -1
  %5251 = and i32 %5250, %5244
  %5252 = and i32 %5249, %5247
  %5253 = or i32 %5252, %5251
  %5254 = add i64 %5245, 16
  %5255 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5254
  %5256 = load i32, i32* %5255, align 4
  %5257 = icmp eq i64 %5206, %5254
  %5258 = sext i1 %5257 to i32
  %5259 = xor i32 %5258, -1
  %5260 = and i32 %5259, %5253
  %5261 = and i32 %5258, %5256
  %5262 = or i32 %5261, %5260
  %5263 = add i64 %5254, 16
  %5264 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5263
  %5265 = load i32, i32* %5264, align 4
  %5266 = icmp eq i64 %5206, %5263
  %5267 = sext i1 %5266 to i32
  %5268 = xor i32 %5267, -1
  %5269 = and i32 %5268, %5262
  %5270 = and i32 %5267, %5265
  %5271 = or i32 %5270, %5269
  %5272 = add i64 %5263, 16
  %5273 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5272
  %5274 = load i32, i32* %5273, align 4
  %5275 = icmp eq i64 %5206, %5272
  %5276 = sext i1 %5275 to i32
  %5277 = xor i32 %5276, -1
  %5278 = and i32 %5277, %5271
  %5279 = and i32 %5276, %5274
  %5280 = or i32 %5279, %5278
  %5281 = add i64 %5272, 16
  %5282 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5281
  %5283 = load i32, i32* %5282, align 4
  %5284 = icmp eq i64 %5206, %5281
  %5285 = sext i1 %5284 to i32
  %5286 = xor i32 %5285, -1
  %5287 = and i32 %5286, %5280
  %5288 = and i32 %5285, %5283
  %5289 = or i32 %5288, %5287
  %5290 = add i64 %5281, 16
  %5291 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5290
  %5292 = load i32, i32* %5291, align 4
  %5293 = icmp eq i64 %5206, %5290
  %5294 = sext i1 %5293 to i32
  %5295 = xor i32 %5294, -1
  %5296 = and i32 %5295, %5289
  %5297 = and i32 %5294, %5292
  %5298 = or i32 %5297, %5296
  %5299 = add i64 %5290, 16
  %5300 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5299
  %5301 = load i32, i32* %5300, align 4
  %5302 = icmp eq i64 %5206, %5299
  %5303 = sext i1 %5302 to i32
  %5304 = xor i32 %5303, -1
  %5305 = and i32 %5304, %5298
  %5306 = and i32 %5303, %5301
  %5307 = or i32 %5306, %5305
  %5308 = add i64 %5299, 16
  %5309 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5308
  %5310 = load i32, i32* %5309, align 4
  %5311 = icmp eq i64 %5206, %5308
  %5312 = sext i1 %5311 to i32
  %5313 = xor i32 %5312, -1
  %5314 = and i32 %5313, %5307
  %5315 = and i32 %5312, %5310
  %5316 = or i32 %5315, %5314
  %5317 = add i64 %5308, 16
  %5318 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5317
  %5319 = load i32, i32* %5318, align 4
  %5320 = icmp eq i64 %5206, %5317
  %5321 = sext i1 %5320 to i32
  %5322 = xor i32 %5321, -1
  %5323 = and i32 %5322, %5316
  %5324 = and i32 %5321, %5319
  %5325 = or i32 %5324, %5323
  %5326 = add i64 %5317, 16
  %5327 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5326
  %5328 = load i32, i32* %5327, align 4
  %5329 = icmp eq i64 %5206, %5326
  %5330 = sext i1 %5329 to i32
  %5331 = xor i32 %5330, -1
  %5332 = and i32 %5331, %5325
  %5333 = and i32 %5330, %5328
  %5334 = or i32 %5333, %5332
  %5335 = add i64 %5326, 16
  %5336 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5335
  %5337 = load i32, i32* %5336, align 4
  %5338 = icmp eq i64 %5206, %5335
  %5339 = sext i1 %5338 to i32
  %5340 = xor i32 %5339, -1
  %5341 = and i32 %5340, %5334
  %5342 = and i32 %5339, %5337
  %5343 = or i32 %5342, %5341
  %5344 = add i64 %5335, 16
  %5345 = getelementptr inbounds [256 x i32], [256 x i32]* %5208, i64 0, i64 %5344
  %5346 = load i32, i32* %5345, align 4
  %5347 = icmp eq i64 %5206, %5344
  %5348 = sext i1 %5347 to i32
  %5349 = xor i32 %5348, -1
  %5350 = and i32 %5349, %5343
  %5351 = and i32 %5348, %5346
  %Mitigated34 = or i32 %5351, %5350
  %5352 = xor i32 %5203, %Mitigated34
  %5353 = lshr i32 %4903, 24
  %5354 = zext i32 %5353 to i64
  %5355 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5356 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5355, i64 0, i64 3
  %5357 = srem i64 %5354, 16
  %5358 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5357
  %5359 = load i32, i32* %5358, align 4
  %5360 = icmp eq i64 %5354, %5357
  %5361 = sext i1 %5360 to i32
  %5362 = xor i32 %5361, -1
  %5363 = and i32 %5362, 0
  %5364 = and i32 %5361, %5359
  %5365 = or i32 %5364, %5363
  %5366 = add i64 %5357, 16
  %5367 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5366
  %5368 = load i32, i32* %5367, align 4
  %5369 = icmp eq i64 %5354, %5366
  %5370 = sext i1 %5369 to i32
  %5371 = xor i32 %5370, -1
  %5372 = and i32 %5371, %5365
  %5373 = and i32 %5370, %5368
  %5374 = or i32 %5373, %5372
  %5375 = add i64 %5366, 16
  %5376 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5375
  %5377 = load i32, i32* %5376, align 4
  %5378 = icmp eq i64 %5354, %5375
  %5379 = sext i1 %5378 to i32
  %5380 = xor i32 %5379, -1
  %5381 = and i32 %5380, %5374
  %5382 = and i32 %5379, %5377
  %5383 = or i32 %5382, %5381
  %5384 = add i64 %5375, 16
  %5385 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5384
  %5386 = load i32, i32* %5385, align 4
  %5387 = icmp eq i64 %5354, %5384
  %5388 = sext i1 %5387 to i32
  %5389 = xor i32 %5388, -1
  %5390 = and i32 %5389, %5383
  %5391 = and i32 %5388, %5386
  %5392 = or i32 %5391, %5390
  %5393 = add i64 %5384, 16
  %5394 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5393
  %5395 = load i32, i32* %5394, align 4
  %5396 = icmp eq i64 %5354, %5393
  %5397 = sext i1 %5396 to i32
  %5398 = xor i32 %5397, -1
  %5399 = and i32 %5398, %5392
  %5400 = and i32 %5397, %5395
  %5401 = or i32 %5400, %5399
  %5402 = add i64 %5393, 16
  %5403 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5402
  %5404 = load i32, i32* %5403, align 4
  %5405 = icmp eq i64 %5354, %5402
  %5406 = sext i1 %5405 to i32
  %5407 = xor i32 %5406, -1
  %5408 = and i32 %5407, %5401
  %5409 = and i32 %5406, %5404
  %5410 = or i32 %5409, %5408
  %5411 = add i64 %5402, 16
  %5412 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5411
  %5413 = load i32, i32* %5412, align 4
  %5414 = icmp eq i64 %5354, %5411
  %5415 = sext i1 %5414 to i32
  %5416 = xor i32 %5415, -1
  %5417 = and i32 %5416, %5410
  %5418 = and i32 %5415, %5413
  %5419 = or i32 %5418, %5417
  %5420 = add i64 %5411, 16
  %5421 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5420
  %5422 = load i32, i32* %5421, align 4
  %5423 = icmp eq i64 %5354, %5420
  %5424 = sext i1 %5423 to i32
  %5425 = xor i32 %5424, -1
  %5426 = and i32 %5425, %5419
  %5427 = and i32 %5424, %5422
  %5428 = or i32 %5427, %5426
  %5429 = add i64 %5420, 16
  %5430 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5429
  %5431 = load i32, i32* %5430, align 4
  %5432 = icmp eq i64 %5354, %5429
  %5433 = sext i1 %5432 to i32
  %5434 = xor i32 %5433, -1
  %5435 = and i32 %5434, %5428
  %5436 = and i32 %5433, %5431
  %5437 = or i32 %5436, %5435
  %5438 = add i64 %5429, 16
  %5439 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5438
  %5440 = load i32, i32* %5439, align 4
  %5441 = icmp eq i64 %5354, %5438
  %5442 = sext i1 %5441 to i32
  %5443 = xor i32 %5442, -1
  %5444 = and i32 %5443, %5437
  %5445 = and i32 %5442, %5440
  %5446 = or i32 %5445, %5444
  %5447 = add i64 %5438, 16
  %5448 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5447
  %5449 = load i32, i32* %5448, align 4
  %5450 = icmp eq i64 %5354, %5447
  %5451 = sext i1 %5450 to i32
  %5452 = xor i32 %5451, -1
  %5453 = and i32 %5452, %5446
  %5454 = and i32 %5451, %5449
  %5455 = or i32 %5454, %5453
  %5456 = add i64 %5447, 16
  %5457 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5456
  %5458 = load i32, i32* %5457, align 4
  %5459 = icmp eq i64 %5354, %5456
  %5460 = sext i1 %5459 to i32
  %5461 = xor i32 %5460, -1
  %5462 = and i32 %5461, %5455
  %5463 = and i32 %5460, %5458
  %5464 = or i32 %5463, %5462
  %5465 = add i64 %5456, 16
  %5466 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5465
  %5467 = load i32, i32* %5466, align 4
  %5468 = icmp eq i64 %5354, %5465
  %5469 = sext i1 %5468 to i32
  %5470 = xor i32 %5469, -1
  %5471 = and i32 %5470, %5464
  %5472 = and i32 %5469, %5467
  %5473 = or i32 %5472, %5471
  %5474 = add i64 %5465, 16
  %5475 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5474
  %5476 = load i32, i32* %5475, align 4
  %5477 = icmp eq i64 %5354, %5474
  %5478 = sext i1 %5477 to i32
  %5479 = xor i32 %5478, -1
  %5480 = and i32 %5479, %5473
  %5481 = and i32 %5478, %5476
  %5482 = or i32 %5481, %5480
  %5483 = add i64 %5474, 16
  %5484 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5483
  %5485 = load i32, i32* %5484, align 4
  %5486 = icmp eq i64 %5354, %5483
  %5487 = sext i1 %5486 to i32
  %5488 = xor i32 %5487, -1
  %5489 = and i32 %5488, %5482
  %5490 = and i32 %5487, %5485
  %5491 = or i32 %5490, %5489
  %5492 = add i64 %5483, 16
  %5493 = getelementptr inbounds [256 x i32], [256 x i32]* %5356, i64 0, i64 %5492
  %5494 = load i32, i32* %5493, align 4
  %5495 = icmp eq i64 %5354, %5492
  %5496 = sext i1 %5495 to i32
  %5497 = xor i32 %5496, -1
  %5498 = and i32 %5497, %5491
  %5499 = and i32 %5496, %5494
  %Mitigated35 = or i32 %5499, %5498
  %5500 = xor i32 %5352, %Mitigated35
  %5501 = and i32 %4907, 255
  %5502 = zext i32 %5501 to i64
  %5503 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5504 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5503, i64 0, i64 1
  %5505 = srem i64 %5502, 16
  %5506 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5505
  %5507 = load i32, i32* %5506, align 4
  %5508 = icmp eq i64 %5502, %5505
  %5509 = sext i1 %5508 to i32
  %5510 = xor i32 %5509, -1
  %5511 = and i32 %5510, 0
  %5512 = and i32 %5509, %5507
  %5513 = or i32 %5512, %5511
  %5514 = add i64 %5505, 16
  %5515 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5514
  %5516 = load i32, i32* %5515, align 4
  %5517 = icmp eq i64 %5502, %5514
  %5518 = sext i1 %5517 to i32
  %5519 = xor i32 %5518, -1
  %5520 = and i32 %5519, %5513
  %5521 = and i32 %5518, %5516
  %5522 = or i32 %5521, %5520
  %5523 = add i64 %5514, 16
  %5524 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5523
  %5525 = load i32, i32* %5524, align 4
  %5526 = icmp eq i64 %5502, %5523
  %5527 = sext i1 %5526 to i32
  %5528 = xor i32 %5527, -1
  %5529 = and i32 %5528, %5522
  %5530 = and i32 %5527, %5525
  %5531 = or i32 %5530, %5529
  %5532 = add i64 %5523, 16
  %5533 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5532
  %5534 = load i32, i32* %5533, align 4
  %5535 = icmp eq i64 %5502, %5532
  %5536 = sext i1 %5535 to i32
  %5537 = xor i32 %5536, -1
  %5538 = and i32 %5537, %5531
  %5539 = and i32 %5536, %5534
  %5540 = or i32 %5539, %5538
  %5541 = add i64 %5532, 16
  %5542 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5541
  %5543 = load i32, i32* %5542, align 4
  %5544 = icmp eq i64 %5502, %5541
  %5545 = sext i1 %5544 to i32
  %5546 = xor i32 %5545, -1
  %5547 = and i32 %5546, %5540
  %5548 = and i32 %5545, %5543
  %5549 = or i32 %5548, %5547
  %5550 = add i64 %5541, 16
  %5551 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5550
  %5552 = load i32, i32* %5551, align 4
  %5553 = icmp eq i64 %5502, %5550
  %5554 = sext i1 %5553 to i32
  %5555 = xor i32 %5554, -1
  %5556 = and i32 %5555, %5549
  %5557 = and i32 %5554, %5552
  %5558 = or i32 %5557, %5556
  %5559 = add i64 %5550, 16
  %5560 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5559
  %5561 = load i32, i32* %5560, align 4
  %5562 = icmp eq i64 %5502, %5559
  %5563 = sext i1 %5562 to i32
  %5564 = xor i32 %5563, -1
  %5565 = and i32 %5564, %5558
  %5566 = and i32 %5563, %5561
  %5567 = or i32 %5566, %5565
  %5568 = add i64 %5559, 16
  %5569 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5568
  %5570 = load i32, i32* %5569, align 4
  %5571 = icmp eq i64 %5502, %5568
  %5572 = sext i1 %5571 to i32
  %5573 = xor i32 %5572, -1
  %5574 = and i32 %5573, %5567
  %5575 = and i32 %5572, %5570
  %5576 = or i32 %5575, %5574
  %5577 = add i64 %5568, 16
  %5578 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5577
  %5579 = load i32, i32* %5578, align 4
  %5580 = icmp eq i64 %5502, %5577
  %5581 = sext i1 %5580 to i32
  %5582 = xor i32 %5581, -1
  %5583 = and i32 %5582, %5576
  %5584 = and i32 %5581, %5579
  %5585 = or i32 %5584, %5583
  %5586 = add i64 %5577, 16
  %5587 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5586
  %5588 = load i32, i32* %5587, align 4
  %5589 = icmp eq i64 %5502, %5586
  %5590 = sext i1 %5589 to i32
  %5591 = xor i32 %5590, -1
  %5592 = and i32 %5591, %5585
  %5593 = and i32 %5590, %5588
  %5594 = or i32 %5593, %5592
  %5595 = add i64 %5586, 16
  %5596 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5595
  %5597 = load i32, i32* %5596, align 4
  %5598 = icmp eq i64 %5502, %5595
  %5599 = sext i1 %5598 to i32
  %5600 = xor i32 %5599, -1
  %5601 = and i32 %5600, %5594
  %5602 = and i32 %5599, %5597
  %5603 = or i32 %5602, %5601
  %5604 = add i64 %5595, 16
  %5605 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5604
  %5606 = load i32, i32* %5605, align 4
  %5607 = icmp eq i64 %5502, %5604
  %5608 = sext i1 %5607 to i32
  %5609 = xor i32 %5608, -1
  %5610 = and i32 %5609, %5603
  %5611 = and i32 %5608, %5606
  %5612 = or i32 %5611, %5610
  %5613 = add i64 %5604, 16
  %5614 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5613
  %5615 = load i32, i32* %5614, align 4
  %5616 = icmp eq i64 %5502, %5613
  %5617 = sext i1 %5616 to i32
  %5618 = xor i32 %5617, -1
  %5619 = and i32 %5618, %5612
  %5620 = and i32 %5617, %5615
  %5621 = or i32 %5620, %5619
  %5622 = add i64 %5613, 16
  %5623 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5622
  %5624 = load i32, i32* %5623, align 4
  %5625 = icmp eq i64 %5502, %5622
  %5626 = sext i1 %5625 to i32
  %5627 = xor i32 %5626, -1
  %5628 = and i32 %5627, %5621
  %5629 = and i32 %5626, %5624
  %5630 = or i32 %5629, %5628
  %5631 = add i64 %5622, 16
  %5632 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5631
  %5633 = load i32, i32* %5632, align 4
  %5634 = icmp eq i64 %5502, %5631
  %5635 = sext i1 %5634 to i32
  %5636 = xor i32 %5635, -1
  %5637 = and i32 %5636, %5630
  %5638 = and i32 %5635, %5633
  %5639 = or i32 %5638, %5637
  %5640 = add i64 %5631, 16
  %5641 = getelementptr inbounds [256 x i32], [256 x i32]* %5504, i64 0, i64 %5640
  %5642 = load i32, i32* %5641, align 4
  %5643 = icmp eq i64 %5502, %5640
  %5644 = sext i1 %5643 to i32
  %5645 = xor i32 %5644, -1
  %5646 = and i32 %5645, %5639
  %5647 = and i32 %5644, %5642
  %Mitigated36 = or i32 %5647, %5646
  %5648 = lshr i32 %4907, 8
  %5649 = and i32 %5648, 255
  %5650 = zext i32 %5649 to i64
  %5651 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5652 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5651, i64 0, i64 2
  %5653 = srem i64 %5650, 16
  %5654 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5653
  %5655 = load i32, i32* %5654, align 4
  %5656 = icmp eq i64 %5650, %5653
  %5657 = sext i1 %5656 to i32
  %5658 = xor i32 %5657, -1
  %5659 = and i32 %5658, 0
  %5660 = and i32 %5657, %5655
  %5661 = or i32 %5660, %5659
  %5662 = add i64 %5653, 16
  %5663 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5662
  %5664 = load i32, i32* %5663, align 4
  %5665 = icmp eq i64 %5650, %5662
  %5666 = sext i1 %5665 to i32
  %5667 = xor i32 %5666, -1
  %5668 = and i32 %5667, %5661
  %5669 = and i32 %5666, %5664
  %5670 = or i32 %5669, %5668
  %5671 = add i64 %5662, 16
  %5672 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5671
  %5673 = load i32, i32* %5672, align 4
  %5674 = icmp eq i64 %5650, %5671
  %5675 = sext i1 %5674 to i32
  %5676 = xor i32 %5675, -1
  %5677 = and i32 %5676, %5670
  %5678 = and i32 %5675, %5673
  %5679 = or i32 %5678, %5677
  %5680 = add i64 %5671, 16
  %5681 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5680
  %5682 = load i32, i32* %5681, align 4
  %5683 = icmp eq i64 %5650, %5680
  %5684 = sext i1 %5683 to i32
  %5685 = xor i32 %5684, -1
  %5686 = and i32 %5685, %5679
  %5687 = and i32 %5684, %5682
  %5688 = or i32 %5687, %5686
  %5689 = add i64 %5680, 16
  %5690 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5689
  %5691 = load i32, i32* %5690, align 4
  %5692 = icmp eq i64 %5650, %5689
  %5693 = sext i1 %5692 to i32
  %5694 = xor i32 %5693, -1
  %5695 = and i32 %5694, %5688
  %5696 = and i32 %5693, %5691
  %5697 = or i32 %5696, %5695
  %5698 = add i64 %5689, 16
  %5699 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5698
  %5700 = load i32, i32* %5699, align 4
  %5701 = icmp eq i64 %5650, %5698
  %5702 = sext i1 %5701 to i32
  %5703 = xor i32 %5702, -1
  %5704 = and i32 %5703, %5697
  %5705 = and i32 %5702, %5700
  %5706 = or i32 %5705, %5704
  %5707 = add i64 %5698, 16
  %5708 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5707
  %5709 = load i32, i32* %5708, align 4
  %5710 = icmp eq i64 %5650, %5707
  %5711 = sext i1 %5710 to i32
  %5712 = xor i32 %5711, -1
  %5713 = and i32 %5712, %5706
  %5714 = and i32 %5711, %5709
  %5715 = or i32 %5714, %5713
  %5716 = add i64 %5707, 16
  %5717 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5716
  %5718 = load i32, i32* %5717, align 4
  %5719 = icmp eq i64 %5650, %5716
  %5720 = sext i1 %5719 to i32
  %5721 = xor i32 %5720, -1
  %5722 = and i32 %5721, %5715
  %5723 = and i32 %5720, %5718
  %5724 = or i32 %5723, %5722
  %5725 = add i64 %5716, 16
  %5726 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5725
  %5727 = load i32, i32* %5726, align 4
  %5728 = icmp eq i64 %5650, %5725
  %5729 = sext i1 %5728 to i32
  %5730 = xor i32 %5729, -1
  %5731 = and i32 %5730, %5724
  %5732 = and i32 %5729, %5727
  %5733 = or i32 %5732, %5731
  %5734 = add i64 %5725, 16
  %5735 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5734
  %5736 = load i32, i32* %5735, align 4
  %5737 = icmp eq i64 %5650, %5734
  %5738 = sext i1 %5737 to i32
  %5739 = xor i32 %5738, -1
  %5740 = and i32 %5739, %5733
  %5741 = and i32 %5738, %5736
  %5742 = or i32 %5741, %5740
  %5743 = add i64 %5734, 16
  %5744 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5743
  %5745 = load i32, i32* %5744, align 4
  %5746 = icmp eq i64 %5650, %5743
  %5747 = sext i1 %5746 to i32
  %5748 = xor i32 %5747, -1
  %5749 = and i32 %5748, %5742
  %5750 = and i32 %5747, %5745
  %5751 = or i32 %5750, %5749
  %5752 = add i64 %5743, 16
  %5753 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5752
  %5754 = load i32, i32* %5753, align 4
  %5755 = icmp eq i64 %5650, %5752
  %5756 = sext i1 %5755 to i32
  %5757 = xor i32 %5756, -1
  %5758 = and i32 %5757, %5751
  %5759 = and i32 %5756, %5754
  %5760 = or i32 %5759, %5758
  %5761 = add i64 %5752, 16
  %5762 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5761
  %5763 = load i32, i32* %5762, align 4
  %5764 = icmp eq i64 %5650, %5761
  %5765 = sext i1 %5764 to i32
  %5766 = xor i32 %5765, -1
  %5767 = and i32 %5766, %5760
  %5768 = and i32 %5765, %5763
  %5769 = or i32 %5768, %5767
  %5770 = add i64 %5761, 16
  %5771 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5770
  %5772 = load i32, i32* %5771, align 4
  %5773 = icmp eq i64 %5650, %5770
  %5774 = sext i1 %5773 to i32
  %5775 = xor i32 %5774, -1
  %5776 = and i32 %5775, %5769
  %5777 = and i32 %5774, %5772
  %5778 = or i32 %5777, %5776
  %5779 = add i64 %5770, 16
  %5780 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5779
  %5781 = load i32, i32* %5780, align 4
  %5782 = icmp eq i64 %5650, %5779
  %5783 = sext i1 %5782 to i32
  %5784 = xor i32 %5783, -1
  %5785 = and i32 %5784, %5778
  %5786 = and i32 %5783, %5781
  %5787 = or i32 %5786, %5785
  %5788 = add i64 %5779, 16
  %5789 = getelementptr inbounds [256 x i32], [256 x i32]* %5652, i64 0, i64 %5788
  %5790 = load i32, i32* %5789, align 4
  %5791 = icmp eq i64 %5650, %5788
  %5792 = sext i1 %5791 to i32
  %5793 = xor i32 %5792, -1
  %5794 = and i32 %5793, %5787
  %5795 = and i32 %5792, %5790
  %Mitigated37 = or i32 %5795, %5794
  %5796 = xor i32 %Mitigated36, %Mitigated37
  %5797 = lshr i32 %4907, 16
  %5798 = and i32 %5797, 255
  %5799 = zext i32 %5798 to i64
  %5800 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5801 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5800, i64 0, i64 3
  %5802 = srem i64 %5799, 16
  %5803 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5802
  %5804 = load i32, i32* %5803, align 4
  %5805 = icmp eq i64 %5799, %5802
  %5806 = sext i1 %5805 to i32
  %5807 = xor i32 %5806, -1
  %5808 = and i32 %5807, 0
  %5809 = and i32 %5806, %5804
  %5810 = or i32 %5809, %5808
  %5811 = add i64 %5802, 16
  %5812 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5811
  %5813 = load i32, i32* %5812, align 4
  %5814 = icmp eq i64 %5799, %5811
  %5815 = sext i1 %5814 to i32
  %5816 = xor i32 %5815, -1
  %5817 = and i32 %5816, %5810
  %5818 = and i32 %5815, %5813
  %5819 = or i32 %5818, %5817
  %5820 = add i64 %5811, 16
  %5821 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5820
  %5822 = load i32, i32* %5821, align 4
  %5823 = icmp eq i64 %5799, %5820
  %5824 = sext i1 %5823 to i32
  %5825 = xor i32 %5824, -1
  %5826 = and i32 %5825, %5819
  %5827 = and i32 %5824, %5822
  %5828 = or i32 %5827, %5826
  %5829 = add i64 %5820, 16
  %5830 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5829
  %5831 = load i32, i32* %5830, align 4
  %5832 = icmp eq i64 %5799, %5829
  %5833 = sext i1 %5832 to i32
  %5834 = xor i32 %5833, -1
  %5835 = and i32 %5834, %5828
  %5836 = and i32 %5833, %5831
  %5837 = or i32 %5836, %5835
  %5838 = add i64 %5829, 16
  %5839 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5838
  %5840 = load i32, i32* %5839, align 4
  %5841 = icmp eq i64 %5799, %5838
  %5842 = sext i1 %5841 to i32
  %5843 = xor i32 %5842, -1
  %5844 = and i32 %5843, %5837
  %5845 = and i32 %5842, %5840
  %5846 = or i32 %5845, %5844
  %5847 = add i64 %5838, 16
  %5848 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5847
  %5849 = load i32, i32* %5848, align 4
  %5850 = icmp eq i64 %5799, %5847
  %5851 = sext i1 %5850 to i32
  %5852 = xor i32 %5851, -1
  %5853 = and i32 %5852, %5846
  %5854 = and i32 %5851, %5849
  %5855 = or i32 %5854, %5853
  %5856 = add i64 %5847, 16
  %5857 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5856
  %5858 = load i32, i32* %5857, align 4
  %5859 = icmp eq i64 %5799, %5856
  %5860 = sext i1 %5859 to i32
  %5861 = xor i32 %5860, -1
  %5862 = and i32 %5861, %5855
  %5863 = and i32 %5860, %5858
  %5864 = or i32 %5863, %5862
  %5865 = add i64 %5856, 16
  %5866 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5865
  %5867 = load i32, i32* %5866, align 4
  %5868 = icmp eq i64 %5799, %5865
  %5869 = sext i1 %5868 to i32
  %5870 = xor i32 %5869, -1
  %5871 = and i32 %5870, %5864
  %5872 = and i32 %5869, %5867
  %5873 = or i32 %5872, %5871
  %5874 = add i64 %5865, 16
  %5875 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5874
  %5876 = load i32, i32* %5875, align 4
  %5877 = icmp eq i64 %5799, %5874
  %5878 = sext i1 %5877 to i32
  %5879 = xor i32 %5878, -1
  %5880 = and i32 %5879, %5873
  %5881 = and i32 %5878, %5876
  %5882 = or i32 %5881, %5880
  %5883 = add i64 %5874, 16
  %5884 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5883
  %5885 = load i32, i32* %5884, align 4
  %5886 = icmp eq i64 %5799, %5883
  %5887 = sext i1 %5886 to i32
  %5888 = xor i32 %5887, -1
  %5889 = and i32 %5888, %5882
  %5890 = and i32 %5887, %5885
  %5891 = or i32 %5890, %5889
  %5892 = add i64 %5883, 16
  %5893 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5892
  %5894 = load i32, i32* %5893, align 4
  %5895 = icmp eq i64 %5799, %5892
  %5896 = sext i1 %5895 to i32
  %5897 = xor i32 %5896, -1
  %5898 = and i32 %5897, %5891
  %5899 = and i32 %5896, %5894
  %5900 = or i32 %5899, %5898
  %5901 = add i64 %5892, 16
  %5902 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5901
  %5903 = load i32, i32* %5902, align 4
  %5904 = icmp eq i64 %5799, %5901
  %5905 = sext i1 %5904 to i32
  %5906 = xor i32 %5905, -1
  %5907 = and i32 %5906, %5900
  %5908 = and i32 %5905, %5903
  %5909 = or i32 %5908, %5907
  %5910 = add i64 %5901, 16
  %5911 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5910
  %5912 = load i32, i32* %5911, align 4
  %5913 = icmp eq i64 %5799, %5910
  %5914 = sext i1 %5913 to i32
  %5915 = xor i32 %5914, -1
  %5916 = and i32 %5915, %5909
  %5917 = and i32 %5914, %5912
  %5918 = or i32 %5917, %5916
  %5919 = add i64 %5910, 16
  %5920 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5919
  %5921 = load i32, i32* %5920, align 4
  %5922 = icmp eq i64 %5799, %5919
  %5923 = sext i1 %5922 to i32
  %5924 = xor i32 %5923, -1
  %5925 = and i32 %5924, %5918
  %5926 = and i32 %5923, %5921
  %5927 = or i32 %5926, %5925
  %5928 = add i64 %5919, 16
  %5929 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5928
  %5930 = load i32, i32* %5929, align 4
  %5931 = icmp eq i64 %5799, %5928
  %5932 = sext i1 %5931 to i32
  %5933 = xor i32 %5932, -1
  %5934 = and i32 %5933, %5927
  %5935 = and i32 %5932, %5930
  %5936 = or i32 %5935, %5934
  %5937 = add i64 %5928, 16
  %5938 = getelementptr inbounds [256 x i32], [256 x i32]* %5801, i64 0, i64 %5937
  %5939 = load i32, i32* %5938, align 4
  %5940 = icmp eq i64 %5799, %5937
  %5941 = sext i1 %5940 to i32
  %5942 = xor i32 %5941, -1
  %5943 = and i32 %5942, %5936
  %5944 = and i32 %5941, %5939
  %Mitigated38 = or i32 %5944, %5943
  %5945 = xor i32 %5796, %Mitigated38
  %5946 = lshr i32 %4907, 24
  %5947 = zext i32 %5946 to i64
  %5948 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %5949 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %5948, i64 0, i64 0
  %5950 = srem i64 %5947, 16
  %5951 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5950
  %5952 = load i32, i32* %5951, align 4
  %5953 = icmp eq i64 %5947, %5950
  %5954 = sext i1 %5953 to i32
  %5955 = xor i32 %5954, -1
  %5956 = and i32 %5955, 0
  %5957 = and i32 %5954, %5952
  %5958 = or i32 %5957, %5956
  %5959 = add i64 %5950, 16
  %5960 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5959
  %5961 = load i32, i32* %5960, align 4
  %5962 = icmp eq i64 %5947, %5959
  %5963 = sext i1 %5962 to i32
  %5964 = xor i32 %5963, -1
  %5965 = and i32 %5964, %5958
  %5966 = and i32 %5963, %5961
  %5967 = or i32 %5966, %5965
  %5968 = add i64 %5959, 16
  %5969 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5968
  %5970 = load i32, i32* %5969, align 4
  %5971 = icmp eq i64 %5947, %5968
  %5972 = sext i1 %5971 to i32
  %5973 = xor i32 %5972, -1
  %5974 = and i32 %5973, %5967
  %5975 = and i32 %5972, %5970
  %5976 = or i32 %5975, %5974
  %5977 = add i64 %5968, 16
  %5978 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5977
  %5979 = load i32, i32* %5978, align 4
  %5980 = icmp eq i64 %5947, %5977
  %5981 = sext i1 %5980 to i32
  %5982 = xor i32 %5981, -1
  %5983 = and i32 %5982, %5976
  %5984 = and i32 %5981, %5979
  %5985 = or i32 %5984, %5983
  %5986 = add i64 %5977, 16
  %5987 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5986
  %5988 = load i32, i32* %5987, align 4
  %5989 = icmp eq i64 %5947, %5986
  %5990 = sext i1 %5989 to i32
  %5991 = xor i32 %5990, -1
  %5992 = and i32 %5991, %5985
  %5993 = and i32 %5990, %5988
  %5994 = or i32 %5993, %5992
  %5995 = add i64 %5986, 16
  %5996 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %5995
  %5997 = load i32, i32* %5996, align 4
  %5998 = icmp eq i64 %5947, %5995
  %5999 = sext i1 %5998 to i32
  %6000 = xor i32 %5999, -1
  %6001 = and i32 %6000, %5994
  %6002 = and i32 %5999, %5997
  %6003 = or i32 %6002, %6001
  %6004 = add i64 %5995, 16
  %6005 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6004
  %6006 = load i32, i32* %6005, align 4
  %6007 = icmp eq i64 %5947, %6004
  %6008 = sext i1 %6007 to i32
  %6009 = xor i32 %6008, -1
  %6010 = and i32 %6009, %6003
  %6011 = and i32 %6008, %6006
  %6012 = or i32 %6011, %6010
  %6013 = add i64 %6004, 16
  %6014 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6013
  %6015 = load i32, i32* %6014, align 4
  %6016 = icmp eq i64 %5947, %6013
  %6017 = sext i1 %6016 to i32
  %6018 = xor i32 %6017, -1
  %6019 = and i32 %6018, %6012
  %6020 = and i32 %6017, %6015
  %6021 = or i32 %6020, %6019
  %6022 = add i64 %6013, 16
  %6023 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6022
  %6024 = load i32, i32* %6023, align 4
  %6025 = icmp eq i64 %5947, %6022
  %6026 = sext i1 %6025 to i32
  %6027 = xor i32 %6026, -1
  %6028 = and i32 %6027, %6021
  %6029 = and i32 %6026, %6024
  %6030 = or i32 %6029, %6028
  %6031 = add i64 %6022, 16
  %6032 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6031
  %6033 = load i32, i32* %6032, align 4
  %6034 = icmp eq i64 %5947, %6031
  %6035 = sext i1 %6034 to i32
  %6036 = xor i32 %6035, -1
  %6037 = and i32 %6036, %6030
  %6038 = and i32 %6035, %6033
  %6039 = or i32 %6038, %6037
  %6040 = add i64 %6031, 16
  %6041 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6040
  %6042 = load i32, i32* %6041, align 4
  %6043 = icmp eq i64 %5947, %6040
  %6044 = sext i1 %6043 to i32
  %6045 = xor i32 %6044, -1
  %6046 = and i32 %6045, %6039
  %6047 = and i32 %6044, %6042
  %6048 = or i32 %6047, %6046
  %6049 = add i64 %6040, 16
  %6050 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6049
  %6051 = load i32, i32* %6050, align 4
  %6052 = icmp eq i64 %5947, %6049
  %6053 = sext i1 %6052 to i32
  %6054 = xor i32 %6053, -1
  %6055 = and i32 %6054, %6048
  %6056 = and i32 %6053, %6051
  %6057 = or i32 %6056, %6055
  %6058 = add i64 %6049, 16
  %6059 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6058
  %6060 = load i32, i32* %6059, align 4
  %6061 = icmp eq i64 %5947, %6058
  %6062 = sext i1 %6061 to i32
  %6063 = xor i32 %6062, -1
  %6064 = and i32 %6063, %6057
  %6065 = and i32 %6062, %6060
  %6066 = or i32 %6065, %6064
  %6067 = add i64 %6058, 16
  %6068 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6067
  %6069 = load i32, i32* %6068, align 4
  %6070 = icmp eq i64 %5947, %6067
  %6071 = sext i1 %6070 to i32
  %6072 = xor i32 %6071, -1
  %6073 = and i32 %6072, %6066
  %6074 = and i32 %6071, %6069
  %6075 = or i32 %6074, %6073
  %6076 = add i64 %6067, 16
  %6077 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6076
  %6078 = load i32, i32* %6077, align 4
  %6079 = icmp eq i64 %5947, %6076
  %6080 = sext i1 %6079 to i32
  %6081 = xor i32 %6080, -1
  %6082 = and i32 %6081, %6075
  %6083 = and i32 %6080, %6078
  %6084 = or i32 %6083, %6082
  %6085 = add i64 %6076, 16
  %6086 = getelementptr inbounds [256 x i32], [256 x i32]* %5949, i64 0, i64 %6085
  %6087 = load i32, i32* %6086, align 4
  %6088 = icmp eq i64 %5947, %6085
  %6089 = sext i1 %6088 to i32
  %6090 = xor i32 %6089, -1
  %6091 = and i32 %6090, %6084
  %6092 = and i32 %6089, %6087
  %Mitigated39 = or i32 %6092, %6091
  %6093 = xor i32 %5945, %Mitigated39
  %6094 = add i32 %5500, %6093
  %6095 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %6096 = getelementptr inbounds [32 x i32], [32 x i32]* %6095, i64 0, i64 9
  %6097 = load i32, i32* %6096, align 4
  %6098 = add i32 %6094, %6097
  %6099 = add i32 %6093, %6098
  %6100 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %6101 = getelementptr inbounds [32 x i32], [32 x i32]* %6100, i64 0, i64 8
  %6102 = load i32, i32* %6101, align 4
  %6103 = add i32 %6094, %6102
  %6104 = xor i32 %3699, %6103
  %6105 = lshr i32 %6104, 1
  %6106 = shl i32 %6104, 31
  %6107 = add i32 %6105, %6106
  %6108 = shl i32 %3703, 1
  %6109 = lshr i32 %3703, 31
  %6110 = add i32 %6108, %6109
  %6111 = xor i32 %6110, %6099
  %6112 = and i32 %6107, 255
  %6113 = zext i32 %6112 to i64
  %6114 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6115 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6114, i64 0, i64 0
  %6116 = srem i64 %6113, 16
  %6117 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6116
  %6118 = load i32, i32* %6117, align 4
  %6119 = icmp eq i64 %6113, %6116
  %6120 = sext i1 %6119 to i32
  %6121 = xor i32 %6120, -1
  %6122 = and i32 %6121, 0
  %6123 = and i32 %6120, %6118
  %6124 = or i32 %6123, %6122
  %6125 = add i64 %6116, 16
  %6126 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6125
  %6127 = load i32, i32* %6126, align 4
  %6128 = icmp eq i64 %6113, %6125
  %6129 = sext i1 %6128 to i32
  %6130 = xor i32 %6129, -1
  %6131 = and i32 %6130, %6124
  %6132 = and i32 %6129, %6127
  %6133 = or i32 %6132, %6131
  %6134 = add i64 %6125, 16
  %6135 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6134
  %6136 = load i32, i32* %6135, align 4
  %6137 = icmp eq i64 %6113, %6134
  %6138 = sext i1 %6137 to i32
  %6139 = xor i32 %6138, -1
  %6140 = and i32 %6139, %6133
  %6141 = and i32 %6138, %6136
  %6142 = or i32 %6141, %6140
  %6143 = add i64 %6134, 16
  %6144 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6143
  %6145 = load i32, i32* %6144, align 4
  %6146 = icmp eq i64 %6113, %6143
  %6147 = sext i1 %6146 to i32
  %6148 = xor i32 %6147, -1
  %6149 = and i32 %6148, %6142
  %6150 = and i32 %6147, %6145
  %6151 = or i32 %6150, %6149
  %6152 = add i64 %6143, 16
  %6153 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6152
  %6154 = load i32, i32* %6153, align 4
  %6155 = icmp eq i64 %6113, %6152
  %6156 = sext i1 %6155 to i32
  %6157 = xor i32 %6156, -1
  %6158 = and i32 %6157, %6151
  %6159 = and i32 %6156, %6154
  %6160 = or i32 %6159, %6158
  %6161 = add i64 %6152, 16
  %6162 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6161
  %6163 = load i32, i32* %6162, align 4
  %6164 = icmp eq i64 %6113, %6161
  %6165 = sext i1 %6164 to i32
  %6166 = xor i32 %6165, -1
  %6167 = and i32 %6166, %6160
  %6168 = and i32 %6165, %6163
  %6169 = or i32 %6168, %6167
  %6170 = add i64 %6161, 16
  %6171 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6170
  %6172 = load i32, i32* %6171, align 4
  %6173 = icmp eq i64 %6113, %6170
  %6174 = sext i1 %6173 to i32
  %6175 = xor i32 %6174, -1
  %6176 = and i32 %6175, %6169
  %6177 = and i32 %6174, %6172
  %6178 = or i32 %6177, %6176
  %6179 = add i64 %6170, 16
  %6180 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6179
  %6181 = load i32, i32* %6180, align 4
  %6182 = icmp eq i64 %6113, %6179
  %6183 = sext i1 %6182 to i32
  %6184 = xor i32 %6183, -1
  %6185 = and i32 %6184, %6178
  %6186 = and i32 %6183, %6181
  %6187 = or i32 %6186, %6185
  %6188 = add i64 %6179, 16
  %6189 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6188
  %6190 = load i32, i32* %6189, align 4
  %6191 = icmp eq i64 %6113, %6188
  %6192 = sext i1 %6191 to i32
  %6193 = xor i32 %6192, -1
  %6194 = and i32 %6193, %6187
  %6195 = and i32 %6192, %6190
  %6196 = or i32 %6195, %6194
  %6197 = add i64 %6188, 16
  %6198 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6197
  %6199 = load i32, i32* %6198, align 4
  %6200 = icmp eq i64 %6113, %6197
  %6201 = sext i1 %6200 to i32
  %6202 = xor i32 %6201, -1
  %6203 = and i32 %6202, %6196
  %6204 = and i32 %6201, %6199
  %6205 = or i32 %6204, %6203
  %6206 = add i64 %6197, 16
  %6207 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6206
  %6208 = load i32, i32* %6207, align 4
  %6209 = icmp eq i64 %6113, %6206
  %6210 = sext i1 %6209 to i32
  %6211 = xor i32 %6210, -1
  %6212 = and i32 %6211, %6205
  %6213 = and i32 %6210, %6208
  %6214 = or i32 %6213, %6212
  %6215 = add i64 %6206, 16
  %6216 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6215
  %6217 = load i32, i32* %6216, align 4
  %6218 = icmp eq i64 %6113, %6215
  %6219 = sext i1 %6218 to i32
  %6220 = xor i32 %6219, -1
  %6221 = and i32 %6220, %6214
  %6222 = and i32 %6219, %6217
  %6223 = or i32 %6222, %6221
  %6224 = add i64 %6215, 16
  %6225 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6224
  %6226 = load i32, i32* %6225, align 4
  %6227 = icmp eq i64 %6113, %6224
  %6228 = sext i1 %6227 to i32
  %6229 = xor i32 %6228, -1
  %6230 = and i32 %6229, %6223
  %6231 = and i32 %6228, %6226
  %6232 = or i32 %6231, %6230
  %6233 = add i64 %6224, 16
  %6234 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6233
  %6235 = load i32, i32* %6234, align 4
  %6236 = icmp eq i64 %6113, %6233
  %6237 = sext i1 %6236 to i32
  %6238 = xor i32 %6237, -1
  %6239 = and i32 %6238, %6232
  %6240 = and i32 %6237, %6235
  %6241 = or i32 %6240, %6239
  %6242 = add i64 %6233, 16
  %6243 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6242
  %6244 = load i32, i32* %6243, align 4
  %6245 = icmp eq i64 %6113, %6242
  %6246 = sext i1 %6245 to i32
  %6247 = xor i32 %6246, -1
  %6248 = and i32 %6247, %6241
  %6249 = and i32 %6246, %6244
  %6250 = or i32 %6249, %6248
  %6251 = add i64 %6242, 16
  %6252 = getelementptr inbounds [256 x i32], [256 x i32]* %6115, i64 0, i64 %6251
  %6253 = load i32, i32* %6252, align 4
  %6254 = icmp eq i64 %6113, %6251
  %6255 = sext i1 %6254 to i32
  %6256 = xor i32 %6255, -1
  %6257 = and i32 %6256, %6250
  %6258 = and i32 %6255, %6253
  %Mitigated40 = or i32 %6258, %6257
  %6259 = lshr i32 %6107, 8
  %6260 = and i32 %6259, 255
  %6261 = zext i32 %6260 to i64
  %6262 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6263 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6262, i64 0, i64 1
  %6264 = srem i64 %6261, 16
  %6265 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6264
  %6266 = load i32, i32* %6265, align 4
  %6267 = icmp eq i64 %6261, %6264
  %6268 = sext i1 %6267 to i32
  %6269 = xor i32 %6268, -1
  %6270 = and i32 %6269, 0
  %6271 = and i32 %6268, %6266
  %6272 = or i32 %6271, %6270
  %6273 = add i64 %6264, 16
  %6274 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6273
  %6275 = load i32, i32* %6274, align 4
  %6276 = icmp eq i64 %6261, %6273
  %6277 = sext i1 %6276 to i32
  %6278 = xor i32 %6277, -1
  %6279 = and i32 %6278, %6272
  %6280 = and i32 %6277, %6275
  %6281 = or i32 %6280, %6279
  %6282 = add i64 %6273, 16
  %6283 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6282
  %6284 = load i32, i32* %6283, align 4
  %6285 = icmp eq i64 %6261, %6282
  %6286 = sext i1 %6285 to i32
  %6287 = xor i32 %6286, -1
  %6288 = and i32 %6287, %6281
  %6289 = and i32 %6286, %6284
  %6290 = or i32 %6289, %6288
  %6291 = add i64 %6282, 16
  %6292 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6291
  %6293 = load i32, i32* %6292, align 4
  %6294 = icmp eq i64 %6261, %6291
  %6295 = sext i1 %6294 to i32
  %6296 = xor i32 %6295, -1
  %6297 = and i32 %6296, %6290
  %6298 = and i32 %6295, %6293
  %6299 = or i32 %6298, %6297
  %6300 = add i64 %6291, 16
  %6301 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6300
  %6302 = load i32, i32* %6301, align 4
  %6303 = icmp eq i64 %6261, %6300
  %6304 = sext i1 %6303 to i32
  %6305 = xor i32 %6304, -1
  %6306 = and i32 %6305, %6299
  %6307 = and i32 %6304, %6302
  %6308 = or i32 %6307, %6306
  %6309 = add i64 %6300, 16
  %6310 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6309
  %6311 = load i32, i32* %6310, align 4
  %6312 = icmp eq i64 %6261, %6309
  %6313 = sext i1 %6312 to i32
  %6314 = xor i32 %6313, -1
  %6315 = and i32 %6314, %6308
  %6316 = and i32 %6313, %6311
  %6317 = or i32 %6316, %6315
  %6318 = add i64 %6309, 16
  %6319 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6318
  %6320 = load i32, i32* %6319, align 4
  %6321 = icmp eq i64 %6261, %6318
  %6322 = sext i1 %6321 to i32
  %6323 = xor i32 %6322, -1
  %6324 = and i32 %6323, %6317
  %6325 = and i32 %6322, %6320
  %6326 = or i32 %6325, %6324
  %6327 = add i64 %6318, 16
  %6328 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6327
  %6329 = load i32, i32* %6328, align 4
  %6330 = icmp eq i64 %6261, %6327
  %6331 = sext i1 %6330 to i32
  %6332 = xor i32 %6331, -1
  %6333 = and i32 %6332, %6326
  %6334 = and i32 %6331, %6329
  %6335 = or i32 %6334, %6333
  %6336 = add i64 %6327, 16
  %6337 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6336
  %6338 = load i32, i32* %6337, align 4
  %6339 = icmp eq i64 %6261, %6336
  %6340 = sext i1 %6339 to i32
  %6341 = xor i32 %6340, -1
  %6342 = and i32 %6341, %6335
  %6343 = and i32 %6340, %6338
  %6344 = or i32 %6343, %6342
  %6345 = add i64 %6336, 16
  %6346 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6345
  %6347 = load i32, i32* %6346, align 4
  %6348 = icmp eq i64 %6261, %6345
  %6349 = sext i1 %6348 to i32
  %6350 = xor i32 %6349, -1
  %6351 = and i32 %6350, %6344
  %6352 = and i32 %6349, %6347
  %6353 = or i32 %6352, %6351
  %6354 = add i64 %6345, 16
  %6355 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6354
  %6356 = load i32, i32* %6355, align 4
  %6357 = icmp eq i64 %6261, %6354
  %6358 = sext i1 %6357 to i32
  %6359 = xor i32 %6358, -1
  %6360 = and i32 %6359, %6353
  %6361 = and i32 %6358, %6356
  %6362 = or i32 %6361, %6360
  %6363 = add i64 %6354, 16
  %6364 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6363
  %6365 = load i32, i32* %6364, align 4
  %6366 = icmp eq i64 %6261, %6363
  %6367 = sext i1 %6366 to i32
  %6368 = xor i32 %6367, -1
  %6369 = and i32 %6368, %6362
  %6370 = and i32 %6367, %6365
  %6371 = or i32 %6370, %6369
  %6372 = add i64 %6363, 16
  %6373 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6372
  %6374 = load i32, i32* %6373, align 4
  %6375 = icmp eq i64 %6261, %6372
  %6376 = sext i1 %6375 to i32
  %6377 = xor i32 %6376, -1
  %6378 = and i32 %6377, %6371
  %6379 = and i32 %6376, %6374
  %6380 = or i32 %6379, %6378
  %6381 = add i64 %6372, 16
  %6382 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6381
  %6383 = load i32, i32* %6382, align 4
  %6384 = icmp eq i64 %6261, %6381
  %6385 = sext i1 %6384 to i32
  %6386 = xor i32 %6385, -1
  %6387 = and i32 %6386, %6380
  %6388 = and i32 %6385, %6383
  %6389 = or i32 %6388, %6387
  %6390 = add i64 %6381, 16
  %6391 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6390
  %6392 = load i32, i32* %6391, align 4
  %6393 = icmp eq i64 %6261, %6390
  %6394 = sext i1 %6393 to i32
  %6395 = xor i32 %6394, -1
  %6396 = and i32 %6395, %6389
  %6397 = and i32 %6394, %6392
  %6398 = or i32 %6397, %6396
  %6399 = add i64 %6390, 16
  %6400 = getelementptr inbounds [256 x i32], [256 x i32]* %6263, i64 0, i64 %6399
  %6401 = load i32, i32* %6400, align 4
  %6402 = icmp eq i64 %6261, %6399
  %6403 = sext i1 %6402 to i32
  %6404 = xor i32 %6403, -1
  %6405 = and i32 %6404, %6398
  %6406 = and i32 %6403, %6401
  %Mitigated41 = or i32 %6406, %6405
  %6407 = xor i32 %Mitigated40, %Mitigated41
  %6408 = lshr i32 %6107, 16
  %6409 = and i32 %6408, 255
  %6410 = zext i32 %6409 to i64
  %6411 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6412 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6411, i64 0, i64 2
  %6413 = srem i64 %6410, 16
  %6414 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6413
  %6415 = load i32, i32* %6414, align 4
  %6416 = icmp eq i64 %6410, %6413
  %6417 = sext i1 %6416 to i32
  %6418 = xor i32 %6417, -1
  %6419 = and i32 %6418, 0
  %6420 = and i32 %6417, %6415
  %6421 = or i32 %6420, %6419
  %6422 = add i64 %6413, 16
  %6423 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6422
  %6424 = load i32, i32* %6423, align 4
  %6425 = icmp eq i64 %6410, %6422
  %6426 = sext i1 %6425 to i32
  %6427 = xor i32 %6426, -1
  %6428 = and i32 %6427, %6421
  %6429 = and i32 %6426, %6424
  %6430 = or i32 %6429, %6428
  %6431 = add i64 %6422, 16
  %6432 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6431
  %6433 = load i32, i32* %6432, align 4
  %6434 = icmp eq i64 %6410, %6431
  %6435 = sext i1 %6434 to i32
  %6436 = xor i32 %6435, -1
  %6437 = and i32 %6436, %6430
  %6438 = and i32 %6435, %6433
  %6439 = or i32 %6438, %6437
  %6440 = add i64 %6431, 16
  %6441 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6440
  %6442 = load i32, i32* %6441, align 4
  %6443 = icmp eq i64 %6410, %6440
  %6444 = sext i1 %6443 to i32
  %6445 = xor i32 %6444, -1
  %6446 = and i32 %6445, %6439
  %6447 = and i32 %6444, %6442
  %6448 = or i32 %6447, %6446
  %6449 = add i64 %6440, 16
  %6450 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6449
  %6451 = load i32, i32* %6450, align 4
  %6452 = icmp eq i64 %6410, %6449
  %6453 = sext i1 %6452 to i32
  %6454 = xor i32 %6453, -1
  %6455 = and i32 %6454, %6448
  %6456 = and i32 %6453, %6451
  %6457 = or i32 %6456, %6455
  %6458 = add i64 %6449, 16
  %6459 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6458
  %6460 = load i32, i32* %6459, align 4
  %6461 = icmp eq i64 %6410, %6458
  %6462 = sext i1 %6461 to i32
  %6463 = xor i32 %6462, -1
  %6464 = and i32 %6463, %6457
  %6465 = and i32 %6462, %6460
  %6466 = or i32 %6465, %6464
  %6467 = add i64 %6458, 16
  %6468 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6467
  %6469 = load i32, i32* %6468, align 4
  %6470 = icmp eq i64 %6410, %6467
  %6471 = sext i1 %6470 to i32
  %6472 = xor i32 %6471, -1
  %6473 = and i32 %6472, %6466
  %6474 = and i32 %6471, %6469
  %6475 = or i32 %6474, %6473
  %6476 = add i64 %6467, 16
  %6477 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6476
  %6478 = load i32, i32* %6477, align 4
  %6479 = icmp eq i64 %6410, %6476
  %6480 = sext i1 %6479 to i32
  %6481 = xor i32 %6480, -1
  %6482 = and i32 %6481, %6475
  %6483 = and i32 %6480, %6478
  %6484 = or i32 %6483, %6482
  %6485 = add i64 %6476, 16
  %6486 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6485
  %6487 = load i32, i32* %6486, align 4
  %6488 = icmp eq i64 %6410, %6485
  %6489 = sext i1 %6488 to i32
  %6490 = xor i32 %6489, -1
  %6491 = and i32 %6490, %6484
  %6492 = and i32 %6489, %6487
  %6493 = or i32 %6492, %6491
  %6494 = add i64 %6485, 16
  %6495 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6494
  %6496 = load i32, i32* %6495, align 4
  %6497 = icmp eq i64 %6410, %6494
  %6498 = sext i1 %6497 to i32
  %6499 = xor i32 %6498, -1
  %6500 = and i32 %6499, %6493
  %6501 = and i32 %6498, %6496
  %6502 = or i32 %6501, %6500
  %6503 = add i64 %6494, 16
  %6504 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6503
  %6505 = load i32, i32* %6504, align 4
  %6506 = icmp eq i64 %6410, %6503
  %6507 = sext i1 %6506 to i32
  %6508 = xor i32 %6507, -1
  %6509 = and i32 %6508, %6502
  %6510 = and i32 %6507, %6505
  %6511 = or i32 %6510, %6509
  %6512 = add i64 %6503, 16
  %6513 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6512
  %6514 = load i32, i32* %6513, align 4
  %6515 = icmp eq i64 %6410, %6512
  %6516 = sext i1 %6515 to i32
  %6517 = xor i32 %6516, -1
  %6518 = and i32 %6517, %6511
  %6519 = and i32 %6516, %6514
  %6520 = or i32 %6519, %6518
  %6521 = add i64 %6512, 16
  %6522 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6521
  %6523 = load i32, i32* %6522, align 4
  %6524 = icmp eq i64 %6410, %6521
  %6525 = sext i1 %6524 to i32
  %6526 = xor i32 %6525, -1
  %6527 = and i32 %6526, %6520
  %6528 = and i32 %6525, %6523
  %6529 = or i32 %6528, %6527
  %6530 = add i64 %6521, 16
  %6531 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6530
  %6532 = load i32, i32* %6531, align 4
  %6533 = icmp eq i64 %6410, %6530
  %6534 = sext i1 %6533 to i32
  %6535 = xor i32 %6534, -1
  %6536 = and i32 %6535, %6529
  %6537 = and i32 %6534, %6532
  %6538 = or i32 %6537, %6536
  %6539 = add i64 %6530, 16
  %6540 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6539
  %6541 = load i32, i32* %6540, align 4
  %6542 = icmp eq i64 %6410, %6539
  %6543 = sext i1 %6542 to i32
  %6544 = xor i32 %6543, -1
  %6545 = and i32 %6544, %6538
  %6546 = and i32 %6543, %6541
  %6547 = or i32 %6546, %6545
  %6548 = add i64 %6539, 16
  %6549 = getelementptr inbounds [256 x i32], [256 x i32]* %6412, i64 0, i64 %6548
  %6550 = load i32, i32* %6549, align 4
  %6551 = icmp eq i64 %6410, %6548
  %6552 = sext i1 %6551 to i32
  %6553 = xor i32 %6552, -1
  %6554 = and i32 %6553, %6547
  %6555 = and i32 %6552, %6550
  %Mitigated42 = or i32 %6555, %6554
  %6556 = xor i32 %6407, %Mitigated42
  %6557 = lshr i32 %6107, 24
  %6558 = zext i32 %6557 to i64
  %6559 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6560 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6559, i64 0, i64 3
  %6561 = srem i64 %6558, 16
  %6562 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6561
  %6563 = load i32, i32* %6562, align 4
  %6564 = icmp eq i64 %6558, %6561
  %6565 = sext i1 %6564 to i32
  %6566 = xor i32 %6565, -1
  %6567 = and i32 %6566, 0
  %6568 = and i32 %6565, %6563
  %6569 = or i32 %6568, %6567
  %6570 = add i64 %6561, 16
  %6571 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6570
  %6572 = load i32, i32* %6571, align 4
  %6573 = icmp eq i64 %6558, %6570
  %6574 = sext i1 %6573 to i32
  %6575 = xor i32 %6574, -1
  %6576 = and i32 %6575, %6569
  %6577 = and i32 %6574, %6572
  %6578 = or i32 %6577, %6576
  %6579 = add i64 %6570, 16
  %6580 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6579
  %6581 = load i32, i32* %6580, align 4
  %6582 = icmp eq i64 %6558, %6579
  %6583 = sext i1 %6582 to i32
  %6584 = xor i32 %6583, -1
  %6585 = and i32 %6584, %6578
  %6586 = and i32 %6583, %6581
  %6587 = or i32 %6586, %6585
  %6588 = add i64 %6579, 16
  %6589 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6588
  %6590 = load i32, i32* %6589, align 4
  %6591 = icmp eq i64 %6558, %6588
  %6592 = sext i1 %6591 to i32
  %6593 = xor i32 %6592, -1
  %6594 = and i32 %6593, %6587
  %6595 = and i32 %6592, %6590
  %6596 = or i32 %6595, %6594
  %6597 = add i64 %6588, 16
  %6598 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6597
  %6599 = load i32, i32* %6598, align 4
  %6600 = icmp eq i64 %6558, %6597
  %6601 = sext i1 %6600 to i32
  %6602 = xor i32 %6601, -1
  %6603 = and i32 %6602, %6596
  %6604 = and i32 %6601, %6599
  %6605 = or i32 %6604, %6603
  %6606 = add i64 %6597, 16
  %6607 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6606
  %6608 = load i32, i32* %6607, align 4
  %6609 = icmp eq i64 %6558, %6606
  %6610 = sext i1 %6609 to i32
  %6611 = xor i32 %6610, -1
  %6612 = and i32 %6611, %6605
  %6613 = and i32 %6610, %6608
  %6614 = or i32 %6613, %6612
  %6615 = add i64 %6606, 16
  %6616 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6615
  %6617 = load i32, i32* %6616, align 4
  %6618 = icmp eq i64 %6558, %6615
  %6619 = sext i1 %6618 to i32
  %6620 = xor i32 %6619, -1
  %6621 = and i32 %6620, %6614
  %6622 = and i32 %6619, %6617
  %6623 = or i32 %6622, %6621
  %6624 = add i64 %6615, 16
  %6625 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6624
  %6626 = load i32, i32* %6625, align 4
  %6627 = icmp eq i64 %6558, %6624
  %6628 = sext i1 %6627 to i32
  %6629 = xor i32 %6628, -1
  %6630 = and i32 %6629, %6623
  %6631 = and i32 %6628, %6626
  %6632 = or i32 %6631, %6630
  %6633 = add i64 %6624, 16
  %6634 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6633
  %6635 = load i32, i32* %6634, align 4
  %6636 = icmp eq i64 %6558, %6633
  %6637 = sext i1 %6636 to i32
  %6638 = xor i32 %6637, -1
  %6639 = and i32 %6638, %6632
  %6640 = and i32 %6637, %6635
  %6641 = or i32 %6640, %6639
  %6642 = add i64 %6633, 16
  %6643 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6642
  %6644 = load i32, i32* %6643, align 4
  %6645 = icmp eq i64 %6558, %6642
  %6646 = sext i1 %6645 to i32
  %6647 = xor i32 %6646, -1
  %6648 = and i32 %6647, %6641
  %6649 = and i32 %6646, %6644
  %6650 = or i32 %6649, %6648
  %6651 = add i64 %6642, 16
  %6652 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6651
  %6653 = load i32, i32* %6652, align 4
  %6654 = icmp eq i64 %6558, %6651
  %6655 = sext i1 %6654 to i32
  %6656 = xor i32 %6655, -1
  %6657 = and i32 %6656, %6650
  %6658 = and i32 %6655, %6653
  %6659 = or i32 %6658, %6657
  %6660 = add i64 %6651, 16
  %6661 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6660
  %6662 = load i32, i32* %6661, align 4
  %6663 = icmp eq i64 %6558, %6660
  %6664 = sext i1 %6663 to i32
  %6665 = xor i32 %6664, -1
  %6666 = and i32 %6665, %6659
  %6667 = and i32 %6664, %6662
  %6668 = or i32 %6667, %6666
  %6669 = add i64 %6660, 16
  %6670 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6669
  %6671 = load i32, i32* %6670, align 4
  %6672 = icmp eq i64 %6558, %6669
  %6673 = sext i1 %6672 to i32
  %6674 = xor i32 %6673, -1
  %6675 = and i32 %6674, %6668
  %6676 = and i32 %6673, %6671
  %6677 = or i32 %6676, %6675
  %6678 = add i64 %6669, 16
  %6679 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6678
  %6680 = load i32, i32* %6679, align 4
  %6681 = icmp eq i64 %6558, %6678
  %6682 = sext i1 %6681 to i32
  %6683 = xor i32 %6682, -1
  %6684 = and i32 %6683, %6677
  %6685 = and i32 %6682, %6680
  %6686 = or i32 %6685, %6684
  %6687 = add i64 %6678, 16
  %6688 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6687
  %6689 = load i32, i32* %6688, align 4
  %6690 = icmp eq i64 %6558, %6687
  %6691 = sext i1 %6690 to i32
  %6692 = xor i32 %6691, -1
  %6693 = and i32 %6692, %6686
  %6694 = and i32 %6691, %6689
  %6695 = or i32 %6694, %6693
  %6696 = add i64 %6687, 16
  %6697 = getelementptr inbounds [256 x i32], [256 x i32]* %6560, i64 0, i64 %6696
  %6698 = load i32, i32* %6697, align 4
  %6699 = icmp eq i64 %6558, %6696
  %6700 = sext i1 %6699 to i32
  %6701 = xor i32 %6700, -1
  %6702 = and i32 %6701, %6695
  %6703 = and i32 %6700, %6698
  %Mitigated43 = or i32 %6703, %6702
  %6704 = xor i32 %6556, %Mitigated43
  %6705 = and i32 %6111, 255
  %6706 = zext i32 %6705 to i64
  %6707 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6708 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6707, i64 0, i64 1
  %6709 = srem i64 %6706, 16
  %6710 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6709
  %6711 = load i32, i32* %6710, align 4
  %6712 = icmp eq i64 %6706, %6709
  %6713 = sext i1 %6712 to i32
  %6714 = xor i32 %6713, -1
  %6715 = and i32 %6714, 0
  %6716 = and i32 %6713, %6711
  %6717 = or i32 %6716, %6715
  %6718 = add i64 %6709, 16
  %6719 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6718
  %6720 = load i32, i32* %6719, align 4
  %6721 = icmp eq i64 %6706, %6718
  %6722 = sext i1 %6721 to i32
  %6723 = xor i32 %6722, -1
  %6724 = and i32 %6723, %6717
  %6725 = and i32 %6722, %6720
  %6726 = or i32 %6725, %6724
  %6727 = add i64 %6718, 16
  %6728 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6727
  %6729 = load i32, i32* %6728, align 4
  %6730 = icmp eq i64 %6706, %6727
  %6731 = sext i1 %6730 to i32
  %6732 = xor i32 %6731, -1
  %6733 = and i32 %6732, %6726
  %6734 = and i32 %6731, %6729
  %6735 = or i32 %6734, %6733
  %6736 = add i64 %6727, 16
  %6737 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6736
  %6738 = load i32, i32* %6737, align 4
  %6739 = icmp eq i64 %6706, %6736
  %6740 = sext i1 %6739 to i32
  %6741 = xor i32 %6740, -1
  %6742 = and i32 %6741, %6735
  %6743 = and i32 %6740, %6738
  %6744 = or i32 %6743, %6742
  %6745 = add i64 %6736, 16
  %6746 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6745
  %6747 = load i32, i32* %6746, align 4
  %6748 = icmp eq i64 %6706, %6745
  %6749 = sext i1 %6748 to i32
  %6750 = xor i32 %6749, -1
  %6751 = and i32 %6750, %6744
  %6752 = and i32 %6749, %6747
  %6753 = or i32 %6752, %6751
  %6754 = add i64 %6745, 16
  %6755 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6754
  %6756 = load i32, i32* %6755, align 4
  %6757 = icmp eq i64 %6706, %6754
  %6758 = sext i1 %6757 to i32
  %6759 = xor i32 %6758, -1
  %6760 = and i32 %6759, %6753
  %6761 = and i32 %6758, %6756
  %6762 = or i32 %6761, %6760
  %6763 = add i64 %6754, 16
  %6764 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6763
  %6765 = load i32, i32* %6764, align 4
  %6766 = icmp eq i64 %6706, %6763
  %6767 = sext i1 %6766 to i32
  %6768 = xor i32 %6767, -1
  %6769 = and i32 %6768, %6762
  %6770 = and i32 %6767, %6765
  %6771 = or i32 %6770, %6769
  %6772 = add i64 %6763, 16
  %6773 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6772
  %6774 = load i32, i32* %6773, align 4
  %6775 = icmp eq i64 %6706, %6772
  %6776 = sext i1 %6775 to i32
  %6777 = xor i32 %6776, -1
  %6778 = and i32 %6777, %6771
  %6779 = and i32 %6776, %6774
  %6780 = or i32 %6779, %6778
  %6781 = add i64 %6772, 16
  %6782 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6781
  %6783 = load i32, i32* %6782, align 4
  %6784 = icmp eq i64 %6706, %6781
  %6785 = sext i1 %6784 to i32
  %6786 = xor i32 %6785, -1
  %6787 = and i32 %6786, %6780
  %6788 = and i32 %6785, %6783
  %6789 = or i32 %6788, %6787
  %6790 = add i64 %6781, 16
  %6791 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6790
  %6792 = load i32, i32* %6791, align 4
  %6793 = icmp eq i64 %6706, %6790
  %6794 = sext i1 %6793 to i32
  %6795 = xor i32 %6794, -1
  %6796 = and i32 %6795, %6789
  %6797 = and i32 %6794, %6792
  %6798 = or i32 %6797, %6796
  %6799 = add i64 %6790, 16
  %6800 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6799
  %6801 = load i32, i32* %6800, align 4
  %6802 = icmp eq i64 %6706, %6799
  %6803 = sext i1 %6802 to i32
  %6804 = xor i32 %6803, -1
  %6805 = and i32 %6804, %6798
  %6806 = and i32 %6803, %6801
  %6807 = or i32 %6806, %6805
  %6808 = add i64 %6799, 16
  %6809 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6808
  %6810 = load i32, i32* %6809, align 4
  %6811 = icmp eq i64 %6706, %6808
  %6812 = sext i1 %6811 to i32
  %6813 = xor i32 %6812, -1
  %6814 = and i32 %6813, %6807
  %6815 = and i32 %6812, %6810
  %6816 = or i32 %6815, %6814
  %6817 = add i64 %6808, 16
  %6818 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6817
  %6819 = load i32, i32* %6818, align 4
  %6820 = icmp eq i64 %6706, %6817
  %6821 = sext i1 %6820 to i32
  %6822 = xor i32 %6821, -1
  %6823 = and i32 %6822, %6816
  %6824 = and i32 %6821, %6819
  %6825 = or i32 %6824, %6823
  %6826 = add i64 %6817, 16
  %6827 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6826
  %6828 = load i32, i32* %6827, align 4
  %6829 = icmp eq i64 %6706, %6826
  %6830 = sext i1 %6829 to i32
  %6831 = xor i32 %6830, -1
  %6832 = and i32 %6831, %6825
  %6833 = and i32 %6830, %6828
  %6834 = or i32 %6833, %6832
  %6835 = add i64 %6826, 16
  %6836 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6835
  %6837 = load i32, i32* %6836, align 4
  %6838 = icmp eq i64 %6706, %6835
  %6839 = sext i1 %6838 to i32
  %6840 = xor i32 %6839, -1
  %6841 = and i32 %6840, %6834
  %6842 = and i32 %6839, %6837
  %6843 = or i32 %6842, %6841
  %6844 = add i64 %6835, 16
  %6845 = getelementptr inbounds [256 x i32], [256 x i32]* %6708, i64 0, i64 %6844
  %6846 = load i32, i32* %6845, align 4
  %6847 = icmp eq i64 %6706, %6844
  %6848 = sext i1 %6847 to i32
  %6849 = xor i32 %6848, -1
  %6850 = and i32 %6849, %6843
  %6851 = and i32 %6848, %6846
  %Mitigated44 = or i32 %6851, %6850
  %6852 = lshr i32 %6111, 8
  %6853 = and i32 %6852, 255
  %6854 = zext i32 %6853 to i64
  %6855 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %6856 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %6855, i64 0, i64 2
  %6857 = srem i64 %6854, 16
  %6858 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6857
  %6859 = load i32, i32* %6858, align 4
  %6860 = icmp eq i64 %6854, %6857
  %6861 = sext i1 %6860 to i32
  %6862 = xor i32 %6861, -1
  %6863 = and i32 %6862, 0
  %6864 = and i32 %6861, %6859
  %6865 = or i32 %6864, %6863
  %6866 = add i64 %6857, 16
  %6867 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6866
  %6868 = load i32, i32* %6867, align 4
  %6869 = icmp eq i64 %6854, %6866
  %6870 = sext i1 %6869 to i32
  %6871 = xor i32 %6870, -1
  %6872 = and i32 %6871, %6865
  %6873 = and i32 %6870, %6868
  %6874 = or i32 %6873, %6872
  %6875 = add i64 %6866, 16
  %6876 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6875
  %6877 = load i32, i32* %6876, align 4
  %6878 = icmp eq i64 %6854, %6875
  %6879 = sext i1 %6878 to i32
  %6880 = xor i32 %6879, -1
  %6881 = and i32 %6880, %6874
  %6882 = and i32 %6879, %6877
  %6883 = or i32 %6882, %6881
  %6884 = add i64 %6875, 16
  %6885 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6884
  %6886 = load i32, i32* %6885, align 4
  %6887 = icmp eq i64 %6854, %6884
  %6888 = sext i1 %6887 to i32
  %6889 = xor i32 %6888, -1
  %6890 = and i32 %6889, %6883
  %6891 = and i32 %6888, %6886
  %6892 = or i32 %6891, %6890
  %6893 = add i64 %6884, 16
  %6894 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6893
  %6895 = load i32, i32* %6894, align 4
  %6896 = icmp eq i64 %6854, %6893
  %6897 = sext i1 %6896 to i32
  %6898 = xor i32 %6897, -1
  %6899 = and i32 %6898, %6892
  %6900 = and i32 %6897, %6895
  %6901 = or i32 %6900, %6899
  %6902 = add i64 %6893, 16
  %6903 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6902
  %6904 = load i32, i32* %6903, align 4
  %6905 = icmp eq i64 %6854, %6902
  %6906 = sext i1 %6905 to i32
  %6907 = xor i32 %6906, -1
  %6908 = and i32 %6907, %6901
  %6909 = and i32 %6906, %6904
  %6910 = or i32 %6909, %6908
  %6911 = add i64 %6902, 16
  %6912 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6911
  %6913 = load i32, i32* %6912, align 4
  %6914 = icmp eq i64 %6854, %6911
  %6915 = sext i1 %6914 to i32
  %6916 = xor i32 %6915, -1
  %6917 = and i32 %6916, %6910
  %6918 = and i32 %6915, %6913
  %6919 = or i32 %6918, %6917
  %6920 = add i64 %6911, 16
  %6921 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6920
  %6922 = load i32, i32* %6921, align 4
  %6923 = icmp eq i64 %6854, %6920
  %6924 = sext i1 %6923 to i32
  %6925 = xor i32 %6924, -1
  %6926 = and i32 %6925, %6919
  %6927 = and i32 %6924, %6922
  %6928 = or i32 %6927, %6926
  %6929 = add i64 %6920, 16
  %6930 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6929
  %6931 = load i32, i32* %6930, align 4
  %6932 = icmp eq i64 %6854, %6929
  %6933 = sext i1 %6932 to i32
  %6934 = xor i32 %6933, -1
  %6935 = and i32 %6934, %6928
  %6936 = and i32 %6933, %6931
  %6937 = or i32 %6936, %6935
  %6938 = add i64 %6929, 16
  %6939 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6938
  %6940 = load i32, i32* %6939, align 4
  %6941 = icmp eq i64 %6854, %6938
  %6942 = sext i1 %6941 to i32
  %6943 = xor i32 %6942, -1
  %6944 = and i32 %6943, %6937
  %6945 = and i32 %6942, %6940
  %6946 = or i32 %6945, %6944
  %6947 = add i64 %6938, 16
  %6948 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6947
  %6949 = load i32, i32* %6948, align 4
  %6950 = icmp eq i64 %6854, %6947
  %6951 = sext i1 %6950 to i32
  %6952 = xor i32 %6951, -1
  %6953 = and i32 %6952, %6946
  %6954 = and i32 %6951, %6949
  %6955 = or i32 %6954, %6953
  %6956 = add i64 %6947, 16
  %6957 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6956
  %6958 = load i32, i32* %6957, align 4
  %6959 = icmp eq i64 %6854, %6956
  %6960 = sext i1 %6959 to i32
  %6961 = xor i32 %6960, -1
  %6962 = and i32 %6961, %6955
  %6963 = and i32 %6960, %6958
  %6964 = or i32 %6963, %6962
  %6965 = add i64 %6956, 16
  %6966 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6965
  %6967 = load i32, i32* %6966, align 4
  %6968 = icmp eq i64 %6854, %6965
  %6969 = sext i1 %6968 to i32
  %6970 = xor i32 %6969, -1
  %6971 = and i32 %6970, %6964
  %6972 = and i32 %6969, %6967
  %6973 = or i32 %6972, %6971
  %6974 = add i64 %6965, 16
  %6975 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6974
  %6976 = load i32, i32* %6975, align 4
  %6977 = icmp eq i64 %6854, %6974
  %6978 = sext i1 %6977 to i32
  %6979 = xor i32 %6978, -1
  %6980 = and i32 %6979, %6973
  %6981 = and i32 %6978, %6976
  %6982 = or i32 %6981, %6980
  %6983 = add i64 %6974, 16
  %6984 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6983
  %6985 = load i32, i32* %6984, align 4
  %6986 = icmp eq i64 %6854, %6983
  %6987 = sext i1 %6986 to i32
  %6988 = xor i32 %6987, -1
  %6989 = and i32 %6988, %6982
  %6990 = and i32 %6987, %6985
  %6991 = or i32 %6990, %6989
  %6992 = add i64 %6983, 16
  %6993 = getelementptr inbounds [256 x i32], [256 x i32]* %6856, i64 0, i64 %6992
  %6994 = load i32, i32* %6993, align 4
  %6995 = icmp eq i64 %6854, %6992
  %6996 = sext i1 %6995 to i32
  %6997 = xor i32 %6996, -1
  %6998 = and i32 %6997, %6991
  %6999 = and i32 %6996, %6994
  %Mitigated45 = or i32 %6999, %6998
  %7000 = xor i32 %Mitigated44, %Mitigated45
  %7001 = lshr i32 %6111, 16
  %7002 = and i32 %7001, 255
  %7003 = zext i32 %7002 to i64
  %7004 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7005 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7004, i64 0, i64 3
  %7006 = srem i64 %7003, 16
  %7007 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7006
  %7008 = load i32, i32* %7007, align 4
  %7009 = icmp eq i64 %7003, %7006
  %7010 = sext i1 %7009 to i32
  %7011 = xor i32 %7010, -1
  %7012 = and i32 %7011, 0
  %7013 = and i32 %7010, %7008
  %7014 = or i32 %7013, %7012
  %7015 = add i64 %7006, 16
  %7016 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7015
  %7017 = load i32, i32* %7016, align 4
  %7018 = icmp eq i64 %7003, %7015
  %7019 = sext i1 %7018 to i32
  %7020 = xor i32 %7019, -1
  %7021 = and i32 %7020, %7014
  %7022 = and i32 %7019, %7017
  %7023 = or i32 %7022, %7021
  %7024 = add i64 %7015, 16
  %7025 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7024
  %7026 = load i32, i32* %7025, align 4
  %7027 = icmp eq i64 %7003, %7024
  %7028 = sext i1 %7027 to i32
  %7029 = xor i32 %7028, -1
  %7030 = and i32 %7029, %7023
  %7031 = and i32 %7028, %7026
  %7032 = or i32 %7031, %7030
  %7033 = add i64 %7024, 16
  %7034 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7033
  %7035 = load i32, i32* %7034, align 4
  %7036 = icmp eq i64 %7003, %7033
  %7037 = sext i1 %7036 to i32
  %7038 = xor i32 %7037, -1
  %7039 = and i32 %7038, %7032
  %7040 = and i32 %7037, %7035
  %7041 = or i32 %7040, %7039
  %7042 = add i64 %7033, 16
  %7043 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7042
  %7044 = load i32, i32* %7043, align 4
  %7045 = icmp eq i64 %7003, %7042
  %7046 = sext i1 %7045 to i32
  %7047 = xor i32 %7046, -1
  %7048 = and i32 %7047, %7041
  %7049 = and i32 %7046, %7044
  %7050 = or i32 %7049, %7048
  %7051 = add i64 %7042, 16
  %7052 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7051
  %7053 = load i32, i32* %7052, align 4
  %7054 = icmp eq i64 %7003, %7051
  %7055 = sext i1 %7054 to i32
  %7056 = xor i32 %7055, -1
  %7057 = and i32 %7056, %7050
  %7058 = and i32 %7055, %7053
  %7059 = or i32 %7058, %7057
  %7060 = add i64 %7051, 16
  %7061 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7060
  %7062 = load i32, i32* %7061, align 4
  %7063 = icmp eq i64 %7003, %7060
  %7064 = sext i1 %7063 to i32
  %7065 = xor i32 %7064, -1
  %7066 = and i32 %7065, %7059
  %7067 = and i32 %7064, %7062
  %7068 = or i32 %7067, %7066
  %7069 = add i64 %7060, 16
  %7070 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7069
  %7071 = load i32, i32* %7070, align 4
  %7072 = icmp eq i64 %7003, %7069
  %7073 = sext i1 %7072 to i32
  %7074 = xor i32 %7073, -1
  %7075 = and i32 %7074, %7068
  %7076 = and i32 %7073, %7071
  %7077 = or i32 %7076, %7075
  %7078 = add i64 %7069, 16
  %7079 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7078
  %7080 = load i32, i32* %7079, align 4
  %7081 = icmp eq i64 %7003, %7078
  %7082 = sext i1 %7081 to i32
  %7083 = xor i32 %7082, -1
  %7084 = and i32 %7083, %7077
  %7085 = and i32 %7082, %7080
  %7086 = or i32 %7085, %7084
  %7087 = add i64 %7078, 16
  %7088 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7087
  %7089 = load i32, i32* %7088, align 4
  %7090 = icmp eq i64 %7003, %7087
  %7091 = sext i1 %7090 to i32
  %7092 = xor i32 %7091, -1
  %7093 = and i32 %7092, %7086
  %7094 = and i32 %7091, %7089
  %7095 = or i32 %7094, %7093
  %7096 = add i64 %7087, 16
  %7097 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7096
  %7098 = load i32, i32* %7097, align 4
  %7099 = icmp eq i64 %7003, %7096
  %7100 = sext i1 %7099 to i32
  %7101 = xor i32 %7100, -1
  %7102 = and i32 %7101, %7095
  %7103 = and i32 %7100, %7098
  %7104 = or i32 %7103, %7102
  %7105 = add i64 %7096, 16
  %7106 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7105
  %7107 = load i32, i32* %7106, align 4
  %7108 = icmp eq i64 %7003, %7105
  %7109 = sext i1 %7108 to i32
  %7110 = xor i32 %7109, -1
  %7111 = and i32 %7110, %7104
  %7112 = and i32 %7109, %7107
  %7113 = or i32 %7112, %7111
  %7114 = add i64 %7105, 16
  %7115 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7114
  %7116 = load i32, i32* %7115, align 4
  %7117 = icmp eq i64 %7003, %7114
  %7118 = sext i1 %7117 to i32
  %7119 = xor i32 %7118, -1
  %7120 = and i32 %7119, %7113
  %7121 = and i32 %7118, %7116
  %7122 = or i32 %7121, %7120
  %7123 = add i64 %7114, 16
  %7124 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7123
  %7125 = load i32, i32* %7124, align 4
  %7126 = icmp eq i64 %7003, %7123
  %7127 = sext i1 %7126 to i32
  %7128 = xor i32 %7127, -1
  %7129 = and i32 %7128, %7122
  %7130 = and i32 %7127, %7125
  %7131 = or i32 %7130, %7129
  %7132 = add i64 %7123, 16
  %7133 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7132
  %7134 = load i32, i32* %7133, align 4
  %7135 = icmp eq i64 %7003, %7132
  %7136 = sext i1 %7135 to i32
  %7137 = xor i32 %7136, -1
  %7138 = and i32 %7137, %7131
  %7139 = and i32 %7136, %7134
  %7140 = or i32 %7139, %7138
  %7141 = add i64 %7132, 16
  %7142 = getelementptr inbounds [256 x i32], [256 x i32]* %7005, i64 0, i64 %7141
  %7143 = load i32, i32* %7142, align 4
  %7144 = icmp eq i64 %7003, %7141
  %7145 = sext i1 %7144 to i32
  %7146 = xor i32 %7145, -1
  %7147 = and i32 %7146, %7140
  %7148 = and i32 %7145, %7143
  %Mitigated46 = or i32 %7148, %7147
  %7149 = xor i32 %7000, %Mitigated46
  %7150 = lshr i32 %6111, 24
  %7151 = zext i32 %7150 to i64
  %7152 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7153 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7152, i64 0, i64 0
  %7154 = srem i64 %7151, 16
  %7155 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7154
  %7156 = load i32, i32* %7155, align 4
  %7157 = icmp eq i64 %7151, %7154
  %7158 = sext i1 %7157 to i32
  %7159 = xor i32 %7158, -1
  %7160 = and i32 %7159, 0
  %7161 = and i32 %7158, %7156
  %7162 = or i32 %7161, %7160
  %7163 = add i64 %7154, 16
  %7164 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7163
  %7165 = load i32, i32* %7164, align 4
  %7166 = icmp eq i64 %7151, %7163
  %7167 = sext i1 %7166 to i32
  %7168 = xor i32 %7167, -1
  %7169 = and i32 %7168, %7162
  %7170 = and i32 %7167, %7165
  %7171 = or i32 %7170, %7169
  %7172 = add i64 %7163, 16
  %7173 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7172
  %7174 = load i32, i32* %7173, align 4
  %7175 = icmp eq i64 %7151, %7172
  %7176 = sext i1 %7175 to i32
  %7177 = xor i32 %7176, -1
  %7178 = and i32 %7177, %7171
  %7179 = and i32 %7176, %7174
  %7180 = or i32 %7179, %7178
  %7181 = add i64 %7172, 16
  %7182 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7181
  %7183 = load i32, i32* %7182, align 4
  %7184 = icmp eq i64 %7151, %7181
  %7185 = sext i1 %7184 to i32
  %7186 = xor i32 %7185, -1
  %7187 = and i32 %7186, %7180
  %7188 = and i32 %7185, %7183
  %7189 = or i32 %7188, %7187
  %7190 = add i64 %7181, 16
  %7191 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7190
  %7192 = load i32, i32* %7191, align 4
  %7193 = icmp eq i64 %7151, %7190
  %7194 = sext i1 %7193 to i32
  %7195 = xor i32 %7194, -1
  %7196 = and i32 %7195, %7189
  %7197 = and i32 %7194, %7192
  %7198 = or i32 %7197, %7196
  %7199 = add i64 %7190, 16
  %7200 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7199
  %7201 = load i32, i32* %7200, align 4
  %7202 = icmp eq i64 %7151, %7199
  %7203 = sext i1 %7202 to i32
  %7204 = xor i32 %7203, -1
  %7205 = and i32 %7204, %7198
  %7206 = and i32 %7203, %7201
  %7207 = or i32 %7206, %7205
  %7208 = add i64 %7199, 16
  %7209 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7208
  %7210 = load i32, i32* %7209, align 4
  %7211 = icmp eq i64 %7151, %7208
  %7212 = sext i1 %7211 to i32
  %7213 = xor i32 %7212, -1
  %7214 = and i32 %7213, %7207
  %7215 = and i32 %7212, %7210
  %7216 = or i32 %7215, %7214
  %7217 = add i64 %7208, 16
  %7218 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7217
  %7219 = load i32, i32* %7218, align 4
  %7220 = icmp eq i64 %7151, %7217
  %7221 = sext i1 %7220 to i32
  %7222 = xor i32 %7221, -1
  %7223 = and i32 %7222, %7216
  %7224 = and i32 %7221, %7219
  %7225 = or i32 %7224, %7223
  %7226 = add i64 %7217, 16
  %7227 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7226
  %7228 = load i32, i32* %7227, align 4
  %7229 = icmp eq i64 %7151, %7226
  %7230 = sext i1 %7229 to i32
  %7231 = xor i32 %7230, -1
  %7232 = and i32 %7231, %7225
  %7233 = and i32 %7230, %7228
  %7234 = or i32 %7233, %7232
  %7235 = add i64 %7226, 16
  %7236 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7235
  %7237 = load i32, i32* %7236, align 4
  %7238 = icmp eq i64 %7151, %7235
  %7239 = sext i1 %7238 to i32
  %7240 = xor i32 %7239, -1
  %7241 = and i32 %7240, %7234
  %7242 = and i32 %7239, %7237
  %7243 = or i32 %7242, %7241
  %7244 = add i64 %7235, 16
  %7245 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7244
  %7246 = load i32, i32* %7245, align 4
  %7247 = icmp eq i64 %7151, %7244
  %7248 = sext i1 %7247 to i32
  %7249 = xor i32 %7248, -1
  %7250 = and i32 %7249, %7243
  %7251 = and i32 %7248, %7246
  %7252 = or i32 %7251, %7250
  %7253 = add i64 %7244, 16
  %7254 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7253
  %7255 = load i32, i32* %7254, align 4
  %7256 = icmp eq i64 %7151, %7253
  %7257 = sext i1 %7256 to i32
  %7258 = xor i32 %7257, -1
  %7259 = and i32 %7258, %7252
  %7260 = and i32 %7257, %7255
  %7261 = or i32 %7260, %7259
  %7262 = add i64 %7253, 16
  %7263 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7262
  %7264 = load i32, i32* %7263, align 4
  %7265 = icmp eq i64 %7151, %7262
  %7266 = sext i1 %7265 to i32
  %7267 = xor i32 %7266, -1
  %7268 = and i32 %7267, %7261
  %7269 = and i32 %7266, %7264
  %7270 = or i32 %7269, %7268
  %7271 = add i64 %7262, 16
  %7272 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7271
  %7273 = load i32, i32* %7272, align 4
  %7274 = icmp eq i64 %7151, %7271
  %7275 = sext i1 %7274 to i32
  %7276 = xor i32 %7275, -1
  %7277 = and i32 %7276, %7270
  %7278 = and i32 %7275, %7273
  %7279 = or i32 %7278, %7277
  %7280 = add i64 %7271, 16
  %7281 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7280
  %7282 = load i32, i32* %7281, align 4
  %7283 = icmp eq i64 %7151, %7280
  %7284 = sext i1 %7283 to i32
  %7285 = xor i32 %7284, -1
  %7286 = and i32 %7285, %7279
  %7287 = and i32 %7284, %7282
  %7288 = or i32 %7287, %7286
  %7289 = add i64 %7280, 16
  %7290 = getelementptr inbounds [256 x i32], [256 x i32]* %7153, i64 0, i64 %7289
  %7291 = load i32, i32* %7290, align 4
  %7292 = icmp eq i64 %7151, %7289
  %7293 = sext i1 %7292 to i32
  %7294 = xor i32 %7293, -1
  %7295 = and i32 %7294, %7288
  %7296 = and i32 %7293, %7291
  %Mitigated47 = or i32 %7296, %7295
  %7297 = xor i32 %7149, %Mitigated47
  %7298 = add i32 %6704, %7297
  %7299 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %7300 = getelementptr inbounds [32 x i32], [32 x i32]* %7299, i64 0, i64 11
  %7301 = load i32, i32* %7300, align 4
  %7302 = add i32 %7298, %7301
  %7303 = add i32 %7297, %7302
  %7304 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %7305 = getelementptr inbounds [32 x i32], [32 x i32]* %7304, i64 0, i64 10
  %7306 = load i32, i32* %7305, align 4
  %7307 = add i32 %7298, %7306
  %7308 = xor i32 %4903, %7307
  %7309 = lshr i32 %7308, 1
  %7310 = shl i32 %7308, 31
  %7311 = add i32 %7309, %7310
  %7312 = shl i32 %4907, 1
  %7313 = lshr i32 %4907, 31
  %7314 = add i32 %7312, %7313
  %7315 = xor i32 %7314, %7303
  %7316 = and i32 %7311, 255
  %7317 = zext i32 %7316 to i64
  %7318 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7319 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7318, i64 0, i64 0
  %7320 = srem i64 %7317, 16
  %7321 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7320
  %7322 = load i32, i32* %7321, align 4
  %7323 = icmp eq i64 %7317, %7320
  %7324 = sext i1 %7323 to i32
  %7325 = xor i32 %7324, -1
  %7326 = and i32 %7325, 0
  %7327 = and i32 %7324, %7322
  %7328 = or i32 %7327, %7326
  %7329 = add i64 %7320, 16
  %7330 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7329
  %7331 = load i32, i32* %7330, align 4
  %7332 = icmp eq i64 %7317, %7329
  %7333 = sext i1 %7332 to i32
  %7334 = xor i32 %7333, -1
  %7335 = and i32 %7334, %7328
  %7336 = and i32 %7333, %7331
  %7337 = or i32 %7336, %7335
  %7338 = add i64 %7329, 16
  %7339 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7338
  %7340 = load i32, i32* %7339, align 4
  %7341 = icmp eq i64 %7317, %7338
  %7342 = sext i1 %7341 to i32
  %7343 = xor i32 %7342, -1
  %7344 = and i32 %7343, %7337
  %7345 = and i32 %7342, %7340
  %7346 = or i32 %7345, %7344
  %7347 = add i64 %7338, 16
  %7348 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7347
  %7349 = load i32, i32* %7348, align 4
  %7350 = icmp eq i64 %7317, %7347
  %7351 = sext i1 %7350 to i32
  %7352 = xor i32 %7351, -1
  %7353 = and i32 %7352, %7346
  %7354 = and i32 %7351, %7349
  %7355 = or i32 %7354, %7353
  %7356 = add i64 %7347, 16
  %7357 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7356
  %7358 = load i32, i32* %7357, align 4
  %7359 = icmp eq i64 %7317, %7356
  %7360 = sext i1 %7359 to i32
  %7361 = xor i32 %7360, -1
  %7362 = and i32 %7361, %7355
  %7363 = and i32 %7360, %7358
  %7364 = or i32 %7363, %7362
  %7365 = add i64 %7356, 16
  %7366 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7365
  %7367 = load i32, i32* %7366, align 4
  %7368 = icmp eq i64 %7317, %7365
  %7369 = sext i1 %7368 to i32
  %7370 = xor i32 %7369, -1
  %7371 = and i32 %7370, %7364
  %7372 = and i32 %7369, %7367
  %7373 = or i32 %7372, %7371
  %7374 = add i64 %7365, 16
  %7375 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7374
  %7376 = load i32, i32* %7375, align 4
  %7377 = icmp eq i64 %7317, %7374
  %7378 = sext i1 %7377 to i32
  %7379 = xor i32 %7378, -1
  %7380 = and i32 %7379, %7373
  %7381 = and i32 %7378, %7376
  %7382 = or i32 %7381, %7380
  %7383 = add i64 %7374, 16
  %7384 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7383
  %7385 = load i32, i32* %7384, align 4
  %7386 = icmp eq i64 %7317, %7383
  %7387 = sext i1 %7386 to i32
  %7388 = xor i32 %7387, -1
  %7389 = and i32 %7388, %7382
  %7390 = and i32 %7387, %7385
  %7391 = or i32 %7390, %7389
  %7392 = add i64 %7383, 16
  %7393 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7392
  %7394 = load i32, i32* %7393, align 4
  %7395 = icmp eq i64 %7317, %7392
  %7396 = sext i1 %7395 to i32
  %7397 = xor i32 %7396, -1
  %7398 = and i32 %7397, %7391
  %7399 = and i32 %7396, %7394
  %7400 = or i32 %7399, %7398
  %7401 = add i64 %7392, 16
  %7402 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7401
  %7403 = load i32, i32* %7402, align 4
  %7404 = icmp eq i64 %7317, %7401
  %7405 = sext i1 %7404 to i32
  %7406 = xor i32 %7405, -1
  %7407 = and i32 %7406, %7400
  %7408 = and i32 %7405, %7403
  %7409 = or i32 %7408, %7407
  %7410 = add i64 %7401, 16
  %7411 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7410
  %7412 = load i32, i32* %7411, align 4
  %7413 = icmp eq i64 %7317, %7410
  %7414 = sext i1 %7413 to i32
  %7415 = xor i32 %7414, -1
  %7416 = and i32 %7415, %7409
  %7417 = and i32 %7414, %7412
  %7418 = or i32 %7417, %7416
  %7419 = add i64 %7410, 16
  %7420 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7419
  %7421 = load i32, i32* %7420, align 4
  %7422 = icmp eq i64 %7317, %7419
  %7423 = sext i1 %7422 to i32
  %7424 = xor i32 %7423, -1
  %7425 = and i32 %7424, %7418
  %7426 = and i32 %7423, %7421
  %7427 = or i32 %7426, %7425
  %7428 = add i64 %7419, 16
  %7429 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7428
  %7430 = load i32, i32* %7429, align 4
  %7431 = icmp eq i64 %7317, %7428
  %7432 = sext i1 %7431 to i32
  %7433 = xor i32 %7432, -1
  %7434 = and i32 %7433, %7427
  %7435 = and i32 %7432, %7430
  %7436 = or i32 %7435, %7434
  %7437 = add i64 %7428, 16
  %7438 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7437
  %7439 = load i32, i32* %7438, align 4
  %7440 = icmp eq i64 %7317, %7437
  %7441 = sext i1 %7440 to i32
  %7442 = xor i32 %7441, -1
  %7443 = and i32 %7442, %7436
  %7444 = and i32 %7441, %7439
  %7445 = or i32 %7444, %7443
  %7446 = add i64 %7437, 16
  %7447 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7446
  %7448 = load i32, i32* %7447, align 4
  %7449 = icmp eq i64 %7317, %7446
  %7450 = sext i1 %7449 to i32
  %7451 = xor i32 %7450, -1
  %7452 = and i32 %7451, %7445
  %7453 = and i32 %7450, %7448
  %7454 = or i32 %7453, %7452
  %7455 = add i64 %7446, 16
  %7456 = getelementptr inbounds [256 x i32], [256 x i32]* %7319, i64 0, i64 %7455
  %7457 = load i32, i32* %7456, align 4
  %7458 = icmp eq i64 %7317, %7455
  %7459 = sext i1 %7458 to i32
  %7460 = xor i32 %7459, -1
  %7461 = and i32 %7460, %7454
  %7462 = and i32 %7459, %7457
  %Mitigated48 = or i32 %7462, %7461
  %7463 = lshr i32 %7311, 8
  %7464 = and i32 %7463, 255
  %7465 = zext i32 %7464 to i64
  %7466 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7467 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7466, i64 0, i64 1
  %7468 = srem i64 %7465, 16
  %7469 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7468
  %7470 = load i32, i32* %7469, align 4
  %7471 = icmp eq i64 %7465, %7468
  %7472 = sext i1 %7471 to i32
  %7473 = xor i32 %7472, -1
  %7474 = and i32 %7473, 0
  %7475 = and i32 %7472, %7470
  %7476 = or i32 %7475, %7474
  %7477 = add i64 %7468, 16
  %7478 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7477
  %7479 = load i32, i32* %7478, align 4
  %7480 = icmp eq i64 %7465, %7477
  %7481 = sext i1 %7480 to i32
  %7482 = xor i32 %7481, -1
  %7483 = and i32 %7482, %7476
  %7484 = and i32 %7481, %7479
  %7485 = or i32 %7484, %7483
  %7486 = add i64 %7477, 16
  %7487 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7486
  %7488 = load i32, i32* %7487, align 4
  %7489 = icmp eq i64 %7465, %7486
  %7490 = sext i1 %7489 to i32
  %7491 = xor i32 %7490, -1
  %7492 = and i32 %7491, %7485
  %7493 = and i32 %7490, %7488
  %7494 = or i32 %7493, %7492
  %7495 = add i64 %7486, 16
  %7496 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7495
  %7497 = load i32, i32* %7496, align 4
  %7498 = icmp eq i64 %7465, %7495
  %7499 = sext i1 %7498 to i32
  %7500 = xor i32 %7499, -1
  %7501 = and i32 %7500, %7494
  %7502 = and i32 %7499, %7497
  %7503 = or i32 %7502, %7501
  %7504 = add i64 %7495, 16
  %7505 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7504
  %7506 = load i32, i32* %7505, align 4
  %7507 = icmp eq i64 %7465, %7504
  %7508 = sext i1 %7507 to i32
  %7509 = xor i32 %7508, -1
  %7510 = and i32 %7509, %7503
  %7511 = and i32 %7508, %7506
  %7512 = or i32 %7511, %7510
  %7513 = add i64 %7504, 16
  %7514 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7513
  %7515 = load i32, i32* %7514, align 4
  %7516 = icmp eq i64 %7465, %7513
  %7517 = sext i1 %7516 to i32
  %7518 = xor i32 %7517, -1
  %7519 = and i32 %7518, %7512
  %7520 = and i32 %7517, %7515
  %7521 = or i32 %7520, %7519
  %7522 = add i64 %7513, 16
  %7523 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7522
  %7524 = load i32, i32* %7523, align 4
  %7525 = icmp eq i64 %7465, %7522
  %7526 = sext i1 %7525 to i32
  %7527 = xor i32 %7526, -1
  %7528 = and i32 %7527, %7521
  %7529 = and i32 %7526, %7524
  %7530 = or i32 %7529, %7528
  %7531 = add i64 %7522, 16
  %7532 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7531
  %7533 = load i32, i32* %7532, align 4
  %7534 = icmp eq i64 %7465, %7531
  %7535 = sext i1 %7534 to i32
  %7536 = xor i32 %7535, -1
  %7537 = and i32 %7536, %7530
  %7538 = and i32 %7535, %7533
  %7539 = or i32 %7538, %7537
  %7540 = add i64 %7531, 16
  %7541 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7540
  %7542 = load i32, i32* %7541, align 4
  %7543 = icmp eq i64 %7465, %7540
  %7544 = sext i1 %7543 to i32
  %7545 = xor i32 %7544, -1
  %7546 = and i32 %7545, %7539
  %7547 = and i32 %7544, %7542
  %7548 = or i32 %7547, %7546
  %7549 = add i64 %7540, 16
  %7550 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7549
  %7551 = load i32, i32* %7550, align 4
  %7552 = icmp eq i64 %7465, %7549
  %7553 = sext i1 %7552 to i32
  %7554 = xor i32 %7553, -1
  %7555 = and i32 %7554, %7548
  %7556 = and i32 %7553, %7551
  %7557 = or i32 %7556, %7555
  %7558 = add i64 %7549, 16
  %7559 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7558
  %7560 = load i32, i32* %7559, align 4
  %7561 = icmp eq i64 %7465, %7558
  %7562 = sext i1 %7561 to i32
  %7563 = xor i32 %7562, -1
  %7564 = and i32 %7563, %7557
  %7565 = and i32 %7562, %7560
  %7566 = or i32 %7565, %7564
  %7567 = add i64 %7558, 16
  %7568 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7567
  %7569 = load i32, i32* %7568, align 4
  %7570 = icmp eq i64 %7465, %7567
  %7571 = sext i1 %7570 to i32
  %7572 = xor i32 %7571, -1
  %7573 = and i32 %7572, %7566
  %7574 = and i32 %7571, %7569
  %7575 = or i32 %7574, %7573
  %7576 = add i64 %7567, 16
  %7577 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7576
  %7578 = load i32, i32* %7577, align 4
  %7579 = icmp eq i64 %7465, %7576
  %7580 = sext i1 %7579 to i32
  %7581 = xor i32 %7580, -1
  %7582 = and i32 %7581, %7575
  %7583 = and i32 %7580, %7578
  %7584 = or i32 %7583, %7582
  %7585 = add i64 %7576, 16
  %7586 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7585
  %7587 = load i32, i32* %7586, align 4
  %7588 = icmp eq i64 %7465, %7585
  %7589 = sext i1 %7588 to i32
  %7590 = xor i32 %7589, -1
  %7591 = and i32 %7590, %7584
  %7592 = and i32 %7589, %7587
  %7593 = or i32 %7592, %7591
  %7594 = add i64 %7585, 16
  %7595 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7594
  %7596 = load i32, i32* %7595, align 4
  %7597 = icmp eq i64 %7465, %7594
  %7598 = sext i1 %7597 to i32
  %7599 = xor i32 %7598, -1
  %7600 = and i32 %7599, %7593
  %7601 = and i32 %7598, %7596
  %7602 = or i32 %7601, %7600
  %7603 = add i64 %7594, 16
  %7604 = getelementptr inbounds [256 x i32], [256 x i32]* %7467, i64 0, i64 %7603
  %7605 = load i32, i32* %7604, align 4
  %7606 = icmp eq i64 %7465, %7603
  %7607 = sext i1 %7606 to i32
  %7608 = xor i32 %7607, -1
  %7609 = and i32 %7608, %7602
  %7610 = and i32 %7607, %7605
  %Mitigated49 = or i32 %7610, %7609
  %7611 = xor i32 %Mitigated48, %Mitigated49
  %7612 = lshr i32 %7311, 16
  %7613 = and i32 %7612, 255
  %7614 = zext i32 %7613 to i64
  %7615 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7616 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7615, i64 0, i64 2
  %7617 = srem i64 %7614, 16
  %7618 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7617
  %7619 = load i32, i32* %7618, align 4
  %7620 = icmp eq i64 %7614, %7617
  %7621 = sext i1 %7620 to i32
  %7622 = xor i32 %7621, -1
  %7623 = and i32 %7622, 0
  %7624 = and i32 %7621, %7619
  %7625 = or i32 %7624, %7623
  %7626 = add i64 %7617, 16
  %7627 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7626
  %7628 = load i32, i32* %7627, align 4
  %7629 = icmp eq i64 %7614, %7626
  %7630 = sext i1 %7629 to i32
  %7631 = xor i32 %7630, -1
  %7632 = and i32 %7631, %7625
  %7633 = and i32 %7630, %7628
  %7634 = or i32 %7633, %7632
  %7635 = add i64 %7626, 16
  %7636 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7635
  %7637 = load i32, i32* %7636, align 4
  %7638 = icmp eq i64 %7614, %7635
  %7639 = sext i1 %7638 to i32
  %7640 = xor i32 %7639, -1
  %7641 = and i32 %7640, %7634
  %7642 = and i32 %7639, %7637
  %7643 = or i32 %7642, %7641
  %7644 = add i64 %7635, 16
  %7645 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7644
  %7646 = load i32, i32* %7645, align 4
  %7647 = icmp eq i64 %7614, %7644
  %7648 = sext i1 %7647 to i32
  %7649 = xor i32 %7648, -1
  %7650 = and i32 %7649, %7643
  %7651 = and i32 %7648, %7646
  %7652 = or i32 %7651, %7650
  %7653 = add i64 %7644, 16
  %7654 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7653
  %7655 = load i32, i32* %7654, align 4
  %7656 = icmp eq i64 %7614, %7653
  %7657 = sext i1 %7656 to i32
  %7658 = xor i32 %7657, -1
  %7659 = and i32 %7658, %7652
  %7660 = and i32 %7657, %7655
  %7661 = or i32 %7660, %7659
  %7662 = add i64 %7653, 16
  %7663 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7662
  %7664 = load i32, i32* %7663, align 4
  %7665 = icmp eq i64 %7614, %7662
  %7666 = sext i1 %7665 to i32
  %7667 = xor i32 %7666, -1
  %7668 = and i32 %7667, %7661
  %7669 = and i32 %7666, %7664
  %7670 = or i32 %7669, %7668
  %7671 = add i64 %7662, 16
  %7672 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7671
  %7673 = load i32, i32* %7672, align 4
  %7674 = icmp eq i64 %7614, %7671
  %7675 = sext i1 %7674 to i32
  %7676 = xor i32 %7675, -1
  %7677 = and i32 %7676, %7670
  %7678 = and i32 %7675, %7673
  %7679 = or i32 %7678, %7677
  %7680 = add i64 %7671, 16
  %7681 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7680
  %7682 = load i32, i32* %7681, align 4
  %7683 = icmp eq i64 %7614, %7680
  %7684 = sext i1 %7683 to i32
  %7685 = xor i32 %7684, -1
  %7686 = and i32 %7685, %7679
  %7687 = and i32 %7684, %7682
  %7688 = or i32 %7687, %7686
  %7689 = add i64 %7680, 16
  %7690 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7689
  %7691 = load i32, i32* %7690, align 4
  %7692 = icmp eq i64 %7614, %7689
  %7693 = sext i1 %7692 to i32
  %7694 = xor i32 %7693, -1
  %7695 = and i32 %7694, %7688
  %7696 = and i32 %7693, %7691
  %7697 = or i32 %7696, %7695
  %7698 = add i64 %7689, 16
  %7699 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7698
  %7700 = load i32, i32* %7699, align 4
  %7701 = icmp eq i64 %7614, %7698
  %7702 = sext i1 %7701 to i32
  %7703 = xor i32 %7702, -1
  %7704 = and i32 %7703, %7697
  %7705 = and i32 %7702, %7700
  %7706 = or i32 %7705, %7704
  %7707 = add i64 %7698, 16
  %7708 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7707
  %7709 = load i32, i32* %7708, align 4
  %7710 = icmp eq i64 %7614, %7707
  %7711 = sext i1 %7710 to i32
  %7712 = xor i32 %7711, -1
  %7713 = and i32 %7712, %7706
  %7714 = and i32 %7711, %7709
  %7715 = or i32 %7714, %7713
  %7716 = add i64 %7707, 16
  %7717 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7716
  %7718 = load i32, i32* %7717, align 4
  %7719 = icmp eq i64 %7614, %7716
  %7720 = sext i1 %7719 to i32
  %7721 = xor i32 %7720, -1
  %7722 = and i32 %7721, %7715
  %7723 = and i32 %7720, %7718
  %7724 = or i32 %7723, %7722
  %7725 = add i64 %7716, 16
  %7726 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7725
  %7727 = load i32, i32* %7726, align 4
  %7728 = icmp eq i64 %7614, %7725
  %7729 = sext i1 %7728 to i32
  %7730 = xor i32 %7729, -1
  %7731 = and i32 %7730, %7724
  %7732 = and i32 %7729, %7727
  %7733 = or i32 %7732, %7731
  %7734 = add i64 %7725, 16
  %7735 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7734
  %7736 = load i32, i32* %7735, align 4
  %7737 = icmp eq i64 %7614, %7734
  %7738 = sext i1 %7737 to i32
  %7739 = xor i32 %7738, -1
  %7740 = and i32 %7739, %7733
  %7741 = and i32 %7738, %7736
  %7742 = or i32 %7741, %7740
  %7743 = add i64 %7734, 16
  %7744 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7743
  %7745 = load i32, i32* %7744, align 4
  %7746 = icmp eq i64 %7614, %7743
  %7747 = sext i1 %7746 to i32
  %7748 = xor i32 %7747, -1
  %7749 = and i32 %7748, %7742
  %7750 = and i32 %7747, %7745
  %7751 = or i32 %7750, %7749
  %7752 = add i64 %7743, 16
  %7753 = getelementptr inbounds [256 x i32], [256 x i32]* %7616, i64 0, i64 %7752
  %7754 = load i32, i32* %7753, align 4
  %7755 = icmp eq i64 %7614, %7752
  %7756 = sext i1 %7755 to i32
  %7757 = xor i32 %7756, -1
  %7758 = and i32 %7757, %7751
  %7759 = and i32 %7756, %7754
  %Mitigated50 = or i32 %7759, %7758
  %7760 = xor i32 %7611, %Mitigated50
  %7761 = lshr i32 %7311, 24
  %7762 = zext i32 %7761 to i64
  %7763 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7764 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7763, i64 0, i64 3
  %7765 = srem i64 %7762, 16
  %7766 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7765
  %7767 = load i32, i32* %7766, align 4
  %7768 = icmp eq i64 %7762, %7765
  %7769 = sext i1 %7768 to i32
  %7770 = xor i32 %7769, -1
  %7771 = and i32 %7770, 0
  %7772 = and i32 %7769, %7767
  %7773 = or i32 %7772, %7771
  %7774 = add i64 %7765, 16
  %7775 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7774
  %7776 = load i32, i32* %7775, align 4
  %7777 = icmp eq i64 %7762, %7774
  %7778 = sext i1 %7777 to i32
  %7779 = xor i32 %7778, -1
  %7780 = and i32 %7779, %7773
  %7781 = and i32 %7778, %7776
  %7782 = or i32 %7781, %7780
  %7783 = add i64 %7774, 16
  %7784 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7783
  %7785 = load i32, i32* %7784, align 4
  %7786 = icmp eq i64 %7762, %7783
  %7787 = sext i1 %7786 to i32
  %7788 = xor i32 %7787, -1
  %7789 = and i32 %7788, %7782
  %7790 = and i32 %7787, %7785
  %7791 = or i32 %7790, %7789
  %7792 = add i64 %7783, 16
  %7793 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7792
  %7794 = load i32, i32* %7793, align 4
  %7795 = icmp eq i64 %7762, %7792
  %7796 = sext i1 %7795 to i32
  %7797 = xor i32 %7796, -1
  %7798 = and i32 %7797, %7791
  %7799 = and i32 %7796, %7794
  %7800 = or i32 %7799, %7798
  %7801 = add i64 %7792, 16
  %7802 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7801
  %7803 = load i32, i32* %7802, align 4
  %7804 = icmp eq i64 %7762, %7801
  %7805 = sext i1 %7804 to i32
  %7806 = xor i32 %7805, -1
  %7807 = and i32 %7806, %7800
  %7808 = and i32 %7805, %7803
  %7809 = or i32 %7808, %7807
  %7810 = add i64 %7801, 16
  %7811 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7810
  %7812 = load i32, i32* %7811, align 4
  %7813 = icmp eq i64 %7762, %7810
  %7814 = sext i1 %7813 to i32
  %7815 = xor i32 %7814, -1
  %7816 = and i32 %7815, %7809
  %7817 = and i32 %7814, %7812
  %7818 = or i32 %7817, %7816
  %7819 = add i64 %7810, 16
  %7820 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7819
  %7821 = load i32, i32* %7820, align 4
  %7822 = icmp eq i64 %7762, %7819
  %7823 = sext i1 %7822 to i32
  %7824 = xor i32 %7823, -1
  %7825 = and i32 %7824, %7818
  %7826 = and i32 %7823, %7821
  %7827 = or i32 %7826, %7825
  %7828 = add i64 %7819, 16
  %7829 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7828
  %7830 = load i32, i32* %7829, align 4
  %7831 = icmp eq i64 %7762, %7828
  %7832 = sext i1 %7831 to i32
  %7833 = xor i32 %7832, -1
  %7834 = and i32 %7833, %7827
  %7835 = and i32 %7832, %7830
  %7836 = or i32 %7835, %7834
  %7837 = add i64 %7828, 16
  %7838 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7837
  %7839 = load i32, i32* %7838, align 4
  %7840 = icmp eq i64 %7762, %7837
  %7841 = sext i1 %7840 to i32
  %7842 = xor i32 %7841, -1
  %7843 = and i32 %7842, %7836
  %7844 = and i32 %7841, %7839
  %7845 = or i32 %7844, %7843
  %7846 = add i64 %7837, 16
  %7847 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7846
  %7848 = load i32, i32* %7847, align 4
  %7849 = icmp eq i64 %7762, %7846
  %7850 = sext i1 %7849 to i32
  %7851 = xor i32 %7850, -1
  %7852 = and i32 %7851, %7845
  %7853 = and i32 %7850, %7848
  %7854 = or i32 %7853, %7852
  %7855 = add i64 %7846, 16
  %7856 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7855
  %7857 = load i32, i32* %7856, align 4
  %7858 = icmp eq i64 %7762, %7855
  %7859 = sext i1 %7858 to i32
  %7860 = xor i32 %7859, -1
  %7861 = and i32 %7860, %7854
  %7862 = and i32 %7859, %7857
  %7863 = or i32 %7862, %7861
  %7864 = add i64 %7855, 16
  %7865 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7864
  %7866 = load i32, i32* %7865, align 4
  %7867 = icmp eq i64 %7762, %7864
  %7868 = sext i1 %7867 to i32
  %7869 = xor i32 %7868, -1
  %7870 = and i32 %7869, %7863
  %7871 = and i32 %7868, %7866
  %7872 = or i32 %7871, %7870
  %7873 = add i64 %7864, 16
  %7874 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7873
  %7875 = load i32, i32* %7874, align 4
  %7876 = icmp eq i64 %7762, %7873
  %7877 = sext i1 %7876 to i32
  %7878 = xor i32 %7877, -1
  %7879 = and i32 %7878, %7872
  %7880 = and i32 %7877, %7875
  %7881 = or i32 %7880, %7879
  %7882 = add i64 %7873, 16
  %7883 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7882
  %7884 = load i32, i32* %7883, align 4
  %7885 = icmp eq i64 %7762, %7882
  %7886 = sext i1 %7885 to i32
  %7887 = xor i32 %7886, -1
  %7888 = and i32 %7887, %7881
  %7889 = and i32 %7886, %7884
  %7890 = or i32 %7889, %7888
  %7891 = add i64 %7882, 16
  %7892 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7891
  %7893 = load i32, i32* %7892, align 4
  %7894 = icmp eq i64 %7762, %7891
  %7895 = sext i1 %7894 to i32
  %7896 = xor i32 %7895, -1
  %7897 = and i32 %7896, %7890
  %7898 = and i32 %7895, %7893
  %7899 = or i32 %7898, %7897
  %7900 = add i64 %7891, 16
  %7901 = getelementptr inbounds [256 x i32], [256 x i32]* %7764, i64 0, i64 %7900
  %7902 = load i32, i32* %7901, align 4
  %7903 = icmp eq i64 %7762, %7900
  %7904 = sext i1 %7903 to i32
  %7905 = xor i32 %7904, -1
  %7906 = and i32 %7905, %7899
  %7907 = and i32 %7904, %7902
  %Mitigated51 = or i32 %7907, %7906
  %7908 = xor i32 %7760, %Mitigated51
  %7909 = and i32 %7315, 255
  %7910 = zext i32 %7909 to i64
  %7911 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %7912 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %7911, i64 0, i64 1
  %7913 = srem i64 %7910, 16
  %7914 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7913
  %7915 = load i32, i32* %7914, align 4
  %7916 = icmp eq i64 %7910, %7913
  %7917 = sext i1 %7916 to i32
  %7918 = xor i32 %7917, -1
  %7919 = and i32 %7918, 0
  %7920 = and i32 %7917, %7915
  %7921 = or i32 %7920, %7919
  %7922 = add i64 %7913, 16
  %7923 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7922
  %7924 = load i32, i32* %7923, align 4
  %7925 = icmp eq i64 %7910, %7922
  %7926 = sext i1 %7925 to i32
  %7927 = xor i32 %7926, -1
  %7928 = and i32 %7927, %7921
  %7929 = and i32 %7926, %7924
  %7930 = or i32 %7929, %7928
  %7931 = add i64 %7922, 16
  %7932 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7931
  %7933 = load i32, i32* %7932, align 4
  %7934 = icmp eq i64 %7910, %7931
  %7935 = sext i1 %7934 to i32
  %7936 = xor i32 %7935, -1
  %7937 = and i32 %7936, %7930
  %7938 = and i32 %7935, %7933
  %7939 = or i32 %7938, %7937
  %7940 = add i64 %7931, 16
  %7941 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7940
  %7942 = load i32, i32* %7941, align 4
  %7943 = icmp eq i64 %7910, %7940
  %7944 = sext i1 %7943 to i32
  %7945 = xor i32 %7944, -1
  %7946 = and i32 %7945, %7939
  %7947 = and i32 %7944, %7942
  %7948 = or i32 %7947, %7946
  %7949 = add i64 %7940, 16
  %7950 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7949
  %7951 = load i32, i32* %7950, align 4
  %7952 = icmp eq i64 %7910, %7949
  %7953 = sext i1 %7952 to i32
  %7954 = xor i32 %7953, -1
  %7955 = and i32 %7954, %7948
  %7956 = and i32 %7953, %7951
  %7957 = or i32 %7956, %7955
  %7958 = add i64 %7949, 16
  %7959 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7958
  %7960 = load i32, i32* %7959, align 4
  %7961 = icmp eq i64 %7910, %7958
  %7962 = sext i1 %7961 to i32
  %7963 = xor i32 %7962, -1
  %7964 = and i32 %7963, %7957
  %7965 = and i32 %7962, %7960
  %7966 = or i32 %7965, %7964
  %7967 = add i64 %7958, 16
  %7968 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7967
  %7969 = load i32, i32* %7968, align 4
  %7970 = icmp eq i64 %7910, %7967
  %7971 = sext i1 %7970 to i32
  %7972 = xor i32 %7971, -1
  %7973 = and i32 %7972, %7966
  %7974 = and i32 %7971, %7969
  %7975 = or i32 %7974, %7973
  %7976 = add i64 %7967, 16
  %7977 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7976
  %7978 = load i32, i32* %7977, align 4
  %7979 = icmp eq i64 %7910, %7976
  %7980 = sext i1 %7979 to i32
  %7981 = xor i32 %7980, -1
  %7982 = and i32 %7981, %7975
  %7983 = and i32 %7980, %7978
  %7984 = or i32 %7983, %7982
  %7985 = add i64 %7976, 16
  %7986 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7985
  %7987 = load i32, i32* %7986, align 4
  %7988 = icmp eq i64 %7910, %7985
  %7989 = sext i1 %7988 to i32
  %7990 = xor i32 %7989, -1
  %7991 = and i32 %7990, %7984
  %7992 = and i32 %7989, %7987
  %7993 = or i32 %7992, %7991
  %7994 = add i64 %7985, 16
  %7995 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %7994
  %7996 = load i32, i32* %7995, align 4
  %7997 = icmp eq i64 %7910, %7994
  %7998 = sext i1 %7997 to i32
  %7999 = xor i32 %7998, -1
  %8000 = and i32 %7999, %7993
  %8001 = and i32 %7998, %7996
  %8002 = or i32 %8001, %8000
  %8003 = add i64 %7994, 16
  %8004 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8003
  %8005 = load i32, i32* %8004, align 4
  %8006 = icmp eq i64 %7910, %8003
  %8007 = sext i1 %8006 to i32
  %8008 = xor i32 %8007, -1
  %8009 = and i32 %8008, %8002
  %8010 = and i32 %8007, %8005
  %8011 = or i32 %8010, %8009
  %8012 = add i64 %8003, 16
  %8013 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8012
  %8014 = load i32, i32* %8013, align 4
  %8015 = icmp eq i64 %7910, %8012
  %8016 = sext i1 %8015 to i32
  %8017 = xor i32 %8016, -1
  %8018 = and i32 %8017, %8011
  %8019 = and i32 %8016, %8014
  %8020 = or i32 %8019, %8018
  %8021 = add i64 %8012, 16
  %8022 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8021
  %8023 = load i32, i32* %8022, align 4
  %8024 = icmp eq i64 %7910, %8021
  %8025 = sext i1 %8024 to i32
  %8026 = xor i32 %8025, -1
  %8027 = and i32 %8026, %8020
  %8028 = and i32 %8025, %8023
  %8029 = or i32 %8028, %8027
  %8030 = add i64 %8021, 16
  %8031 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8030
  %8032 = load i32, i32* %8031, align 4
  %8033 = icmp eq i64 %7910, %8030
  %8034 = sext i1 %8033 to i32
  %8035 = xor i32 %8034, -1
  %8036 = and i32 %8035, %8029
  %8037 = and i32 %8034, %8032
  %8038 = or i32 %8037, %8036
  %8039 = add i64 %8030, 16
  %8040 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8039
  %8041 = load i32, i32* %8040, align 4
  %8042 = icmp eq i64 %7910, %8039
  %8043 = sext i1 %8042 to i32
  %8044 = xor i32 %8043, -1
  %8045 = and i32 %8044, %8038
  %8046 = and i32 %8043, %8041
  %8047 = or i32 %8046, %8045
  %8048 = add i64 %8039, 16
  %8049 = getelementptr inbounds [256 x i32], [256 x i32]* %7912, i64 0, i64 %8048
  %8050 = load i32, i32* %8049, align 4
  %8051 = icmp eq i64 %7910, %8048
  %8052 = sext i1 %8051 to i32
  %8053 = xor i32 %8052, -1
  %8054 = and i32 %8053, %8047
  %8055 = and i32 %8052, %8050
  %Mitigated52 = or i32 %8055, %8054
  %8056 = lshr i32 %7315, 8
  %8057 = and i32 %8056, 255
  %8058 = zext i32 %8057 to i64
  %8059 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8060 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8059, i64 0, i64 2
  %8061 = srem i64 %8058, 16
  %8062 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8061
  %8063 = load i32, i32* %8062, align 4
  %8064 = icmp eq i64 %8058, %8061
  %8065 = sext i1 %8064 to i32
  %8066 = xor i32 %8065, -1
  %8067 = and i32 %8066, 0
  %8068 = and i32 %8065, %8063
  %8069 = or i32 %8068, %8067
  %8070 = add i64 %8061, 16
  %8071 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8070
  %8072 = load i32, i32* %8071, align 4
  %8073 = icmp eq i64 %8058, %8070
  %8074 = sext i1 %8073 to i32
  %8075 = xor i32 %8074, -1
  %8076 = and i32 %8075, %8069
  %8077 = and i32 %8074, %8072
  %8078 = or i32 %8077, %8076
  %8079 = add i64 %8070, 16
  %8080 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8079
  %8081 = load i32, i32* %8080, align 4
  %8082 = icmp eq i64 %8058, %8079
  %8083 = sext i1 %8082 to i32
  %8084 = xor i32 %8083, -1
  %8085 = and i32 %8084, %8078
  %8086 = and i32 %8083, %8081
  %8087 = or i32 %8086, %8085
  %8088 = add i64 %8079, 16
  %8089 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8088
  %8090 = load i32, i32* %8089, align 4
  %8091 = icmp eq i64 %8058, %8088
  %8092 = sext i1 %8091 to i32
  %8093 = xor i32 %8092, -1
  %8094 = and i32 %8093, %8087
  %8095 = and i32 %8092, %8090
  %8096 = or i32 %8095, %8094
  %8097 = add i64 %8088, 16
  %8098 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8097
  %8099 = load i32, i32* %8098, align 4
  %8100 = icmp eq i64 %8058, %8097
  %8101 = sext i1 %8100 to i32
  %8102 = xor i32 %8101, -1
  %8103 = and i32 %8102, %8096
  %8104 = and i32 %8101, %8099
  %8105 = or i32 %8104, %8103
  %8106 = add i64 %8097, 16
  %8107 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8106
  %8108 = load i32, i32* %8107, align 4
  %8109 = icmp eq i64 %8058, %8106
  %8110 = sext i1 %8109 to i32
  %8111 = xor i32 %8110, -1
  %8112 = and i32 %8111, %8105
  %8113 = and i32 %8110, %8108
  %8114 = or i32 %8113, %8112
  %8115 = add i64 %8106, 16
  %8116 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8115
  %8117 = load i32, i32* %8116, align 4
  %8118 = icmp eq i64 %8058, %8115
  %8119 = sext i1 %8118 to i32
  %8120 = xor i32 %8119, -1
  %8121 = and i32 %8120, %8114
  %8122 = and i32 %8119, %8117
  %8123 = or i32 %8122, %8121
  %8124 = add i64 %8115, 16
  %8125 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8124
  %8126 = load i32, i32* %8125, align 4
  %8127 = icmp eq i64 %8058, %8124
  %8128 = sext i1 %8127 to i32
  %8129 = xor i32 %8128, -1
  %8130 = and i32 %8129, %8123
  %8131 = and i32 %8128, %8126
  %8132 = or i32 %8131, %8130
  %8133 = add i64 %8124, 16
  %8134 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8133
  %8135 = load i32, i32* %8134, align 4
  %8136 = icmp eq i64 %8058, %8133
  %8137 = sext i1 %8136 to i32
  %8138 = xor i32 %8137, -1
  %8139 = and i32 %8138, %8132
  %8140 = and i32 %8137, %8135
  %8141 = or i32 %8140, %8139
  %8142 = add i64 %8133, 16
  %8143 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8142
  %8144 = load i32, i32* %8143, align 4
  %8145 = icmp eq i64 %8058, %8142
  %8146 = sext i1 %8145 to i32
  %8147 = xor i32 %8146, -1
  %8148 = and i32 %8147, %8141
  %8149 = and i32 %8146, %8144
  %8150 = or i32 %8149, %8148
  %8151 = add i64 %8142, 16
  %8152 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8151
  %8153 = load i32, i32* %8152, align 4
  %8154 = icmp eq i64 %8058, %8151
  %8155 = sext i1 %8154 to i32
  %8156 = xor i32 %8155, -1
  %8157 = and i32 %8156, %8150
  %8158 = and i32 %8155, %8153
  %8159 = or i32 %8158, %8157
  %8160 = add i64 %8151, 16
  %8161 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8160
  %8162 = load i32, i32* %8161, align 4
  %8163 = icmp eq i64 %8058, %8160
  %8164 = sext i1 %8163 to i32
  %8165 = xor i32 %8164, -1
  %8166 = and i32 %8165, %8159
  %8167 = and i32 %8164, %8162
  %8168 = or i32 %8167, %8166
  %8169 = add i64 %8160, 16
  %8170 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8169
  %8171 = load i32, i32* %8170, align 4
  %8172 = icmp eq i64 %8058, %8169
  %8173 = sext i1 %8172 to i32
  %8174 = xor i32 %8173, -1
  %8175 = and i32 %8174, %8168
  %8176 = and i32 %8173, %8171
  %8177 = or i32 %8176, %8175
  %8178 = add i64 %8169, 16
  %8179 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8178
  %8180 = load i32, i32* %8179, align 4
  %8181 = icmp eq i64 %8058, %8178
  %8182 = sext i1 %8181 to i32
  %8183 = xor i32 %8182, -1
  %8184 = and i32 %8183, %8177
  %8185 = and i32 %8182, %8180
  %8186 = or i32 %8185, %8184
  %8187 = add i64 %8178, 16
  %8188 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8187
  %8189 = load i32, i32* %8188, align 4
  %8190 = icmp eq i64 %8058, %8187
  %8191 = sext i1 %8190 to i32
  %8192 = xor i32 %8191, -1
  %8193 = and i32 %8192, %8186
  %8194 = and i32 %8191, %8189
  %8195 = or i32 %8194, %8193
  %8196 = add i64 %8187, 16
  %8197 = getelementptr inbounds [256 x i32], [256 x i32]* %8060, i64 0, i64 %8196
  %8198 = load i32, i32* %8197, align 4
  %8199 = icmp eq i64 %8058, %8196
  %8200 = sext i1 %8199 to i32
  %8201 = xor i32 %8200, -1
  %8202 = and i32 %8201, %8195
  %8203 = and i32 %8200, %8198
  %Mitigated53 = or i32 %8203, %8202
  %8204 = xor i32 %Mitigated52, %Mitigated53
  %8205 = lshr i32 %7315, 16
  %8206 = and i32 %8205, 255
  %8207 = zext i32 %8206 to i64
  %8208 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8209 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8208, i64 0, i64 3
  %8210 = srem i64 %8207, 16
  %8211 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8210
  %8212 = load i32, i32* %8211, align 4
  %8213 = icmp eq i64 %8207, %8210
  %8214 = sext i1 %8213 to i32
  %8215 = xor i32 %8214, -1
  %8216 = and i32 %8215, 0
  %8217 = and i32 %8214, %8212
  %8218 = or i32 %8217, %8216
  %8219 = add i64 %8210, 16
  %8220 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8219
  %8221 = load i32, i32* %8220, align 4
  %8222 = icmp eq i64 %8207, %8219
  %8223 = sext i1 %8222 to i32
  %8224 = xor i32 %8223, -1
  %8225 = and i32 %8224, %8218
  %8226 = and i32 %8223, %8221
  %8227 = or i32 %8226, %8225
  %8228 = add i64 %8219, 16
  %8229 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8228
  %8230 = load i32, i32* %8229, align 4
  %8231 = icmp eq i64 %8207, %8228
  %8232 = sext i1 %8231 to i32
  %8233 = xor i32 %8232, -1
  %8234 = and i32 %8233, %8227
  %8235 = and i32 %8232, %8230
  %8236 = or i32 %8235, %8234
  %8237 = add i64 %8228, 16
  %8238 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8237
  %8239 = load i32, i32* %8238, align 4
  %8240 = icmp eq i64 %8207, %8237
  %8241 = sext i1 %8240 to i32
  %8242 = xor i32 %8241, -1
  %8243 = and i32 %8242, %8236
  %8244 = and i32 %8241, %8239
  %8245 = or i32 %8244, %8243
  %8246 = add i64 %8237, 16
  %8247 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8246
  %8248 = load i32, i32* %8247, align 4
  %8249 = icmp eq i64 %8207, %8246
  %8250 = sext i1 %8249 to i32
  %8251 = xor i32 %8250, -1
  %8252 = and i32 %8251, %8245
  %8253 = and i32 %8250, %8248
  %8254 = or i32 %8253, %8252
  %8255 = add i64 %8246, 16
  %8256 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8255
  %8257 = load i32, i32* %8256, align 4
  %8258 = icmp eq i64 %8207, %8255
  %8259 = sext i1 %8258 to i32
  %8260 = xor i32 %8259, -1
  %8261 = and i32 %8260, %8254
  %8262 = and i32 %8259, %8257
  %8263 = or i32 %8262, %8261
  %8264 = add i64 %8255, 16
  %8265 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8264
  %8266 = load i32, i32* %8265, align 4
  %8267 = icmp eq i64 %8207, %8264
  %8268 = sext i1 %8267 to i32
  %8269 = xor i32 %8268, -1
  %8270 = and i32 %8269, %8263
  %8271 = and i32 %8268, %8266
  %8272 = or i32 %8271, %8270
  %8273 = add i64 %8264, 16
  %8274 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8273
  %8275 = load i32, i32* %8274, align 4
  %8276 = icmp eq i64 %8207, %8273
  %8277 = sext i1 %8276 to i32
  %8278 = xor i32 %8277, -1
  %8279 = and i32 %8278, %8272
  %8280 = and i32 %8277, %8275
  %8281 = or i32 %8280, %8279
  %8282 = add i64 %8273, 16
  %8283 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8282
  %8284 = load i32, i32* %8283, align 4
  %8285 = icmp eq i64 %8207, %8282
  %8286 = sext i1 %8285 to i32
  %8287 = xor i32 %8286, -1
  %8288 = and i32 %8287, %8281
  %8289 = and i32 %8286, %8284
  %8290 = or i32 %8289, %8288
  %8291 = add i64 %8282, 16
  %8292 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8291
  %8293 = load i32, i32* %8292, align 4
  %8294 = icmp eq i64 %8207, %8291
  %8295 = sext i1 %8294 to i32
  %8296 = xor i32 %8295, -1
  %8297 = and i32 %8296, %8290
  %8298 = and i32 %8295, %8293
  %8299 = or i32 %8298, %8297
  %8300 = add i64 %8291, 16
  %8301 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8300
  %8302 = load i32, i32* %8301, align 4
  %8303 = icmp eq i64 %8207, %8300
  %8304 = sext i1 %8303 to i32
  %8305 = xor i32 %8304, -1
  %8306 = and i32 %8305, %8299
  %8307 = and i32 %8304, %8302
  %8308 = or i32 %8307, %8306
  %8309 = add i64 %8300, 16
  %8310 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8309
  %8311 = load i32, i32* %8310, align 4
  %8312 = icmp eq i64 %8207, %8309
  %8313 = sext i1 %8312 to i32
  %8314 = xor i32 %8313, -1
  %8315 = and i32 %8314, %8308
  %8316 = and i32 %8313, %8311
  %8317 = or i32 %8316, %8315
  %8318 = add i64 %8309, 16
  %8319 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8318
  %8320 = load i32, i32* %8319, align 4
  %8321 = icmp eq i64 %8207, %8318
  %8322 = sext i1 %8321 to i32
  %8323 = xor i32 %8322, -1
  %8324 = and i32 %8323, %8317
  %8325 = and i32 %8322, %8320
  %8326 = or i32 %8325, %8324
  %8327 = add i64 %8318, 16
  %8328 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8327
  %8329 = load i32, i32* %8328, align 4
  %8330 = icmp eq i64 %8207, %8327
  %8331 = sext i1 %8330 to i32
  %8332 = xor i32 %8331, -1
  %8333 = and i32 %8332, %8326
  %8334 = and i32 %8331, %8329
  %8335 = or i32 %8334, %8333
  %8336 = add i64 %8327, 16
  %8337 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8336
  %8338 = load i32, i32* %8337, align 4
  %8339 = icmp eq i64 %8207, %8336
  %8340 = sext i1 %8339 to i32
  %8341 = xor i32 %8340, -1
  %8342 = and i32 %8341, %8335
  %8343 = and i32 %8340, %8338
  %8344 = or i32 %8343, %8342
  %8345 = add i64 %8336, 16
  %8346 = getelementptr inbounds [256 x i32], [256 x i32]* %8209, i64 0, i64 %8345
  %8347 = load i32, i32* %8346, align 4
  %8348 = icmp eq i64 %8207, %8345
  %8349 = sext i1 %8348 to i32
  %8350 = xor i32 %8349, -1
  %8351 = and i32 %8350, %8344
  %8352 = and i32 %8349, %8347
  %Mitigated54 = or i32 %8352, %8351
  %8353 = xor i32 %8204, %Mitigated54
  %8354 = lshr i32 %7315, 24
  %8355 = zext i32 %8354 to i64
  %8356 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8357 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8356, i64 0, i64 0
  %8358 = srem i64 %8355, 16
  %8359 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8358
  %8360 = load i32, i32* %8359, align 4
  %8361 = icmp eq i64 %8355, %8358
  %8362 = sext i1 %8361 to i32
  %8363 = xor i32 %8362, -1
  %8364 = and i32 %8363, 0
  %8365 = and i32 %8362, %8360
  %8366 = or i32 %8365, %8364
  %8367 = add i64 %8358, 16
  %8368 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8367
  %8369 = load i32, i32* %8368, align 4
  %8370 = icmp eq i64 %8355, %8367
  %8371 = sext i1 %8370 to i32
  %8372 = xor i32 %8371, -1
  %8373 = and i32 %8372, %8366
  %8374 = and i32 %8371, %8369
  %8375 = or i32 %8374, %8373
  %8376 = add i64 %8367, 16
  %8377 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8376
  %8378 = load i32, i32* %8377, align 4
  %8379 = icmp eq i64 %8355, %8376
  %8380 = sext i1 %8379 to i32
  %8381 = xor i32 %8380, -1
  %8382 = and i32 %8381, %8375
  %8383 = and i32 %8380, %8378
  %8384 = or i32 %8383, %8382
  %8385 = add i64 %8376, 16
  %8386 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8385
  %8387 = load i32, i32* %8386, align 4
  %8388 = icmp eq i64 %8355, %8385
  %8389 = sext i1 %8388 to i32
  %8390 = xor i32 %8389, -1
  %8391 = and i32 %8390, %8384
  %8392 = and i32 %8389, %8387
  %8393 = or i32 %8392, %8391
  %8394 = add i64 %8385, 16
  %8395 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8394
  %8396 = load i32, i32* %8395, align 4
  %8397 = icmp eq i64 %8355, %8394
  %8398 = sext i1 %8397 to i32
  %8399 = xor i32 %8398, -1
  %8400 = and i32 %8399, %8393
  %8401 = and i32 %8398, %8396
  %8402 = or i32 %8401, %8400
  %8403 = add i64 %8394, 16
  %8404 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8403
  %8405 = load i32, i32* %8404, align 4
  %8406 = icmp eq i64 %8355, %8403
  %8407 = sext i1 %8406 to i32
  %8408 = xor i32 %8407, -1
  %8409 = and i32 %8408, %8402
  %8410 = and i32 %8407, %8405
  %8411 = or i32 %8410, %8409
  %8412 = add i64 %8403, 16
  %8413 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8412
  %8414 = load i32, i32* %8413, align 4
  %8415 = icmp eq i64 %8355, %8412
  %8416 = sext i1 %8415 to i32
  %8417 = xor i32 %8416, -1
  %8418 = and i32 %8417, %8411
  %8419 = and i32 %8416, %8414
  %8420 = or i32 %8419, %8418
  %8421 = add i64 %8412, 16
  %8422 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8421
  %8423 = load i32, i32* %8422, align 4
  %8424 = icmp eq i64 %8355, %8421
  %8425 = sext i1 %8424 to i32
  %8426 = xor i32 %8425, -1
  %8427 = and i32 %8426, %8420
  %8428 = and i32 %8425, %8423
  %8429 = or i32 %8428, %8427
  %8430 = add i64 %8421, 16
  %8431 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8430
  %8432 = load i32, i32* %8431, align 4
  %8433 = icmp eq i64 %8355, %8430
  %8434 = sext i1 %8433 to i32
  %8435 = xor i32 %8434, -1
  %8436 = and i32 %8435, %8429
  %8437 = and i32 %8434, %8432
  %8438 = or i32 %8437, %8436
  %8439 = add i64 %8430, 16
  %8440 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8439
  %8441 = load i32, i32* %8440, align 4
  %8442 = icmp eq i64 %8355, %8439
  %8443 = sext i1 %8442 to i32
  %8444 = xor i32 %8443, -1
  %8445 = and i32 %8444, %8438
  %8446 = and i32 %8443, %8441
  %8447 = or i32 %8446, %8445
  %8448 = add i64 %8439, 16
  %8449 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8448
  %8450 = load i32, i32* %8449, align 4
  %8451 = icmp eq i64 %8355, %8448
  %8452 = sext i1 %8451 to i32
  %8453 = xor i32 %8452, -1
  %8454 = and i32 %8453, %8447
  %8455 = and i32 %8452, %8450
  %8456 = or i32 %8455, %8454
  %8457 = add i64 %8448, 16
  %8458 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8457
  %8459 = load i32, i32* %8458, align 4
  %8460 = icmp eq i64 %8355, %8457
  %8461 = sext i1 %8460 to i32
  %8462 = xor i32 %8461, -1
  %8463 = and i32 %8462, %8456
  %8464 = and i32 %8461, %8459
  %8465 = or i32 %8464, %8463
  %8466 = add i64 %8457, 16
  %8467 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8466
  %8468 = load i32, i32* %8467, align 4
  %8469 = icmp eq i64 %8355, %8466
  %8470 = sext i1 %8469 to i32
  %8471 = xor i32 %8470, -1
  %8472 = and i32 %8471, %8465
  %8473 = and i32 %8470, %8468
  %8474 = or i32 %8473, %8472
  %8475 = add i64 %8466, 16
  %8476 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8475
  %8477 = load i32, i32* %8476, align 4
  %8478 = icmp eq i64 %8355, %8475
  %8479 = sext i1 %8478 to i32
  %8480 = xor i32 %8479, -1
  %8481 = and i32 %8480, %8474
  %8482 = and i32 %8479, %8477
  %8483 = or i32 %8482, %8481
  %8484 = add i64 %8475, 16
  %8485 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8484
  %8486 = load i32, i32* %8485, align 4
  %8487 = icmp eq i64 %8355, %8484
  %8488 = sext i1 %8487 to i32
  %8489 = xor i32 %8488, -1
  %8490 = and i32 %8489, %8483
  %8491 = and i32 %8488, %8486
  %8492 = or i32 %8491, %8490
  %8493 = add i64 %8484, 16
  %8494 = getelementptr inbounds [256 x i32], [256 x i32]* %8357, i64 0, i64 %8493
  %8495 = load i32, i32* %8494, align 4
  %8496 = icmp eq i64 %8355, %8493
  %8497 = sext i1 %8496 to i32
  %8498 = xor i32 %8497, -1
  %8499 = and i32 %8498, %8492
  %8500 = and i32 %8497, %8495
  %Mitigated55 = or i32 %8500, %8499
  %8501 = xor i32 %8353, %Mitigated55
  %8502 = add i32 %7908, %8501
  %8503 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %8504 = getelementptr inbounds [32 x i32], [32 x i32]* %8503, i64 0, i64 13
  %8505 = load i32, i32* %8504, align 4
  %8506 = add i32 %8502, %8505
  %8507 = add i32 %8501, %8506
  %8508 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %8509 = getelementptr inbounds [32 x i32], [32 x i32]* %8508, i64 0, i64 12
  %8510 = load i32, i32* %8509, align 4
  %8511 = add i32 %8502, %8510
  %8512 = xor i32 %6107, %8511
  %8513 = lshr i32 %8512, 1
  %8514 = shl i32 %8512, 31
  %8515 = add i32 %8513, %8514
  %8516 = shl i32 %6111, 1
  %8517 = lshr i32 %6111, 31
  %8518 = add i32 %8516, %8517
  %8519 = xor i32 %8518, %8507
  %8520 = and i32 %8515, 255
  %8521 = zext i32 %8520 to i64
  %8522 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8523 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8522, i64 0, i64 0
  %8524 = srem i64 %8521, 16
  %8525 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8524
  %8526 = load i32, i32* %8525, align 4
  %8527 = icmp eq i64 %8521, %8524
  %8528 = sext i1 %8527 to i32
  %8529 = xor i32 %8528, -1
  %8530 = and i32 %8529, 0
  %8531 = and i32 %8528, %8526
  %8532 = or i32 %8531, %8530
  %8533 = add i64 %8524, 16
  %8534 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8533
  %8535 = load i32, i32* %8534, align 4
  %8536 = icmp eq i64 %8521, %8533
  %8537 = sext i1 %8536 to i32
  %8538 = xor i32 %8537, -1
  %8539 = and i32 %8538, %8532
  %8540 = and i32 %8537, %8535
  %8541 = or i32 %8540, %8539
  %8542 = add i64 %8533, 16
  %8543 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8542
  %8544 = load i32, i32* %8543, align 4
  %8545 = icmp eq i64 %8521, %8542
  %8546 = sext i1 %8545 to i32
  %8547 = xor i32 %8546, -1
  %8548 = and i32 %8547, %8541
  %8549 = and i32 %8546, %8544
  %8550 = or i32 %8549, %8548
  %8551 = add i64 %8542, 16
  %8552 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8551
  %8553 = load i32, i32* %8552, align 4
  %8554 = icmp eq i64 %8521, %8551
  %8555 = sext i1 %8554 to i32
  %8556 = xor i32 %8555, -1
  %8557 = and i32 %8556, %8550
  %8558 = and i32 %8555, %8553
  %8559 = or i32 %8558, %8557
  %8560 = add i64 %8551, 16
  %8561 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8560
  %8562 = load i32, i32* %8561, align 4
  %8563 = icmp eq i64 %8521, %8560
  %8564 = sext i1 %8563 to i32
  %8565 = xor i32 %8564, -1
  %8566 = and i32 %8565, %8559
  %8567 = and i32 %8564, %8562
  %8568 = or i32 %8567, %8566
  %8569 = add i64 %8560, 16
  %8570 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8569
  %8571 = load i32, i32* %8570, align 4
  %8572 = icmp eq i64 %8521, %8569
  %8573 = sext i1 %8572 to i32
  %8574 = xor i32 %8573, -1
  %8575 = and i32 %8574, %8568
  %8576 = and i32 %8573, %8571
  %8577 = or i32 %8576, %8575
  %8578 = add i64 %8569, 16
  %8579 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8578
  %8580 = load i32, i32* %8579, align 4
  %8581 = icmp eq i64 %8521, %8578
  %8582 = sext i1 %8581 to i32
  %8583 = xor i32 %8582, -1
  %8584 = and i32 %8583, %8577
  %8585 = and i32 %8582, %8580
  %8586 = or i32 %8585, %8584
  %8587 = add i64 %8578, 16
  %8588 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8587
  %8589 = load i32, i32* %8588, align 4
  %8590 = icmp eq i64 %8521, %8587
  %8591 = sext i1 %8590 to i32
  %8592 = xor i32 %8591, -1
  %8593 = and i32 %8592, %8586
  %8594 = and i32 %8591, %8589
  %8595 = or i32 %8594, %8593
  %8596 = add i64 %8587, 16
  %8597 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8596
  %8598 = load i32, i32* %8597, align 4
  %8599 = icmp eq i64 %8521, %8596
  %8600 = sext i1 %8599 to i32
  %8601 = xor i32 %8600, -1
  %8602 = and i32 %8601, %8595
  %8603 = and i32 %8600, %8598
  %8604 = or i32 %8603, %8602
  %8605 = add i64 %8596, 16
  %8606 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8605
  %8607 = load i32, i32* %8606, align 4
  %8608 = icmp eq i64 %8521, %8605
  %8609 = sext i1 %8608 to i32
  %8610 = xor i32 %8609, -1
  %8611 = and i32 %8610, %8604
  %8612 = and i32 %8609, %8607
  %8613 = or i32 %8612, %8611
  %8614 = add i64 %8605, 16
  %8615 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8614
  %8616 = load i32, i32* %8615, align 4
  %8617 = icmp eq i64 %8521, %8614
  %8618 = sext i1 %8617 to i32
  %8619 = xor i32 %8618, -1
  %8620 = and i32 %8619, %8613
  %8621 = and i32 %8618, %8616
  %8622 = or i32 %8621, %8620
  %8623 = add i64 %8614, 16
  %8624 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8623
  %8625 = load i32, i32* %8624, align 4
  %8626 = icmp eq i64 %8521, %8623
  %8627 = sext i1 %8626 to i32
  %8628 = xor i32 %8627, -1
  %8629 = and i32 %8628, %8622
  %8630 = and i32 %8627, %8625
  %8631 = or i32 %8630, %8629
  %8632 = add i64 %8623, 16
  %8633 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8632
  %8634 = load i32, i32* %8633, align 4
  %8635 = icmp eq i64 %8521, %8632
  %8636 = sext i1 %8635 to i32
  %8637 = xor i32 %8636, -1
  %8638 = and i32 %8637, %8631
  %8639 = and i32 %8636, %8634
  %8640 = or i32 %8639, %8638
  %8641 = add i64 %8632, 16
  %8642 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8641
  %8643 = load i32, i32* %8642, align 4
  %8644 = icmp eq i64 %8521, %8641
  %8645 = sext i1 %8644 to i32
  %8646 = xor i32 %8645, -1
  %8647 = and i32 %8646, %8640
  %8648 = and i32 %8645, %8643
  %8649 = or i32 %8648, %8647
  %8650 = add i64 %8641, 16
  %8651 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8650
  %8652 = load i32, i32* %8651, align 4
  %8653 = icmp eq i64 %8521, %8650
  %8654 = sext i1 %8653 to i32
  %8655 = xor i32 %8654, -1
  %8656 = and i32 %8655, %8649
  %8657 = and i32 %8654, %8652
  %8658 = or i32 %8657, %8656
  %8659 = add i64 %8650, 16
  %8660 = getelementptr inbounds [256 x i32], [256 x i32]* %8523, i64 0, i64 %8659
  %8661 = load i32, i32* %8660, align 4
  %8662 = icmp eq i64 %8521, %8659
  %8663 = sext i1 %8662 to i32
  %8664 = xor i32 %8663, -1
  %8665 = and i32 %8664, %8658
  %8666 = and i32 %8663, %8661
  %Mitigated56 = or i32 %8666, %8665
  %8667 = lshr i32 %8515, 8
  %8668 = and i32 %8667, 255
  %8669 = zext i32 %8668 to i64
  %8670 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8671 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8670, i64 0, i64 1
  %8672 = srem i64 %8669, 16
  %8673 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8672
  %8674 = load i32, i32* %8673, align 4
  %8675 = icmp eq i64 %8669, %8672
  %8676 = sext i1 %8675 to i32
  %8677 = xor i32 %8676, -1
  %8678 = and i32 %8677, 0
  %8679 = and i32 %8676, %8674
  %8680 = or i32 %8679, %8678
  %8681 = add i64 %8672, 16
  %8682 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8681
  %8683 = load i32, i32* %8682, align 4
  %8684 = icmp eq i64 %8669, %8681
  %8685 = sext i1 %8684 to i32
  %8686 = xor i32 %8685, -1
  %8687 = and i32 %8686, %8680
  %8688 = and i32 %8685, %8683
  %8689 = or i32 %8688, %8687
  %8690 = add i64 %8681, 16
  %8691 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8690
  %8692 = load i32, i32* %8691, align 4
  %8693 = icmp eq i64 %8669, %8690
  %8694 = sext i1 %8693 to i32
  %8695 = xor i32 %8694, -1
  %8696 = and i32 %8695, %8689
  %8697 = and i32 %8694, %8692
  %8698 = or i32 %8697, %8696
  %8699 = add i64 %8690, 16
  %8700 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8699
  %8701 = load i32, i32* %8700, align 4
  %8702 = icmp eq i64 %8669, %8699
  %8703 = sext i1 %8702 to i32
  %8704 = xor i32 %8703, -1
  %8705 = and i32 %8704, %8698
  %8706 = and i32 %8703, %8701
  %8707 = or i32 %8706, %8705
  %8708 = add i64 %8699, 16
  %8709 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8708
  %8710 = load i32, i32* %8709, align 4
  %8711 = icmp eq i64 %8669, %8708
  %8712 = sext i1 %8711 to i32
  %8713 = xor i32 %8712, -1
  %8714 = and i32 %8713, %8707
  %8715 = and i32 %8712, %8710
  %8716 = or i32 %8715, %8714
  %8717 = add i64 %8708, 16
  %8718 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8717
  %8719 = load i32, i32* %8718, align 4
  %8720 = icmp eq i64 %8669, %8717
  %8721 = sext i1 %8720 to i32
  %8722 = xor i32 %8721, -1
  %8723 = and i32 %8722, %8716
  %8724 = and i32 %8721, %8719
  %8725 = or i32 %8724, %8723
  %8726 = add i64 %8717, 16
  %8727 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8726
  %8728 = load i32, i32* %8727, align 4
  %8729 = icmp eq i64 %8669, %8726
  %8730 = sext i1 %8729 to i32
  %8731 = xor i32 %8730, -1
  %8732 = and i32 %8731, %8725
  %8733 = and i32 %8730, %8728
  %8734 = or i32 %8733, %8732
  %8735 = add i64 %8726, 16
  %8736 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8735
  %8737 = load i32, i32* %8736, align 4
  %8738 = icmp eq i64 %8669, %8735
  %8739 = sext i1 %8738 to i32
  %8740 = xor i32 %8739, -1
  %8741 = and i32 %8740, %8734
  %8742 = and i32 %8739, %8737
  %8743 = or i32 %8742, %8741
  %8744 = add i64 %8735, 16
  %8745 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8744
  %8746 = load i32, i32* %8745, align 4
  %8747 = icmp eq i64 %8669, %8744
  %8748 = sext i1 %8747 to i32
  %8749 = xor i32 %8748, -1
  %8750 = and i32 %8749, %8743
  %8751 = and i32 %8748, %8746
  %8752 = or i32 %8751, %8750
  %8753 = add i64 %8744, 16
  %8754 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8753
  %8755 = load i32, i32* %8754, align 4
  %8756 = icmp eq i64 %8669, %8753
  %8757 = sext i1 %8756 to i32
  %8758 = xor i32 %8757, -1
  %8759 = and i32 %8758, %8752
  %8760 = and i32 %8757, %8755
  %8761 = or i32 %8760, %8759
  %8762 = add i64 %8753, 16
  %8763 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8762
  %8764 = load i32, i32* %8763, align 4
  %8765 = icmp eq i64 %8669, %8762
  %8766 = sext i1 %8765 to i32
  %8767 = xor i32 %8766, -1
  %8768 = and i32 %8767, %8761
  %8769 = and i32 %8766, %8764
  %8770 = or i32 %8769, %8768
  %8771 = add i64 %8762, 16
  %8772 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8771
  %8773 = load i32, i32* %8772, align 4
  %8774 = icmp eq i64 %8669, %8771
  %8775 = sext i1 %8774 to i32
  %8776 = xor i32 %8775, -1
  %8777 = and i32 %8776, %8770
  %8778 = and i32 %8775, %8773
  %8779 = or i32 %8778, %8777
  %8780 = add i64 %8771, 16
  %8781 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8780
  %8782 = load i32, i32* %8781, align 4
  %8783 = icmp eq i64 %8669, %8780
  %8784 = sext i1 %8783 to i32
  %8785 = xor i32 %8784, -1
  %8786 = and i32 %8785, %8779
  %8787 = and i32 %8784, %8782
  %8788 = or i32 %8787, %8786
  %8789 = add i64 %8780, 16
  %8790 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8789
  %8791 = load i32, i32* %8790, align 4
  %8792 = icmp eq i64 %8669, %8789
  %8793 = sext i1 %8792 to i32
  %8794 = xor i32 %8793, -1
  %8795 = and i32 %8794, %8788
  %8796 = and i32 %8793, %8791
  %8797 = or i32 %8796, %8795
  %8798 = add i64 %8789, 16
  %8799 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8798
  %8800 = load i32, i32* %8799, align 4
  %8801 = icmp eq i64 %8669, %8798
  %8802 = sext i1 %8801 to i32
  %8803 = xor i32 %8802, -1
  %8804 = and i32 %8803, %8797
  %8805 = and i32 %8802, %8800
  %8806 = or i32 %8805, %8804
  %8807 = add i64 %8798, 16
  %8808 = getelementptr inbounds [256 x i32], [256 x i32]* %8671, i64 0, i64 %8807
  %8809 = load i32, i32* %8808, align 4
  %8810 = icmp eq i64 %8669, %8807
  %8811 = sext i1 %8810 to i32
  %8812 = xor i32 %8811, -1
  %8813 = and i32 %8812, %8806
  %8814 = and i32 %8811, %8809
  %Mitigated57 = or i32 %8814, %8813
  %8815 = xor i32 %Mitigated56, %Mitigated57
  %8816 = lshr i32 %8515, 16
  %8817 = and i32 %8816, 255
  %8818 = zext i32 %8817 to i64
  %8819 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8820 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8819, i64 0, i64 2
  %8821 = srem i64 %8818, 16
  %8822 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8821
  %8823 = load i32, i32* %8822, align 4
  %8824 = icmp eq i64 %8818, %8821
  %8825 = sext i1 %8824 to i32
  %8826 = xor i32 %8825, -1
  %8827 = and i32 %8826, 0
  %8828 = and i32 %8825, %8823
  %8829 = or i32 %8828, %8827
  %8830 = add i64 %8821, 16
  %8831 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8830
  %8832 = load i32, i32* %8831, align 4
  %8833 = icmp eq i64 %8818, %8830
  %8834 = sext i1 %8833 to i32
  %8835 = xor i32 %8834, -1
  %8836 = and i32 %8835, %8829
  %8837 = and i32 %8834, %8832
  %8838 = or i32 %8837, %8836
  %8839 = add i64 %8830, 16
  %8840 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8839
  %8841 = load i32, i32* %8840, align 4
  %8842 = icmp eq i64 %8818, %8839
  %8843 = sext i1 %8842 to i32
  %8844 = xor i32 %8843, -1
  %8845 = and i32 %8844, %8838
  %8846 = and i32 %8843, %8841
  %8847 = or i32 %8846, %8845
  %8848 = add i64 %8839, 16
  %8849 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8848
  %8850 = load i32, i32* %8849, align 4
  %8851 = icmp eq i64 %8818, %8848
  %8852 = sext i1 %8851 to i32
  %8853 = xor i32 %8852, -1
  %8854 = and i32 %8853, %8847
  %8855 = and i32 %8852, %8850
  %8856 = or i32 %8855, %8854
  %8857 = add i64 %8848, 16
  %8858 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8857
  %8859 = load i32, i32* %8858, align 4
  %8860 = icmp eq i64 %8818, %8857
  %8861 = sext i1 %8860 to i32
  %8862 = xor i32 %8861, -1
  %8863 = and i32 %8862, %8856
  %8864 = and i32 %8861, %8859
  %8865 = or i32 %8864, %8863
  %8866 = add i64 %8857, 16
  %8867 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8866
  %8868 = load i32, i32* %8867, align 4
  %8869 = icmp eq i64 %8818, %8866
  %8870 = sext i1 %8869 to i32
  %8871 = xor i32 %8870, -1
  %8872 = and i32 %8871, %8865
  %8873 = and i32 %8870, %8868
  %8874 = or i32 %8873, %8872
  %8875 = add i64 %8866, 16
  %8876 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8875
  %8877 = load i32, i32* %8876, align 4
  %8878 = icmp eq i64 %8818, %8875
  %8879 = sext i1 %8878 to i32
  %8880 = xor i32 %8879, -1
  %8881 = and i32 %8880, %8874
  %8882 = and i32 %8879, %8877
  %8883 = or i32 %8882, %8881
  %8884 = add i64 %8875, 16
  %8885 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8884
  %8886 = load i32, i32* %8885, align 4
  %8887 = icmp eq i64 %8818, %8884
  %8888 = sext i1 %8887 to i32
  %8889 = xor i32 %8888, -1
  %8890 = and i32 %8889, %8883
  %8891 = and i32 %8888, %8886
  %8892 = or i32 %8891, %8890
  %8893 = add i64 %8884, 16
  %8894 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8893
  %8895 = load i32, i32* %8894, align 4
  %8896 = icmp eq i64 %8818, %8893
  %8897 = sext i1 %8896 to i32
  %8898 = xor i32 %8897, -1
  %8899 = and i32 %8898, %8892
  %8900 = and i32 %8897, %8895
  %8901 = or i32 %8900, %8899
  %8902 = add i64 %8893, 16
  %8903 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8902
  %8904 = load i32, i32* %8903, align 4
  %8905 = icmp eq i64 %8818, %8902
  %8906 = sext i1 %8905 to i32
  %8907 = xor i32 %8906, -1
  %8908 = and i32 %8907, %8901
  %8909 = and i32 %8906, %8904
  %8910 = or i32 %8909, %8908
  %8911 = add i64 %8902, 16
  %8912 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8911
  %8913 = load i32, i32* %8912, align 4
  %8914 = icmp eq i64 %8818, %8911
  %8915 = sext i1 %8914 to i32
  %8916 = xor i32 %8915, -1
  %8917 = and i32 %8916, %8910
  %8918 = and i32 %8915, %8913
  %8919 = or i32 %8918, %8917
  %8920 = add i64 %8911, 16
  %8921 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8920
  %8922 = load i32, i32* %8921, align 4
  %8923 = icmp eq i64 %8818, %8920
  %8924 = sext i1 %8923 to i32
  %8925 = xor i32 %8924, -1
  %8926 = and i32 %8925, %8919
  %8927 = and i32 %8924, %8922
  %8928 = or i32 %8927, %8926
  %8929 = add i64 %8920, 16
  %8930 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8929
  %8931 = load i32, i32* %8930, align 4
  %8932 = icmp eq i64 %8818, %8929
  %8933 = sext i1 %8932 to i32
  %8934 = xor i32 %8933, -1
  %8935 = and i32 %8934, %8928
  %8936 = and i32 %8933, %8931
  %8937 = or i32 %8936, %8935
  %8938 = add i64 %8929, 16
  %8939 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8938
  %8940 = load i32, i32* %8939, align 4
  %8941 = icmp eq i64 %8818, %8938
  %8942 = sext i1 %8941 to i32
  %8943 = xor i32 %8942, -1
  %8944 = and i32 %8943, %8937
  %8945 = and i32 %8942, %8940
  %8946 = or i32 %8945, %8944
  %8947 = add i64 %8938, 16
  %8948 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8947
  %8949 = load i32, i32* %8948, align 4
  %8950 = icmp eq i64 %8818, %8947
  %8951 = sext i1 %8950 to i32
  %8952 = xor i32 %8951, -1
  %8953 = and i32 %8952, %8946
  %8954 = and i32 %8951, %8949
  %8955 = or i32 %8954, %8953
  %8956 = add i64 %8947, 16
  %8957 = getelementptr inbounds [256 x i32], [256 x i32]* %8820, i64 0, i64 %8956
  %8958 = load i32, i32* %8957, align 4
  %8959 = icmp eq i64 %8818, %8956
  %8960 = sext i1 %8959 to i32
  %8961 = xor i32 %8960, -1
  %8962 = and i32 %8961, %8955
  %8963 = and i32 %8960, %8958
  %Mitigated58 = or i32 %8963, %8962
  %8964 = xor i32 %8815, %Mitigated58
  %8965 = lshr i32 %8515, 24
  %8966 = zext i32 %8965 to i64
  %8967 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %8968 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %8967, i64 0, i64 3
  %8969 = srem i64 %8966, 16
  %8970 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %8969
  %8971 = load i32, i32* %8970, align 4
  %8972 = icmp eq i64 %8966, %8969
  %8973 = sext i1 %8972 to i32
  %8974 = xor i32 %8973, -1
  %8975 = and i32 %8974, 0
  %8976 = and i32 %8973, %8971
  %8977 = or i32 %8976, %8975
  %8978 = add i64 %8969, 16
  %8979 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %8978
  %8980 = load i32, i32* %8979, align 4
  %8981 = icmp eq i64 %8966, %8978
  %8982 = sext i1 %8981 to i32
  %8983 = xor i32 %8982, -1
  %8984 = and i32 %8983, %8977
  %8985 = and i32 %8982, %8980
  %8986 = or i32 %8985, %8984
  %8987 = add i64 %8978, 16
  %8988 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %8987
  %8989 = load i32, i32* %8988, align 4
  %8990 = icmp eq i64 %8966, %8987
  %8991 = sext i1 %8990 to i32
  %8992 = xor i32 %8991, -1
  %8993 = and i32 %8992, %8986
  %8994 = and i32 %8991, %8989
  %8995 = or i32 %8994, %8993
  %8996 = add i64 %8987, 16
  %8997 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %8996
  %8998 = load i32, i32* %8997, align 4
  %8999 = icmp eq i64 %8966, %8996
  %9000 = sext i1 %8999 to i32
  %9001 = xor i32 %9000, -1
  %9002 = and i32 %9001, %8995
  %9003 = and i32 %9000, %8998
  %9004 = or i32 %9003, %9002
  %9005 = add i64 %8996, 16
  %9006 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9005
  %9007 = load i32, i32* %9006, align 4
  %9008 = icmp eq i64 %8966, %9005
  %9009 = sext i1 %9008 to i32
  %9010 = xor i32 %9009, -1
  %9011 = and i32 %9010, %9004
  %9012 = and i32 %9009, %9007
  %9013 = or i32 %9012, %9011
  %9014 = add i64 %9005, 16
  %9015 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9014
  %9016 = load i32, i32* %9015, align 4
  %9017 = icmp eq i64 %8966, %9014
  %9018 = sext i1 %9017 to i32
  %9019 = xor i32 %9018, -1
  %9020 = and i32 %9019, %9013
  %9021 = and i32 %9018, %9016
  %9022 = or i32 %9021, %9020
  %9023 = add i64 %9014, 16
  %9024 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9023
  %9025 = load i32, i32* %9024, align 4
  %9026 = icmp eq i64 %8966, %9023
  %9027 = sext i1 %9026 to i32
  %9028 = xor i32 %9027, -1
  %9029 = and i32 %9028, %9022
  %9030 = and i32 %9027, %9025
  %9031 = or i32 %9030, %9029
  %9032 = add i64 %9023, 16
  %9033 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9032
  %9034 = load i32, i32* %9033, align 4
  %9035 = icmp eq i64 %8966, %9032
  %9036 = sext i1 %9035 to i32
  %9037 = xor i32 %9036, -1
  %9038 = and i32 %9037, %9031
  %9039 = and i32 %9036, %9034
  %9040 = or i32 %9039, %9038
  %9041 = add i64 %9032, 16
  %9042 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9041
  %9043 = load i32, i32* %9042, align 4
  %9044 = icmp eq i64 %8966, %9041
  %9045 = sext i1 %9044 to i32
  %9046 = xor i32 %9045, -1
  %9047 = and i32 %9046, %9040
  %9048 = and i32 %9045, %9043
  %9049 = or i32 %9048, %9047
  %9050 = add i64 %9041, 16
  %9051 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9050
  %9052 = load i32, i32* %9051, align 4
  %9053 = icmp eq i64 %8966, %9050
  %9054 = sext i1 %9053 to i32
  %9055 = xor i32 %9054, -1
  %9056 = and i32 %9055, %9049
  %9057 = and i32 %9054, %9052
  %9058 = or i32 %9057, %9056
  %9059 = add i64 %9050, 16
  %9060 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9059
  %9061 = load i32, i32* %9060, align 4
  %9062 = icmp eq i64 %8966, %9059
  %9063 = sext i1 %9062 to i32
  %9064 = xor i32 %9063, -1
  %9065 = and i32 %9064, %9058
  %9066 = and i32 %9063, %9061
  %9067 = or i32 %9066, %9065
  %9068 = add i64 %9059, 16
  %9069 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9068
  %9070 = load i32, i32* %9069, align 4
  %9071 = icmp eq i64 %8966, %9068
  %9072 = sext i1 %9071 to i32
  %9073 = xor i32 %9072, -1
  %9074 = and i32 %9073, %9067
  %9075 = and i32 %9072, %9070
  %9076 = or i32 %9075, %9074
  %9077 = add i64 %9068, 16
  %9078 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9077
  %9079 = load i32, i32* %9078, align 4
  %9080 = icmp eq i64 %8966, %9077
  %9081 = sext i1 %9080 to i32
  %9082 = xor i32 %9081, -1
  %9083 = and i32 %9082, %9076
  %9084 = and i32 %9081, %9079
  %9085 = or i32 %9084, %9083
  %9086 = add i64 %9077, 16
  %9087 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9086
  %9088 = load i32, i32* %9087, align 4
  %9089 = icmp eq i64 %8966, %9086
  %9090 = sext i1 %9089 to i32
  %9091 = xor i32 %9090, -1
  %9092 = and i32 %9091, %9085
  %9093 = and i32 %9090, %9088
  %9094 = or i32 %9093, %9092
  %9095 = add i64 %9086, 16
  %9096 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9095
  %9097 = load i32, i32* %9096, align 4
  %9098 = icmp eq i64 %8966, %9095
  %9099 = sext i1 %9098 to i32
  %9100 = xor i32 %9099, -1
  %9101 = and i32 %9100, %9094
  %9102 = and i32 %9099, %9097
  %9103 = or i32 %9102, %9101
  %9104 = add i64 %9095, 16
  %9105 = getelementptr inbounds [256 x i32], [256 x i32]* %8968, i64 0, i64 %9104
  %9106 = load i32, i32* %9105, align 4
  %9107 = icmp eq i64 %8966, %9104
  %9108 = sext i1 %9107 to i32
  %9109 = xor i32 %9108, -1
  %9110 = and i32 %9109, %9103
  %9111 = and i32 %9108, %9106
  %Mitigated59 = or i32 %9111, %9110
  %9112 = xor i32 %8964, %Mitigated59
  %9113 = and i32 %8519, 255
  %9114 = zext i32 %9113 to i64
  %9115 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9116 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9115, i64 0, i64 1
  %9117 = srem i64 %9114, 16
  %9118 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9117
  %9119 = load i32, i32* %9118, align 4
  %9120 = icmp eq i64 %9114, %9117
  %9121 = sext i1 %9120 to i32
  %9122 = xor i32 %9121, -1
  %9123 = and i32 %9122, 0
  %9124 = and i32 %9121, %9119
  %9125 = or i32 %9124, %9123
  %9126 = add i64 %9117, 16
  %9127 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9126
  %9128 = load i32, i32* %9127, align 4
  %9129 = icmp eq i64 %9114, %9126
  %9130 = sext i1 %9129 to i32
  %9131 = xor i32 %9130, -1
  %9132 = and i32 %9131, %9125
  %9133 = and i32 %9130, %9128
  %9134 = or i32 %9133, %9132
  %9135 = add i64 %9126, 16
  %9136 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9135
  %9137 = load i32, i32* %9136, align 4
  %9138 = icmp eq i64 %9114, %9135
  %9139 = sext i1 %9138 to i32
  %9140 = xor i32 %9139, -1
  %9141 = and i32 %9140, %9134
  %9142 = and i32 %9139, %9137
  %9143 = or i32 %9142, %9141
  %9144 = add i64 %9135, 16
  %9145 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9144
  %9146 = load i32, i32* %9145, align 4
  %9147 = icmp eq i64 %9114, %9144
  %9148 = sext i1 %9147 to i32
  %9149 = xor i32 %9148, -1
  %9150 = and i32 %9149, %9143
  %9151 = and i32 %9148, %9146
  %9152 = or i32 %9151, %9150
  %9153 = add i64 %9144, 16
  %9154 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9153
  %9155 = load i32, i32* %9154, align 4
  %9156 = icmp eq i64 %9114, %9153
  %9157 = sext i1 %9156 to i32
  %9158 = xor i32 %9157, -1
  %9159 = and i32 %9158, %9152
  %9160 = and i32 %9157, %9155
  %9161 = or i32 %9160, %9159
  %9162 = add i64 %9153, 16
  %9163 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9162
  %9164 = load i32, i32* %9163, align 4
  %9165 = icmp eq i64 %9114, %9162
  %9166 = sext i1 %9165 to i32
  %9167 = xor i32 %9166, -1
  %9168 = and i32 %9167, %9161
  %9169 = and i32 %9166, %9164
  %9170 = or i32 %9169, %9168
  %9171 = add i64 %9162, 16
  %9172 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9171
  %9173 = load i32, i32* %9172, align 4
  %9174 = icmp eq i64 %9114, %9171
  %9175 = sext i1 %9174 to i32
  %9176 = xor i32 %9175, -1
  %9177 = and i32 %9176, %9170
  %9178 = and i32 %9175, %9173
  %9179 = or i32 %9178, %9177
  %9180 = add i64 %9171, 16
  %9181 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9180
  %9182 = load i32, i32* %9181, align 4
  %9183 = icmp eq i64 %9114, %9180
  %9184 = sext i1 %9183 to i32
  %9185 = xor i32 %9184, -1
  %9186 = and i32 %9185, %9179
  %9187 = and i32 %9184, %9182
  %9188 = or i32 %9187, %9186
  %9189 = add i64 %9180, 16
  %9190 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9189
  %9191 = load i32, i32* %9190, align 4
  %9192 = icmp eq i64 %9114, %9189
  %9193 = sext i1 %9192 to i32
  %9194 = xor i32 %9193, -1
  %9195 = and i32 %9194, %9188
  %9196 = and i32 %9193, %9191
  %9197 = or i32 %9196, %9195
  %9198 = add i64 %9189, 16
  %9199 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9198
  %9200 = load i32, i32* %9199, align 4
  %9201 = icmp eq i64 %9114, %9198
  %9202 = sext i1 %9201 to i32
  %9203 = xor i32 %9202, -1
  %9204 = and i32 %9203, %9197
  %9205 = and i32 %9202, %9200
  %9206 = or i32 %9205, %9204
  %9207 = add i64 %9198, 16
  %9208 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9207
  %9209 = load i32, i32* %9208, align 4
  %9210 = icmp eq i64 %9114, %9207
  %9211 = sext i1 %9210 to i32
  %9212 = xor i32 %9211, -1
  %9213 = and i32 %9212, %9206
  %9214 = and i32 %9211, %9209
  %9215 = or i32 %9214, %9213
  %9216 = add i64 %9207, 16
  %9217 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9216
  %9218 = load i32, i32* %9217, align 4
  %9219 = icmp eq i64 %9114, %9216
  %9220 = sext i1 %9219 to i32
  %9221 = xor i32 %9220, -1
  %9222 = and i32 %9221, %9215
  %9223 = and i32 %9220, %9218
  %9224 = or i32 %9223, %9222
  %9225 = add i64 %9216, 16
  %9226 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9225
  %9227 = load i32, i32* %9226, align 4
  %9228 = icmp eq i64 %9114, %9225
  %9229 = sext i1 %9228 to i32
  %9230 = xor i32 %9229, -1
  %9231 = and i32 %9230, %9224
  %9232 = and i32 %9229, %9227
  %9233 = or i32 %9232, %9231
  %9234 = add i64 %9225, 16
  %9235 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9234
  %9236 = load i32, i32* %9235, align 4
  %9237 = icmp eq i64 %9114, %9234
  %9238 = sext i1 %9237 to i32
  %9239 = xor i32 %9238, -1
  %9240 = and i32 %9239, %9233
  %9241 = and i32 %9238, %9236
  %9242 = or i32 %9241, %9240
  %9243 = add i64 %9234, 16
  %9244 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9243
  %9245 = load i32, i32* %9244, align 4
  %9246 = icmp eq i64 %9114, %9243
  %9247 = sext i1 %9246 to i32
  %9248 = xor i32 %9247, -1
  %9249 = and i32 %9248, %9242
  %9250 = and i32 %9247, %9245
  %9251 = or i32 %9250, %9249
  %9252 = add i64 %9243, 16
  %9253 = getelementptr inbounds [256 x i32], [256 x i32]* %9116, i64 0, i64 %9252
  %9254 = load i32, i32* %9253, align 4
  %9255 = icmp eq i64 %9114, %9252
  %9256 = sext i1 %9255 to i32
  %9257 = xor i32 %9256, -1
  %9258 = and i32 %9257, %9251
  %9259 = and i32 %9256, %9254
  %Mitigated60 = or i32 %9259, %9258
  %9260 = lshr i32 %8519, 8
  %9261 = and i32 %9260, 255
  %9262 = zext i32 %9261 to i64
  %9263 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9264 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9263, i64 0, i64 2
  %9265 = srem i64 %9262, 16
  %9266 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9265
  %9267 = load i32, i32* %9266, align 4
  %9268 = icmp eq i64 %9262, %9265
  %9269 = sext i1 %9268 to i32
  %9270 = xor i32 %9269, -1
  %9271 = and i32 %9270, 0
  %9272 = and i32 %9269, %9267
  %9273 = or i32 %9272, %9271
  %9274 = add i64 %9265, 16
  %9275 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9274
  %9276 = load i32, i32* %9275, align 4
  %9277 = icmp eq i64 %9262, %9274
  %9278 = sext i1 %9277 to i32
  %9279 = xor i32 %9278, -1
  %9280 = and i32 %9279, %9273
  %9281 = and i32 %9278, %9276
  %9282 = or i32 %9281, %9280
  %9283 = add i64 %9274, 16
  %9284 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9283
  %9285 = load i32, i32* %9284, align 4
  %9286 = icmp eq i64 %9262, %9283
  %9287 = sext i1 %9286 to i32
  %9288 = xor i32 %9287, -1
  %9289 = and i32 %9288, %9282
  %9290 = and i32 %9287, %9285
  %9291 = or i32 %9290, %9289
  %9292 = add i64 %9283, 16
  %9293 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9292
  %9294 = load i32, i32* %9293, align 4
  %9295 = icmp eq i64 %9262, %9292
  %9296 = sext i1 %9295 to i32
  %9297 = xor i32 %9296, -1
  %9298 = and i32 %9297, %9291
  %9299 = and i32 %9296, %9294
  %9300 = or i32 %9299, %9298
  %9301 = add i64 %9292, 16
  %9302 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9301
  %9303 = load i32, i32* %9302, align 4
  %9304 = icmp eq i64 %9262, %9301
  %9305 = sext i1 %9304 to i32
  %9306 = xor i32 %9305, -1
  %9307 = and i32 %9306, %9300
  %9308 = and i32 %9305, %9303
  %9309 = or i32 %9308, %9307
  %9310 = add i64 %9301, 16
  %9311 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9310
  %9312 = load i32, i32* %9311, align 4
  %9313 = icmp eq i64 %9262, %9310
  %9314 = sext i1 %9313 to i32
  %9315 = xor i32 %9314, -1
  %9316 = and i32 %9315, %9309
  %9317 = and i32 %9314, %9312
  %9318 = or i32 %9317, %9316
  %9319 = add i64 %9310, 16
  %9320 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9319
  %9321 = load i32, i32* %9320, align 4
  %9322 = icmp eq i64 %9262, %9319
  %9323 = sext i1 %9322 to i32
  %9324 = xor i32 %9323, -1
  %9325 = and i32 %9324, %9318
  %9326 = and i32 %9323, %9321
  %9327 = or i32 %9326, %9325
  %9328 = add i64 %9319, 16
  %9329 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9328
  %9330 = load i32, i32* %9329, align 4
  %9331 = icmp eq i64 %9262, %9328
  %9332 = sext i1 %9331 to i32
  %9333 = xor i32 %9332, -1
  %9334 = and i32 %9333, %9327
  %9335 = and i32 %9332, %9330
  %9336 = or i32 %9335, %9334
  %9337 = add i64 %9328, 16
  %9338 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9337
  %9339 = load i32, i32* %9338, align 4
  %9340 = icmp eq i64 %9262, %9337
  %9341 = sext i1 %9340 to i32
  %9342 = xor i32 %9341, -1
  %9343 = and i32 %9342, %9336
  %9344 = and i32 %9341, %9339
  %9345 = or i32 %9344, %9343
  %9346 = add i64 %9337, 16
  %9347 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9346
  %9348 = load i32, i32* %9347, align 4
  %9349 = icmp eq i64 %9262, %9346
  %9350 = sext i1 %9349 to i32
  %9351 = xor i32 %9350, -1
  %9352 = and i32 %9351, %9345
  %9353 = and i32 %9350, %9348
  %9354 = or i32 %9353, %9352
  %9355 = add i64 %9346, 16
  %9356 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9355
  %9357 = load i32, i32* %9356, align 4
  %9358 = icmp eq i64 %9262, %9355
  %9359 = sext i1 %9358 to i32
  %9360 = xor i32 %9359, -1
  %9361 = and i32 %9360, %9354
  %9362 = and i32 %9359, %9357
  %9363 = or i32 %9362, %9361
  %9364 = add i64 %9355, 16
  %9365 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9364
  %9366 = load i32, i32* %9365, align 4
  %9367 = icmp eq i64 %9262, %9364
  %9368 = sext i1 %9367 to i32
  %9369 = xor i32 %9368, -1
  %9370 = and i32 %9369, %9363
  %9371 = and i32 %9368, %9366
  %9372 = or i32 %9371, %9370
  %9373 = add i64 %9364, 16
  %9374 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9373
  %9375 = load i32, i32* %9374, align 4
  %9376 = icmp eq i64 %9262, %9373
  %9377 = sext i1 %9376 to i32
  %9378 = xor i32 %9377, -1
  %9379 = and i32 %9378, %9372
  %9380 = and i32 %9377, %9375
  %9381 = or i32 %9380, %9379
  %9382 = add i64 %9373, 16
  %9383 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9382
  %9384 = load i32, i32* %9383, align 4
  %9385 = icmp eq i64 %9262, %9382
  %9386 = sext i1 %9385 to i32
  %9387 = xor i32 %9386, -1
  %9388 = and i32 %9387, %9381
  %9389 = and i32 %9386, %9384
  %9390 = or i32 %9389, %9388
  %9391 = add i64 %9382, 16
  %9392 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9391
  %9393 = load i32, i32* %9392, align 4
  %9394 = icmp eq i64 %9262, %9391
  %9395 = sext i1 %9394 to i32
  %9396 = xor i32 %9395, -1
  %9397 = and i32 %9396, %9390
  %9398 = and i32 %9395, %9393
  %9399 = or i32 %9398, %9397
  %9400 = add i64 %9391, 16
  %9401 = getelementptr inbounds [256 x i32], [256 x i32]* %9264, i64 0, i64 %9400
  %9402 = load i32, i32* %9401, align 4
  %9403 = icmp eq i64 %9262, %9400
  %9404 = sext i1 %9403 to i32
  %9405 = xor i32 %9404, -1
  %9406 = and i32 %9405, %9399
  %9407 = and i32 %9404, %9402
  %Mitigated61 = or i32 %9407, %9406
  %9408 = xor i32 %Mitigated60, %Mitigated61
  %9409 = lshr i32 %8519, 16
  %9410 = and i32 %9409, 255
  %9411 = zext i32 %9410 to i64
  %9412 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9413 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9412, i64 0, i64 3
  %9414 = srem i64 %9411, 16
  %9415 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9414
  %9416 = load i32, i32* %9415, align 4
  %9417 = icmp eq i64 %9411, %9414
  %9418 = sext i1 %9417 to i32
  %9419 = xor i32 %9418, -1
  %9420 = and i32 %9419, 0
  %9421 = and i32 %9418, %9416
  %9422 = or i32 %9421, %9420
  %9423 = add i64 %9414, 16
  %9424 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9423
  %9425 = load i32, i32* %9424, align 4
  %9426 = icmp eq i64 %9411, %9423
  %9427 = sext i1 %9426 to i32
  %9428 = xor i32 %9427, -1
  %9429 = and i32 %9428, %9422
  %9430 = and i32 %9427, %9425
  %9431 = or i32 %9430, %9429
  %9432 = add i64 %9423, 16
  %9433 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9432
  %9434 = load i32, i32* %9433, align 4
  %9435 = icmp eq i64 %9411, %9432
  %9436 = sext i1 %9435 to i32
  %9437 = xor i32 %9436, -1
  %9438 = and i32 %9437, %9431
  %9439 = and i32 %9436, %9434
  %9440 = or i32 %9439, %9438
  %9441 = add i64 %9432, 16
  %9442 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9441
  %9443 = load i32, i32* %9442, align 4
  %9444 = icmp eq i64 %9411, %9441
  %9445 = sext i1 %9444 to i32
  %9446 = xor i32 %9445, -1
  %9447 = and i32 %9446, %9440
  %9448 = and i32 %9445, %9443
  %9449 = or i32 %9448, %9447
  %9450 = add i64 %9441, 16
  %9451 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9450
  %9452 = load i32, i32* %9451, align 4
  %9453 = icmp eq i64 %9411, %9450
  %9454 = sext i1 %9453 to i32
  %9455 = xor i32 %9454, -1
  %9456 = and i32 %9455, %9449
  %9457 = and i32 %9454, %9452
  %9458 = or i32 %9457, %9456
  %9459 = add i64 %9450, 16
  %9460 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9459
  %9461 = load i32, i32* %9460, align 4
  %9462 = icmp eq i64 %9411, %9459
  %9463 = sext i1 %9462 to i32
  %9464 = xor i32 %9463, -1
  %9465 = and i32 %9464, %9458
  %9466 = and i32 %9463, %9461
  %9467 = or i32 %9466, %9465
  %9468 = add i64 %9459, 16
  %9469 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9468
  %9470 = load i32, i32* %9469, align 4
  %9471 = icmp eq i64 %9411, %9468
  %9472 = sext i1 %9471 to i32
  %9473 = xor i32 %9472, -1
  %9474 = and i32 %9473, %9467
  %9475 = and i32 %9472, %9470
  %9476 = or i32 %9475, %9474
  %9477 = add i64 %9468, 16
  %9478 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9477
  %9479 = load i32, i32* %9478, align 4
  %9480 = icmp eq i64 %9411, %9477
  %9481 = sext i1 %9480 to i32
  %9482 = xor i32 %9481, -1
  %9483 = and i32 %9482, %9476
  %9484 = and i32 %9481, %9479
  %9485 = or i32 %9484, %9483
  %9486 = add i64 %9477, 16
  %9487 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9486
  %9488 = load i32, i32* %9487, align 4
  %9489 = icmp eq i64 %9411, %9486
  %9490 = sext i1 %9489 to i32
  %9491 = xor i32 %9490, -1
  %9492 = and i32 %9491, %9485
  %9493 = and i32 %9490, %9488
  %9494 = or i32 %9493, %9492
  %9495 = add i64 %9486, 16
  %9496 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9495
  %9497 = load i32, i32* %9496, align 4
  %9498 = icmp eq i64 %9411, %9495
  %9499 = sext i1 %9498 to i32
  %9500 = xor i32 %9499, -1
  %9501 = and i32 %9500, %9494
  %9502 = and i32 %9499, %9497
  %9503 = or i32 %9502, %9501
  %9504 = add i64 %9495, 16
  %9505 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9504
  %9506 = load i32, i32* %9505, align 4
  %9507 = icmp eq i64 %9411, %9504
  %9508 = sext i1 %9507 to i32
  %9509 = xor i32 %9508, -1
  %9510 = and i32 %9509, %9503
  %9511 = and i32 %9508, %9506
  %9512 = or i32 %9511, %9510
  %9513 = add i64 %9504, 16
  %9514 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9513
  %9515 = load i32, i32* %9514, align 4
  %9516 = icmp eq i64 %9411, %9513
  %9517 = sext i1 %9516 to i32
  %9518 = xor i32 %9517, -1
  %9519 = and i32 %9518, %9512
  %9520 = and i32 %9517, %9515
  %9521 = or i32 %9520, %9519
  %9522 = add i64 %9513, 16
  %9523 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9522
  %9524 = load i32, i32* %9523, align 4
  %9525 = icmp eq i64 %9411, %9522
  %9526 = sext i1 %9525 to i32
  %9527 = xor i32 %9526, -1
  %9528 = and i32 %9527, %9521
  %9529 = and i32 %9526, %9524
  %9530 = or i32 %9529, %9528
  %9531 = add i64 %9522, 16
  %9532 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9531
  %9533 = load i32, i32* %9532, align 4
  %9534 = icmp eq i64 %9411, %9531
  %9535 = sext i1 %9534 to i32
  %9536 = xor i32 %9535, -1
  %9537 = and i32 %9536, %9530
  %9538 = and i32 %9535, %9533
  %9539 = or i32 %9538, %9537
  %9540 = add i64 %9531, 16
  %9541 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9540
  %9542 = load i32, i32* %9541, align 4
  %9543 = icmp eq i64 %9411, %9540
  %9544 = sext i1 %9543 to i32
  %9545 = xor i32 %9544, -1
  %9546 = and i32 %9545, %9539
  %9547 = and i32 %9544, %9542
  %9548 = or i32 %9547, %9546
  %9549 = add i64 %9540, 16
  %9550 = getelementptr inbounds [256 x i32], [256 x i32]* %9413, i64 0, i64 %9549
  %9551 = load i32, i32* %9550, align 4
  %9552 = icmp eq i64 %9411, %9549
  %9553 = sext i1 %9552 to i32
  %9554 = xor i32 %9553, -1
  %9555 = and i32 %9554, %9548
  %9556 = and i32 %9553, %9551
  %Mitigated62 = or i32 %9556, %9555
  %9557 = xor i32 %9408, %Mitigated62
  %9558 = lshr i32 %8519, 24
  %9559 = zext i32 %9558 to i64
  %9560 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9561 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9560, i64 0, i64 0
  %9562 = srem i64 %9559, 16
  %9563 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9562
  %9564 = load i32, i32* %9563, align 4
  %9565 = icmp eq i64 %9559, %9562
  %9566 = sext i1 %9565 to i32
  %9567 = xor i32 %9566, -1
  %9568 = and i32 %9567, 0
  %9569 = and i32 %9566, %9564
  %9570 = or i32 %9569, %9568
  %9571 = add i64 %9562, 16
  %9572 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9571
  %9573 = load i32, i32* %9572, align 4
  %9574 = icmp eq i64 %9559, %9571
  %9575 = sext i1 %9574 to i32
  %9576 = xor i32 %9575, -1
  %9577 = and i32 %9576, %9570
  %9578 = and i32 %9575, %9573
  %9579 = or i32 %9578, %9577
  %9580 = add i64 %9571, 16
  %9581 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9580
  %9582 = load i32, i32* %9581, align 4
  %9583 = icmp eq i64 %9559, %9580
  %9584 = sext i1 %9583 to i32
  %9585 = xor i32 %9584, -1
  %9586 = and i32 %9585, %9579
  %9587 = and i32 %9584, %9582
  %9588 = or i32 %9587, %9586
  %9589 = add i64 %9580, 16
  %9590 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9589
  %9591 = load i32, i32* %9590, align 4
  %9592 = icmp eq i64 %9559, %9589
  %9593 = sext i1 %9592 to i32
  %9594 = xor i32 %9593, -1
  %9595 = and i32 %9594, %9588
  %9596 = and i32 %9593, %9591
  %9597 = or i32 %9596, %9595
  %9598 = add i64 %9589, 16
  %9599 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9598
  %9600 = load i32, i32* %9599, align 4
  %9601 = icmp eq i64 %9559, %9598
  %9602 = sext i1 %9601 to i32
  %9603 = xor i32 %9602, -1
  %9604 = and i32 %9603, %9597
  %9605 = and i32 %9602, %9600
  %9606 = or i32 %9605, %9604
  %9607 = add i64 %9598, 16
  %9608 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9607
  %9609 = load i32, i32* %9608, align 4
  %9610 = icmp eq i64 %9559, %9607
  %9611 = sext i1 %9610 to i32
  %9612 = xor i32 %9611, -1
  %9613 = and i32 %9612, %9606
  %9614 = and i32 %9611, %9609
  %9615 = or i32 %9614, %9613
  %9616 = add i64 %9607, 16
  %9617 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9616
  %9618 = load i32, i32* %9617, align 4
  %9619 = icmp eq i64 %9559, %9616
  %9620 = sext i1 %9619 to i32
  %9621 = xor i32 %9620, -1
  %9622 = and i32 %9621, %9615
  %9623 = and i32 %9620, %9618
  %9624 = or i32 %9623, %9622
  %9625 = add i64 %9616, 16
  %9626 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9625
  %9627 = load i32, i32* %9626, align 4
  %9628 = icmp eq i64 %9559, %9625
  %9629 = sext i1 %9628 to i32
  %9630 = xor i32 %9629, -1
  %9631 = and i32 %9630, %9624
  %9632 = and i32 %9629, %9627
  %9633 = or i32 %9632, %9631
  %9634 = add i64 %9625, 16
  %9635 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9634
  %9636 = load i32, i32* %9635, align 4
  %9637 = icmp eq i64 %9559, %9634
  %9638 = sext i1 %9637 to i32
  %9639 = xor i32 %9638, -1
  %9640 = and i32 %9639, %9633
  %9641 = and i32 %9638, %9636
  %9642 = or i32 %9641, %9640
  %9643 = add i64 %9634, 16
  %9644 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9643
  %9645 = load i32, i32* %9644, align 4
  %9646 = icmp eq i64 %9559, %9643
  %9647 = sext i1 %9646 to i32
  %9648 = xor i32 %9647, -1
  %9649 = and i32 %9648, %9642
  %9650 = and i32 %9647, %9645
  %9651 = or i32 %9650, %9649
  %9652 = add i64 %9643, 16
  %9653 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9652
  %9654 = load i32, i32* %9653, align 4
  %9655 = icmp eq i64 %9559, %9652
  %9656 = sext i1 %9655 to i32
  %9657 = xor i32 %9656, -1
  %9658 = and i32 %9657, %9651
  %9659 = and i32 %9656, %9654
  %9660 = or i32 %9659, %9658
  %9661 = add i64 %9652, 16
  %9662 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9661
  %9663 = load i32, i32* %9662, align 4
  %9664 = icmp eq i64 %9559, %9661
  %9665 = sext i1 %9664 to i32
  %9666 = xor i32 %9665, -1
  %9667 = and i32 %9666, %9660
  %9668 = and i32 %9665, %9663
  %9669 = or i32 %9668, %9667
  %9670 = add i64 %9661, 16
  %9671 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9670
  %9672 = load i32, i32* %9671, align 4
  %9673 = icmp eq i64 %9559, %9670
  %9674 = sext i1 %9673 to i32
  %9675 = xor i32 %9674, -1
  %9676 = and i32 %9675, %9669
  %9677 = and i32 %9674, %9672
  %9678 = or i32 %9677, %9676
  %9679 = add i64 %9670, 16
  %9680 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9679
  %9681 = load i32, i32* %9680, align 4
  %9682 = icmp eq i64 %9559, %9679
  %9683 = sext i1 %9682 to i32
  %9684 = xor i32 %9683, -1
  %9685 = and i32 %9684, %9678
  %9686 = and i32 %9683, %9681
  %9687 = or i32 %9686, %9685
  %9688 = add i64 %9679, 16
  %9689 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9688
  %9690 = load i32, i32* %9689, align 4
  %9691 = icmp eq i64 %9559, %9688
  %9692 = sext i1 %9691 to i32
  %9693 = xor i32 %9692, -1
  %9694 = and i32 %9693, %9687
  %9695 = and i32 %9692, %9690
  %9696 = or i32 %9695, %9694
  %9697 = add i64 %9688, 16
  %9698 = getelementptr inbounds [256 x i32], [256 x i32]* %9561, i64 0, i64 %9697
  %9699 = load i32, i32* %9698, align 4
  %9700 = icmp eq i64 %9559, %9697
  %9701 = sext i1 %9700 to i32
  %9702 = xor i32 %9701, -1
  %9703 = and i32 %9702, %9696
  %9704 = and i32 %9701, %9699
  %Mitigated63 = or i32 %9704, %9703
  %9705 = xor i32 %9557, %Mitigated63
  %9706 = add i32 %9112, %9705
  %9707 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %9708 = getelementptr inbounds [32 x i32], [32 x i32]* %9707, i64 0, i64 15
  %9709 = load i32, i32* %9708, align 4
  %9710 = add i32 %9706, %9709
  %9711 = add i32 %9705, %9710
  %9712 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %9713 = getelementptr inbounds [32 x i32], [32 x i32]* %9712, i64 0, i64 14
  %9714 = load i32, i32* %9713, align 4
  %9715 = add i32 %9706, %9714
  %9716 = xor i32 %7311, %9715
  %9717 = lshr i32 %9716, 1
  %9718 = shl i32 %9716, 31
  %9719 = add i32 %9717, %9718
  %9720 = shl i32 %7315, 1
  %9721 = lshr i32 %7315, 31
  %9722 = add i32 %9720, %9721
  %9723 = xor i32 %9722, %9711
  %9724 = and i32 %9719, 255
  %9725 = zext i32 %9724 to i64
  %9726 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9727 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9726, i64 0, i64 0
  %9728 = srem i64 %9725, 16
  %9729 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9728
  %9730 = load i32, i32* %9729, align 4
  %9731 = icmp eq i64 %9725, %9728
  %9732 = sext i1 %9731 to i32
  %9733 = xor i32 %9732, -1
  %9734 = and i32 %9733, 0
  %9735 = and i32 %9732, %9730
  %9736 = or i32 %9735, %9734
  %9737 = add i64 %9728, 16
  %9738 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9737
  %9739 = load i32, i32* %9738, align 4
  %9740 = icmp eq i64 %9725, %9737
  %9741 = sext i1 %9740 to i32
  %9742 = xor i32 %9741, -1
  %9743 = and i32 %9742, %9736
  %9744 = and i32 %9741, %9739
  %9745 = or i32 %9744, %9743
  %9746 = add i64 %9737, 16
  %9747 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9746
  %9748 = load i32, i32* %9747, align 4
  %9749 = icmp eq i64 %9725, %9746
  %9750 = sext i1 %9749 to i32
  %9751 = xor i32 %9750, -1
  %9752 = and i32 %9751, %9745
  %9753 = and i32 %9750, %9748
  %9754 = or i32 %9753, %9752
  %9755 = add i64 %9746, 16
  %9756 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9755
  %9757 = load i32, i32* %9756, align 4
  %9758 = icmp eq i64 %9725, %9755
  %9759 = sext i1 %9758 to i32
  %9760 = xor i32 %9759, -1
  %9761 = and i32 %9760, %9754
  %9762 = and i32 %9759, %9757
  %9763 = or i32 %9762, %9761
  %9764 = add i64 %9755, 16
  %9765 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9764
  %9766 = load i32, i32* %9765, align 4
  %9767 = icmp eq i64 %9725, %9764
  %9768 = sext i1 %9767 to i32
  %9769 = xor i32 %9768, -1
  %9770 = and i32 %9769, %9763
  %9771 = and i32 %9768, %9766
  %9772 = or i32 %9771, %9770
  %9773 = add i64 %9764, 16
  %9774 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9773
  %9775 = load i32, i32* %9774, align 4
  %9776 = icmp eq i64 %9725, %9773
  %9777 = sext i1 %9776 to i32
  %9778 = xor i32 %9777, -1
  %9779 = and i32 %9778, %9772
  %9780 = and i32 %9777, %9775
  %9781 = or i32 %9780, %9779
  %9782 = add i64 %9773, 16
  %9783 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9782
  %9784 = load i32, i32* %9783, align 4
  %9785 = icmp eq i64 %9725, %9782
  %9786 = sext i1 %9785 to i32
  %9787 = xor i32 %9786, -1
  %9788 = and i32 %9787, %9781
  %9789 = and i32 %9786, %9784
  %9790 = or i32 %9789, %9788
  %9791 = add i64 %9782, 16
  %9792 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9791
  %9793 = load i32, i32* %9792, align 4
  %9794 = icmp eq i64 %9725, %9791
  %9795 = sext i1 %9794 to i32
  %9796 = xor i32 %9795, -1
  %9797 = and i32 %9796, %9790
  %9798 = and i32 %9795, %9793
  %9799 = or i32 %9798, %9797
  %9800 = add i64 %9791, 16
  %9801 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9800
  %9802 = load i32, i32* %9801, align 4
  %9803 = icmp eq i64 %9725, %9800
  %9804 = sext i1 %9803 to i32
  %9805 = xor i32 %9804, -1
  %9806 = and i32 %9805, %9799
  %9807 = and i32 %9804, %9802
  %9808 = or i32 %9807, %9806
  %9809 = add i64 %9800, 16
  %9810 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9809
  %9811 = load i32, i32* %9810, align 4
  %9812 = icmp eq i64 %9725, %9809
  %9813 = sext i1 %9812 to i32
  %9814 = xor i32 %9813, -1
  %9815 = and i32 %9814, %9808
  %9816 = and i32 %9813, %9811
  %9817 = or i32 %9816, %9815
  %9818 = add i64 %9809, 16
  %9819 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9818
  %9820 = load i32, i32* %9819, align 4
  %9821 = icmp eq i64 %9725, %9818
  %9822 = sext i1 %9821 to i32
  %9823 = xor i32 %9822, -1
  %9824 = and i32 %9823, %9817
  %9825 = and i32 %9822, %9820
  %9826 = or i32 %9825, %9824
  %9827 = add i64 %9818, 16
  %9828 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9827
  %9829 = load i32, i32* %9828, align 4
  %9830 = icmp eq i64 %9725, %9827
  %9831 = sext i1 %9830 to i32
  %9832 = xor i32 %9831, -1
  %9833 = and i32 %9832, %9826
  %9834 = and i32 %9831, %9829
  %9835 = or i32 %9834, %9833
  %9836 = add i64 %9827, 16
  %9837 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9836
  %9838 = load i32, i32* %9837, align 4
  %9839 = icmp eq i64 %9725, %9836
  %9840 = sext i1 %9839 to i32
  %9841 = xor i32 %9840, -1
  %9842 = and i32 %9841, %9835
  %9843 = and i32 %9840, %9838
  %9844 = or i32 %9843, %9842
  %9845 = add i64 %9836, 16
  %9846 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9845
  %9847 = load i32, i32* %9846, align 4
  %9848 = icmp eq i64 %9725, %9845
  %9849 = sext i1 %9848 to i32
  %9850 = xor i32 %9849, -1
  %9851 = and i32 %9850, %9844
  %9852 = and i32 %9849, %9847
  %9853 = or i32 %9852, %9851
  %9854 = add i64 %9845, 16
  %9855 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9854
  %9856 = load i32, i32* %9855, align 4
  %9857 = icmp eq i64 %9725, %9854
  %9858 = sext i1 %9857 to i32
  %9859 = xor i32 %9858, -1
  %9860 = and i32 %9859, %9853
  %9861 = and i32 %9858, %9856
  %9862 = or i32 %9861, %9860
  %9863 = add i64 %9854, 16
  %9864 = getelementptr inbounds [256 x i32], [256 x i32]* %9727, i64 0, i64 %9863
  %9865 = load i32, i32* %9864, align 4
  %9866 = icmp eq i64 %9725, %9863
  %9867 = sext i1 %9866 to i32
  %9868 = xor i32 %9867, -1
  %9869 = and i32 %9868, %9862
  %9870 = and i32 %9867, %9865
  %Mitigated64 = or i32 %9870, %9869
  %9871 = lshr i32 %9719, 8
  %9872 = and i32 %9871, 255
  %9873 = zext i32 %9872 to i64
  %9874 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %9875 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %9874, i64 0, i64 1
  %9876 = srem i64 %9873, 16
  %9877 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9876
  %9878 = load i32, i32* %9877, align 4
  %9879 = icmp eq i64 %9873, %9876
  %9880 = sext i1 %9879 to i32
  %9881 = xor i32 %9880, -1
  %9882 = and i32 %9881, 0
  %9883 = and i32 %9880, %9878
  %9884 = or i32 %9883, %9882
  %9885 = add i64 %9876, 16
  %9886 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9885
  %9887 = load i32, i32* %9886, align 4
  %9888 = icmp eq i64 %9873, %9885
  %9889 = sext i1 %9888 to i32
  %9890 = xor i32 %9889, -1
  %9891 = and i32 %9890, %9884
  %9892 = and i32 %9889, %9887
  %9893 = or i32 %9892, %9891
  %9894 = add i64 %9885, 16
  %9895 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9894
  %9896 = load i32, i32* %9895, align 4
  %9897 = icmp eq i64 %9873, %9894
  %9898 = sext i1 %9897 to i32
  %9899 = xor i32 %9898, -1
  %9900 = and i32 %9899, %9893
  %9901 = and i32 %9898, %9896
  %9902 = or i32 %9901, %9900
  %9903 = add i64 %9894, 16
  %9904 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9903
  %9905 = load i32, i32* %9904, align 4
  %9906 = icmp eq i64 %9873, %9903
  %9907 = sext i1 %9906 to i32
  %9908 = xor i32 %9907, -1
  %9909 = and i32 %9908, %9902
  %9910 = and i32 %9907, %9905
  %9911 = or i32 %9910, %9909
  %9912 = add i64 %9903, 16
  %9913 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9912
  %9914 = load i32, i32* %9913, align 4
  %9915 = icmp eq i64 %9873, %9912
  %9916 = sext i1 %9915 to i32
  %9917 = xor i32 %9916, -1
  %9918 = and i32 %9917, %9911
  %9919 = and i32 %9916, %9914
  %9920 = or i32 %9919, %9918
  %9921 = add i64 %9912, 16
  %9922 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9921
  %9923 = load i32, i32* %9922, align 4
  %9924 = icmp eq i64 %9873, %9921
  %9925 = sext i1 %9924 to i32
  %9926 = xor i32 %9925, -1
  %9927 = and i32 %9926, %9920
  %9928 = and i32 %9925, %9923
  %9929 = or i32 %9928, %9927
  %9930 = add i64 %9921, 16
  %9931 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9930
  %9932 = load i32, i32* %9931, align 4
  %9933 = icmp eq i64 %9873, %9930
  %9934 = sext i1 %9933 to i32
  %9935 = xor i32 %9934, -1
  %9936 = and i32 %9935, %9929
  %9937 = and i32 %9934, %9932
  %9938 = or i32 %9937, %9936
  %9939 = add i64 %9930, 16
  %9940 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9939
  %9941 = load i32, i32* %9940, align 4
  %9942 = icmp eq i64 %9873, %9939
  %9943 = sext i1 %9942 to i32
  %9944 = xor i32 %9943, -1
  %9945 = and i32 %9944, %9938
  %9946 = and i32 %9943, %9941
  %9947 = or i32 %9946, %9945
  %9948 = add i64 %9939, 16
  %9949 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9948
  %9950 = load i32, i32* %9949, align 4
  %9951 = icmp eq i64 %9873, %9948
  %9952 = sext i1 %9951 to i32
  %9953 = xor i32 %9952, -1
  %9954 = and i32 %9953, %9947
  %9955 = and i32 %9952, %9950
  %9956 = or i32 %9955, %9954
  %9957 = add i64 %9948, 16
  %9958 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9957
  %9959 = load i32, i32* %9958, align 4
  %9960 = icmp eq i64 %9873, %9957
  %9961 = sext i1 %9960 to i32
  %9962 = xor i32 %9961, -1
  %9963 = and i32 %9962, %9956
  %9964 = and i32 %9961, %9959
  %9965 = or i32 %9964, %9963
  %9966 = add i64 %9957, 16
  %9967 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9966
  %9968 = load i32, i32* %9967, align 4
  %9969 = icmp eq i64 %9873, %9966
  %9970 = sext i1 %9969 to i32
  %9971 = xor i32 %9970, -1
  %9972 = and i32 %9971, %9965
  %9973 = and i32 %9970, %9968
  %9974 = or i32 %9973, %9972
  %9975 = add i64 %9966, 16
  %9976 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9975
  %9977 = load i32, i32* %9976, align 4
  %9978 = icmp eq i64 %9873, %9975
  %9979 = sext i1 %9978 to i32
  %9980 = xor i32 %9979, -1
  %9981 = and i32 %9980, %9974
  %9982 = and i32 %9979, %9977
  %9983 = or i32 %9982, %9981
  %9984 = add i64 %9975, 16
  %9985 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9984
  %9986 = load i32, i32* %9985, align 4
  %9987 = icmp eq i64 %9873, %9984
  %9988 = sext i1 %9987 to i32
  %9989 = xor i32 %9988, -1
  %9990 = and i32 %9989, %9983
  %9991 = and i32 %9988, %9986
  %9992 = or i32 %9991, %9990
  %9993 = add i64 %9984, 16
  %9994 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %9993
  %9995 = load i32, i32* %9994, align 4
  %9996 = icmp eq i64 %9873, %9993
  %9997 = sext i1 %9996 to i32
  %9998 = xor i32 %9997, -1
  %9999 = and i32 %9998, %9992
  %10000 = and i32 %9997, %9995
  %10001 = or i32 %10000, %9999
  %10002 = add i64 %9993, 16
  %10003 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %10002
  %10004 = load i32, i32* %10003, align 4
  %10005 = icmp eq i64 %9873, %10002
  %10006 = sext i1 %10005 to i32
  %10007 = xor i32 %10006, -1
  %10008 = and i32 %10007, %10001
  %10009 = and i32 %10006, %10004
  %10010 = or i32 %10009, %10008
  %10011 = add i64 %10002, 16
  %10012 = getelementptr inbounds [256 x i32], [256 x i32]* %9875, i64 0, i64 %10011
  %10013 = load i32, i32* %10012, align 4
  %10014 = icmp eq i64 %9873, %10011
  %10015 = sext i1 %10014 to i32
  %10016 = xor i32 %10015, -1
  %10017 = and i32 %10016, %10010
  %10018 = and i32 %10015, %10013
  %Mitigated65 = or i32 %10018, %10017
  %10019 = xor i32 %Mitigated64, %Mitigated65
  %10020 = lshr i32 %9719, 16
  %10021 = and i32 %10020, 255
  %10022 = zext i32 %10021 to i64
  %10023 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10024 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10023, i64 0, i64 2
  %10025 = srem i64 %10022, 16
  %10026 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10025
  %10027 = load i32, i32* %10026, align 4
  %10028 = icmp eq i64 %10022, %10025
  %10029 = sext i1 %10028 to i32
  %10030 = xor i32 %10029, -1
  %10031 = and i32 %10030, 0
  %10032 = and i32 %10029, %10027
  %10033 = or i32 %10032, %10031
  %10034 = add i64 %10025, 16
  %10035 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10034
  %10036 = load i32, i32* %10035, align 4
  %10037 = icmp eq i64 %10022, %10034
  %10038 = sext i1 %10037 to i32
  %10039 = xor i32 %10038, -1
  %10040 = and i32 %10039, %10033
  %10041 = and i32 %10038, %10036
  %10042 = or i32 %10041, %10040
  %10043 = add i64 %10034, 16
  %10044 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10043
  %10045 = load i32, i32* %10044, align 4
  %10046 = icmp eq i64 %10022, %10043
  %10047 = sext i1 %10046 to i32
  %10048 = xor i32 %10047, -1
  %10049 = and i32 %10048, %10042
  %10050 = and i32 %10047, %10045
  %10051 = or i32 %10050, %10049
  %10052 = add i64 %10043, 16
  %10053 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10052
  %10054 = load i32, i32* %10053, align 4
  %10055 = icmp eq i64 %10022, %10052
  %10056 = sext i1 %10055 to i32
  %10057 = xor i32 %10056, -1
  %10058 = and i32 %10057, %10051
  %10059 = and i32 %10056, %10054
  %10060 = or i32 %10059, %10058
  %10061 = add i64 %10052, 16
  %10062 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10061
  %10063 = load i32, i32* %10062, align 4
  %10064 = icmp eq i64 %10022, %10061
  %10065 = sext i1 %10064 to i32
  %10066 = xor i32 %10065, -1
  %10067 = and i32 %10066, %10060
  %10068 = and i32 %10065, %10063
  %10069 = or i32 %10068, %10067
  %10070 = add i64 %10061, 16
  %10071 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10070
  %10072 = load i32, i32* %10071, align 4
  %10073 = icmp eq i64 %10022, %10070
  %10074 = sext i1 %10073 to i32
  %10075 = xor i32 %10074, -1
  %10076 = and i32 %10075, %10069
  %10077 = and i32 %10074, %10072
  %10078 = or i32 %10077, %10076
  %10079 = add i64 %10070, 16
  %10080 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10079
  %10081 = load i32, i32* %10080, align 4
  %10082 = icmp eq i64 %10022, %10079
  %10083 = sext i1 %10082 to i32
  %10084 = xor i32 %10083, -1
  %10085 = and i32 %10084, %10078
  %10086 = and i32 %10083, %10081
  %10087 = or i32 %10086, %10085
  %10088 = add i64 %10079, 16
  %10089 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10088
  %10090 = load i32, i32* %10089, align 4
  %10091 = icmp eq i64 %10022, %10088
  %10092 = sext i1 %10091 to i32
  %10093 = xor i32 %10092, -1
  %10094 = and i32 %10093, %10087
  %10095 = and i32 %10092, %10090
  %10096 = or i32 %10095, %10094
  %10097 = add i64 %10088, 16
  %10098 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10097
  %10099 = load i32, i32* %10098, align 4
  %10100 = icmp eq i64 %10022, %10097
  %10101 = sext i1 %10100 to i32
  %10102 = xor i32 %10101, -1
  %10103 = and i32 %10102, %10096
  %10104 = and i32 %10101, %10099
  %10105 = or i32 %10104, %10103
  %10106 = add i64 %10097, 16
  %10107 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10106
  %10108 = load i32, i32* %10107, align 4
  %10109 = icmp eq i64 %10022, %10106
  %10110 = sext i1 %10109 to i32
  %10111 = xor i32 %10110, -1
  %10112 = and i32 %10111, %10105
  %10113 = and i32 %10110, %10108
  %10114 = or i32 %10113, %10112
  %10115 = add i64 %10106, 16
  %10116 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10115
  %10117 = load i32, i32* %10116, align 4
  %10118 = icmp eq i64 %10022, %10115
  %10119 = sext i1 %10118 to i32
  %10120 = xor i32 %10119, -1
  %10121 = and i32 %10120, %10114
  %10122 = and i32 %10119, %10117
  %10123 = or i32 %10122, %10121
  %10124 = add i64 %10115, 16
  %10125 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10124
  %10126 = load i32, i32* %10125, align 4
  %10127 = icmp eq i64 %10022, %10124
  %10128 = sext i1 %10127 to i32
  %10129 = xor i32 %10128, -1
  %10130 = and i32 %10129, %10123
  %10131 = and i32 %10128, %10126
  %10132 = or i32 %10131, %10130
  %10133 = add i64 %10124, 16
  %10134 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10133
  %10135 = load i32, i32* %10134, align 4
  %10136 = icmp eq i64 %10022, %10133
  %10137 = sext i1 %10136 to i32
  %10138 = xor i32 %10137, -1
  %10139 = and i32 %10138, %10132
  %10140 = and i32 %10137, %10135
  %10141 = or i32 %10140, %10139
  %10142 = add i64 %10133, 16
  %10143 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10142
  %10144 = load i32, i32* %10143, align 4
  %10145 = icmp eq i64 %10022, %10142
  %10146 = sext i1 %10145 to i32
  %10147 = xor i32 %10146, -1
  %10148 = and i32 %10147, %10141
  %10149 = and i32 %10146, %10144
  %10150 = or i32 %10149, %10148
  %10151 = add i64 %10142, 16
  %10152 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10151
  %10153 = load i32, i32* %10152, align 4
  %10154 = icmp eq i64 %10022, %10151
  %10155 = sext i1 %10154 to i32
  %10156 = xor i32 %10155, -1
  %10157 = and i32 %10156, %10150
  %10158 = and i32 %10155, %10153
  %10159 = or i32 %10158, %10157
  %10160 = add i64 %10151, 16
  %10161 = getelementptr inbounds [256 x i32], [256 x i32]* %10024, i64 0, i64 %10160
  %10162 = load i32, i32* %10161, align 4
  %10163 = icmp eq i64 %10022, %10160
  %10164 = sext i1 %10163 to i32
  %10165 = xor i32 %10164, -1
  %10166 = and i32 %10165, %10159
  %10167 = and i32 %10164, %10162
  %Mitigated66 = or i32 %10167, %10166
  %10168 = xor i32 %10019, %Mitigated66
  %10169 = lshr i32 %9719, 24
  %10170 = zext i32 %10169 to i64
  %10171 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10172 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10171, i64 0, i64 3
  %10173 = srem i64 %10170, 16
  %10174 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10173
  %10175 = load i32, i32* %10174, align 4
  %10176 = icmp eq i64 %10170, %10173
  %10177 = sext i1 %10176 to i32
  %10178 = xor i32 %10177, -1
  %10179 = and i32 %10178, 0
  %10180 = and i32 %10177, %10175
  %10181 = or i32 %10180, %10179
  %10182 = add i64 %10173, 16
  %10183 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10182
  %10184 = load i32, i32* %10183, align 4
  %10185 = icmp eq i64 %10170, %10182
  %10186 = sext i1 %10185 to i32
  %10187 = xor i32 %10186, -1
  %10188 = and i32 %10187, %10181
  %10189 = and i32 %10186, %10184
  %10190 = or i32 %10189, %10188
  %10191 = add i64 %10182, 16
  %10192 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10191
  %10193 = load i32, i32* %10192, align 4
  %10194 = icmp eq i64 %10170, %10191
  %10195 = sext i1 %10194 to i32
  %10196 = xor i32 %10195, -1
  %10197 = and i32 %10196, %10190
  %10198 = and i32 %10195, %10193
  %10199 = or i32 %10198, %10197
  %10200 = add i64 %10191, 16
  %10201 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10200
  %10202 = load i32, i32* %10201, align 4
  %10203 = icmp eq i64 %10170, %10200
  %10204 = sext i1 %10203 to i32
  %10205 = xor i32 %10204, -1
  %10206 = and i32 %10205, %10199
  %10207 = and i32 %10204, %10202
  %10208 = or i32 %10207, %10206
  %10209 = add i64 %10200, 16
  %10210 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10209
  %10211 = load i32, i32* %10210, align 4
  %10212 = icmp eq i64 %10170, %10209
  %10213 = sext i1 %10212 to i32
  %10214 = xor i32 %10213, -1
  %10215 = and i32 %10214, %10208
  %10216 = and i32 %10213, %10211
  %10217 = or i32 %10216, %10215
  %10218 = add i64 %10209, 16
  %10219 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10218
  %10220 = load i32, i32* %10219, align 4
  %10221 = icmp eq i64 %10170, %10218
  %10222 = sext i1 %10221 to i32
  %10223 = xor i32 %10222, -1
  %10224 = and i32 %10223, %10217
  %10225 = and i32 %10222, %10220
  %10226 = or i32 %10225, %10224
  %10227 = add i64 %10218, 16
  %10228 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10227
  %10229 = load i32, i32* %10228, align 4
  %10230 = icmp eq i64 %10170, %10227
  %10231 = sext i1 %10230 to i32
  %10232 = xor i32 %10231, -1
  %10233 = and i32 %10232, %10226
  %10234 = and i32 %10231, %10229
  %10235 = or i32 %10234, %10233
  %10236 = add i64 %10227, 16
  %10237 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10236
  %10238 = load i32, i32* %10237, align 4
  %10239 = icmp eq i64 %10170, %10236
  %10240 = sext i1 %10239 to i32
  %10241 = xor i32 %10240, -1
  %10242 = and i32 %10241, %10235
  %10243 = and i32 %10240, %10238
  %10244 = or i32 %10243, %10242
  %10245 = add i64 %10236, 16
  %10246 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10245
  %10247 = load i32, i32* %10246, align 4
  %10248 = icmp eq i64 %10170, %10245
  %10249 = sext i1 %10248 to i32
  %10250 = xor i32 %10249, -1
  %10251 = and i32 %10250, %10244
  %10252 = and i32 %10249, %10247
  %10253 = or i32 %10252, %10251
  %10254 = add i64 %10245, 16
  %10255 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10254
  %10256 = load i32, i32* %10255, align 4
  %10257 = icmp eq i64 %10170, %10254
  %10258 = sext i1 %10257 to i32
  %10259 = xor i32 %10258, -1
  %10260 = and i32 %10259, %10253
  %10261 = and i32 %10258, %10256
  %10262 = or i32 %10261, %10260
  %10263 = add i64 %10254, 16
  %10264 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10263
  %10265 = load i32, i32* %10264, align 4
  %10266 = icmp eq i64 %10170, %10263
  %10267 = sext i1 %10266 to i32
  %10268 = xor i32 %10267, -1
  %10269 = and i32 %10268, %10262
  %10270 = and i32 %10267, %10265
  %10271 = or i32 %10270, %10269
  %10272 = add i64 %10263, 16
  %10273 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10272
  %10274 = load i32, i32* %10273, align 4
  %10275 = icmp eq i64 %10170, %10272
  %10276 = sext i1 %10275 to i32
  %10277 = xor i32 %10276, -1
  %10278 = and i32 %10277, %10271
  %10279 = and i32 %10276, %10274
  %10280 = or i32 %10279, %10278
  %10281 = add i64 %10272, 16
  %10282 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10281
  %10283 = load i32, i32* %10282, align 4
  %10284 = icmp eq i64 %10170, %10281
  %10285 = sext i1 %10284 to i32
  %10286 = xor i32 %10285, -1
  %10287 = and i32 %10286, %10280
  %10288 = and i32 %10285, %10283
  %10289 = or i32 %10288, %10287
  %10290 = add i64 %10281, 16
  %10291 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10290
  %10292 = load i32, i32* %10291, align 4
  %10293 = icmp eq i64 %10170, %10290
  %10294 = sext i1 %10293 to i32
  %10295 = xor i32 %10294, -1
  %10296 = and i32 %10295, %10289
  %10297 = and i32 %10294, %10292
  %10298 = or i32 %10297, %10296
  %10299 = add i64 %10290, 16
  %10300 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10299
  %10301 = load i32, i32* %10300, align 4
  %10302 = icmp eq i64 %10170, %10299
  %10303 = sext i1 %10302 to i32
  %10304 = xor i32 %10303, -1
  %10305 = and i32 %10304, %10298
  %10306 = and i32 %10303, %10301
  %10307 = or i32 %10306, %10305
  %10308 = add i64 %10299, 16
  %10309 = getelementptr inbounds [256 x i32], [256 x i32]* %10172, i64 0, i64 %10308
  %10310 = load i32, i32* %10309, align 4
  %10311 = icmp eq i64 %10170, %10308
  %10312 = sext i1 %10311 to i32
  %10313 = xor i32 %10312, -1
  %10314 = and i32 %10313, %10307
  %10315 = and i32 %10312, %10310
  %Mitigated67 = or i32 %10315, %10314
  %10316 = xor i32 %10168, %Mitigated67
  %10317 = and i32 %9723, 255
  %10318 = zext i32 %10317 to i64
  %10319 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10320 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10319, i64 0, i64 1
  %10321 = srem i64 %10318, 16
  %10322 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10321
  %10323 = load i32, i32* %10322, align 4
  %10324 = icmp eq i64 %10318, %10321
  %10325 = sext i1 %10324 to i32
  %10326 = xor i32 %10325, -1
  %10327 = and i32 %10326, 0
  %10328 = and i32 %10325, %10323
  %10329 = or i32 %10328, %10327
  %10330 = add i64 %10321, 16
  %10331 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10330
  %10332 = load i32, i32* %10331, align 4
  %10333 = icmp eq i64 %10318, %10330
  %10334 = sext i1 %10333 to i32
  %10335 = xor i32 %10334, -1
  %10336 = and i32 %10335, %10329
  %10337 = and i32 %10334, %10332
  %10338 = or i32 %10337, %10336
  %10339 = add i64 %10330, 16
  %10340 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10339
  %10341 = load i32, i32* %10340, align 4
  %10342 = icmp eq i64 %10318, %10339
  %10343 = sext i1 %10342 to i32
  %10344 = xor i32 %10343, -1
  %10345 = and i32 %10344, %10338
  %10346 = and i32 %10343, %10341
  %10347 = or i32 %10346, %10345
  %10348 = add i64 %10339, 16
  %10349 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10348
  %10350 = load i32, i32* %10349, align 4
  %10351 = icmp eq i64 %10318, %10348
  %10352 = sext i1 %10351 to i32
  %10353 = xor i32 %10352, -1
  %10354 = and i32 %10353, %10347
  %10355 = and i32 %10352, %10350
  %10356 = or i32 %10355, %10354
  %10357 = add i64 %10348, 16
  %10358 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10357
  %10359 = load i32, i32* %10358, align 4
  %10360 = icmp eq i64 %10318, %10357
  %10361 = sext i1 %10360 to i32
  %10362 = xor i32 %10361, -1
  %10363 = and i32 %10362, %10356
  %10364 = and i32 %10361, %10359
  %10365 = or i32 %10364, %10363
  %10366 = add i64 %10357, 16
  %10367 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10366
  %10368 = load i32, i32* %10367, align 4
  %10369 = icmp eq i64 %10318, %10366
  %10370 = sext i1 %10369 to i32
  %10371 = xor i32 %10370, -1
  %10372 = and i32 %10371, %10365
  %10373 = and i32 %10370, %10368
  %10374 = or i32 %10373, %10372
  %10375 = add i64 %10366, 16
  %10376 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10375
  %10377 = load i32, i32* %10376, align 4
  %10378 = icmp eq i64 %10318, %10375
  %10379 = sext i1 %10378 to i32
  %10380 = xor i32 %10379, -1
  %10381 = and i32 %10380, %10374
  %10382 = and i32 %10379, %10377
  %10383 = or i32 %10382, %10381
  %10384 = add i64 %10375, 16
  %10385 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10384
  %10386 = load i32, i32* %10385, align 4
  %10387 = icmp eq i64 %10318, %10384
  %10388 = sext i1 %10387 to i32
  %10389 = xor i32 %10388, -1
  %10390 = and i32 %10389, %10383
  %10391 = and i32 %10388, %10386
  %10392 = or i32 %10391, %10390
  %10393 = add i64 %10384, 16
  %10394 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10393
  %10395 = load i32, i32* %10394, align 4
  %10396 = icmp eq i64 %10318, %10393
  %10397 = sext i1 %10396 to i32
  %10398 = xor i32 %10397, -1
  %10399 = and i32 %10398, %10392
  %10400 = and i32 %10397, %10395
  %10401 = or i32 %10400, %10399
  %10402 = add i64 %10393, 16
  %10403 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10402
  %10404 = load i32, i32* %10403, align 4
  %10405 = icmp eq i64 %10318, %10402
  %10406 = sext i1 %10405 to i32
  %10407 = xor i32 %10406, -1
  %10408 = and i32 %10407, %10401
  %10409 = and i32 %10406, %10404
  %10410 = or i32 %10409, %10408
  %10411 = add i64 %10402, 16
  %10412 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10411
  %10413 = load i32, i32* %10412, align 4
  %10414 = icmp eq i64 %10318, %10411
  %10415 = sext i1 %10414 to i32
  %10416 = xor i32 %10415, -1
  %10417 = and i32 %10416, %10410
  %10418 = and i32 %10415, %10413
  %10419 = or i32 %10418, %10417
  %10420 = add i64 %10411, 16
  %10421 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10420
  %10422 = load i32, i32* %10421, align 4
  %10423 = icmp eq i64 %10318, %10420
  %10424 = sext i1 %10423 to i32
  %10425 = xor i32 %10424, -1
  %10426 = and i32 %10425, %10419
  %10427 = and i32 %10424, %10422
  %10428 = or i32 %10427, %10426
  %10429 = add i64 %10420, 16
  %10430 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10429
  %10431 = load i32, i32* %10430, align 4
  %10432 = icmp eq i64 %10318, %10429
  %10433 = sext i1 %10432 to i32
  %10434 = xor i32 %10433, -1
  %10435 = and i32 %10434, %10428
  %10436 = and i32 %10433, %10431
  %10437 = or i32 %10436, %10435
  %10438 = add i64 %10429, 16
  %10439 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10438
  %10440 = load i32, i32* %10439, align 4
  %10441 = icmp eq i64 %10318, %10438
  %10442 = sext i1 %10441 to i32
  %10443 = xor i32 %10442, -1
  %10444 = and i32 %10443, %10437
  %10445 = and i32 %10442, %10440
  %10446 = or i32 %10445, %10444
  %10447 = add i64 %10438, 16
  %10448 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10447
  %10449 = load i32, i32* %10448, align 4
  %10450 = icmp eq i64 %10318, %10447
  %10451 = sext i1 %10450 to i32
  %10452 = xor i32 %10451, -1
  %10453 = and i32 %10452, %10446
  %10454 = and i32 %10451, %10449
  %10455 = or i32 %10454, %10453
  %10456 = add i64 %10447, 16
  %10457 = getelementptr inbounds [256 x i32], [256 x i32]* %10320, i64 0, i64 %10456
  %10458 = load i32, i32* %10457, align 4
  %10459 = icmp eq i64 %10318, %10456
  %10460 = sext i1 %10459 to i32
  %10461 = xor i32 %10460, -1
  %10462 = and i32 %10461, %10455
  %10463 = and i32 %10460, %10458
  %Mitigated68 = or i32 %10463, %10462
  %10464 = lshr i32 %9723, 8
  %10465 = and i32 %10464, 255
  %10466 = zext i32 %10465 to i64
  %10467 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10468 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10467, i64 0, i64 2
  %10469 = srem i64 %10466, 16
  %10470 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10469
  %10471 = load i32, i32* %10470, align 4
  %10472 = icmp eq i64 %10466, %10469
  %10473 = sext i1 %10472 to i32
  %10474 = xor i32 %10473, -1
  %10475 = and i32 %10474, 0
  %10476 = and i32 %10473, %10471
  %10477 = or i32 %10476, %10475
  %10478 = add i64 %10469, 16
  %10479 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10478
  %10480 = load i32, i32* %10479, align 4
  %10481 = icmp eq i64 %10466, %10478
  %10482 = sext i1 %10481 to i32
  %10483 = xor i32 %10482, -1
  %10484 = and i32 %10483, %10477
  %10485 = and i32 %10482, %10480
  %10486 = or i32 %10485, %10484
  %10487 = add i64 %10478, 16
  %10488 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10487
  %10489 = load i32, i32* %10488, align 4
  %10490 = icmp eq i64 %10466, %10487
  %10491 = sext i1 %10490 to i32
  %10492 = xor i32 %10491, -1
  %10493 = and i32 %10492, %10486
  %10494 = and i32 %10491, %10489
  %10495 = or i32 %10494, %10493
  %10496 = add i64 %10487, 16
  %10497 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10496
  %10498 = load i32, i32* %10497, align 4
  %10499 = icmp eq i64 %10466, %10496
  %10500 = sext i1 %10499 to i32
  %10501 = xor i32 %10500, -1
  %10502 = and i32 %10501, %10495
  %10503 = and i32 %10500, %10498
  %10504 = or i32 %10503, %10502
  %10505 = add i64 %10496, 16
  %10506 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10505
  %10507 = load i32, i32* %10506, align 4
  %10508 = icmp eq i64 %10466, %10505
  %10509 = sext i1 %10508 to i32
  %10510 = xor i32 %10509, -1
  %10511 = and i32 %10510, %10504
  %10512 = and i32 %10509, %10507
  %10513 = or i32 %10512, %10511
  %10514 = add i64 %10505, 16
  %10515 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10514
  %10516 = load i32, i32* %10515, align 4
  %10517 = icmp eq i64 %10466, %10514
  %10518 = sext i1 %10517 to i32
  %10519 = xor i32 %10518, -1
  %10520 = and i32 %10519, %10513
  %10521 = and i32 %10518, %10516
  %10522 = or i32 %10521, %10520
  %10523 = add i64 %10514, 16
  %10524 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10523
  %10525 = load i32, i32* %10524, align 4
  %10526 = icmp eq i64 %10466, %10523
  %10527 = sext i1 %10526 to i32
  %10528 = xor i32 %10527, -1
  %10529 = and i32 %10528, %10522
  %10530 = and i32 %10527, %10525
  %10531 = or i32 %10530, %10529
  %10532 = add i64 %10523, 16
  %10533 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10532
  %10534 = load i32, i32* %10533, align 4
  %10535 = icmp eq i64 %10466, %10532
  %10536 = sext i1 %10535 to i32
  %10537 = xor i32 %10536, -1
  %10538 = and i32 %10537, %10531
  %10539 = and i32 %10536, %10534
  %10540 = or i32 %10539, %10538
  %10541 = add i64 %10532, 16
  %10542 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10541
  %10543 = load i32, i32* %10542, align 4
  %10544 = icmp eq i64 %10466, %10541
  %10545 = sext i1 %10544 to i32
  %10546 = xor i32 %10545, -1
  %10547 = and i32 %10546, %10540
  %10548 = and i32 %10545, %10543
  %10549 = or i32 %10548, %10547
  %10550 = add i64 %10541, 16
  %10551 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10550
  %10552 = load i32, i32* %10551, align 4
  %10553 = icmp eq i64 %10466, %10550
  %10554 = sext i1 %10553 to i32
  %10555 = xor i32 %10554, -1
  %10556 = and i32 %10555, %10549
  %10557 = and i32 %10554, %10552
  %10558 = or i32 %10557, %10556
  %10559 = add i64 %10550, 16
  %10560 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10559
  %10561 = load i32, i32* %10560, align 4
  %10562 = icmp eq i64 %10466, %10559
  %10563 = sext i1 %10562 to i32
  %10564 = xor i32 %10563, -1
  %10565 = and i32 %10564, %10558
  %10566 = and i32 %10563, %10561
  %10567 = or i32 %10566, %10565
  %10568 = add i64 %10559, 16
  %10569 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10568
  %10570 = load i32, i32* %10569, align 4
  %10571 = icmp eq i64 %10466, %10568
  %10572 = sext i1 %10571 to i32
  %10573 = xor i32 %10572, -1
  %10574 = and i32 %10573, %10567
  %10575 = and i32 %10572, %10570
  %10576 = or i32 %10575, %10574
  %10577 = add i64 %10568, 16
  %10578 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10577
  %10579 = load i32, i32* %10578, align 4
  %10580 = icmp eq i64 %10466, %10577
  %10581 = sext i1 %10580 to i32
  %10582 = xor i32 %10581, -1
  %10583 = and i32 %10582, %10576
  %10584 = and i32 %10581, %10579
  %10585 = or i32 %10584, %10583
  %10586 = add i64 %10577, 16
  %10587 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10586
  %10588 = load i32, i32* %10587, align 4
  %10589 = icmp eq i64 %10466, %10586
  %10590 = sext i1 %10589 to i32
  %10591 = xor i32 %10590, -1
  %10592 = and i32 %10591, %10585
  %10593 = and i32 %10590, %10588
  %10594 = or i32 %10593, %10592
  %10595 = add i64 %10586, 16
  %10596 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10595
  %10597 = load i32, i32* %10596, align 4
  %10598 = icmp eq i64 %10466, %10595
  %10599 = sext i1 %10598 to i32
  %10600 = xor i32 %10599, -1
  %10601 = and i32 %10600, %10594
  %10602 = and i32 %10599, %10597
  %10603 = or i32 %10602, %10601
  %10604 = add i64 %10595, 16
  %10605 = getelementptr inbounds [256 x i32], [256 x i32]* %10468, i64 0, i64 %10604
  %10606 = load i32, i32* %10605, align 4
  %10607 = icmp eq i64 %10466, %10604
  %10608 = sext i1 %10607 to i32
  %10609 = xor i32 %10608, -1
  %10610 = and i32 %10609, %10603
  %10611 = and i32 %10608, %10606
  %Mitigated69 = or i32 %10611, %10610
  %10612 = xor i32 %Mitigated68, %Mitigated69
  %10613 = lshr i32 %9723, 16
  %10614 = and i32 %10613, 255
  %10615 = zext i32 %10614 to i64
  %10616 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10617 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10616, i64 0, i64 3
  %10618 = srem i64 %10615, 16
  %10619 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10618
  %10620 = load i32, i32* %10619, align 4
  %10621 = icmp eq i64 %10615, %10618
  %10622 = sext i1 %10621 to i32
  %10623 = xor i32 %10622, -1
  %10624 = and i32 %10623, 0
  %10625 = and i32 %10622, %10620
  %10626 = or i32 %10625, %10624
  %10627 = add i64 %10618, 16
  %10628 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10627
  %10629 = load i32, i32* %10628, align 4
  %10630 = icmp eq i64 %10615, %10627
  %10631 = sext i1 %10630 to i32
  %10632 = xor i32 %10631, -1
  %10633 = and i32 %10632, %10626
  %10634 = and i32 %10631, %10629
  %10635 = or i32 %10634, %10633
  %10636 = add i64 %10627, 16
  %10637 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10636
  %10638 = load i32, i32* %10637, align 4
  %10639 = icmp eq i64 %10615, %10636
  %10640 = sext i1 %10639 to i32
  %10641 = xor i32 %10640, -1
  %10642 = and i32 %10641, %10635
  %10643 = and i32 %10640, %10638
  %10644 = or i32 %10643, %10642
  %10645 = add i64 %10636, 16
  %10646 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10645
  %10647 = load i32, i32* %10646, align 4
  %10648 = icmp eq i64 %10615, %10645
  %10649 = sext i1 %10648 to i32
  %10650 = xor i32 %10649, -1
  %10651 = and i32 %10650, %10644
  %10652 = and i32 %10649, %10647
  %10653 = or i32 %10652, %10651
  %10654 = add i64 %10645, 16
  %10655 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10654
  %10656 = load i32, i32* %10655, align 4
  %10657 = icmp eq i64 %10615, %10654
  %10658 = sext i1 %10657 to i32
  %10659 = xor i32 %10658, -1
  %10660 = and i32 %10659, %10653
  %10661 = and i32 %10658, %10656
  %10662 = or i32 %10661, %10660
  %10663 = add i64 %10654, 16
  %10664 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10663
  %10665 = load i32, i32* %10664, align 4
  %10666 = icmp eq i64 %10615, %10663
  %10667 = sext i1 %10666 to i32
  %10668 = xor i32 %10667, -1
  %10669 = and i32 %10668, %10662
  %10670 = and i32 %10667, %10665
  %10671 = or i32 %10670, %10669
  %10672 = add i64 %10663, 16
  %10673 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10672
  %10674 = load i32, i32* %10673, align 4
  %10675 = icmp eq i64 %10615, %10672
  %10676 = sext i1 %10675 to i32
  %10677 = xor i32 %10676, -1
  %10678 = and i32 %10677, %10671
  %10679 = and i32 %10676, %10674
  %10680 = or i32 %10679, %10678
  %10681 = add i64 %10672, 16
  %10682 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10681
  %10683 = load i32, i32* %10682, align 4
  %10684 = icmp eq i64 %10615, %10681
  %10685 = sext i1 %10684 to i32
  %10686 = xor i32 %10685, -1
  %10687 = and i32 %10686, %10680
  %10688 = and i32 %10685, %10683
  %10689 = or i32 %10688, %10687
  %10690 = add i64 %10681, 16
  %10691 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10690
  %10692 = load i32, i32* %10691, align 4
  %10693 = icmp eq i64 %10615, %10690
  %10694 = sext i1 %10693 to i32
  %10695 = xor i32 %10694, -1
  %10696 = and i32 %10695, %10689
  %10697 = and i32 %10694, %10692
  %10698 = or i32 %10697, %10696
  %10699 = add i64 %10690, 16
  %10700 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10699
  %10701 = load i32, i32* %10700, align 4
  %10702 = icmp eq i64 %10615, %10699
  %10703 = sext i1 %10702 to i32
  %10704 = xor i32 %10703, -1
  %10705 = and i32 %10704, %10698
  %10706 = and i32 %10703, %10701
  %10707 = or i32 %10706, %10705
  %10708 = add i64 %10699, 16
  %10709 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10708
  %10710 = load i32, i32* %10709, align 4
  %10711 = icmp eq i64 %10615, %10708
  %10712 = sext i1 %10711 to i32
  %10713 = xor i32 %10712, -1
  %10714 = and i32 %10713, %10707
  %10715 = and i32 %10712, %10710
  %10716 = or i32 %10715, %10714
  %10717 = add i64 %10708, 16
  %10718 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10717
  %10719 = load i32, i32* %10718, align 4
  %10720 = icmp eq i64 %10615, %10717
  %10721 = sext i1 %10720 to i32
  %10722 = xor i32 %10721, -1
  %10723 = and i32 %10722, %10716
  %10724 = and i32 %10721, %10719
  %10725 = or i32 %10724, %10723
  %10726 = add i64 %10717, 16
  %10727 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10726
  %10728 = load i32, i32* %10727, align 4
  %10729 = icmp eq i64 %10615, %10726
  %10730 = sext i1 %10729 to i32
  %10731 = xor i32 %10730, -1
  %10732 = and i32 %10731, %10725
  %10733 = and i32 %10730, %10728
  %10734 = or i32 %10733, %10732
  %10735 = add i64 %10726, 16
  %10736 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10735
  %10737 = load i32, i32* %10736, align 4
  %10738 = icmp eq i64 %10615, %10735
  %10739 = sext i1 %10738 to i32
  %10740 = xor i32 %10739, -1
  %10741 = and i32 %10740, %10734
  %10742 = and i32 %10739, %10737
  %10743 = or i32 %10742, %10741
  %10744 = add i64 %10735, 16
  %10745 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10744
  %10746 = load i32, i32* %10745, align 4
  %10747 = icmp eq i64 %10615, %10744
  %10748 = sext i1 %10747 to i32
  %10749 = xor i32 %10748, -1
  %10750 = and i32 %10749, %10743
  %10751 = and i32 %10748, %10746
  %10752 = or i32 %10751, %10750
  %10753 = add i64 %10744, 16
  %10754 = getelementptr inbounds [256 x i32], [256 x i32]* %10617, i64 0, i64 %10753
  %10755 = load i32, i32* %10754, align 4
  %10756 = icmp eq i64 %10615, %10753
  %10757 = sext i1 %10756 to i32
  %10758 = xor i32 %10757, -1
  %10759 = and i32 %10758, %10752
  %10760 = and i32 %10757, %10755
  %Mitigated70 = or i32 %10760, %10759
  %10761 = xor i32 %10612, %Mitigated70
  %10762 = lshr i32 %9723, 24
  %10763 = zext i32 %10762 to i64
  %10764 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10765 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10764, i64 0, i64 0
  %10766 = srem i64 %10763, 16
  %10767 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10766
  %10768 = load i32, i32* %10767, align 4
  %10769 = icmp eq i64 %10763, %10766
  %10770 = sext i1 %10769 to i32
  %10771 = xor i32 %10770, -1
  %10772 = and i32 %10771, 0
  %10773 = and i32 %10770, %10768
  %10774 = or i32 %10773, %10772
  %10775 = add i64 %10766, 16
  %10776 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10775
  %10777 = load i32, i32* %10776, align 4
  %10778 = icmp eq i64 %10763, %10775
  %10779 = sext i1 %10778 to i32
  %10780 = xor i32 %10779, -1
  %10781 = and i32 %10780, %10774
  %10782 = and i32 %10779, %10777
  %10783 = or i32 %10782, %10781
  %10784 = add i64 %10775, 16
  %10785 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10784
  %10786 = load i32, i32* %10785, align 4
  %10787 = icmp eq i64 %10763, %10784
  %10788 = sext i1 %10787 to i32
  %10789 = xor i32 %10788, -1
  %10790 = and i32 %10789, %10783
  %10791 = and i32 %10788, %10786
  %10792 = or i32 %10791, %10790
  %10793 = add i64 %10784, 16
  %10794 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10793
  %10795 = load i32, i32* %10794, align 4
  %10796 = icmp eq i64 %10763, %10793
  %10797 = sext i1 %10796 to i32
  %10798 = xor i32 %10797, -1
  %10799 = and i32 %10798, %10792
  %10800 = and i32 %10797, %10795
  %10801 = or i32 %10800, %10799
  %10802 = add i64 %10793, 16
  %10803 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10802
  %10804 = load i32, i32* %10803, align 4
  %10805 = icmp eq i64 %10763, %10802
  %10806 = sext i1 %10805 to i32
  %10807 = xor i32 %10806, -1
  %10808 = and i32 %10807, %10801
  %10809 = and i32 %10806, %10804
  %10810 = or i32 %10809, %10808
  %10811 = add i64 %10802, 16
  %10812 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10811
  %10813 = load i32, i32* %10812, align 4
  %10814 = icmp eq i64 %10763, %10811
  %10815 = sext i1 %10814 to i32
  %10816 = xor i32 %10815, -1
  %10817 = and i32 %10816, %10810
  %10818 = and i32 %10815, %10813
  %10819 = or i32 %10818, %10817
  %10820 = add i64 %10811, 16
  %10821 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10820
  %10822 = load i32, i32* %10821, align 4
  %10823 = icmp eq i64 %10763, %10820
  %10824 = sext i1 %10823 to i32
  %10825 = xor i32 %10824, -1
  %10826 = and i32 %10825, %10819
  %10827 = and i32 %10824, %10822
  %10828 = or i32 %10827, %10826
  %10829 = add i64 %10820, 16
  %10830 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10829
  %10831 = load i32, i32* %10830, align 4
  %10832 = icmp eq i64 %10763, %10829
  %10833 = sext i1 %10832 to i32
  %10834 = xor i32 %10833, -1
  %10835 = and i32 %10834, %10828
  %10836 = and i32 %10833, %10831
  %10837 = or i32 %10836, %10835
  %10838 = add i64 %10829, 16
  %10839 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10838
  %10840 = load i32, i32* %10839, align 4
  %10841 = icmp eq i64 %10763, %10838
  %10842 = sext i1 %10841 to i32
  %10843 = xor i32 %10842, -1
  %10844 = and i32 %10843, %10837
  %10845 = and i32 %10842, %10840
  %10846 = or i32 %10845, %10844
  %10847 = add i64 %10838, 16
  %10848 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10847
  %10849 = load i32, i32* %10848, align 4
  %10850 = icmp eq i64 %10763, %10847
  %10851 = sext i1 %10850 to i32
  %10852 = xor i32 %10851, -1
  %10853 = and i32 %10852, %10846
  %10854 = and i32 %10851, %10849
  %10855 = or i32 %10854, %10853
  %10856 = add i64 %10847, 16
  %10857 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10856
  %10858 = load i32, i32* %10857, align 4
  %10859 = icmp eq i64 %10763, %10856
  %10860 = sext i1 %10859 to i32
  %10861 = xor i32 %10860, -1
  %10862 = and i32 %10861, %10855
  %10863 = and i32 %10860, %10858
  %10864 = or i32 %10863, %10862
  %10865 = add i64 %10856, 16
  %10866 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10865
  %10867 = load i32, i32* %10866, align 4
  %10868 = icmp eq i64 %10763, %10865
  %10869 = sext i1 %10868 to i32
  %10870 = xor i32 %10869, -1
  %10871 = and i32 %10870, %10864
  %10872 = and i32 %10869, %10867
  %10873 = or i32 %10872, %10871
  %10874 = add i64 %10865, 16
  %10875 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10874
  %10876 = load i32, i32* %10875, align 4
  %10877 = icmp eq i64 %10763, %10874
  %10878 = sext i1 %10877 to i32
  %10879 = xor i32 %10878, -1
  %10880 = and i32 %10879, %10873
  %10881 = and i32 %10878, %10876
  %10882 = or i32 %10881, %10880
  %10883 = add i64 %10874, 16
  %10884 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10883
  %10885 = load i32, i32* %10884, align 4
  %10886 = icmp eq i64 %10763, %10883
  %10887 = sext i1 %10886 to i32
  %10888 = xor i32 %10887, -1
  %10889 = and i32 %10888, %10882
  %10890 = and i32 %10887, %10885
  %10891 = or i32 %10890, %10889
  %10892 = add i64 %10883, 16
  %10893 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10892
  %10894 = load i32, i32* %10893, align 4
  %10895 = icmp eq i64 %10763, %10892
  %10896 = sext i1 %10895 to i32
  %10897 = xor i32 %10896, -1
  %10898 = and i32 %10897, %10891
  %10899 = and i32 %10896, %10894
  %10900 = or i32 %10899, %10898
  %10901 = add i64 %10892, 16
  %10902 = getelementptr inbounds [256 x i32], [256 x i32]* %10765, i64 0, i64 %10901
  %10903 = load i32, i32* %10902, align 4
  %10904 = icmp eq i64 %10763, %10901
  %10905 = sext i1 %10904 to i32
  %10906 = xor i32 %10905, -1
  %10907 = and i32 %10906, %10900
  %10908 = and i32 %10905, %10903
  %Mitigated71 = or i32 %10908, %10907
  %10909 = xor i32 %10761, %Mitigated71
  %10910 = add i32 %10316, %10909
  %10911 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %10912 = getelementptr inbounds [32 x i32], [32 x i32]* %10911, i64 0, i64 17
  %10913 = load i32, i32* %10912, align 4
  %10914 = add i32 %10910, %10913
  %10915 = add i32 %10909, %10914
  %10916 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %10917 = getelementptr inbounds [32 x i32], [32 x i32]* %10916, i64 0, i64 16
  %10918 = load i32, i32* %10917, align 4
  %10919 = add i32 %10910, %10918
  %10920 = xor i32 %8515, %10919
  %10921 = lshr i32 %10920, 1
  %10922 = shl i32 %10920, 31
  %10923 = add i32 %10921, %10922
  %10924 = shl i32 %8519, 1
  %10925 = lshr i32 %8519, 31
  %10926 = add i32 %10924, %10925
  %10927 = xor i32 %10926, %10915
  %10928 = and i32 %10923, 255
  %10929 = zext i32 %10928 to i64
  %10930 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %10931 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %10930, i64 0, i64 0
  %10932 = srem i64 %10929, 16
  %10933 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10932
  %10934 = load i32, i32* %10933, align 4
  %10935 = icmp eq i64 %10929, %10932
  %10936 = sext i1 %10935 to i32
  %10937 = xor i32 %10936, -1
  %10938 = and i32 %10937, 0
  %10939 = and i32 %10936, %10934
  %10940 = or i32 %10939, %10938
  %10941 = add i64 %10932, 16
  %10942 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10941
  %10943 = load i32, i32* %10942, align 4
  %10944 = icmp eq i64 %10929, %10941
  %10945 = sext i1 %10944 to i32
  %10946 = xor i32 %10945, -1
  %10947 = and i32 %10946, %10940
  %10948 = and i32 %10945, %10943
  %10949 = or i32 %10948, %10947
  %10950 = add i64 %10941, 16
  %10951 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10950
  %10952 = load i32, i32* %10951, align 4
  %10953 = icmp eq i64 %10929, %10950
  %10954 = sext i1 %10953 to i32
  %10955 = xor i32 %10954, -1
  %10956 = and i32 %10955, %10949
  %10957 = and i32 %10954, %10952
  %10958 = or i32 %10957, %10956
  %10959 = add i64 %10950, 16
  %10960 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10959
  %10961 = load i32, i32* %10960, align 4
  %10962 = icmp eq i64 %10929, %10959
  %10963 = sext i1 %10962 to i32
  %10964 = xor i32 %10963, -1
  %10965 = and i32 %10964, %10958
  %10966 = and i32 %10963, %10961
  %10967 = or i32 %10966, %10965
  %10968 = add i64 %10959, 16
  %10969 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10968
  %10970 = load i32, i32* %10969, align 4
  %10971 = icmp eq i64 %10929, %10968
  %10972 = sext i1 %10971 to i32
  %10973 = xor i32 %10972, -1
  %10974 = and i32 %10973, %10967
  %10975 = and i32 %10972, %10970
  %10976 = or i32 %10975, %10974
  %10977 = add i64 %10968, 16
  %10978 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10977
  %10979 = load i32, i32* %10978, align 4
  %10980 = icmp eq i64 %10929, %10977
  %10981 = sext i1 %10980 to i32
  %10982 = xor i32 %10981, -1
  %10983 = and i32 %10982, %10976
  %10984 = and i32 %10981, %10979
  %10985 = or i32 %10984, %10983
  %10986 = add i64 %10977, 16
  %10987 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10986
  %10988 = load i32, i32* %10987, align 4
  %10989 = icmp eq i64 %10929, %10986
  %10990 = sext i1 %10989 to i32
  %10991 = xor i32 %10990, -1
  %10992 = and i32 %10991, %10985
  %10993 = and i32 %10990, %10988
  %10994 = or i32 %10993, %10992
  %10995 = add i64 %10986, 16
  %10996 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %10995
  %10997 = load i32, i32* %10996, align 4
  %10998 = icmp eq i64 %10929, %10995
  %10999 = sext i1 %10998 to i32
  %11000 = xor i32 %10999, -1
  %11001 = and i32 %11000, %10994
  %11002 = and i32 %10999, %10997
  %11003 = or i32 %11002, %11001
  %11004 = add i64 %10995, 16
  %11005 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11004
  %11006 = load i32, i32* %11005, align 4
  %11007 = icmp eq i64 %10929, %11004
  %11008 = sext i1 %11007 to i32
  %11009 = xor i32 %11008, -1
  %11010 = and i32 %11009, %11003
  %11011 = and i32 %11008, %11006
  %11012 = or i32 %11011, %11010
  %11013 = add i64 %11004, 16
  %11014 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11013
  %11015 = load i32, i32* %11014, align 4
  %11016 = icmp eq i64 %10929, %11013
  %11017 = sext i1 %11016 to i32
  %11018 = xor i32 %11017, -1
  %11019 = and i32 %11018, %11012
  %11020 = and i32 %11017, %11015
  %11021 = or i32 %11020, %11019
  %11022 = add i64 %11013, 16
  %11023 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11022
  %11024 = load i32, i32* %11023, align 4
  %11025 = icmp eq i64 %10929, %11022
  %11026 = sext i1 %11025 to i32
  %11027 = xor i32 %11026, -1
  %11028 = and i32 %11027, %11021
  %11029 = and i32 %11026, %11024
  %11030 = or i32 %11029, %11028
  %11031 = add i64 %11022, 16
  %11032 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11031
  %11033 = load i32, i32* %11032, align 4
  %11034 = icmp eq i64 %10929, %11031
  %11035 = sext i1 %11034 to i32
  %11036 = xor i32 %11035, -1
  %11037 = and i32 %11036, %11030
  %11038 = and i32 %11035, %11033
  %11039 = or i32 %11038, %11037
  %11040 = add i64 %11031, 16
  %11041 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11040
  %11042 = load i32, i32* %11041, align 4
  %11043 = icmp eq i64 %10929, %11040
  %11044 = sext i1 %11043 to i32
  %11045 = xor i32 %11044, -1
  %11046 = and i32 %11045, %11039
  %11047 = and i32 %11044, %11042
  %11048 = or i32 %11047, %11046
  %11049 = add i64 %11040, 16
  %11050 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11049
  %11051 = load i32, i32* %11050, align 4
  %11052 = icmp eq i64 %10929, %11049
  %11053 = sext i1 %11052 to i32
  %11054 = xor i32 %11053, -1
  %11055 = and i32 %11054, %11048
  %11056 = and i32 %11053, %11051
  %11057 = or i32 %11056, %11055
  %11058 = add i64 %11049, 16
  %11059 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11058
  %11060 = load i32, i32* %11059, align 4
  %11061 = icmp eq i64 %10929, %11058
  %11062 = sext i1 %11061 to i32
  %11063 = xor i32 %11062, -1
  %11064 = and i32 %11063, %11057
  %11065 = and i32 %11062, %11060
  %11066 = or i32 %11065, %11064
  %11067 = add i64 %11058, 16
  %11068 = getelementptr inbounds [256 x i32], [256 x i32]* %10931, i64 0, i64 %11067
  %11069 = load i32, i32* %11068, align 4
  %11070 = icmp eq i64 %10929, %11067
  %11071 = sext i1 %11070 to i32
  %11072 = xor i32 %11071, -1
  %11073 = and i32 %11072, %11066
  %11074 = and i32 %11071, %11069
  %Mitigated72 = or i32 %11074, %11073
  %11075 = lshr i32 %10923, 8
  %11076 = and i32 %11075, 255
  %11077 = zext i32 %11076 to i64
  %11078 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11079 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11078, i64 0, i64 1
  %11080 = srem i64 %11077, 16
  %11081 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11080
  %11082 = load i32, i32* %11081, align 4
  %11083 = icmp eq i64 %11077, %11080
  %11084 = sext i1 %11083 to i32
  %11085 = xor i32 %11084, -1
  %11086 = and i32 %11085, 0
  %11087 = and i32 %11084, %11082
  %11088 = or i32 %11087, %11086
  %11089 = add i64 %11080, 16
  %11090 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11089
  %11091 = load i32, i32* %11090, align 4
  %11092 = icmp eq i64 %11077, %11089
  %11093 = sext i1 %11092 to i32
  %11094 = xor i32 %11093, -1
  %11095 = and i32 %11094, %11088
  %11096 = and i32 %11093, %11091
  %11097 = or i32 %11096, %11095
  %11098 = add i64 %11089, 16
  %11099 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11098
  %11100 = load i32, i32* %11099, align 4
  %11101 = icmp eq i64 %11077, %11098
  %11102 = sext i1 %11101 to i32
  %11103 = xor i32 %11102, -1
  %11104 = and i32 %11103, %11097
  %11105 = and i32 %11102, %11100
  %11106 = or i32 %11105, %11104
  %11107 = add i64 %11098, 16
  %11108 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11107
  %11109 = load i32, i32* %11108, align 4
  %11110 = icmp eq i64 %11077, %11107
  %11111 = sext i1 %11110 to i32
  %11112 = xor i32 %11111, -1
  %11113 = and i32 %11112, %11106
  %11114 = and i32 %11111, %11109
  %11115 = or i32 %11114, %11113
  %11116 = add i64 %11107, 16
  %11117 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11116
  %11118 = load i32, i32* %11117, align 4
  %11119 = icmp eq i64 %11077, %11116
  %11120 = sext i1 %11119 to i32
  %11121 = xor i32 %11120, -1
  %11122 = and i32 %11121, %11115
  %11123 = and i32 %11120, %11118
  %11124 = or i32 %11123, %11122
  %11125 = add i64 %11116, 16
  %11126 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11125
  %11127 = load i32, i32* %11126, align 4
  %11128 = icmp eq i64 %11077, %11125
  %11129 = sext i1 %11128 to i32
  %11130 = xor i32 %11129, -1
  %11131 = and i32 %11130, %11124
  %11132 = and i32 %11129, %11127
  %11133 = or i32 %11132, %11131
  %11134 = add i64 %11125, 16
  %11135 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11134
  %11136 = load i32, i32* %11135, align 4
  %11137 = icmp eq i64 %11077, %11134
  %11138 = sext i1 %11137 to i32
  %11139 = xor i32 %11138, -1
  %11140 = and i32 %11139, %11133
  %11141 = and i32 %11138, %11136
  %11142 = or i32 %11141, %11140
  %11143 = add i64 %11134, 16
  %11144 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11143
  %11145 = load i32, i32* %11144, align 4
  %11146 = icmp eq i64 %11077, %11143
  %11147 = sext i1 %11146 to i32
  %11148 = xor i32 %11147, -1
  %11149 = and i32 %11148, %11142
  %11150 = and i32 %11147, %11145
  %11151 = or i32 %11150, %11149
  %11152 = add i64 %11143, 16
  %11153 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11152
  %11154 = load i32, i32* %11153, align 4
  %11155 = icmp eq i64 %11077, %11152
  %11156 = sext i1 %11155 to i32
  %11157 = xor i32 %11156, -1
  %11158 = and i32 %11157, %11151
  %11159 = and i32 %11156, %11154
  %11160 = or i32 %11159, %11158
  %11161 = add i64 %11152, 16
  %11162 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11161
  %11163 = load i32, i32* %11162, align 4
  %11164 = icmp eq i64 %11077, %11161
  %11165 = sext i1 %11164 to i32
  %11166 = xor i32 %11165, -1
  %11167 = and i32 %11166, %11160
  %11168 = and i32 %11165, %11163
  %11169 = or i32 %11168, %11167
  %11170 = add i64 %11161, 16
  %11171 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11170
  %11172 = load i32, i32* %11171, align 4
  %11173 = icmp eq i64 %11077, %11170
  %11174 = sext i1 %11173 to i32
  %11175 = xor i32 %11174, -1
  %11176 = and i32 %11175, %11169
  %11177 = and i32 %11174, %11172
  %11178 = or i32 %11177, %11176
  %11179 = add i64 %11170, 16
  %11180 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11179
  %11181 = load i32, i32* %11180, align 4
  %11182 = icmp eq i64 %11077, %11179
  %11183 = sext i1 %11182 to i32
  %11184 = xor i32 %11183, -1
  %11185 = and i32 %11184, %11178
  %11186 = and i32 %11183, %11181
  %11187 = or i32 %11186, %11185
  %11188 = add i64 %11179, 16
  %11189 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11188
  %11190 = load i32, i32* %11189, align 4
  %11191 = icmp eq i64 %11077, %11188
  %11192 = sext i1 %11191 to i32
  %11193 = xor i32 %11192, -1
  %11194 = and i32 %11193, %11187
  %11195 = and i32 %11192, %11190
  %11196 = or i32 %11195, %11194
  %11197 = add i64 %11188, 16
  %11198 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11197
  %11199 = load i32, i32* %11198, align 4
  %11200 = icmp eq i64 %11077, %11197
  %11201 = sext i1 %11200 to i32
  %11202 = xor i32 %11201, -1
  %11203 = and i32 %11202, %11196
  %11204 = and i32 %11201, %11199
  %11205 = or i32 %11204, %11203
  %11206 = add i64 %11197, 16
  %11207 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11206
  %11208 = load i32, i32* %11207, align 4
  %11209 = icmp eq i64 %11077, %11206
  %11210 = sext i1 %11209 to i32
  %11211 = xor i32 %11210, -1
  %11212 = and i32 %11211, %11205
  %11213 = and i32 %11210, %11208
  %11214 = or i32 %11213, %11212
  %11215 = add i64 %11206, 16
  %11216 = getelementptr inbounds [256 x i32], [256 x i32]* %11079, i64 0, i64 %11215
  %11217 = load i32, i32* %11216, align 4
  %11218 = icmp eq i64 %11077, %11215
  %11219 = sext i1 %11218 to i32
  %11220 = xor i32 %11219, -1
  %11221 = and i32 %11220, %11214
  %11222 = and i32 %11219, %11217
  %Mitigated73 = or i32 %11222, %11221
  %11223 = xor i32 %Mitigated72, %Mitigated73
  %11224 = lshr i32 %10923, 16
  %11225 = and i32 %11224, 255
  %11226 = zext i32 %11225 to i64
  %11227 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11228 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11227, i64 0, i64 2
  %11229 = srem i64 %11226, 16
  %11230 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11229
  %11231 = load i32, i32* %11230, align 4
  %11232 = icmp eq i64 %11226, %11229
  %11233 = sext i1 %11232 to i32
  %11234 = xor i32 %11233, -1
  %11235 = and i32 %11234, 0
  %11236 = and i32 %11233, %11231
  %11237 = or i32 %11236, %11235
  %11238 = add i64 %11229, 16
  %11239 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11238
  %11240 = load i32, i32* %11239, align 4
  %11241 = icmp eq i64 %11226, %11238
  %11242 = sext i1 %11241 to i32
  %11243 = xor i32 %11242, -1
  %11244 = and i32 %11243, %11237
  %11245 = and i32 %11242, %11240
  %11246 = or i32 %11245, %11244
  %11247 = add i64 %11238, 16
  %11248 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11247
  %11249 = load i32, i32* %11248, align 4
  %11250 = icmp eq i64 %11226, %11247
  %11251 = sext i1 %11250 to i32
  %11252 = xor i32 %11251, -1
  %11253 = and i32 %11252, %11246
  %11254 = and i32 %11251, %11249
  %11255 = or i32 %11254, %11253
  %11256 = add i64 %11247, 16
  %11257 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11256
  %11258 = load i32, i32* %11257, align 4
  %11259 = icmp eq i64 %11226, %11256
  %11260 = sext i1 %11259 to i32
  %11261 = xor i32 %11260, -1
  %11262 = and i32 %11261, %11255
  %11263 = and i32 %11260, %11258
  %11264 = or i32 %11263, %11262
  %11265 = add i64 %11256, 16
  %11266 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11265
  %11267 = load i32, i32* %11266, align 4
  %11268 = icmp eq i64 %11226, %11265
  %11269 = sext i1 %11268 to i32
  %11270 = xor i32 %11269, -1
  %11271 = and i32 %11270, %11264
  %11272 = and i32 %11269, %11267
  %11273 = or i32 %11272, %11271
  %11274 = add i64 %11265, 16
  %11275 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11274
  %11276 = load i32, i32* %11275, align 4
  %11277 = icmp eq i64 %11226, %11274
  %11278 = sext i1 %11277 to i32
  %11279 = xor i32 %11278, -1
  %11280 = and i32 %11279, %11273
  %11281 = and i32 %11278, %11276
  %11282 = or i32 %11281, %11280
  %11283 = add i64 %11274, 16
  %11284 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11283
  %11285 = load i32, i32* %11284, align 4
  %11286 = icmp eq i64 %11226, %11283
  %11287 = sext i1 %11286 to i32
  %11288 = xor i32 %11287, -1
  %11289 = and i32 %11288, %11282
  %11290 = and i32 %11287, %11285
  %11291 = or i32 %11290, %11289
  %11292 = add i64 %11283, 16
  %11293 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11292
  %11294 = load i32, i32* %11293, align 4
  %11295 = icmp eq i64 %11226, %11292
  %11296 = sext i1 %11295 to i32
  %11297 = xor i32 %11296, -1
  %11298 = and i32 %11297, %11291
  %11299 = and i32 %11296, %11294
  %11300 = or i32 %11299, %11298
  %11301 = add i64 %11292, 16
  %11302 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11301
  %11303 = load i32, i32* %11302, align 4
  %11304 = icmp eq i64 %11226, %11301
  %11305 = sext i1 %11304 to i32
  %11306 = xor i32 %11305, -1
  %11307 = and i32 %11306, %11300
  %11308 = and i32 %11305, %11303
  %11309 = or i32 %11308, %11307
  %11310 = add i64 %11301, 16
  %11311 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11310
  %11312 = load i32, i32* %11311, align 4
  %11313 = icmp eq i64 %11226, %11310
  %11314 = sext i1 %11313 to i32
  %11315 = xor i32 %11314, -1
  %11316 = and i32 %11315, %11309
  %11317 = and i32 %11314, %11312
  %11318 = or i32 %11317, %11316
  %11319 = add i64 %11310, 16
  %11320 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11319
  %11321 = load i32, i32* %11320, align 4
  %11322 = icmp eq i64 %11226, %11319
  %11323 = sext i1 %11322 to i32
  %11324 = xor i32 %11323, -1
  %11325 = and i32 %11324, %11318
  %11326 = and i32 %11323, %11321
  %11327 = or i32 %11326, %11325
  %11328 = add i64 %11319, 16
  %11329 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11328
  %11330 = load i32, i32* %11329, align 4
  %11331 = icmp eq i64 %11226, %11328
  %11332 = sext i1 %11331 to i32
  %11333 = xor i32 %11332, -1
  %11334 = and i32 %11333, %11327
  %11335 = and i32 %11332, %11330
  %11336 = or i32 %11335, %11334
  %11337 = add i64 %11328, 16
  %11338 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11337
  %11339 = load i32, i32* %11338, align 4
  %11340 = icmp eq i64 %11226, %11337
  %11341 = sext i1 %11340 to i32
  %11342 = xor i32 %11341, -1
  %11343 = and i32 %11342, %11336
  %11344 = and i32 %11341, %11339
  %11345 = or i32 %11344, %11343
  %11346 = add i64 %11337, 16
  %11347 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11346
  %11348 = load i32, i32* %11347, align 4
  %11349 = icmp eq i64 %11226, %11346
  %11350 = sext i1 %11349 to i32
  %11351 = xor i32 %11350, -1
  %11352 = and i32 %11351, %11345
  %11353 = and i32 %11350, %11348
  %11354 = or i32 %11353, %11352
  %11355 = add i64 %11346, 16
  %11356 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11355
  %11357 = load i32, i32* %11356, align 4
  %11358 = icmp eq i64 %11226, %11355
  %11359 = sext i1 %11358 to i32
  %11360 = xor i32 %11359, -1
  %11361 = and i32 %11360, %11354
  %11362 = and i32 %11359, %11357
  %11363 = or i32 %11362, %11361
  %11364 = add i64 %11355, 16
  %11365 = getelementptr inbounds [256 x i32], [256 x i32]* %11228, i64 0, i64 %11364
  %11366 = load i32, i32* %11365, align 4
  %11367 = icmp eq i64 %11226, %11364
  %11368 = sext i1 %11367 to i32
  %11369 = xor i32 %11368, -1
  %11370 = and i32 %11369, %11363
  %11371 = and i32 %11368, %11366
  %Mitigated74 = or i32 %11371, %11370
  %11372 = xor i32 %11223, %Mitigated74
  %11373 = lshr i32 %10923, 24
  %11374 = zext i32 %11373 to i64
  %11375 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11376 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11375, i64 0, i64 3
  %11377 = srem i64 %11374, 16
  %11378 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11377
  %11379 = load i32, i32* %11378, align 4
  %11380 = icmp eq i64 %11374, %11377
  %11381 = sext i1 %11380 to i32
  %11382 = xor i32 %11381, -1
  %11383 = and i32 %11382, 0
  %11384 = and i32 %11381, %11379
  %11385 = or i32 %11384, %11383
  %11386 = add i64 %11377, 16
  %11387 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11386
  %11388 = load i32, i32* %11387, align 4
  %11389 = icmp eq i64 %11374, %11386
  %11390 = sext i1 %11389 to i32
  %11391 = xor i32 %11390, -1
  %11392 = and i32 %11391, %11385
  %11393 = and i32 %11390, %11388
  %11394 = or i32 %11393, %11392
  %11395 = add i64 %11386, 16
  %11396 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11395
  %11397 = load i32, i32* %11396, align 4
  %11398 = icmp eq i64 %11374, %11395
  %11399 = sext i1 %11398 to i32
  %11400 = xor i32 %11399, -1
  %11401 = and i32 %11400, %11394
  %11402 = and i32 %11399, %11397
  %11403 = or i32 %11402, %11401
  %11404 = add i64 %11395, 16
  %11405 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11404
  %11406 = load i32, i32* %11405, align 4
  %11407 = icmp eq i64 %11374, %11404
  %11408 = sext i1 %11407 to i32
  %11409 = xor i32 %11408, -1
  %11410 = and i32 %11409, %11403
  %11411 = and i32 %11408, %11406
  %11412 = or i32 %11411, %11410
  %11413 = add i64 %11404, 16
  %11414 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11413
  %11415 = load i32, i32* %11414, align 4
  %11416 = icmp eq i64 %11374, %11413
  %11417 = sext i1 %11416 to i32
  %11418 = xor i32 %11417, -1
  %11419 = and i32 %11418, %11412
  %11420 = and i32 %11417, %11415
  %11421 = or i32 %11420, %11419
  %11422 = add i64 %11413, 16
  %11423 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11422
  %11424 = load i32, i32* %11423, align 4
  %11425 = icmp eq i64 %11374, %11422
  %11426 = sext i1 %11425 to i32
  %11427 = xor i32 %11426, -1
  %11428 = and i32 %11427, %11421
  %11429 = and i32 %11426, %11424
  %11430 = or i32 %11429, %11428
  %11431 = add i64 %11422, 16
  %11432 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11431
  %11433 = load i32, i32* %11432, align 4
  %11434 = icmp eq i64 %11374, %11431
  %11435 = sext i1 %11434 to i32
  %11436 = xor i32 %11435, -1
  %11437 = and i32 %11436, %11430
  %11438 = and i32 %11435, %11433
  %11439 = or i32 %11438, %11437
  %11440 = add i64 %11431, 16
  %11441 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11440
  %11442 = load i32, i32* %11441, align 4
  %11443 = icmp eq i64 %11374, %11440
  %11444 = sext i1 %11443 to i32
  %11445 = xor i32 %11444, -1
  %11446 = and i32 %11445, %11439
  %11447 = and i32 %11444, %11442
  %11448 = or i32 %11447, %11446
  %11449 = add i64 %11440, 16
  %11450 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11449
  %11451 = load i32, i32* %11450, align 4
  %11452 = icmp eq i64 %11374, %11449
  %11453 = sext i1 %11452 to i32
  %11454 = xor i32 %11453, -1
  %11455 = and i32 %11454, %11448
  %11456 = and i32 %11453, %11451
  %11457 = or i32 %11456, %11455
  %11458 = add i64 %11449, 16
  %11459 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11458
  %11460 = load i32, i32* %11459, align 4
  %11461 = icmp eq i64 %11374, %11458
  %11462 = sext i1 %11461 to i32
  %11463 = xor i32 %11462, -1
  %11464 = and i32 %11463, %11457
  %11465 = and i32 %11462, %11460
  %11466 = or i32 %11465, %11464
  %11467 = add i64 %11458, 16
  %11468 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11467
  %11469 = load i32, i32* %11468, align 4
  %11470 = icmp eq i64 %11374, %11467
  %11471 = sext i1 %11470 to i32
  %11472 = xor i32 %11471, -1
  %11473 = and i32 %11472, %11466
  %11474 = and i32 %11471, %11469
  %11475 = or i32 %11474, %11473
  %11476 = add i64 %11467, 16
  %11477 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11476
  %11478 = load i32, i32* %11477, align 4
  %11479 = icmp eq i64 %11374, %11476
  %11480 = sext i1 %11479 to i32
  %11481 = xor i32 %11480, -1
  %11482 = and i32 %11481, %11475
  %11483 = and i32 %11480, %11478
  %11484 = or i32 %11483, %11482
  %11485 = add i64 %11476, 16
  %11486 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11485
  %11487 = load i32, i32* %11486, align 4
  %11488 = icmp eq i64 %11374, %11485
  %11489 = sext i1 %11488 to i32
  %11490 = xor i32 %11489, -1
  %11491 = and i32 %11490, %11484
  %11492 = and i32 %11489, %11487
  %11493 = or i32 %11492, %11491
  %11494 = add i64 %11485, 16
  %11495 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11494
  %11496 = load i32, i32* %11495, align 4
  %11497 = icmp eq i64 %11374, %11494
  %11498 = sext i1 %11497 to i32
  %11499 = xor i32 %11498, -1
  %11500 = and i32 %11499, %11493
  %11501 = and i32 %11498, %11496
  %11502 = or i32 %11501, %11500
  %11503 = add i64 %11494, 16
  %11504 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11503
  %11505 = load i32, i32* %11504, align 4
  %11506 = icmp eq i64 %11374, %11503
  %11507 = sext i1 %11506 to i32
  %11508 = xor i32 %11507, -1
  %11509 = and i32 %11508, %11502
  %11510 = and i32 %11507, %11505
  %11511 = or i32 %11510, %11509
  %11512 = add i64 %11503, 16
  %11513 = getelementptr inbounds [256 x i32], [256 x i32]* %11376, i64 0, i64 %11512
  %11514 = load i32, i32* %11513, align 4
  %11515 = icmp eq i64 %11374, %11512
  %11516 = sext i1 %11515 to i32
  %11517 = xor i32 %11516, -1
  %11518 = and i32 %11517, %11511
  %11519 = and i32 %11516, %11514
  %Mitigated75 = or i32 %11519, %11518
  %11520 = xor i32 %11372, %Mitigated75
  %11521 = and i32 %10927, 255
  %11522 = zext i32 %11521 to i64
  %11523 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11524 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11523, i64 0, i64 1
  %11525 = srem i64 %11522, 16
  %11526 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11525
  %11527 = load i32, i32* %11526, align 4
  %11528 = icmp eq i64 %11522, %11525
  %11529 = sext i1 %11528 to i32
  %11530 = xor i32 %11529, -1
  %11531 = and i32 %11530, 0
  %11532 = and i32 %11529, %11527
  %11533 = or i32 %11532, %11531
  %11534 = add i64 %11525, 16
  %11535 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11534
  %11536 = load i32, i32* %11535, align 4
  %11537 = icmp eq i64 %11522, %11534
  %11538 = sext i1 %11537 to i32
  %11539 = xor i32 %11538, -1
  %11540 = and i32 %11539, %11533
  %11541 = and i32 %11538, %11536
  %11542 = or i32 %11541, %11540
  %11543 = add i64 %11534, 16
  %11544 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11543
  %11545 = load i32, i32* %11544, align 4
  %11546 = icmp eq i64 %11522, %11543
  %11547 = sext i1 %11546 to i32
  %11548 = xor i32 %11547, -1
  %11549 = and i32 %11548, %11542
  %11550 = and i32 %11547, %11545
  %11551 = or i32 %11550, %11549
  %11552 = add i64 %11543, 16
  %11553 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11552
  %11554 = load i32, i32* %11553, align 4
  %11555 = icmp eq i64 %11522, %11552
  %11556 = sext i1 %11555 to i32
  %11557 = xor i32 %11556, -1
  %11558 = and i32 %11557, %11551
  %11559 = and i32 %11556, %11554
  %11560 = or i32 %11559, %11558
  %11561 = add i64 %11552, 16
  %11562 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11561
  %11563 = load i32, i32* %11562, align 4
  %11564 = icmp eq i64 %11522, %11561
  %11565 = sext i1 %11564 to i32
  %11566 = xor i32 %11565, -1
  %11567 = and i32 %11566, %11560
  %11568 = and i32 %11565, %11563
  %11569 = or i32 %11568, %11567
  %11570 = add i64 %11561, 16
  %11571 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11570
  %11572 = load i32, i32* %11571, align 4
  %11573 = icmp eq i64 %11522, %11570
  %11574 = sext i1 %11573 to i32
  %11575 = xor i32 %11574, -1
  %11576 = and i32 %11575, %11569
  %11577 = and i32 %11574, %11572
  %11578 = or i32 %11577, %11576
  %11579 = add i64 %11570, 16
  %11580 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11579
  %11581 = load i32, i32* %11580, align 4
  %11582 = icmp eq i64 %11522, %11579
  %11583 = sext i1 %11582 to i32
  %11584 = xor i32 %11583, -1
  %11585 = and i32 %11584, %11578
  %11586 = and i32 %11583, %11581
  %11587 = or i32 %11586, %11585
  %11588 = add i64 %11579, 16
  %11589 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11588
  %11590 = load i32, i32* %11589, align 4
  %11591 = icmp eq i64 %11522, %11588
  %11592 = sext i1 %11591 to i32
  %11593 = xor i32 %11592, -1
  %11594 = and i32 %11593, %11587
  %11595 = and i32 %11592, %11590
  %11596 = or i32 %11595, %11594
  %11597 = add i64 %11588, 16
  %11598 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11597
  %11599 = load i32, i32* %11598, align 4
  %11600 = icmp eq i64 %11522, %11597
  %11601 = sext i1 %11600 to i32
  %11602 = xor i32 %11601, -1
  %11603 = and i32 %11602, %11596
  %11604 = and i32 %11601, %11599
  %11605 = or i32 %11604, %11603
  %11606 = add i64 %11597, 16
  %11607 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11606
  %11608 = load i32, i32* %11607, align 4
  %11609 = icmp eq i64 %11522, %11606
  %11610 = sext i1 %11609 to i32
  %11611 = xor i32 %11610, -1
  %11612 = and i32 %11611, %11605
  %11613 = and i32 %11610, %11608
  %11614 = or i32 %11613, %11612
  %11615 = add i64 %11606, 16
  %11616 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11615
  %11617 = load i32, i32* %11616, align 4
  %11618 = icmp eq i64 %11522, %11615
  %11619 = sext i1 %11618 to i32
  %11620 = xor i32 %11619, -1
  %11621 = and i32 %11620, %11614
  %11622 = and i32 %11619, %11617
  %11623 = or i32 %11622, %11621
  %11624 = add i64 %11615, 16
  %11625 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11624
  %11626 = load i32, i32* %11625, align 4
  %11627 = icmp eq i64 %11522, %11624
  %11628 = sext i1 %11627 to i32
  %11629 = xor i32 %11628, -1
  %11630 = and i32 %11629, %11623
  %11631 = and i32 %11628, %11626
  %11632 = or i32 %11631, %11630
  %11633 = add i64 %11624, 16
  %11634 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11633
  %11635 = load i32, i32* %11634, align 4
  %11636 = icmp eq i64 %11522, %11633
  %11637 = sext i1 %11636 to i32
  %11638 = xor i32 %11637, -1
  %11639 = and i32 %11638, %11632
  %11640 = and i32 %11637, %11635
  %11641 = or i32 %11640, %11639
  %11642 = add i64 %11633, 16
  %11643 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11642
  %11644 = load i32, i32* %11643, align 4
  %11645 = icmp eq i64 %11522, %11642
  %11646 = sext i1 %11645 to i32
  %11647 = xor i32 %11646, -1
  %11648 = and i32 %11647, %11641
  %11649 = and i32 %11646, %11644
  %11650 = or i32 %11649, %11648
  %11651 = add i64 %11642, 16
  %11652 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11651
  %11653 = load i32, i32* %11652, align 4
  %11654 = icmp eq i64 %11522, %11651
  %11655 = sext i1 %11654 to i32
  %11656 = xor i32 %11655, -1
  %11657 = and i32 %11656, %11650
  %11658 = and i32 %11655, %11653
  %11659 = or i32 %11658, %11657
  %11660 = add i64 %11651, 16
  %11661 = getelementptr inbounds [256 x i32], [256 x i32]* %11524, i64 0, i64 %11660
  %11662 = load i32, i32* %11661, align 4
  %11663 = icmp eq i64 %11522, %11660
  %11664 = sext i1 %11663 to i32
  %11665 = xor i32 %11664, -1
  %11666 = and i32 %11665, %11659
  %11667 = and i32 %11664, %11662
  %Mitigated76 = or i32 %11667, %11666
  %11668 = lshr i32 %10927, 8
  %11669 = and i32 %11668, 255
  %11670 = zext i32 %11669 to i64
  %11671 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11672 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11671, i64 0, i64 2
  %11673 = srem i64 %11670, 16
  %11674 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11673
  %11675 = load i32, i32* %11674, align 4
  %11676 = icmp eq i64 %11670, %11673
  %11677 = sext i1 %11676 to i32
  %11678 = xor i32 %11677, -1
  %11679 = and i32 %11678, 0
  %11680 = and i32 %11677, %11675
  %11681 = or i32 %11680, %11679
  %11682 = add i64 %11673, 16
  %11683 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11682
  %11684 = load i32, i32* %11683, align 4
  %11685 = icmp eq i64 %11670, %11682
  %11686 = sext i1 %11685 to i32
  %11687 = xor i32 %11686, -1
  %11688 = and i32 %11687, %11681
  %11689 = and i32 %11686, %11684
  %11690 = or i32 %11689, %11688
  %11691 = add i64 %11682, 16
  %11692 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11691
  %11693 = load i32, i32* %11692, align 4
  %11694 = icmp eq i64 %11670, %11691
  %11695 = sext i1 %11694 to i32
  %11696 = xor i32 %11695, -1
  %11697 = and i32 %11696, %11690
  %11698 = and i32 %11695, %11693
  %11699 = or i32 %11698, %11697
  %11700 = add i64 %11691, 16
  %11701 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11700
  %11702 = load i32, i32* %11701, align 4
  %11703 = icmp eq i64 %11670, %11700
  %11704 = sext i1 %11703 to i32
  %11705 = xor i32 %11704, -1
  %11706 = and i32 %11705, %11699
  %11707 = and i32 %11704, %11702
  %11708 = or i32 %11707, %11706
  %11709 = add i64 %11700, 16
  %11710 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11709
  %11711 = load i32, i32* %11710, align 4
  %11712 = icmp eq i64 %11670, %11709
  %11713 = sext i1 %11712 to i32
  %11714 = xor i32 %11713, -1
  %11715 = and i32 %11714, %11708
  %11716 = and i32 %11713, %11711
  %11717 = or i32 %11716, %11715
  %11718 = add i64 %11709, 16
  %11719 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11718
  %11720 = load i32, i32* %11719, align 4
  %11721 = icmp eq i64 %11670, %11718
  %11722 = sext i1 %11721 to i32
  %11723 = xor i32 %11722, -1
  %11724 = and i32 %11723, %11717
  %11725 = and i32 %11722, %11720
  %11726 = or i32 %11725, %11724
  %11727 = add i64 %11718, 16
  %11728 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11727
  %11729 = load i32, i32* %11728, align 4
  %11730 = icmp eq i64 %11670, %11727
  %11731 = sext i1 %11730 to i32
  %11732 = xor i32 %11731, -1
  %11733 = and i32 %11732, %11726
  %11734 = and i32 %11731, %11729
  %11735 = or i32 %11734, %11733
  %11736 = add i64 %11727, 16
  %11737 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11736
  %11738 = load i32, i32* %11737, align 4
  %11739 = icmp eq i64 %11670, %11736
  %11740 = sext i1 %11739 to i32
  %11741 = xor i32 %11740, -1
  %11742 = and i32 %11741, %11735
  %11743 = and i32 %11740, %11738
  %11744 = or i32 %11743, %11742
  %11745 = add i64 %11736, 16
  %11746 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11745
  %11747 = load i32, i32* %11746, align 4
  %11748 = icmp eq i64 %11670, %11745
  %11749 = sext i1 %11748 to i32
  %11750 = xor i32 %11749, -1
  %11751 = and i32 %11750, %11744
  %11752 = and i32 %11749, %11747
  %11753 = or i32 %11752, %11751
  %11754 = add i64 %11745, 16
  %11755 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11754
  %11756 = load i32, i32* %11755, align 4
  %11757 = icmp eq i64 %11670, %11754
  %11758 = sext i1 %11757 to i32
  %11759 = xor i32 %11758, -1
  %11760 = and i32 %11759, %11753
  %11761 = and i32 %11758, %11756
  %11762 = or i32 %11761, %11760
  %11763 = add i64 %11754, 16
  %11764 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11763
  %11765 = load i32, i32* %11764, align 4
  %11766 = icmp eq i64 %11670, %11763
  %11767 = sext i1 %11766 to i32
  %11768 = xor i32 %11767, -1
  %11769 = and i32 %11768, %11762
  %11770 = and i32 %11767, %11765
  %11771 = or i32 %11770, %11769
  %11772 = add i64 %11763, 16
  %11773 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11772
  %11774 = load i32, i32* %11773, align 4
  %11775 = icmp eq i64 %11670, %11772
  %11776 = sext i1 %11775 to i32
  %11777 = xor i32 %11776, -1
  %11778 = and i32 %11777, %11771
  %11779 = and i32 %11776, %11774
  %11780 = or i32 %11779, %11778
  %11781 = add i64 %11772, 16
  %11782 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11781
  %11783 = load i32, i32* %11782, align 4
  %11784 = icmp eq i64 %11670, %11781
  %11785 = sext i1 %11784 to i32
  %11786 = xor i32 %11785, -1
  %11787 = and i32 %11786, %11780
  %11788 = and i32 %11785, %11783
  %11789 = or i32 %11788, %11787
  %11790 = add i64 %11781, 16
  %11791 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11790
  %11792 = load i32, i32* %11791, align 4
  %11793 = icmp eq i64 %11670, %11790
  %11794 = sext i1 %11793 to i32
  %11795 = xor i32 %11794, -1
  %11796 = and i32 %11795, %11789
  %11797 = and i32 %11794, %11792
  %11798 = or i32 %11797, %11796
  %11799 = add i64 %11790, 16
  %11800 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11799
  %11801 = load i32, i32* %11800, align 4
  %11802 = icmp eq i64 %11670, %11799
  %11803 = sext i1 %11802 to i32
  %11804 = xor i32 %11803, -1
  %11805 = and i32 %11804, %11798
  %11806 = and i32 %11803, %11801
  %11807 = or i32 %11806, %11805
  %11808 = add i64 %11799, 16
  %11809 = getelementptr inbounds [256 x i32], [256 x i32]* %11672, i64 0, i64 %11808
  %11810 = load i32, i32* %11809, align 4
  %11811 = icmp eq i64 %11670, %11808
  %11812 = sext i1 %11811 to i32
  %11813 = xor i32 %11812, -1
  %11814 = and i32 %11813, %11807
  %11815 = and i32 %11812, %11810
  %Mitigated77 = or i32 %11815, %11814
  %11816 = xor i32 %Mitigated76, %Mitigated77
  %11817 = lshr i32 %10927, 16
  %11818 = and i32 %11817, 255
  %11819 = zext i32 %11818 to i64
  %11820 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11821 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11820, i64 0, i64 3
  %11822 = srem i64 %11819, 16
  %11823 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11822
  %11824 = load i32, i32* %11823, align 4
  %11825 = icmp eq i64 %11819, %11822
  %11826 = sext i1 %11825 to i32
  %11827 = xor i32 %11826, -1
  %11828 = and i32 %11827, 0
  %11829 = and i32 %11826, %11824
  %11830 = or i32 %11829, %11828
  %11831 = add i64 %11822, 16
  %11832 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11831
  %11833 = load i32, i32* %11832, align 4
  %11834 = icmp eq i64 %11819, %11831
  %11835 = sext i1 %11834 to i32
  %11836 = xor i32 %11835, -1
  %11837 = and i32 %11836, %11830
  %11838 = and i32 %11835, %11833
  %11839 = or i32 %11838, %11837
  %11840 = add i64 %11831, 16
  %11841 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11840
  %11842 = load i32, i32* %11841, align 4
  %11843 = icmp eq i64 %11819, %11840
  %11844 = sext i1 %11843 to i32
  %11845 = xor i32 %11844, -1
  %11846 = and i32 %11845, %11839
  %11847 = and i32 %11844, %11842
  %11848 = or i32 %11847, %11846
  %11849 = add i64 %11840, 16
  %11850 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11849
  %11851 = load i32, i32* %11850, align 4
  %11852 = icmp eq i64 %11819, %11849
  %11853 = sext i1 %11852 to i32
  %11854 = xor i32 %11853, -1
  %11855 = and i32 %11854, %11848
  %11856 = and i32 %11853, %11851
  %11857 = or i32 %11856, %11855
  %11858 = add i64 %11849, 16
  %11859 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11858
  %11860 = load i32, i32* %11859, align 4
  %11861 = icmp eq i64 %11819, %11858
  %11862 = sext i1 %11861 to i32
  %11863 = xor i32 %11862, -1
  %11864 = and i32 %11863, %11857
  %11865 = and i32 %11862, %11860
  %11866 = or i32 %11865, %11864
  %11867 = add i64 %11858, 16
  %11868 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11867
  %11869 = load i32, i32* %11868, align 4
  %11870 = icmp eq i64 %11819, %11867
  %11871 = sext i1 %11870 to i32
  %11872 = xor i32 %11871, -1
  %11873 = and i32 %11872, %11866
  %11874 = and i32 %11871, %11869
  %11875 = or i32 %11874, %11873
  %11876 = add i64 %11867, 16
  %11877 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11876
  %11878 = load i32, i32* %11877, align 4
  %11879 = icmp eq i64 %11819, %11876
  %11880 = sext i1 %11879 to i32
  %11881 = xor i32 %11880, -1
  %11882 = and i32 %11881, %11875
  %11883 = and i32 %11880, %11878
  %11884 = or i32 %11883, %11882
  %11885 = add i64 %11876, 16
  %11886 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11885
  %11887 = load i32, i32* %11886, align 4
  %11888 = icmp eq i64 %11819, %11885
  %11889 = sext i1 %11888 to i32
  %11890 = xor i32 %11889, -1
  %11891 = and i32 %11890, %11884
  %11892 = and i32 %11889, %11887
  %11893 = or i32 %11892, %11891
  %11894 = add i64 %11885, 16
  %11895 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11894
  %11896 = load i32, i32* %11895, align 4
  %11897 = icmp eq i64 %11819, %11894
  %11898 = sext i1 %11897 to i32
  %11899 = xor i32 %11898, -1
  %11900 = and i32 %11899, %11893
  %11901 = and i32 %11898, %11896
  %11902 = or i32 %11901, %11900
  %11903 = add i64 %11894, 16
  %11904 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11903
  %11905 = load i32, i32* %11904, align 4
  %11906 = icmp eq i64 %11819, %11903
  %11907 = sext i1 %11906 to i32
  %11908 = xor i32 %11907, -1
  %11909 = and i32 %11908, %11902
  %11910 = and i32 %11907, %11905
  %11911 = or i32 %11910, %11909
  %11912 = add i64 %11903, 16
  %11913 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11912
  %11914 = load i32, i32* %11913, align 4
  %11915 = icmp eq i64 %11819, %11912
  %11916 = sext i1 %11915 to i32
  %11917 = xor i32 %11916, -1
  %11918 = and i32 %11917, %11911
  %11919 = and i32 %11916, %11914
  %11920 = or i32 %11919, %11918
  %11921 = add i64 %11912, 16
  %11922 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11921
  %11923 = load i32, i32* %11922, align 4
  %11924 = icmp eq i64 %11819, %11921
  %11925 = sext i1 %11924 to i32
  %11926 = xor i32 %11925, -1
  %11927 = and i32 %11926, %11920
  %11928 = and i32 %11925, %11923
  %11929 = or i32 %11928, %11927
  %11930 = add i64 %11921, 16
  %11931 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11930
  %11932 = load i32, i32* %11931, align 4
  %11933 = icmp eq i64 %11819, %11930
  %11934 = sext i1 %11933 to i32
  %11935 = xor i32 %11934, -1
  %11936 = and i32 %11935, %11929
  %11937 = and i32 %11934, %11932
  %11938 = or i32 %11937, %11936
  %11939 = add i64 %11930, 16
  %11940 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11939
  %11941 = load i32, i32* %11940, align 4
  %11942 = icmp eq i64 %11819, %11939
  %11943 = sext i1 %11942 to i32
  %11944 = xor i32 %11943, -1
  %11945 = and i32 %11944, %11938
  %11946 = and i32 %11943, %11941
  %11947 = or i32 %11946, %11945
  %11948 = add i64 %11939, 16
  %11949 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11948
  %11950 = load i32, i32* %11949, align 4
  %11951 = icmp eq i64 %11819, %11948
  %11952 = sext i1 %11951 to i32
  %11953 = xor i32 %11952, -1
  %11954 = and i32 %11953, %11947
  %11955 = and i32 %11952, %11950
  %11956 = or i32 %11955, %11954
  %11957 = add i64 %11948, 16
  %11958 = getelementptr inbounds [256 x i32], [256 x i32]* %11821, i64 0, i64 %11957
  %11959 = load i32, i32* %11958, align 4
  %11960 = icmp eq i64 %11819, %11957
  %11961 = sext i1 %11960 to i32
  %11962 = xor i32 %11961, -1
  %11963 = and i32 %11962, %11956
  %11964 = and i32 %11961, %11959
  %Mitigated78 = or i32 %11964, %11963
  %11965 = xor i32 %11816, %Mitigated78
  %11966 = lshr i32 %10927, 24
  %11967 = zext i32 %11966 to i64
  %11968 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %11969 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %11968, i64 0, i64 0
  %11970 = srem i64 %11967, 16
  %11971 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %11970
  %11972 = load i32, i32* %11971, align 4
  %11973 = icmp eq i64 %11967, %11970
  %11974 = sext i1 %11973 to i32
  %11975 = xor i32 %11974, -1
  %11976 = and i32 %11975, 0
  %11977 = and i32 %11974, %11972
  %11978 = or i32 %11977, %11976
  %11979 = add i64 %11970, 16
  %11980 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %11979
  %11981 = load i32, i32* %11980, align 4
  %11982 = icmp eq i64 %11967, %11979
  %11983 = sext i1 %11982 to i32
  %11984 = xor i32 %11983, -1
  %11985 = and i32 %11984, %11978
  %11986 = and i32 %11983, %11981
  %11987 = or i32 %11986, %11985
  %11988 = add i64 %11979, 16
  %11989 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %11988
  %11990 = load i32, i32* %11989, align 4
  %11991 = icmp eq i64 %11967, %11988
  %11992 = sext i1 %11991 to i32
  %11993 = xor i32 %11992, -1
  %11994 = and i32 %11993, %11987
  %11995 = and i32 %11992, %11990
  %11996 = or i32 %11995, %11994
  %11997 = add i64 %11988, 16
  %11998 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %11997
  %11999 = load i32, i32* %11998, align 4
  %12000 = icmp eq i64 %11967, %11997
  %12001 = sext i1 %12000 to i32
  %12002 = xor i32 %12001, -1
  %12003 = and i32 %12002, %11996
  %12004 = and i32 %12001, %11999
  %12005 = or i32 %12004, %12003
  %12006 = add i64 %11997, 16
  %12007 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12006
  %12008 = load i32, i32* %12007, align 4
  %12009 = icmp eq i64 %11967, %12006
  %12010 = sext i1 %12009 to i32
  %12011 = xor i32 %12010, -1
  %12012 = and i32 %12011, %12005
  %12013 = and i32 %12010, %12008
  %12014 = or i32 %12013, %12012
  %12015 = add i64 %12006, 16
  %12016 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12015
  %12017 = load i32, i32* %12016, align 4
  %12018 = icmp eq i64 %11967, %12015
  %12019 = sext i1 %12018 to i32
  %12020 = xor i32 %12019, -1
  %12021 = and i32 %12020, %12014
  %12022 = and i32 %12019, %12017
  %12023 = or i32 %12022, %12021
  %12024 = add i64 %12015, 16
  %12025 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12024
  %12026 = load i32, i32* %12025, align 4
  %12027 = icmp eq i64 %11967, %12024
  %12028 = sext i1 %12027 to i32
  %12029 = xor i32 %12028, -1
  %12030 = and i32 %12029, %12023
  %12031 = and i32 %12028, %12026
  %12032 = or i32 %12031, %12030
  %12033 = add i64 %12024, 16
  %12034 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12033
  %12035 = load i32, i32* %12034, align 4
  %12036 = icmp eq i64 %11967, %12033
  %12037 = sext i1 %12036 to i32
  %12038 = xor i32 %12037, -1
  %12039 = and i32 %12038, %12032
  %12040 = and i32 %12037, %12035
  %12041 = or i32 %12040, %12039
  %12042 = add i64 %12033, 16
  %12043 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12042
  %12044 = load i32, i32* %12043, align 4
  %12045 = icmp eq i64 %11967, %12042
  %12046 = sext i1 %12045 to i32
  %12047 = xor i32 %12046, -1
  %12048 = and i32 %12047, %12041
  %12049 = and i32 %12046, %12044
  %12050 = or i32 %12049, %12048
  %12051 = add i64 %12042, 16
  %12052 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12051
  %12053 = load i32, i32* %12052, align 4
  %12054 = icmp eq i64 %11967, %12051
  %12055 = sext i1 %12054 to i32
  %12056 = xor i32 %12055, -1
  %12057 = and i32 %12056, %12050
  %12058 = and i32 %12055, %12053
  %12059 = or i32 %12058, %12057
  %12060 = add i64 %12051, 16
  %12061 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12060
  %12062 = load i32, i32* %12061, align 4
  %12063 = icmp eq i64 %11967, %12060
  %12064 = sext i1 %12063 to i32
  %12065 = xor i32 %12064, -1
  %12066 = and i32 %12065, %12059
  %12067 = and i32 %12064, %12062
  %12068 = or i32 %12067, %12066
  %12069 = add i64 %12060, 16
  %12070 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12069
  %12071 = load i32, i32* %12070, align 4
  %12072 = icmp eq i64 %11967, %12069
  %12073 = sext i1 %12072 to i32
  %12074 = xor i32 %12073, -1
  %12075 = and i32 %12074, %12068
  %12076 = and i32 %12073, %12071
  %12077 = or i32 %12076, %12075
  %12078 = add i64 %12069, 16
  %12079 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12078
  %12080 = load i32, i32* %12079, align 4
  %12081 = icmp eq i64 %11967, %12078
  %12082 = sext i1 %12081 to i32
  %12083 = xor i32 %12082, -1
  %12084 = and i32 %12083, %12077
  %12085 = and i32 %12082, %12080
  %12086 = or i32 %12085, %12084
  %12087 = add i64 %12078, 16
  %12088 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12087
  %12089 = load i32, i32* %12088, align 4
  %12090 = icmp eq i64 %11967, %12087
  %12091 = sext i1 %12090 to i32
  %12092 = xor i32 %12091, -1
  %12093 = and i32 %12092, %12086
  %12094 = and i32 %12091, %12089
  %12095 = or i32 %12094, %12093
  %12096 = add i64 %12087, 16
  %12097 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12096
  %12098 = load i32, i32* %12097, align 4
  %12099 = icmp eq i64 %11967, %12096
  %12100 = sext i1 %12099 to i32
  %12101 = xor i32 %12100, -1
  %12102 = and i32 %12101, %12095
  %12103 = and i32 %12100, %12098
  %12104 = or i32 %12103, %12102
  %12105 = add i64 %12096, 16
  %12106 = getelementptr inbounds [256 x i32], [256 x i32]* %11969, i64 0, i64 %12105
  %12107 = load i32, i32* %12106, align 4
  %12108 = icmp eq i64 %11967, %12105
  %12109 = sext i1 %12108 to i32
  %12110 = xor i32 %12109, -1
  %12111 = and i32 %12110, %12104
  %12112 = and i32 %12109, %12107
  %Mitigated79 = or i32 %12112, %12111
  %12113 = xor i32 %11965, %Mitigated79
  %12114 = add i32 %11520, %12113
  %12115 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %12116 = getelementptr inbounds [32 x i32], [32 x i32]* %12115, i64 0, i64 19
  %12117 = load i32, i32* %12116, align 4
  %12118 = add i32 %12114, %12117
  %12119 = add i32 %12113, %12118
  %12120 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %12121 = getelementptr inbounds [32 x i32], [32 x i32]* %12120, i64 0, i64 18
  %12122 = load i32, i32* %12121, align 4
  %12123 = add i32 %12114, %12122
  %12124 = xor i32 %9719, %12123
  %12125 = lshr i32 %12124, 1
  %12126 = shl i32 %12124, 31
  %12127 = add i32 %12125, %12126
  %12128 = shl i32 %9723, 1
  %12129 = lshr i32 %9723, 31
  %12130 = add i32 %12128, %12129
  %12131 = xor i32 %12130, %12119
  %12132 = and i32 %12127, 255
  %12133 = zext i32 %12132 to i64
  %12134 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12135 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12134, i64 0, i64 0
  %12136 = srem i64 %12133, 16
  %12137 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12136
  %12138 = load i32, i32* %12137, align 4
  %12139 = icmp eq i64 %12133, %12136
  %12140 = sext i1 %12139 to i32
  %12141 = xor i32 %12140, -1
  %12142 = and i32 %12141, 0
  %12143 = and i32 %12140, %12138
  %12144 = or i32 %12143, %12142
  %12145 = add i64 %12136, 16
  %12146 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12145
  %12147 = load i32, i32* %12146, align 4
  %12148 = icmp eq i64 %12133, %12145
  %12149 = sext i1 %12148 to i32
  %12150 = xor i32 %12149, -1
  %12151 = and i32 %12150, %12144
  %12152 = and i32 %12149, %12147
  %12153 = or i32 %12152, %12151
  %12154 = add i64 %12145, 16
  %12155 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12154
  %12156 = load i32, i32* %12155, align 4
  %12157 = icmp eq i64 %12133, %12154
  %12158 = sext i1 %12157 to i32
  %12159 = xor i32 %12158, -1
  %12160 = and i32 %12159, %12153
  %12161 = and i32 %12158, %12156
  %12162 = or i32 %12161, %12160
  %12163 = add i64 %12154, 16
  %12164 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12163
  %12165 = load i32, i32* %12164, align 4
  %12166 = icmp eq i64 %12133, %12163
  %12167 = sext i1 %12166 to i32
  %12168 = xor i32 %12167, -1
  %12169 = and i32 %12168, %12162
  %12170 = and i32 %12167, %12165
  %12171 = or i32 %12170, %12169
  %12172 = add i64 %12163, 16
  %12173 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12172
  %12174 = load i32, i32* %12173, align 4
  %12175 = icmp eq i64 %12133, %12172
  %12176 = sext i1 %12175 to i32
  %12177 = xor i32 %12176, -1
  %12178 = and i32 %12177, %12171
  %12179 = and i32 %12176, %12174
  %12180 = or i32 %12179, %12178
  %12181 = add i64 %12172, 16
  %12182 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12181
  %12183 = load i32, i32* %12182, align 4
  %12184 = icmp eq i64 %12133, %12181
  %12185 = sext i1 %12184 to i32
  %12186 = xor i32 %12185, -1
  %12187 = and i32 %12186, %12180
  %12188 = and i32 %12185, %12183
  %12189 = or i32 %12188, %12187
  %12190 = add i64 %12181, 16
  %12191 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12190
  %12192 = load i32, i32* %12191, align 4
  %12193 = icmp eq i64 %12133, %12190
  %12194 = sext i1 %12193 to i32
  %12195 = xor i32 %12194, -1
  %12196 = and i32 %12195, %12189
  %12197 = and i32 %12194, %12192
  %12198 = or i32 %12197, %12196
  %12199 = add i64 %12190, 16
  %12200 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12199
  %12201 = load i32, i32* %12200, align 4
  %12202 = icmp eq i64 %12133, %12199
  %12203 = sext i1 %12202 to i32
  %12204 = xor i32 %12203, -1
  %12205 = and i32 %12204, %12198
  %12206 = and i32 %12203, %12201
  %12207 = or i32 %12206, %12205
  %12208 = add i64 %12199, 16
  %12209 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12208
  %12210 = load i32, i32* %12209, align 4
  %12211 = icmp eq i64 %12133, %12208
  %12212 = sext i1 %12211 to i32
  %12213 = xor i32 %12212, -1
  %12214 = and i32 %12213, %12207
  %12215 = and i32 %12212, %12210
  %12216 = or i32 %12215, %12214
  %12217 = add i64 %12208, 16
  %12218 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12217
  %12219 = load i32, i32* %12218, align 4
  %12220 = icmp eq i64 %12133, %12217
  %12221 = sext i1 %12220 to i32
  %12222 = xor i32 %12221, -1
  %12223 = and i32 %12222, %12216
  %12224 = and i32 %12221, %12219
  %12225 = or i32 %12224, %12223
  %12226 = add i64 %12217, 16
  %12227 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12226
  %12228 = load i32, i32* %12227, align 4
  %12229 = icmp eq i64 %12133, %12226
  %12230 = sext i1 %12229 to i32
  %12231 = xor i32 %12230, -1
  %12232 = and i32 %12231, %12225
  %12233 = and i32 %12230, %12228
  %12234 = or i32 %12233, %12232
  %12235 = add i64 %12226, 16
  %12236 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12235
  %12237 = load i32, i32* %12236, align 4
  %12238 = icmp eq i64 %12133, %12235
  %12239 = sext i1 %12238 to i32
  %12240 = xor i32 %12239, -1
  %12241 = and i32 %12240, %12234
  %12242 = and i32 %12239, %12237
  %12243 = or i32 %12242, %12241
  %12244 = add i64 %12235, 16
  %12245 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12244
  %12246 = load i32, i32* %12245, align 4
  %12247 = icmp eq i64 %12133, %12244
  %12248 = sext i1 %12247 to i32
  %12249 = xor i32 %12248, -1
  %12250 = and i32 %12249, %12243
  %12251 = and i32 %12248, %12246
  %12252 = or i32 %12251, %12250
  %12253 = add i64 %12244, 16
  %12254 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12253
  %12255 = load i32, i32* %12254, align 4
  %12256 = icmp eq i64 %12133, %12253
  %12257 = sext i1 %12256 to i32
  %12258 = xor i32 %12257, -1
  %12259 = and i32 %12258, %12252
  %12260 = and i32 %12257, %12255
  %12261 = or i32 %12260, %12259
  %12262 = add i64 %12253, 16
  %12263 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12262
  %12264 = load i32, i32* %12263, align 4
  %12265 = icmp eq i64 %12133, %12262
  %12266 = sext i1 %12265 to i32
  %12267 = xor i32 %12266, -1
  %12268 = and i32 %12267, %12261
  %12269 = and i32 %12266, %12264
  %12270 = or i32 %12269, %12268
  %12271 = add i64 %12262, 16
  %12272 = getelementptr inbounds [256 x i32], [256 x i32]* %12135, i64 0, i64 %12271
  %12273 = load i32, i32* %12272, align 4
  %12274 = icmp eq i64 %12133, %12271
  %12275 = sext i1 %12274 to i32
  %12276 = xor i32 %12275, -1
  %12277 = and i32 %12276, %12270
  %12278 = and i32 %12275, %12273
  %Mitigated80 = or i32 %12278, %12277
  %12279 = lshr i32 %12127, 8
  %12280 = and i32 %12279, 255
  %12281 = zext i32 %12280 to i64
  %12282 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12283 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12282, i64 0, i64 1
  %12284 = srem i64 %12281, 16
  %12285 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12284
  %12286 = load i32, i32* %12285, align 4
  %12287 = icmp eq i64 %12281, %12284
  %12288 = sext i1 %12287 to i32
  %12289 = xor i32 %12288, -1
  %12290 = and i32 %12289, 0
  %12291 = and i32 %12288, %12286
  %12292 = or i32 %12291, %12290
  %12293 = add i64 %12284, 16
  %12294 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12293
  %12295 = load i32, i32* %12294, align 4
  %12296 = icmp eq i64 %12281, %12293
  %12297 = sext i1 %12296 to i32
  %12298 = xor i32 %12297, -1
  %12299 = and i32 %12298, %12292
  %12300 = and i32 %12297, %12295
  %12301 = or i32 %12300, %12299
  %12302 = add i64 %12293, 16
  %12303 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12302
  %12304 = load i32, i32* %12303, align 4
  %12305 = icmp eq i64 %12281, %12302
  %12306 = sext i1 %12305 to i32
  %12307 = xor i32 %12306, -1
  %12308 = and i32 %12307, %12301
  %12309 = and i32 %12306, %12304
  %12310 = or i32 %12309, %12308
  %12311 = add i64 %12302, 16
  %12312 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12311
  %12313 = load i32, i32* %12312, align 4
  %12314 = icmp eq i64 %12281, %12311
  %12315 = sext i1 %12314 to i32
  %12316 = xor i32 %12315, -1
  %12317 = and i32 %12316, %12310
  %12318 = and i32 %12315, %12313
  %12319 = or i32 %12318, %12317
  %12320 = add i64 %12311, 16
  %12321 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12320
  %12322 = load i32, i32* %12321, align 4
  %12323 = icmp eq i64 %12281, %12320
  %12324 = sext i1 %12323 to i32
  %12325 = xor i32 %12324, -1
  %12326 = and i32 %12325, %12319
  %12327 = and i32 %12324, %12322
  %12328 = or i32 %12327, %12326
  %12329 = add i64 %12320, 16
  %12330 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12329
  %12331 = load i32, i32* %12330, align 4
  %12332 = icmp eq i64 %12281, %12329
  %12333 = sext i1 %12332 to i32
  %12334 = xor i32 %12333, -1
  %12335 = and i32 %12334, %12328
  %12336 = and i32 %12333, %12331
  %12337 = or i32 %12336, %12335
  %12338 = add i64 %12329, 16
  %12339 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12338
  %12340 = load i32, i32* %12339, align 4
  %12341 = icmp eq i64 %12281, %12338
  %12342 = sext i1 %12341 to i32
  %12343 = xor i32 %12342, -1
  %12344 = and i32 %12343, %12337
  %12345 = and i32 %12342, %12340
  %12346 = or i32 %12345, %12344
  %12347 = add i64 %12338, 16
  %12348 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12347
  %12349 = load i32, i32* %12348, align 4
  %12350 = icmp eq i64 %12281, %12347
  %12351 = sext i1 %12350 to i32
  %12352 = xor i32 %12351, -1
  %12353 = and i32 %12352, %12346
  %12354 = and i32 %12351, %12349
  %12355 = or i32 %12354, %12353
  %12356 = add i64 %12347, 16
  %12357 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12356
  %12358 = load i32, i32* %12357, align 4
  %12359 = icmp eq i64 %12281, %12356
  %12360 = sext i1 %12359 to i32
  %12361 = xor i32 %12360, -1
  %12362 = and i32 %12361, %12355
  %12363 = and i32 %12360, %12358
  %12364 = or i32 %12363, %12362
  %12365 = add i64 %12356, 16
  %12366 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12365
  %12367 = load i32, i32* %12366, align 4
  %12368 = icmp eq i64 %12281, %12365
  %12369 = sext i1 %12368 to i32
  %12370 = xor i32 %12369, -1
  %12371 = and i32 %12370, %12364
  %12372 = and i32 %12369, %12367
  %12373 = or i32 %12372, %12371
  %12374 = add i64 %12365, 16
  %12375 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12374
  %12376 = load i32, i32* %12375, align 4
  %12377 = icmp eq i64 %12281, %12374
  %12378 = sext i1 %12377 to i32
  %12379 = xor i32 %12378, -1
  %12380 = and i32 %12379, %12373
  %12381 = and i32 %12378, %12376
  %12382 = or i32 %12381, %12380
  %12383 = add i64 %12374, 16
  %12384 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12383
  %12385 = load i32, i32* %12384, align 4
  %12386 = icmp eq i64 %12281, %12383
  %12387 = sext i1 %12386 to i32
  %12388 = xor i32 %12387, -1
  %12389 = and i32 %12388, %12382
  %12390 = and i32 %12387, %12385
  %12391 = or i32 %12390, %12389
  %12392 = add i64 %12383, 16
  %12393 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12392
  %12394 = load i32, i32* %12393, align 4
  %12395 = icmp eq i64 %12281, %12392
  %12396 = sext i1 %12395 to i32
  %12397 = xor i32 %12396, -1
  %12398 = and i32 %12397, %12391
  %12399 = and i32 %12396, %12394
  %12400 = or i32 %12399, %12398
  %12401 = add i64 %12392, 16
  %12402 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12401
  %12403 = load i32, i32* %12402, align 4
  %12404 = icmp eq i64 %12281, %12401
  %12405 = sext i1 %12404 to i32
  %12406 = xor i32 %12405, -1
  %12407 = and i32 %12406, %12400
  %12408 = and i32 %12405, %12403
  %12409 = or i32 %12408, %12407
  %12410 = add i64 %12401, 16
  %12411 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12410
  %12412 = load i32, i32* %12411, align 4
  %12413 = icmp eq i64 %12281, %12410
  %12414 = sext i1 %12413 to i32
  %12415 = xor i32 %12414, -1
  %12416 = and i32 %12415, %12409
  %12417 = and i32 %12414, %12412
  %12418 = or i32 %12417, %12416
  %12419 = add i64 %12410, 16
  %12420 = getelementptr inbounds [256 x i32], [256 x i32]* %12283, i64 0, i64 %12419
  %12421 = load i32, i32* %12420, align 4
  %12422 = icmp eq i64 %12281, %12419
  %12423 = sext i1 %12422 to i32
  %12424 = xor i32 %12423, -1
  %12425 = and i32 %12424, %12418
  %12426 = and i32 %12423, %12421
  %Mitigated81 = or i32 %12426, %12425
  %12427 = xor i32 %Mitigated80, %Mitigated81
  %12428 = lshr i32 %12127, 16
  %12429 = and i32 %12428, 255
  %12430 = zext i32 %12429 to i64
  %12431 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12432 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12431, i64 0, i64 2
  %12433 = srem i64 %12430, 16
  %12434 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12433
  %12435 = load i32, i32* %12434, align 4
  %12436 = icmp eq i64 %12430, %12433
  %12437 = sext i1 %12436 to i32
  %12438 = xor i32 %12437, -1
  %12439 = and i32 %12438, 0
  %12440 = and i32 %12437, %12435
  %12441 = or i32 %12440, %12439
  %12442 = add i64 %12433, 16
  %12443 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12442
  %12444 = load i32, i32* %12443, align 4
  %12445 = icmp eq i64 %12430, %12442
  %12446 = sext i1 %12445 to i32
  %12447 = xor i32 %12446, -1
  %12448 = and i32 %12447, %12441
  %12449 = and i32 %12446, %12444
  %12450 = or i32 %12449, %12448
  %12451 = add i64 %12442, 16
  %12452 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12451
  %12453 = load i32, i32* %12452, align 4
  %12454 = icmp eq i64 %12430, %12451
  %12455 = sext i1 %12454 to i32
  %12456 = xor i32 %12455, -1
  %12457 = and i32 %12456, %12450
  %12458 = and i32 %12455, %12453
  %12459 = or i32 %12458, %12457
  %12460 = add i64 %12451, 16
  %12461 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12460
  %12462 = load i32, i32* %12461, align 4
  %12463 = icmp eq i64 %12430, %12460
  %12464 = sext i1 %12463 to i32
  %12465 = xor i32 %12464, -1
  %12466 = and i32 %12465, %12459
  %12467 = and i32 %12464, %12462
  %12468 = or i32 %12467, %12466
  %12469 = add i64 %12460, 16
  %12470 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12469
  %12471 = load i32, i32* %12470, align 4
  %12472 = icmp eq i64 %12430, %12469
  %12473 = sext i1 %12472 to i32
  %12474 = xor i32 %12473, -1
  %12475 = and i32 %12474, %12468
  %12476 = and i32 %12473, %12471
  %12477 = or i32 %12476, %12475
  %12478 = add i64 %12469, 16
  %12479 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12478
  %12480 = load i32, i32* %12479, align 4
  %12481 = icmp eq i64 %12430, %12478
  %12482 = sext i1 %12481 to i32
  %12483 = xor i32 %12482, -1
  %12484 = and i32 %12483, %12477
  %12485 = and i32 %12482, %12480
  %12486 = or i32 %12485, %12484
  %12487 = add i64 %12478, 16
  %12488 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12487
  %12489 = load i32, i32* %12488, align 4
  %12490 = icmp eq i64 %12430, %12487
  %12491 = sext i1 %12490 to i32
  %12492 = xor i32 %12491, -1
  %12493 = and i32 %12492, %12486
  %12494 = and i32 %12491, %12489
  %12495 = or i32 %12494, %12493
  %12496 = add i64 %12487, 16
  %12497 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12496
  %12498 = load i32, i32* %12497, align 4
  %12499 = icmp eq i64 %12430, %12496
  %12500 = sext i1 %12499 to i32
  %12501 = xor i32 %12500, -1
  %12502 = and i32 %12501, %12495
  %12503 = and i32 %12500, %12498
  %12504 = or i32 %12503, %12502
  %12505 = add i64 %12496, 16
  %12506 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12505
  %12507 = load i32, i32* %12506, align 4
  %12508 = icmp eq i64 %12430, %12505
  %12509 = sext i1 %12508 to i32
  %12510 = xor i32 %12509, -1
  %12511 = and i32 %12510, %12504
  %12512 = and i32 %12509, %12507
  %12513 = or i32 %12512, %12511
  %12514 = add i64 %12505, 16
  %12515 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12514
  %12516 = load i32, i32* %12515, align 4
  %12517 = icmp eq i64 %12430, %12514
  %12518 = sext i1 %12517 to i32
  %12519 = xor i32 %12518, -1
  %12520 = and i32 %12519, %12513
  %12521 = and i32 %12518, %12516
  %12522 = or i32 %12521, %12520
  %12523 = add i64 %12514, 16
  %12524 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12523
  %12525 = load i32, i32* %12524, align 4
  %12526 = icmp eq i64 %12430, %12523
  %12527 = sext i1 %12526 to i32
  %12528 = xor i32 %12527, -1
  %12529 = and i32 %12528, %12522
  %12530 = and i32 %12527, %12525
  %12531 = or i32 %12530, %12529
  %12532 = add i64 %12523, 16
  %12533 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12532
  %12534 = load i32, i32* %12533, align 4
  %12535 = icmp eq i64 %12430, %12532
  %12536 = sext i1 %12535 to i32
  %12537 = xor i32 %12536, -1
  %12538 = and i32 %12537, %12531
  %12539 = and i32 %12536, %12534
  %12540 = or i32 %12539, %12538
  %12541 = add i64 %12532, 16
  %12542 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12541
  %12543 = load i32, i32* %12542, align 4
  %12544 = icmp eq i64 %12430, %12541
  %12545 = sext i1 %12544 to i32
  %12546 = xor i32 %12545, -1
  %12547 = and i32 %12546, %12540
  %12548 = and i32 %12545, %12543
  %12549 = or i32 %12548, %12547
  %12550 = add i64 %12541, 16
  %12551 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12550
  %12552 = load i32, i32* %12551, align 4
  %12553 = icmp eq i64 %12430, %12550
  %12554 = sext i1 %12553 to i32
  %12555 = xor i32 %12554, -1
  %12556 = and i32 %12555, %12549
  %12557 = and i32 %12554, %12552
  %12558 = or i32 %12557, %12556
  %12559 = add i64 %12550, 16
  %12560 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12559
  %12561 = load i32, i32* %12560, align 4
  %12562 = icmp eq i64 %12430, %12559
  %12563 = sext i1 %12562 to i32
  %12564 = xor i32 %12563, -1
  %12565 = and i32 %12564, %12558
  %12566 = and i32 %12563, %12561
  %12567 = or i32 %12566, %12565
  %12568 = add i64 %12559, 16
  %12569 = getelementptr inbounds [256 x i32], [256 x i32]* %12432, i64 0, i64 %12568
  %12570 = load i32, i32* %12569, align 4
  %12571 = icmp eq i64 %12430, %12568
  %12572 = sext i1 %12571 to i32
  %12573 = xor i32 %12572, -1
  %12574 = and i32 %12573, %12567
  %12575 = and i32 %12572, %12570
  %Mitigated82 = or i32 %12575, %12574
  %12576 = xor i32 %12427, %Mitigated82
  %12577 = lshr i32 %12127, 24
  %12578 = zext i32 %12577 to i64
  %12579 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12580 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12579, i64 0, i64 3
  %12581 = srem i64 %12578, 16
  %12582 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12581
  %12583 = load i32, i32* %12582, align 4
  %12584 = icmp eq i64 %12578, %12581
  %12585 = sext i1 %12584 to i32
  %12586 = xor i32 %12585, -1
  %12587 = and i32 %12586, 0
  %12588 = and i32 %12585, %12583
  %12589 = or i32 %12588, %12587
  %12590 = add i64 %12581, 16
  %12591 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12590
  %12592 = load i32, i32* %12591, align 4
  %12593 = icmp eq i64 %12578, %12590
  %12594 = sext i1 %12593 to i32
  %12595 = xor i32 %12594, -1
  %12596 = and i32 %12595, %12589
  %12597 = and i32 %12594, %12592
  %12598 = or i32 %12597, %12596
  %12599 = add i64 %12590, 16
  %12600 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12599
  %12601 = load i32, i32* %12600, align 4
  %12602 = icmp eq i64 %12578, %12599
  %12603 = sext i1 %12602 to i32
  %12604 = xor i32 %12603, -1
  %12605 = and i32 %12604, %12598
  %12606 = and i32 %12603, %12601
  %12607 = or i32 %12606, %12605
  %12608 = add i64 %12599, 16
  %12609 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12608
  %12610 = load i32, i32* %12609, align 4
  %12611 = icmp eq i64 %12578, %12608
  %12612 = sext i1 %12611 to i32
  %12613 = xor i32 %12612, -1
  %12614 = and i32 %12613, %12607
  %12615 = and i32 %12612, %12610
  %12616 = or i32 %12615, %12614
  %12617 = add i64 %12608, 16
  %12618 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12617
  %12619 = load i32, i32* %12618, align 4
  %12620 = icmp eq i64 %12578, %12617
  %12621 = sext i1 %12620 to i32
  %12622 = xor i32 %12621, -1
  %12623 = and i32 %12622, %12616
  %12624 = and i32 %12621, %12619
  %12625 = or i32 %12624, %12623
  %12626 = add i64 %12617, 16
  %12627 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12626
  %12628 = load i32, i32* %12627, align 4
  %12629 = icmp eq i64 %12578, %12626
  %12630 = sext i1 %12629 to i32
  %12631 = xor i32 %12630, -1
  %12632 = and i32 %12631, %12625
  %12633 = and i32 %12630, %12628
  %12634 = or i32 %12633, %12632
  %12635 = add i64 %12626, 16
  %12636 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12635
  %12637 = load i32, i32* %12636, align 4
  %12638 = icmp eq i64 %12578, %12635
  %12639 = sext i1 %12638 to i32
  %12640 = xor i32 %12639, -1
  %12641 = and i32 %12640, %12634
  %12642 = and i32 %12639, %12637
  %12643 = or i32 %12642, %12641
  %12644 = add i64 %12635, 16
  %12645 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12644
  %12646 = load i32, i32* %12645, align 4
  %12647 = icmp eq i64 %12578, %12644
  %12648 = sext i1 %12647 to i32
  %12649 = xor i32 %12648, -1
  %12650 = and i32 %12649, %12643
  %12651 = and i32 %12648, %12646
  %12652 = or i32 %12651, %12650
  %12653 = add i64 %12644, 16
  %12654 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12653
  %12655 = load i32, i32* %12654, align 4
  %12656 = icmp eq i64 %12578, %12653
  %12657 = sext i1 %12656 to i32
  %12658 = xor i32 %12657, -1
  %12659 = and i32 %12658, %12652
  %12660 = and i32 %12657, %12655
  %12661 = or i32 %12660, %12659
  %12662 = add i64 %12653, 16
  %12663 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12662
  %12664 = load i32, i32* %12663, align 4
  %12665 = icmp eq i64 %12578, %12662
  %12666 = sext i1 %12665 to i32
  %12667 = xor i32 %12666, -1
  %12668 = and i32 %12667, %12661
  %12669 = and i32 %12666, %12664
  %12670 = or i32 %12669, %12668
  %12671 = add i64 %12662, 16
  %12672 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12671
  %12673 = load i32, i32* %12672, align 4
  %12674 = icmp eq i64 %12578, %12671
  %12675 = sext i1 %12674 to i32
  %12676 = xor i32 %12675, -1
  %12677 = and i32 %12676, %12670
  %12678 = and i32 %12675, %12673
  %12679 = or i32 %12678, %12677
  %12680 = add i64 %12671, 16
  %12681 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12680
  %12682 = load i32, i32* %12681, align 4
  %12683 = icmp eq i64 %12578, %12680
  %12684 = sext i1 %12683 to i32
  %12685 = xor i32 %12684, -1
  %12686 = and i32 %12685, %12679
  %12687 = and i32 %12684, %12682
  %12688 = or i32 %12687, %12686
  %12689 = add i64 %12680, 16
  %12690 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12689
  %12691 = load i32, i32* %12690, align 4
  %12692 = icmp eq i64 %12578, %12689
  %12693 = sext i1 %12692 to i32
  %12694 = xor i32 %12693, -1
  %12695 = and i32 %12694, %12688
  %12696 = and i32 %12693, %12691
  %12697 = or i32 %12696, %12695
  %12698 = add i64 %12689, 16
  %12699 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12698
  %12700 = load i32, i32* %12699, align 4
  %12701 = icmp eq i64 %12578, %12698
  %12702 = sext i1 %12701 to i32
  %12703 = xor i32 %12702, -1
  %12704 = and i32 %12703, %12697
  %12705 = and i32 %12702, %12700
  %12706 = or i32 %12705, %12704
  %12707 = add i64 %12698, 16
  %12708 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12707
  %12709 = load i32, i32* %12708, align 4
  %12710 = icmp eq i64 %12578, %12707
  %12711 = sext i1 %12710 to i32
  %12712 = xor i32 %12711, -1
  %12713 = and i32 %12712, %12706
  %12714 = and i32 %12711, %12709
  %12715 = or i32 %12714, %12713
  %12716 = add i64 %12707, 16
  %12717 = getelementptr inbounds [256 x i32], [256 x i32]* %12580, i64 0, i64 %12716
  %12718 = load i32, i32* %12717, align 4
  %12719 = icmp eq i64 %12578, %12716
  %12720 = sext i1 %12719 to i32
  %12721 = xor i32 %12720, -1
  %12722 = and i32 %12721, %12715
  %12723 = and i32 %12720, %12718
  %Mitigated83 = or i32 %12723, %12722
  %12724 = xor i32 %12576, %Mitigated83
  %12725 = and i32 %12131, 255
  %12726 = zext i32 %12725 to i64
  %12727 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12728 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12727, i64 0, i64 1
  %12729 = srem i64 %12726, 16
  %12730 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12729
  %12731 = load i32, i32* %12730, align 4
  %12732 = icmp eq i64 %12726, %12729
  %12733 = sext i1 %12732 to i32
  %12734 = xor i32 %12733, -1
  %12735 = and i32 %12734, 0
  %12736 = and i32 %12733, %12731
  %12737 = or i32 %12736, %12735
  %12738 = add i64 %12729, 16
  %12739 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12738
  %12740 = load i32, i32* %12739, align 4
  %12741 = icmp eq i64 %12726, %12738
  %12742 = sext i1 %12741 to i32
  %12743 = xor i32 %12742, -1
  %12744 = and i32 %12743, %12737
  %12745 = and i32 %12742, %12740
  %12746 = or i32 %12745, %12744
  %12747 = add i64 %12738, 16
  %12748 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12747
  %12749 = load i32, i32* %12748, align 4
  %12750 = icmp eq i64 %12726, %12747
  %12751 = sext i1 %12750 to i32
  %12752 = xor i32 %12751, -1
  %12753 = and i32 %12752, %12746
  %12754 = and i32 %12751, %12749
  %12755 = or i32 %12754, %12753
  %12756 = add i64 %12747, 16
  %12757 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12756
  %12758 = load i32, i32* %12757, align 4
  %12759 = icmp eq i64 %12726, %12756
  %12760 = sext i1 %12759 to i32
  %12761 = xor i32 %12760, -1
  %12762 = and i32 %12761, %12755
  %12763 = and i32 %12760, %12758
  %12764 = or i32 %12763, %12762
  %12765 = add i64 %12756, 16
  %12766 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12765
  %12767 = load i32, i32* %12766, align 4
  %12768 = icmp eq i64 %12726, %12765
  %12769 = sext i1 %12768 to i32
  %12770 = xor i32 %12769, -1
  %12771 = and i32 %12770, %12764
  %12772 = and i32 %12769, %12767
  %12773 = or i32 %12772, %12771
  %12774 = add i64 %12765, 16
  %12775 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12774
  %12776 = load i32, i32* %12775, align 4
  %12777 = icmp eq i64 %12726, %12774
  %12778 = sext i1 %12777 to i32
  %12779 = xor i32 %12778, -1
  %12780 = and i32 %12779, %12773
  %12781 = and i32 %12778, %12776
  %12782 = or i32 %12781, %12780
  %12783 = add i64 %12774, 16
  %12784 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12783
  %12785 = load i32, i32* %12784, align 4
  %12786 = icmp eq i64 %12726, %12783
  %12787 = sext i1 %12786 to i32
  %12788 = xor i32 %12787, -1
  %12789 = and i32 %12788, %12782
  %12790 = and i32 %12787, %12785
  %12791 = or i32 %12790, %12789
  %12792 = add i64 %12783, 16
  %12793 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12792
  %12794 = load i32, i32* %12793, align 4
  %12795 = icmp eq i64 %12726, %12792
  %12796 = sext i1 %12795 to i32
  %12797 = xor i32 %12796, -1
  %12798 = and i32 %12797, %12791
  %12799 = and i32 %12796, %12794
  %12800 = or i32 %12799, %12798
  %12801 = add i64 %12792, 16
  %12802 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12801
  %12803 = load i32, i32* %12802, align 4
  %12804 = icmp eq i64 %12726, %12801
  %12805 = sext i1 %12804 to i32
  %12806 = xor i32 %12805, -1
  %12807 = and i32 %12806, %12800
  %12808 = and i32 %12805, %12803
  %12809 = or i32 %12808, %12807
  %12810 = add i64 %12801, 16
  %12811 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12810
  %12812 = load i32, i32* %12811, align 4
  %12813 = icmp eq i64 %12726, %12810
  %12814 = sext i1 %12813 to i32
  %12815 = xor i32 %12814, -1
  %12816 = and i32 %12815, %12809
  %12817 = and i32 %12814, %12812
  %12818 = or i32 %12817, %12816
  %12819 = add i64 %12810, 16
  %12820 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12819
  %12821 = load i32, i32* %12820, align 4
  %12822 = icmp eq i64 %12726, %12819
  %12823 = sext i1 %12822 to i32
  %12824 = xor i32 %12823, -1
  %12825 = and i32 %12824, %12818
  %12826 = and i32 %12823, %12821
  %12827 = or i32 %12826, %12825
  %12828 = add i64 %12819, 16
  %12829 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12828
  %12830 = load i32, i32* %12829, align 4
  %12831 = icmp eq i64 %12726, %12828
  %12832 = sext i1 %12831 to i32
  %12833 = xor i32 %12832, -1
  %12834 = and i32 %12833, %12827
  %12835 = and i32 %12832, %12830
  %12836 = or i32 %12835, %12834
  %12837 = add i64 %12828, 16
  %12838 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12837
  %12839 = load i32, i32* %12838, align 4
  %12840 = icmp eq i64 %12726, %12837
  %12841 = sext i1 %12840 to i32
  %12842 = xor i32 %12841, -1
  %12843 = and i32 %12842, %12836
  %12844 = and i32 %12841, %12839
  %12845 = or i32 %12844, %12843
  %12846 = add i64 %12837, 16
  %12847 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12846
  %12848 = load i32, i32* %12847, align 4
  %12849 = icmp eq i64 %12726, %12846
  %12850 = sext i1 %12849 to i32
  %12851 = xor i32 %12850, -1
  %12852 = and i32 %12851, %12845
  %12853 = and i32 %12850, %12848
  %12854 = or i32 %12853, %12852
  %12855 = add i64 %12846, 16
  %12856 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12855
  %12857 = load i32, i32* %12856, align 4
  %12858 = icmp eq i64 %12726, %12855
  %12859 = sext i1 %12858 to i32
  %12860 = xor i32 %12859, -1
  %12861 = and i32 %12860, %12854
  %12862 = and i32 %12859, %12857
  %12863 = or i32 %12862, %12861
  %12864 = add i64 %12855, 16
  %12865 = getelementptr inbounds [256 x i32], [256 x i32]* %12728, i64 0, i64 %12864
  %12866 = load i32, i32* %12865, align 4
  %12867 = icmp eq i64 %12726, %12864
  %12868 = sext i1 %12867 to i32
  %12869 = xor i32 %12868, -1
  %12870 = and i32 %12869, %12863
  %12871 = and i32 %12868, %12866
  %Mitigated84 = or i32 %12871, %12870
  %12872 = lshr i32 %12131, 8
  %12873 = and i32 %12872, 255
  %12874 = zext i32 %12873 to i64
  %12875 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %12876 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %12875, i64 0, i64 2
  %12877 = srem i64 %12874, 16
  %12878 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12877
  %12879 = load i32, i32* %12878, align 4
  %12880 = icmp eq i64 %12874, %12877
  %12881 = sext i1 %12880 to i32
  %12882 = xor i32 %12881, -1
  %12883 = and i32 %12882, 0
  %12884 = and i32 %12881, %12879
  %12885 = or i32 %12884, %12883
  %12886 = add i64 %12877, 16
  %12887 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12886
  %12888 = load i32, i32* %12887, align 4
  %12889 = icmp eq i64 %12874, %12886
  %12890 = sext i1 %12889 to i32
  %12891 = xor i32 %12890, -1
  %12892 = and i32 %12891, %12885
  %12893 = and i32 %12890, %12888
  %12894 = or i32 %12893, %12892
  %12895 = add i64 %12886, 16
  %12896 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12895
  %12897 = load i32, i32* %12896, align 4
  %12898 = icmp eq i64 %12874, %12895
  %12899 = sext i1 %12898 to i32
  %12900 = xor i32 %12899, -1
  %12901 = and i32 %12900, %12894
  %12902 = and i32 %12899, %12897
  %12903 = or i32 %12902, %12901
  %12904 = add i64 %12895, 16
  %12905 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12904
  %12906 = load i32, i32* %12905, align 4
  %12907 = icmp eq i64 %12874, %12904
  %12908 = sext i1 %12907 to i32
  %12909 = xor i32 %12908, -1
  %12910 = and i32 %12909, %12903
  %12911 = and i32 %12908, %12906
  %12912 = or i32 %12911, %12910
  %12913 = add i64 %12904, 16
  %12914 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12913
  %12915 = load i32, i32* %12914, align 4
  %12916 = icmp eq i64 %12874, %12913
  %12917 = sext i1 %12916 to i32
  %12918 = xor i32 %12917, -1
  %12919 = and i32 %12918, %12912
  %12920 = and i32 %12917, %12915
  %12921 = or i32 %12920, %12919
  %12922 = add i64 %12913, 16
  %12923 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12922
  %12924 = load i32, i32* %12923, align 4
  %12925 = icmp eq i64 %12874, %12922
  %12926 = sext i1 %12925 to i32
  %12927 = xor i32 %12926, -1
  %12928 = and i32 %12927, %12921
  %12929 = and i32 %12926, %12924
  %12930 = or i32 %12929, %12928
  %12931 = add i64 %12922, 16
  %12932 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12931
  %12933 = load i32, i32* %12932, align 4
  %12934 = icmp eq i64 %12874, %12931
  %12935 = sext i1 %12934 to i32
  %12936 = xor i32 %12935, -1
  %12937 = and i32 %12936, %12930
  %12938 = and i32 %12935, %12933
  %12939 = or i32 %12938, %12937
  %12940 = add i64 %12931, 16
  %12941 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12940
  %12942 = load i32, i32* %12941, align 4
  %12943 = icmp eq i64 %12874, %12940
  %12944 = sext i1 %12943 to i32
  %12945 = xor i32 %12944, -1
  %12946 = and i32 %12945, %12939
  %12947 = and i32 %12944, %12942
  %12948 = or i32 %12947, %12946
  %12949 = add i64 %12940, 16
  %12950 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12949
  %12951 = load i32, i32* %12950, align 4
  %12952 = icmp eq i64 %12874, %12949
  %12953 = sext i1 %12952 to i32
  %12954 = xor i32 %12953, -1
  %12955 = and i32 %12954, %12948
  %12956 = and i32 %12953, %12951
  %12957 = or i32 %12956, %12955
  %12958 = add i64 %12949, 16
  %12959 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12958
  %12960 = load i32, i32* %12959, align 4
  %12961 = icmp eq i64 %12874, %12958
  %12962 = sext i1 %12961 to i32
  %12963 = xor i32 %12962, -1
  %12964 = and i32 %12963, %12957
  %12965 = and i32 %12962, %12960
  %12966 = or i32 %12965, %12964
  %12967 = add i64 %12958, 16
  %12968 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12967
  %12969 = load i32, i32* %12968, align 4
  %12970 = icmp eq i64 %12874, %12967
  %12971 = sext i1 %12970 to i32
  %12972 = xor i32 %12971, -1
  %12973 = and i32 %12972, %12966
  %12974 = and i32 %12971, %12969
  %12975 = or i32 %12974, %12973
  %12976 = add i64 %12967, 16
  %12977 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12976
  %12978 = load i32, i32* %12977, align 4
  %12979 = icmp eq i64 %12874, %12976
  %12980 = sext i1 %12979 to i32
  %12981 = xor i32 %12980, -1
  %12982 = and i32 %12981, %12975
  %12983 = and i32 %12980, %12978
  %12984 = or i32 %12983, %12982
  %12985 = add i64 %12976, 16
  %12986 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12985
  %12987 = load i32, i32* %12986, align 4
  %12988 = icmp eq i64 %12874, %12985
  %12989 = sext i1 %12988 to i32
  %12990 = xor i32 %12989, -1
  %12991 = and i32 %12990, %12984
  %12992 = and i32 %12989, %12987
  %12993 = or i32 %12992, %12991
  %12994 = add i64 %12985, 16
  %12995 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %12994
  %12996 = load i32, i32* %12995, align 4
  %12997 = icmp eq i64 %12874, %12994
  %12998 = sext i1 %12997 to i32
  %12999 = xor i32 %12998, -1
  %13000 = and i32 %12999, %12993
  %13001 = and i32 %12998, %12996
  %13002 = or i32 %13001, %13000
  %13003 = add i64 %12994, 16
  %13004 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %13003
  %13005 = load i32, i32* %13004, align 4
  %13006 = icmp eq i64 %12874, %13003
  %13007 = sext i1 %13006 to i32
  %13008 = xor i32 %13007, -1
  %13009 = and i32 %13008, %13002
  %13010 = and i32 %13007, %13005
  %13011 = or i32 %13010, %13009
  %13012 = add i64 %13003, 16
  %13013 = getelementptr inbounds [256 x i32], [256 x i32]* %12876, i64 0, i64 %13012
  %13014 = load i32, i32* %13013, align 4
  %13015 = icmp eq i64 %12874, %13012
  %13016 = sext i1 %13015 to i32
  %13017 = xor i32 %13016, -1
  %13018 = and i32 %13017, %13011
  %13019 = and i32 %13016, %13014
  %Mitigated85 = or i32 %13019, %13018
  %13020 = xor i32 %Mitigated84, %Mitigated85
  %13021 = lshr i32 %12131, 16
  %13022 = and i32 %13021, 255
  %13023 = zext i32 %13022 to i64
  %13024 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13025 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13024, i64 0, i64 3
  %13026 = srem i64 %13023, 16
  %13027 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13026
  %13028 = load i32, i32* %13027, align 4
  %13029 = icmp eq i64 %13023, %13026
  %13030 = sext i1 %13029 to i32
  %13031 = xor i32 %13030, -1
  %13032 = and i32 %13031, 0
  %13033 = and i32 %13030, %13028
  %13034 = or i32 %13033, %13032
  %13035 = add i64 %13026, 16
  %13036 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13035
  %13037 = load i32, i32* %13036, align 4
  %13038 = icmp eq i64 %13023, %13035
  %13039 = sext i1 %13038 to i32
  %13040 = xor i32 %13039, -1
  %13041 = and i32 %13040, %13034
  %13042 = and i32 %13039, %13037
  %13043 = or i32 %13042, %13041
  %13044 = add i64 %13035, 16
  %13045 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13044
  %13046 = load i32, i32* %13045, align 4
  %13047 = icmp eq i64 %13023, %13044
  %13048 = sext i1 %13047 to i32
  %13049 = xor i32 %13048, -1
  %13050 = and i32 %13049, %13043
  %13051 = and i32 %13048, %13046
  %13052 = or i32 %13051, %13050
  %13053 = add i64 %13044, 16
  %13054 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13053
  %13055 = load i32, i32* %13054, align 4
  %13056 = icmp eq i64 %13023, %13053
  %13057 = sext i1 %13056 to i32
  %13058 = xor i32 %13057, -1
  %13059 = and i32 %13058, %13052
  %13060 = and i32 %13057, %13055
  %13061 = or i32 %13060, %13059
  %13062 = add i64 %13053, 16
  %13063 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13062
  %13064 = load i32, i32* %13063, align 4
  %13065 = icmp eq i64 %13023, %13062
  %13066 = sext i1 %13065 to i32
  %13067 = xor i32 %13066, -1
  %13068 = and i32 %13067, %13061
  %13069 = and i32 %13066, %13064
  %13070 = or i32 %13069, %13068
  %13071 = add i64 %13062, 16
  %13072 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13071
  %13073 = load i32, i32* %13072, align 4
  %13074 = icmp eq i64 %13023, %13071
  %13075 = sext i1 %13074 to i32
  %13076 = xor i32 %13075, -1
  %13077 = and i32 %13076, %13070
  %13078 = and i32 %13075, %13073
  %13079 = or i32 %13078, %13077
  %13080 = add i64 %13071, 16
  %13081 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13080
  %13082 = load i32, i32* %13081, align 4
  %13083 = icmp eq i64 %13023, %13080
  %13084 = sext i1 %13083 to i32
  %13085 = xor i32 %13084, -1
  %13086 = and i32 %13085, %13079
  %13087 = and i32 %13084, %13082
  %13088 = or i32 %13087, %13086
  %13089 = add i64 %13080, 16
  %13090 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13089
  %13091 = load i32, i32* %13090, align 4
  %13092 = icmp eq i64 %13023, %13089
  %13093 = sext i1 %13092 to i32
  %13094 = xor i32 %13093, -1
  %13095 = and i32 %13094, %13088
  %13096 = and i32 %13093, %13091
  %13097 = or i32 %13096, %13095
  %13098 = add i64 %13089, 16
  %13099 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13098
  %13100 = load i32, i32* %13099, align 4
  %13101 = icmp eq i64 %13023, %13098
  %13102 = sext i1 %13101 to i32
  %13103 = xor i32 %13102, -1
  %13104 = and i32 %13103, %13097
  %13105 = and i32 %13102, %13100
  %13106 = or i32 %13105, %13104
  %13107 = add i64 %13098, 16
  %13108 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13107
  %13109 = load i32, i32* %13108, align 4
  %13110 = icmp eq i64 %13023, %13107
  %13111 = sext i1 %13110 to i32
  %13112 = xor i32 %13111, -1
  %13113 = and i32 %13112, %13106
  %13114 = and i32 %13111, %13109
  %13115 = or i32 %13114, %13113
  %13116 = add i64 %13107, 16
  %13117 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13116
  %13118 = load i32, i32* %13117, align 4
  %13119 = icmp eq i64 %13023, %13116
  %13120 = sext i1 %13119 to i32
  %13121 = xor i32 %13120, -1
  %13122 = and i32 %13121, %13115
  %13123 = and i32 %13120, %13118
  %13124 = or i32 %13123, %13122
  %13125 = add i64 %13116, 16
  %13126 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13125
  %13127 = load i32, i32* %13126, align 4
  %13128 = icmp eq i64 %13023, %13125
  %13129 = sext i1 %13128 to i32
  %13130 = xor i32 %13129, -1
  %13131 = and i32 %13130, %13124
  %13132 = and i32 %13129, %13127
  %13133 = or i32 %13132, %13131
  %13134 = add i64 %13125, 16
  %13135 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13134
  %13136 = load i32, i32* %13135, align 4
  %13137 = icmp eq i64 %13023, %13134
  %13138 = sext i1 %13137 to i32
  %13139 = xor i32 %13138, -1
  %13140 = and i32 %13139, %13133
  %13141 = and i32 %13138, %13136
  %13142 = or i32 %13141, %13140
  %13143 = add i64 %13134, 16
  %13144 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13143
  %13145 = load i32, i32* %13144, align 4
  %13146 = icmp eq i64 %13023, %13143
  %13147 = sext i1 %13146 to i32
  %13148 = xor i32 %13147, -1
  %13149 = and i32 %13148, %13142
  %13150 = and i32 %13147, %13145
  %13151 = or i32 %13150, %13149
  %13152 = add i64 %13143, 16
  %13153 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13152
  %13154 = load i32, i32* %13153, align 4
  %13155 = icmp eq i64 %13023, %13152
  %13156 = sext i1 %13155 to i32
  %13157 = xor i32 %13156, -1
  %13158 = and i32 %13157, %13151
  %13159 = and i32 %13156, %13154
  %13160 = or i32 %13159, %13158
  %13161 = add i64 %13152, 16
  %13162 = getelementptr inbounds [256 x i32], [256 x i32]* %13025, i64 0, i64 %13161
  %13163 = load i32, i32* %13162, align 4
  %13164 = icmp eq i64 %13023, %13161
  %13165 = sext i1 %13164 to i32
  %13166 = xor i32 %13165, -1
  %13167 = and i32 %13166, %13160
  %13168 = and i32 %13165, %13163
  %Mitigated86 = or i32 %13168, %13167
  %13169 = xor i32 %13020, %Mitigated86
  %13170 = lshr i32 %12131, 24
  %13171 = zext i32 %13170 to i64
  %13172 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13173 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13172, i64 0, i64 0
  %13174 = srem i64 %13171, 16
  %13175 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13174
  %13176 = load i32, i32* %13175, align 4
  %13177 = icmp eq i64 %13171, %13174
  %13178 = sext i1 %13177 to i32
  %13179 = xor i32 %13178, -1
  %13180 = and i32 %13179, 0
  %13181 = and i32 %13178, %13176
  %13182 = or i32 %13181, %13180
  %13183 = add i64 %13174, 16
  %13184 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13183
  %13185 = load i32, i32* %13184, align 4
  %13186 = icmp eq i64 %13171, %13183
  %13187 = sext i1 %13186 to i32
  %13188 = xor i32 %13187, -1
  %13189 = and i32 %13188, %13182
  %13190 = and i32 %13187, %13185
  %13191 = or i32 %13190, %13189
  %13192 = add i64 %13183, 16
  %13193 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13192
  %13194 = load i32, i32* %13193, align 4
  %13195 = icmp eq i64 %13171, %13192
  %13196 = sext i1 %13195 to i32
  %13197 = xor i32 %13196, -1
  %13198 = and i32 %13197, %13191
  %13199 = and i32 %13196, %13194
  %13200 = or i32 %13199, %13198
  %13201 = add i64 %13192, 16
  %13202 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13201
  %13203 = load i32, i32* %13202, align 4
  %13204 = icmp eq i64 %13171, %13201
  %13205 = sext i1 %13204 to i32
  %13206 = xor i32 %13205, -1
  %13207 = and i32 %13206, %13200
  %13208 = and i32 %13205, %13203
  %13209 = or i32 %13208, %13207
  %13210 = add i64 %13201, 16
  %13211 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13210
  %13212 = load i32, i32* %13211, align 4
  %13213 = icmp eq i64 %13171, %13210
  %13214 = sext i1 %13213 to i32
  %13215 = xor i32 %13214, -1
  %13216 = and i32 %13215, %13209
  %13217 = and i32 %13214, %13212
  %13218 = or i32 %13217, %13216
  %13219 = add i64 %13210, 16
  %13220 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13219
  %13221 = load i32, i32* %13220, align 4
  %13222 = icmp eq i64 %13171, %13219
  %13223 = sext i1 %13222 to i32
  %13224 = xor i32 %13223, -1
  %13225 = and i32 %13224, %13218
  %13226 = and i32 %13223, %13221
  %13227 = or i32 %13226, %13225
  %13228 = add i64 %13219, 16
  %13229 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13228
  %13230 = load i32, i32* %13229, align 4
  %13231 = icmp eq i64 %13171, %13228
  %13232 = sext i1 %13231 to i32
  %13233 = xor i32 %13232, -1
  %13234 = and i32 %13233, %13227
  %13235 = and i32 %13232, %13230
  %13236 = or i32 %13235, %13234
  %13237 = add i64 %13228, 16
  %13238 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13237
  %13239 = load i32, i32* %13238, align 4
  %13240 = icmp eq i64 %13171, %13237
  %13241 = sext i1 %13240 to i32
  %13242 = xor i32 %13241, -1
  %13243 = and i32 %13242, %13236
  %13244 = and i32 %13241, %13239
  %13245 = or i32 %13244, %13243
  %13246 = add i64 %13237, 16
  %13247 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13246
  %13248 = load i32, i32* %13247, align 4
  %13249 = icmp eq i64 %13171, %13246
  %13250 = sext i1 %13249 to i32
  %13251 = xor i32 %13250, -1
  %13252 = and i32 %13251, %13245
  %13253 = and i32 %13250, %13248
  %13254 = or i32 %13253, %13252
  %13255 = add i64 %13246, 16
  %13256 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13255
  %13257 = load i32, i32* %13256, align 4
  %13258 = icmp eq i64 %13171, %13255
  %13259 = sext i1 %13258 to i32
  %13260 = xor i32 %13259, -1
  %13261 = and i32 %13260, %13254
  %13262 = and i32 %13259, %13257
  %13263 = or i32 %13262, %13261
  %13264 = add i64 %13255, 16
  %13265 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13264
  %13266 = load i32, i32* %13265, align 4
  %13267 = icmp eq i64 %13171, %13264
  %13268 = sext i1 %13267 to i32
  %13269 = xor i32 %13268, -1
  %13270 = and i32 %13269, %13263
  %13271 = and i32 %13268, %13266
  %13272 = or i32 %13271, %13270
  %13273 = add i64 %13264, 16
  %13274 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13273
  %13275 = load i32, i32* %13274, align 4
  %13276 = icmp eq i64 %13171, %13273
  %13277 = sext i1 %13276 to i32
  %13278 = xor i32 %13277, -1
  %13279 = and i32 %13278, %13272
  %13280 = and i32 %13277, %13275
  %13281 = or i32 %13280, %13279
  %13282 = add i64 %13273, 16
  %13283 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13282
  %13284 = load i32, i32* %13283, align 4
  %13285 = icmp eq i64 %13171, %13282
  %13286 = sext i1 %13285 to i32
  %13287 = xor i32 %13286, -1
  %13288 = and i32 %13287, %13281
  %13289 = and i32 %13286, %13284
  %13290 = or i32 %13289, %13288
  %13291 = add i64 %13282, 16
  %13292 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13291
  %13293 = load i32, i32* %13292, align 4
  %13294 = icmp eq i64 %13171, %13291
  %13295 = sext i1 %13294 to i32
  %13296 = xor i32 %13295, -1
  %13297 = and i32 %13296, %13290
  %13298 = and i32 %13295, %13293
  %13299 = or i32 %13298, %13297
  %13300 = add i64 %13291, 16
  %13301 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13300
  %13302 = load i32, i32* %13301, align 4
  %13303 = icmp eq i64 %13171, %13300
  %13304 = sext i1 %13303 to i32
  %13305 = xor i32 %13304, -1
  %13306 = and i32 %13305, %13299
  %13307 = and i32 %13304, %13302
  %13308 = or i32 %13307, %13306
  %13309 = add i64 %13300, 16
  %13310 = getelementptr inbounds [256 x i32], [256 x i32]* %13173, i64 0, i64 %13309
  %13311 = load i32, i32* %13310, align 4
  %13312 = icmp eq i64 %13171, %13309
  %13313 = sext i1 %13312 to i32
  %13314 = xor i32 %13313, -1
  %13315 = and i32 %13314, %13308
  %13316 = and i32 %13313, %13311
  %Mitigated87 = or i32 %13316, %13315
  %13317 = xor i32 %13169, %Mitigated87
  %13318 = add i32 %12724, %13317
  %13319 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %13320 = getelementptr inbounds [32 x i32], [32 x i32]* %13319, i64 0, i64 21
  %13321 = load i32, i32* %13320, align 4
  %13322 = add i32 %13318, %13321
  %13323 = add i32 %13317, %13322
  %13324 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %13325 = getelementptr inbounds [32 x i32], [32 x i32]* %13324, i64 0, i64 20
  %13326 = load i32, i32* %13325, align 4
  %13327 = add i32 %13318, %13326
  %13328 = xor i32 %10923, %13327
  %13329 = lshr i32 %13328, 1
  %13330 = shl i32 %13328, 31
  %13331 = add i32 %13329, %13330
  %13332 = shl i32 %10927, 1
  %13333 = lshr i32 %10927, 31
  %13334 = add i32 %13332, %13333
  %13335 = xor i32 %13334, %13323
  %13336 = and i32 %13331, 255
  %13337 = zext i32 %13336 to i64
  %13338 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13339 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13338, i64 0, i64 0
  %13340 = srem i64 %13337, 16
  %13341 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13340
  %13342 = load i32, i32* %13341, align 4
  %13343 = icmp eq i64 %13337, %13340
  %13344 = sext i1 %13343 to i32
  %13345 = xor i32 %13344, -1
  %13346 = and i32 %13345, 0
  %13347 = and i32 %13344, %13342
  %13348 = or i32 %13347, %13346
  %13349 = add i64 %13340, 16
  %13350 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13349
  %13351 = load i32, i32* %13350, align 4
  %13352 = icmp eq i64 %13337, %13349
  %13353 = sext i1 %13352 to i32
  %13354 = xor i32 %13353, -1
  %13355 = and i32 %13354, %13348
  %13356 = and i32 %13353, %13351
  %13357 = or i32 %13356, %13355
  %13358 = add i64 %13349, 16
  %13359 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13358
  %13360 = load i32, i32* %13359, align 4
  %13361 = icmp eq i64 %13337, %13358
  %13362 = sext i1 %13361 to i32
  %13363 = xor i32 %13362, -1
  %13364 = and i32 %13363, %13357
  %13365 = and i32 %13362, %13360
  %13366 = or i32 %13365, %13364
  %13367 = add i64 %13358, 16
  %13368 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13367
  %13369 = load i32, i32* %13368, align 4
  %13370 = icmp eq i64 %13337, %13367
  %13371 = sext i1 %13370 to i32
  %13372 = xor i32 %13371, -1
  %13373 = and i32 %13372, %13366
  %13374 = and i32 %13371, %13369
  %13375 = or i32 %13374, %13373
  %13376 = add i64 %13367, 16
  %13377 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13376
  %13378 = load i32, i32* %13377, align 4
  %13379 = icmp eq i64 %13337, %13376
  %13380 = sext i1 %13379 to i32
  %13381 = xor i32 %13380, -1
  %13382 = and i32 %13381, %13375
  %13383 = and i32 %13380, %13378
  %13384 = or i32 %13383, %13382
  %13385 = add i64 %13376, 16
  %13386 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13385
  %13387 = load i32, i32* %13386, align 4
  %13388 = icmp eq i64 %13337, %13385
  %13389 = sext i1 %13388 to i32
  %13390 = xor i32 %13389, -1
  %13391 = and i32 %13390, %13384
  %13392 = and i32 %13389, %13387
  %13393 = or i32 %13392, %13391
  %13394 = add i64 %13385, 16
  %13395 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13394
  %13396 = load i32, i32* %13395, align 4
  %13397 = icmp eq i64 %13337, %13394
  %13398 = sext i1 %13397 to i32
  %13399 = xor i32 %13398, -1
  %13400 = and i32 %13399, %13393
  %13401 = and i32 %13398, %13396
  %13402 = or i32 %13401, %13400
  %13403 = add i64 %13394, 16
  %13404 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13403
  %13405 = load i32, i32* %13404, align 4
  %13406 = icmp eq i64 %13337, %13403
  %13407 = sext i1 %13406 to i32
  %13408 = xor i32 %13407, -1
  %13409 = and i32 %13408, %13402
  %13410 = and i32 %13407, %13405
  %13411 = or i32 %13410, %13409
  %13412 = add i64 %13403, 16
  %13413 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13412
  %13414 = load i32, i32* %13413, align 4
  %13415 = icmp eq i64 %13337, %13412
  %13416 = sext i1 %13415 to i32
  %13417 = xor i32 %13416, -1
  %13418 = and i32 %13417, %13411
  %13419 = and i32 %13416, %13414
  %13420 = or i32 %13419, %13418
  %13421 = add i64 %13412, 16
  %13422 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13421
  %13423 = load i32, i32* %13422, align 4
  %13424 = icmp eq i64 %13337, %13421
  %13425 = sext i1 %13424 to i32
  %13426 = xor i32 %13425, -1
  %13427 = and i32 %13426, %13420
  %13428 = and i32 %13425, %13423
  %13429 = or i32 %13428, %13427
  %13430 = add i64 %13421, 16
  %13431 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13430
  %13432 = load i32, i32* %13431, align 4
  %13433 = icmp eq i64 %13337, %13430
  %13434 = sext i1 %13433 to i32
  %13435 = xor i32 %13434, -1
  %13436 = and i32 %13435, %13429
  %13437 = and i32 %13434, %13432
  %13438 = or i32 %13437, %13436
  %13439 = add i64 %13430, 16
  %13440 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13439
  %13441 = load i32, i32* %13440, align 4
  %13442 = icmp eq i64 %13337, %13439
  %13443 = sext i1 %13442 to i32
  %13444 = xor i32 %13443, -1
  %13445 = and i32 %13444, %13438
  %13446 = and i32 %13443, %13441
  %13447 = or i32 %13446, %13445
  %13448 = add i64 %13439, 16
  %13449 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13448
  %13450 = load i32, i32* %13449, align 4
  %13451 = icmp eq i64 %13337, %13448
  %13452 = sext i1 %13451 to i32
  %13453 = xor i32 %13452, -1
  %13454 = and i32 %13453, %13447
  %13455 = and i32 %13452, %13450
  %13456 = or i32 %13455, %13454
  %13457 = add i64 %13448, 16
  %13458 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13457
  %13459 = load i32, i32* %13458, align 4
  %13460 = icmp eq i64 %13337, %13457
  %13461 = sext i1 %13460 to i32
  %13462 = xor i32 %13461, -1
  %13463 = and i32 %13462, %13456
  %13464 = and i32 %13461, %13459
  %13465 = or i32 %13464, %13463
  %13466 = add i64 %13457, 16
  %13467 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13466
  %13468 = load i32, i32* %13467, align 4
  %13469 = icmp eq i64 %13337, %13466
  %13470 = sext i1 %13469 to i32
  %13471 = xor i32 %13470, -1
  %13472 = and i32 %13471, %13465
  %13473 = and i32 %13470, %13468
  %13474 = or i32 %13473, %13472
  %13475 = add i64 %13466, 16
  %13476 = getelementptr inbounds [256 x i32], [256 x i32]* %13339, i64 0, i64 %13475
  %13477 = load i32, i32* %13476, align 4
  %13478 = icmp eq i64 %13337, %13475
  %13479 = sext i1 %13478 to i32
  %13480 = xor i32 %13479, -1
  %13481 = and i32 %13480, %13474
  %13482 = and i32 %13479, %13477
  %Mitigated88 = or i32 %13482, %13481
  %13483 = lshr i32 %13331, 8
  %13484 = and i32 %13483, 255
  %13485 = zext i32 %13484 to i64
  %13486 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13487 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13486, i64 0, i64 1
  %13488 = srem i64 %13485, 16
  %13489 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13488
  %13490 = load i32, i32* %13489, align 4
  %13491 = icmp eq i64 %13485, %13488
  %13492 = sext i1 %13491 to i32
  %13493 = xor i32 %13492, -1
  %13494 = and i32 %13493, 0
  %13495 = and i32 %13492, %13490
  %13496 = or i32 %13495, %13494
  %13497 = add i64 %13488, 16
  %13498 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13497
  %13499 = load i32, i32* %13498, align 4
  %13500 = icmp eq i64 %13485, %13497
  %13501 = sext i1 %13500 to i32
  %13502 = xor i32 %13501, -1
  %13503 = and i32 %13502, %13496
  %13504 = and i32 %13501, %13499
  %13505 = or i32 %13504, %13503
  %13506 = add i64 %13497, 16
  %13507 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13506
  %13508 = load i32, i32* %13507, align 4
  %13509 = icmp eq i64 %13485, %13506
  %13510 = sext i1 %13509 to i32
  %13511 = xor i32 %13510, -1
  %13512 = and i32 %13511, %13505
  %13513 = and i32 %13510, %13508
  %13514 = or i32 %13513, %13512
  %13515 = add i64 %13506, 16
  %13516 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13515
  %13517 = load i32, i32* %13516, align 4
  %13518 = icmp eq i64 %13485, %13515
  %13519 = sext i1 %13518 to i32
  %13520 = xor i32 %13519, -1
  %13521 = and i32 %13520, %13514
  %13522 = and i32 %13519, %13517
  %13523 = or i32 %13522, %13521
  %13524 = add i64 %13515, 16
  %13525 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13524
  %13526 = load i32, i32* %13525, align 4
  %13527 = icmp eq i64 %13485, %13524
  %13528 = sext i1 %13527 to i32
  %13529 = xor i32 %13528, -1
  %13530 = and i32 %13529, %13523
  %13531 = and i32 %13528, %13526
  %13532 = or i32 %13531, %13530
  %13533 = add i64 %13524, 16
  %13534 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13533
  %13535 = load i32, i32* %13534, align 4
  %13536 = icmp eq i64 %13485, %13533
  %13537 = sext i1 %13536 to i32
  %13538 = xor i32 %13537, -1
  %13539 = and i32 %13538, %13532
  %13540 = and i32 %13537, %13535
  %13541 = or i32 %13540, %13539
  %13542 = add i64 %13533, 16
  %13543 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13542
  %13544 = load i32, i32* %13543, align 4
  %13545 = icmp eq i64 %13485, %13542
  %13546 = sext i1 %13545 to i32
  %13547 = xor i32 %13546, -1
  %13548 = and i32 %13547, %13541
  %13549 = and i32 %13546, %13544
  %13550 = or i32 %13549, %13548
  %13551 = add i64 %13542, 16
  %13552 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13551
  %13553 = load i32, i32* %13552, align 4
  %13554 = icmp eq i64 %13485, %13551
  %13555 = sext i1 %13554 to i32
  %13556 = xor i32 %13555, -1
  %13557 = and i32 %13556, %13550
  %13558 = and i32 %13555, %13553
  %13559 = or i32 %13558, %13557
  %13560 = add i64 %13551, 16
  %13561 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13560
  %13562 = load i32, i32* %13561, align 4
  %13563 = icmp eq i64 %13485, %13560
  %13564 = sext i1 %13563 to i32
  %13565 = xor i32 %13564, -1
  %13566 = and i32 %13565, %13559
  %13567 = and i32 %13564, %13562
  %13568 = or i32 %13567, %13566
  %13569 = add i64 %13560, 16
  %13570 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13569
  %13571 = load i32, i32* %13570, align 4
  %13572 = icmp eq i64 %13485, %13569
  %13573 = sext i1 %13572 to i32
  %13574 = xor i32 %13573, -1
  %13575 = and i32 %13574, %13568
  %13576 = and i32 %13573, %13571
  %13577 = or i32 %13576, %13575
  %13578 = add i64 %13569, 16
  %13579 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13578
  %13580 = load i32, i32* %13579, align 4
  %13581 = icmp eq i64 %13485, %13578
  %13582 = sext i1 %13581 to i32
  %13583 = xor i32 %13582, -1
  %13584 = and i32 %13583, %13577
  %13585 = and i32 %13582, %13580
  %13586 = or i32 %13585, %13584
  %13587 = add i64 %13578, 16
  %13588 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13587
  %13589 = load i32, i32* %13588, align 4
  %13590 = icmp eq i64 %13485, %13587
  %13591 = sext i1 %13590 to i32
  %13592 = xor i32 %13591, -1
  %13593 = and i32 %13592, %13586
  %13594 = and i32 %13591, %13589
  %13595 = or i32 %13594, %13593
  %13596 = add i64 %13587, 16
  %13597 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13596
  %13598 = load i32, i32* %13597, align 4
  %13599 = icmp eq i64 %13485, %13596
  %13600 = sext i1 %13599 to i32
  %13601 = xor i32 %13600, -1
  %13602 = and i32 %13601, %13595
  %13603 = and i32 %13600, %13598
  %13604 = or i32 %13603, %13602
  %13605 = add i64 %13596, 16
  %13606 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13605
  %13607 = load i32, i32* %13606, align 4
  %13608 = icmp eq i64 %13485, %13605
  %13609 = sext i1 %13608 to i32
  %13610 = xor i32 %13609, -1
  %13611 = and i32 %13610, %13604
  %13612 = and i32 %13609, %13607
  %13613 = or i32 %13612, %13611
  %13614 = add i64 %13605, 16
  %13615 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13614
  %13616 = load i32, i32* %13615, align 4
  %13617 = icmp eq i64 %13485, %13614
  %13618 = sext i1 %13617 to i32
  %13619 = xor i32 %13618, -1
  %13620 = and i32 %13619, %13613
  %13621 = and i32 %13618, %13616
  %13622 = or i32 %13621, %13620
  %13623 = add i64 %13614, 16
  %13624 = getelementptr inbounds [256 x i32], [256 x i32]* %13487, i64 0, i64 %13623
  %13625 = load i32, i32* %13624, align 4
  %13626 = icmp eq i64 %13485, %13623
  %13627 = sext i1 %13626 to i32
  %13628 = xor i32 %13627, -1
  %13629 = and i32 %13628, %13622
  %13630 = and i32 %13627, %13625
  %Mitigated89 = or i32 %13630, %13629
  %13631 = xor i32 %Mitigated88, %Mitigated89
  %13632 = lshr i32 %13331, 16
  %13633 = and i32 %13632, 255
  %13634 = zext i32 %13633 to i64
  %13635 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13636 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13635, i64 0, i64 2
  %13637 = srem i64 %13634, 16
  %13638 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13637
  %13639 = load i32, i32* %13638, align 4
  %13640 = icmp eq i64 %13634, %13637
  %13641 = sext i1 %13640 to i32
  %13642 = xor i32 %13641, -1
  %13643 = and i32 %13642, 0
  %13644 = and i32 %13641, %13639
  %13645 = or i32 %13644, %13643
  %13646 = add i64 %13637, 16
  %13647 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13646
  %13648 = load i32, i32* %13647, align 4
  %13649 = icmp eq i64 %13634, %13646
  %13650 = sext i1 %13649 to i32
  %13651 = xor i32 %13650, -1
  %13652 = and i32 %13651, %13645
  %13653 = and i32 %13650, %13648
  %13654 = or i32 %13653, %13652
  %13655 = add i64 %13646, 16
  %13656 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13655
  %13657 = load i32, i32* %13656, align 4
  %13658 = icmp eq i64 %13634, %13655
  %13659 = sext i1 %13658 to i32
  %13660 = xor i32 %13659, -1
  %13661 = and i32 %13660, %13654
  %13662 = and i32 %13659, %13657
  %13663 = or i32 %13662, %13661
  %13664 = add i64 %13655, 16
  %13665 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13664
  %13666 = load i32, i32* %13665, align 4
  %13667 = icmp eq i64 %13634, %13664
  %13668 = sext i1 %13667 to i32
  %13669 = xor i32 %13668, -1
  %13670 = and i32 %13669, %13663
  %13671 = and i32 %13668, %13666
  %13672 = or i32 %13671, %13670
  %13673 = add i64 %13664, 16
  %13674 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13673
  %13675 = load i32, i32* %13674, align 4
  %13676 = icmp eq i64 %13634, %13673
  %13677 = sext i1 %13676 to i32
  %13678 = xor i32 %13677, -1
  %13679 = and i32 %13678, %13672
  %13680 = and i32 %13677, %13675
  %13681 = or i32 %13680, %13679
  %13682 = add i64 %13673, 16
  %13683 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13682
  %13684 = load i32, i32* %13683, align 4
  %13685 = icmp eq i64 %13634, %13682
  %13686 = sext i1 %13685 to i32
  %13687 = xor i32 %13686, -1
  %13688 = and i32 %13687, %13681
  %13689 = and i32 %13686, %13684
  %13690 = or i32 %13689, %13688
  %13691 = add i64 %13682, 16
  %13692 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13691
  %13693 = load i32, i32* %13692, align 4
  %13694 = icmp eq i64 %13634, %13691
  %13695 = sext i1 %13694 to i32
  %13696 = xor i32 %13695, -1
  %13697 = and i32 %13696, %13690
  %13698 = and i32 %13695, %13693
  %13699 = or i32 %13698, %13697
  %13700 = add i64 %13691, 16
  %13701 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13700
  %13702 = load i32, i32* %13701, align 4
  %13703 = icmp eq i64 %13634, %13700
  %13704 = sext i1 %13703 to i32
  %13705 = xor i32 %13704, -1
  %13706 = and i32 %13705, %13699
  %13707 = and i32 %13704, %13702
  %13708 = or i32 %13707, %13706
  %13709 = add i64 %13700, 16
  %13710 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13709
  %13711 = load i32, i32* %13710, align 4
  %13712 = icmp eq i64 %13634, %13709
  %13713 = sext i1 %13712 to i32
  %13714 = xor i32 %13713, -1
  %13715 = and i32 %13714, %13708
  %13716 = and i32 %13713, %13711
  %13717 = or i32 %13716, %13715
  %13718 = add i64 %13709, 16
  %13719 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13718
  %13720 = load i32, i32* %13719, align 4
  %13721 = icmp eq i64 %13634, %13718
  %13722 = sext i1 %13721 to i32
  %13723 = xor i32 %13722, -1
  %13724 = and i32 %13723, %13717
  %13725 = and i32 %13722, %13720
  %13726 = or i32 %13725, %13724
  %13727 = add i64 %13718, 16
  %13728 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13727
  %13729 = load i32, i32* %13728, align 4
  %13730 = icmp eq i64 %13634, %13727
  %13731 = sext i1 %13730 to i32
  %13732 = xor i32 %13731, -1
  %13733 = and i32 %13732, %13726
  %13734 = and i32 %13731, %13729
  %13735 = or i32 %13734, %13733
  %13736 = add i64 %13727, 16
  %13737 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13736
  %13738 = load i32, i32* %13737, align 4
  %13739 = icmp eq i64 %13634, %13736
  %13740 = sext i1 %13739 to i32
  %13741 = xor i32 %13740, -1
  %13742 = and i32 %13741, %13735
  %13743 = and i32 %13740, %13738
  %13744 = or i32 %13743, %13742
  %13745 = add i64 %13736, 16
  %13746 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13745
  %13747 = load i32, i32* %13746, align 4
  %13748 = icmp eq i64 %13634, %13745
  %13749 = sext i1 %13748 to i32
  %13750 = xor i32 %13749, -1
  %13751 = and i32 %13750, %13744
  %13752 = and i32 %13749, %13747
  %13753 = or i32 %13752, %13751
  %13754 = add i64 %13745, 16
  %13755 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13754
  %13756 = load i32, i32* %13755, align 4
  %13757 = icmp eq i64 %13634, %13754
  %13758 = sext i1 %13757 to i32
  %13759 = xor i32 %13758, -1
  %13760 = and i32 %13759, %13753
  %13761 = and i32 %13758, %13756
  %13762 = or i32 %13761, %13760
  %13763 = add i64 %13754, 16
  %13764 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13763
  %13765 = load i32, i32* %13764, align 4
  %13766 = icmp eq i64 %13634, %13763
  %13767 = sext i1 %13766 to i32
  %13768 = xor i32 %13767, -1
  %13769 = and i32 %13768, %13762
  %13770 = and i32 %13767, %13765
  %13771 = or i32 %13770, %13769
  %13772 = add i64 %13763, 16
  %13773 = getelementptr inbounds [256 x i32], [256 x i32]* %13636, i64 0, i64 %13772
  %13774 = load i32, i32* %13773, align 4
  %13775 = icmp eq i64 %13634, %13772
  %13776 = sext i1 %13775 to i32
  %13777 = xor i32 %13776, -1
  %13778 = and i32 %13777, %13771
  %13779 = and i32 %13776, %13774
  %Mitigated90 = or i32 %13779, %13778
  %13780 = xor i32 %13631, %Mitigated90
  %13781 = lshr i32 %13331, 24
  %13782 = zext i32 %13781 to i64
  %13783 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13784 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13783, i64 0, i64 3
  %13785 = srem i64 %13782, 16
  %13786 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13785
  %13787 = load i32, i32* %13786, align 4
  %13788 = icmp eq i64 %13782, %13785
  %13789 = sext i1 %13788 to i32
  %13790 = xor i32 %13789, -1
  %13791 = and i32 %13790, 0
  %13792 = and i32 %13789, %13787
  %13793 = or i32 %13792, %13791
  %13794 = add i64 %13785, 16
  %13795 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13794
  %13796 = load i32, i32* %13795, align 4
  %13797 = icmp eq i64 %13782, %13794
  %13798 = sext i1 %13797 to i32
  %13799 = xor i32 %13798, -1
  %13800 = and i32 %13799, %13793
  %13801 = and i32 %13798, %13796
  %13802 = or i32 %13801, %13800
  %13803 = add i64 %13794, 16
  %13804 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13803
  %13805 = load i32, i32* %13804, align 4
  %13806 = icmp eq i64 %13782, %13803
  %13807 = sext i1 %13806 to i32
  %13808 = xor i32 %13807, -1
  %13809 = and i32 %13808, %13802
  %13810 = and i32 %13807, %13805
  %13811 = or i32 %13810, %13809
  %13812 = add i64 %13803, 16
  %13813 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13812
  %13814 = load i32, i32* %13813, align 4
  %13815 = icmp eq i64 %13782, %13812
  %13816 = sext i1 %13815 to i32
  %13817 = xor i32 %13816, -1
  %13818 = and i32 %13817, %13811
  %13819 = and i32 %13816, %13814
  %13820 = or i32 %13819, %13818
  %13821 = add i64 %13812, 16
  %13822 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13821
  %13823 = load i32, i32* %13822, align 4
  %13824 = icmp eq i64 %13782, %13821
  %13825 = sext i1 %13824 to i32
  %13826 = xor i32 %13825, -1
  %13827 = and i32 %13826, %13820
  %13828 = and i32 %13825, %13823
  %13829 = or i32 %13828, %13827
  %13830 = add i64 %13821, 16
  %13831 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13830
  %13832 = load i32, i32* %13831, align 4
  %13833 = icmp eq i64 %13782, %13830
  %13834 = sext i1 %13833 to i32
  %13835 = xor i32 %13834, -1
  %13836 = and i32 %13835, %13829
  %13837 = and i32 %13834, %13832
  %13838 = or i32 %13837, %13836
  %13839 = add i64 %13830, 16
  %13840 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13839
  %13841 = load i32, i32* %13840, align 4
  %13842 = icmp eq i64 %13782, %13839
  %13843 = sext i1 %13842 to i32
  %13844 = xor i32 %13843, -1
  %13845 = and i32 %13844, %13838
  %13846 = and i32 %13843, %13841
  %13847 = or i32 %13846, %13845
  %13848 = add i64 %13839, 16
  %13849 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13848
  %13850 = load i32, i32* %13849, align 4
  %13851 = icmp eq i64 %13782, %13848
  %13852 = sext i1 %13851 to i32
  %13853 = xor i32 %13852, -1
  %13854 = and i32 %13853, %13847
  %13855 = and i32 %13852, %13850
  %13856 = or i32 %13855, %13854
  %13857 = add i64 %13848, 16
  %13858 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13857
  %13859 = load i32, i32* %13858, align 4
  %13860 = icmp eq i64 %13782, %13857
  %13861 = sext i1 %13860 to i32
  %13862 = xor i32 %13861, -1
  %13863 = and i32 %13862, %13856
  %13864 = and i32 %13861, %13859
  %13865 = or i32 %13864, %13863
  %13866 = add i64 %13857, 16
  %13867 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13866
  %13868 = load i32, i32* %13867, align 4
  %13869 = icmp eq i64 %13782, %13866
  %13870 = sext i1 %13869 to i32
  %13871 = xor i32 %13870, -1
  %13872 = and i32 %13871, %13865
  %13873 = and i32 %13870, %13868
  %13874 = or i32 %13873, %13872
  %13875 = add i64 %13866, 16
  %13876 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13875
  %13877 = load i32, i32* %13876, align 4
  %13878 = icmp eq i64 %13782, %13875
  %13879 = sext i1 %13878 to i32
  %13880 = xor i32 %13879, -1
  %13881 = and i32 %13880, %13874
  %13882 = and i32 %13879, %13877
  %13883 = or i32 %13882, %13881
  %13884 = add i64 %13875, 16
  %13885 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13884
  %13886 = load i32, i32* %13885, align 4
  %13887 = icmp eq i64 %13782, %13884
  %13888 = sext i1 %13887 to i32
  %13889 = xor i32 %13888, -1
  %13890 = and i32 %13889, %13883
  %13891 = and i32 %13888, %13886
  %13892 = or i32 %13891, %13890
  %13893 = add i64 %13884, 16
  %13894 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13893
  %13895 = load i32, i32* %13894, align 4
  %13896 = icmp eq i64 %13782, %13893
  %13897 = sext i1 %13896 to i32
  %13898 = xor i32 %13897, -1
  %13899 = and i32 %13898, %13892
  %13900 = and i32 %13897, %13895
  %13901 = or i32 %13900, %13899
  %13902 = add i64 %13893, 16
  %13903 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13902
  %13904 = load i32, i32* %13903, align 4
  %13905 = icmp eq i64 %13782, %13902
  %13906 = sext i1 %13905 to i32
  %13907 = xor i32 %13906, -1
  %13908 = and i32 %13907, %13901
  %13909 = and i32 %13906, %13904
  %13910 = or i32 %13909, %13908
  %13911 = add i64 %13902, 16
  %13912 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13911
  %13913 = load i32, i32* %13912, align 4
  %13914 = icmp eq i64 %13782, %13911
  %13915 = sext i1 %13914 to i32
  %13916 = xor i32 %13915, -1
  %13917 = and i32 %13916, %13910
  %13918 = and i32 %13915, %13913
  %13919 = or i32 %13918, %13917
  %13920 = add i64 %13911, 16
  %13921 = getelementptr inbounds [256 x i32], [256 x i32]* %13784, i64 0, i64 %13920
  %13922 = load i32, i32* %13921, align 4
  %13923 = icmp eq i64 %13782, %13920
  %13924 = sext i1 %13923 to i32
  %13925 = xor i32 %13924, -1
  %13926 = and i32 %13925, %13919
  %13927 = and i32 %13924, %13922
  %Mitigated91 = or i32 %13927, %13926
  %13928 = xor i32 %13780, %Mitigated91
  %13929 = and i32 %13335, 255
  %13930 = zext i32 %13929 to i64
  %13931 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %13932 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %13931, i64 0, i64 1
  %13933 = srem i64 %13930, 16
  %13934 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13933
  %13935 = load i32, i32* %13934, align 4
  %13936 = icmp eq i64 %13930, %13933
  %13937 = sext i1 %13936 to i32
  %13938 = xor i32 %13937, -1
  %13939 = and i32 %13938, 0
  %13940 = and i32 %13937, %13935
  %13941 = or i32 %13940, %13939
  %13942 = add i64 %13933, 16
  %13943 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13942
  %13944 = load i32, i32* %13943, align 4
  %13945 = icmp eq i64 %13930, %13942
  %13946 = sext i1 %13945 to i32
  %13947 = xor i32 %13946, -1
  %13948 = and i32 %13947, %13941
  %13949 = and i32 %13946, %13944
  %13950 = or i32 %13949, %13948
  %13951 = add i64 %13942, 16
  %13952 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13951
  %13953 = load i32, i32* %13952, align 4
  %13954 = icmp eq i64 %13930, %13951
  %13955 = sext i1 %13954 to i32
  %13956 = xor i32 %13955, -1
  %13957 = and i32 %13956, %13950
  %13958 = and i32 %13955, %13953
  %13959 = or i32 %13958, %13957
  %13960 = add i64 %13951, 16
  %13961 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13960
  %13962 = load i32, i32* %13961, align 4
  %13963 = icmp eq i64 %13930, %13960
  %13964 = sext i1 %13963 to i32
  %13965 = xor i32 %13964, -1
  %13966 = and i32 %13965, %13959
  %13967 = and i32 %13964, %13962
  %13968 = or i32 %13967, %13966
  %13969 = add i64 %13960, 16
  %13970 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13969
  %13971 = load i32, i32* %13970, align 4
  %13972 = icmp eq i64 %13930, %13969
  %13973 = sext i1 %13972 to i32
  %13974 = xor i32 %13973, -1
  %13975 = and i32 %13974, %13968
  %13976 = and i32 %13973, %13971
  %13977 = or i32 %13976, %13975
  %13978 = add i64 %13969, 16
  %13979 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13978
  %13980 = load i32, i32* %13979, align 4
  %13981 = icmp eq i64 %13930, %13978
  %13982 = sext i1 %13981 to i32
  %13983 = xor i32 %13982, -1
  %13984 = and i32 %13983, %13977
  %13985 = and i32 %13982, %13980
  %13986 = or i32 %13985, %13984
  %13987 = add i64 %13978, 16
  %13988 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13987
  %13989 = load i32, i32* %13988, align 4
  %13990 = icmp eq i64 %13930, %13987
  %13991 = sext i1 %13990 to i32
  %13992 = xor i32 %13991, -1
  %13993 = and i32 %13992, %13986
  %13994 = and i32 %13991, %13989
  %13995 = or i32 %13994, %13993
  %13996 = add i64 %13987, 16
  %13997 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %13996
  %13998 = load i32, i32* %13997, align 4
  %13999 = icmp eq i64 %13930, %13996
  %14000 = sext i1 %13999 to i32
  %14001 = xor i32 %14000, -1
  %14002 = and i32 %14001, %13995
  %14003 = and i32 %14000, %13998
  %14004 = or i32 %14003, %14002
  %14005 = add i64 %13996, 16
  %14006 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14005
  %14007 = load i32, i32* %14006, align 4
  %14008 = icmp eq i64 %13930, %14005
  %14009 = sext i1 %14008 to i32
  %14010 = xor i32 %14009, -1
  %14011 = and i32 %14010, %14004
  %14012 = and i32 %14009, %14007
  %14013 = or i32 %14012, %14011
  %14014 = add i64 %14005, 16
  %14015 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14014
  %14016 = load i32, i32* %14015, align 4
  %14017 = icmp eq i64 %13930, %14014
  %14018 = sext i1 %14017 to i32
  %14019 = xor i32 %14018, -1
  %14020 = and i32 %14019, %14013
  %14021 = and i32 %14018, %14016
  %14022 = or i32 %14021, %14020
  %14023 = add i64 %14014, 16
  %14024 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14023
  %14025 = load i32, i32* %14024, align 4
  %14026 = icmp eq i64 %13930, %14023
  %14027 = sext i1 %14026 to i32
  %14028 = xor i32 %14027, -1
  %14029 = and i32 %14028, %14022
  %14030 = and i32 %14027, %14025
  %14031 = or i32 %14030, %14029
  %14032 = add i64 %14023, 16
  %14033 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14032
  %14034 = load i32, i32* %14033, align 4
  %14035 = icmp eq i64 %13930, %14032
  %14036 = sext i1 %14035 to i32
  %14037 = xor i32 %14036, -1
  %14038 = and i32 %14037, %14031
  %14039 = and i32 %14036, %14034
  %14040 = or i32 %14039, %14038
  %14041 = add i64 %14032, 16
  %14042 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14041
  %14043 = load i32, i32* %14042, align 4
  %14044 = icmp eq i64 %13930, %14041
  %14045 = sext i1 %14044 to i32
  %14046 = xor i32 %14045, -1
  %14047 = and i32 %14046, %14040
  %14048 = and i32 %14045, %14043
  %14049 = or i32 %14048, %14047
  %14050 = add i64 %14041, 16
  %14051 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14050
  %14052 = load i32, i32* %14051, align 4
  %14053 = icmp eq i64 %13930, %14050
  %14054 = sext i1 %14053 to i32
  %14055 = xor i32 %14054, -1
  %14056 = and i32 %14055, %14049
  %14057 = and i32 %14054, %14052
  %14058 = or i32 %14057, %14056
  %14059 = add i64 %14050, 16
  %14060 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14059
  %14061 = load i32, i32* %14060, align 4
  %14062 = icmp eq i64 %13930, %14059
  %14063 = sext i1 %14062 to i32
  %14064 = xor i32 %14063, -1
  %14065 = and i32 %14064, %14058
  %14066 = and i32 %14063, %14061
  %14067 = or i32 %14066, %14065
  %14068 = add i64 %14059, 16
  %14069 = getelementptr inbounds [256 x i32], [256 x i32]* %13932, i64 0, i64 %14068
  %14070 = load i32, i32* %14069, align 4
  %14071 = icmp eq i64 %13930, %14068
  %14072 = sext i1 %14071 to i32
  %14073 = xor i32 %14072, -1
  %14074 = and i32 %14073, %14067
  %14075 = and i32 %14072, %14070
  %Mitigated92 = or i32 %14075, %14074
  %14076 = lshr i32 %13335, 8
  %14077 = and i32 %14076, 255
  %14078 = zext i32 %14077 to i64
  %14079 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14080 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14079, i64 0, i64 2
  %14081 = srem i64 %14078, 16
  %14082 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14081
  %14083 = load i32, i32* %14082, align 4
  %14084 = icmp eq i64 %14078, %14081
  %14085 = sext i1 %14084 to i32
  %14086 = xor i32 %14085, -1
  %14087 = and i32 %14086, 0
  %14088 = and i32 %14085, %14083
  %14089 = or i32 %14088, %14087
  %14090 = add i64 %14081, 16
  %14091 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14090
  %14092 = load i32, i32* %14091, align 4
  %14093 = icmp eq i64 %14078, %14090
  %14094 = sext i1 %14093 to i32
  %14095 = xor i32 %14094, -1
  %14096 = and i32 %14095, %14089
  %14097 = and i32 %14094, %14092
  %14098 = or i32 %14097, %14096
  %14099 = add i64 %14090, 16
  %14100 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14099
  %14101 = load i32, i32* %14100, align 4
  %14102 = icmp eq i64 %14078, %14099
  %14103 = sext i1 %14102 to i32
  %14104 = xor i32 %14103, -1
  %14105 = and i32 %14104, %14098
  %14106 = and i32 %14103, %14101
  %14107 = or i32 %14106, %14105
  %14108 = add i64 %14099, 16
  %14109 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14108
  %14110 = load i32, i32* %14109, align 4
  %14111 = icmp eq i64 %14078, %14108
  %14112 = sext i1 %14111 to i32
  %14113 = xor i32 %14112, -1
  %14114 = and i32 %14113, %14107
  %14115 = and i32 %14112, %14110
  %14116 = or i32 %14115, %14114
  %14117 = add i64 %14108, 16
  %14118 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14117
  %14119 = load i32, i32* %14118, align 4
  %14120 = icmp eq i64 %14078, %14117
  %14121 = sext i1 %14120 to i32
  %14122 = xor i32 %14121, -1
  %14123 = and i32 %14122, %14116
  %14124 = and i32 %14121, %14119
  %14125 = or i32 %14124, %14123
  %14126 = add i64 %14117, 16
  %14127 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14126
  %14128 = load i32, i32* %14127, align 4
  %14129 = icmp eq i64 %14078, %14126
  %14130 = sext i1 %14129 to i32
  %14131 = xor i32 %14130, -1
  %14132 = and i32 %14131, %14125
  %14133 = and i32 %14130, %14128
  %14134 = or i32 %14133, %14132
  %14135 = add i64 %14126, 16
  %14136 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14135
  %14137 = load i32, i32* %14136, align 4
  %14138 = icmp eq i64 %14078, %14135
  %14139 = sext i1 %14138 to i32
  %14140 = xor i32 %14139, -1
  %14141 = and i32 %14140, %14134
  %14142 = and i32 %14139, %14137
  %14143 = or i32 %14142, %14141
  %14144 = add i64 %14135, 16
  %14145 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14144
  %14146 = load i32, i32* %14145, align 4
  %14147 = icmp eq i64 %14078, %14144
  %14148 = sext i1 %14147 to i32
  %14149 = xor i32 %14148, -1
  %14150 = and i32 %14149, %14143
  %14151 = and i32 %14148, %14146
  %14152 = or i32 %14151, %14150
  %14153 = add i64 %14144, 16
  %14154 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14153
  %14155 = load i32, i32* %14154, align 4
  %14156 = icmp eq i64 %14078, %14153
  %14157 = sext i1 %14156 to i32
  %14158 = xor i32 %14157, -1
  %14159 = and i32 %14158, %14152
  %14160 = and i32 %14157, %14155
  %14161 = or i32 %14160, %14159
  %14162 = add i64 %14153, 16
  %14163 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14162
  %14164 = load i32, i32* %14163, align 4
  %14165 = icmp eq i64 %14078, %14162
  %14166 = sext i1 %14165 to i32
  %14167 = xor i32 %14166, -1
  %14168 = and i32 %14167, %14161
  %14169 = and i32 %14166, %14164
  %14170 = or i32 %14169, %14168
  %14171 = add i64 %14162, 16
  %14172 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14171
  %14173 = load i32, i32* %14172, align 4
  %14174 = icmp eq i64 %14078, %14171
  %14175 = sext i1 %14174 to i32
  %14176 = xor i32 %14175, -1
  %14177 = and i32 %14176, %14170
  %14178 = and i32 %14175, %14173
  %14179 = or i32 %14178, %14177
  %14180 = add i64 %14171, 16
  %14181 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14180
  %14182 = load i32, i32* %14181, align 4
  %14183 = icmp eq i64 %14078, %14180
  %14184 = sext i1 %14183 to i32
  %14185 = xor i32 %14184, -1
  %14186 = and i32 %14185, %14179
  %14187 = and i32 %14184, %14182
  %14188 = or i32 %14187, %14186
  %14189 = add i64 %14180, 16
  %14190 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14189
  %14191 = load i32, i32* %14190, align 4
  %14192 = icmp eq i64 %14078, %14189
  %14193 = sext i1 %14192 to i32
  %14194 = xor i32 %14193, -1
  %14195 = and i32 %14194, %14188
  %14196 = and i32 %14193, %14191
  %14197 = or i32 %14196, %14195
  %14198 = add i64 %14189, 16
  %14199 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14198
  %14200 = load i32, i32* %14199, align 4
  %14201 = icmp eq i64 %14078, %14198
  %14202 = sext i1 %14201 to i32
  %14203 = xor i32 %14202, -1
  %14204 = and i32 %14203, %14197
  %14205 = and i32 %14202, %14200
  %14206 = or i32 %14205, %14204
  %14207 = add i64 %14198, 16
  %14208 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14207
  %14209 = load i32, i32* %14208, align 4
  %14210 = icmp eq i64 %14078, %14207
  %14211 = sext i1 %14210 to i32
  %14212 = xor i32 %14211, -1
  %14213 = and i32 %14212, %14206
  %14214 = and i32 %14211, %14209
  %14215 = or i32 %14214, %14213
  %14216 = add i64 %14207, 16
  %14217 = getelementptr inbounds [256 x i32], [256 x i32]* %14080, i64 0, i64 %14216
  %14218 = load i32, i32* %14217, align 4
  %14219 = icmp eq i64 %14078, %14216
  %14220 = sext i1 %14219 to i32
  %14221 = xor i32 %14220, -1
  %14222 = and i32 %14221, %14215
  %14223 = and i32 %14220, %14218
  %Mitigated93 = or i32 %14223, %14222
  %14224 = xor i32 %Mitigated92, %Mitigated93
  %14225 = lshr i32 %13335, 16
  %14226 = and i32 %14225, 255
  %14227 = zext i32 %14226 to i64
  %14228 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14229 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14228, i64 0, i64 3
  %14230 = srem i64 %14227, 16
  %14231 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14230
  %14232 = load i32, i32* %14231, align 4
  %14233 = icmp eq i64 %14227, %14230
  %14234 = sext i1 %14233 to i32
  %14235 = xor i32 %14234, -1
  %14236 = and i32 %14235, 0
  %14237 = and i32 %14234, %14232
  %14238 = or i32 %14237, %14236
  %14239 = add i64 %14230, 16
  %14240 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14239
  %14241 = load i32, i32* %14240, align 4
  %14242 = icmp eq i64 %14227, %14239
  %14243 = sext i1 %14242 to i32
  %14244 = xor i32 %14243, -1
  %14245 = and i32 %14244, %14238
  %14246 = and i32 %14243, %14241
  %14247 = or i32 %14246, %14245
  %14248 = add i64 %14239, 16
  %14249 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14248
  %14250 = load i32, i32* %14249, align 4
  %14251 = icmp eq i64 %14227, %14248
  %14252 = sext i1 %14251 to i32
  %14253 = xor i32 %14252, -1
  %14254 = and i32 %14253, %14247
  %14255 = and i32 %14252, %14250
  %14256 = or i32 %14255, %14254
  %14257 = add i64 %14248, 16
  %14258 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14257
  %14259 = load i32, i32* %14258, align 4
  %14260 = icmp eq i64 %14227, %14257
  %14261 = sext i1 %14260 to i32
  %14262 = xor i32 %14261, -1
  %14263 = and i32 %14262, %14256
  %14264 = and i32 %14261, %14259
  %14265 = or i32 %14264, %14263
  %14266 = add i64 %14257, 16
  %14267 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14266
  %14268 = load i32, i32* %14267, align 4
  %14269 = icmp eq i64 %14227, %14266
  %14270 = sext i1 %14269 to i32
  %14271 = xor i32 %14270, -1
  %14272 = and i32 %14271, %14265
  %14273 = and i32 %14270, %14268
  %14274 = or i32 %14273, %14272
  %14275 = add i64 %14266, 16
  %14276 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14275
  %14277 = load i32, i32* %14276, align 4
  %14278 = icmp eq i64 %14227, %14275
  %14279 = sext i1 %14278 to i32
  %14280 = xor i32 %14279, -1
  %14281 = and i32 %14280, %14274
  %14282 = and i32 %14279, %14277
  %14283 = or i32 %14282, %14281
  %14284 = add i64 %14275, 16
  %14285 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14284
  %14286 = load i32, i32* %14285, align 4
  %14287 = icmp eq i64 %14227, %14284
  %14288 = sext i1 %14287 to i32
  %14289 = xor i32 %14288, -1
  %14290 = and i32 %14289, %14283
  %14291 = and i32 %14288, %14286
  %14292 = or i32 %14291, %14290
  %14293 = add i64 %14284, 16
  %14294 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14293
  %14295 = load i32, i32* %14294, align 4
  %14296 = icmp eq i64 %14227, %14293
  %14297 = sext i1 %14296 to i32
  %14298 = xor i32 %14297, -1
  %14299 = and i32 %14298, %14292
  %14300 = and i32 %14297, %14295
  %14301 = or i32 %14300, %14299
  %14302 = add i64 %14293, 16
  %14303 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14302
  %14304 = load i32, i32* %14303, align 4
  %14305 = icmp eq i64 %14227, %14302
  %14306 = sext i1 %14305 to i32
  %14307 = xor i32 %14306, -1
  %14308 = and i32 %14307, %14301
  %14309 = and i32 %14306, %14304
  %14310 = or i32 %14309, %14308
  %14311 = add i64 %14302, 16
  %14312 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14311
  %14313 = load i32, i32* %14312, align 4
  %14314 = icmp eq i64 %14227, %14311
  %14315 = sext i1 %14314 to i32
  %14316 = xor i32 %14315, -1
  %14317 = and i32 %14316, %14310
  %14318 = and i32 %14315, %14313
  %14319 = or i32 %14318, %14317
  %14320 = add i64 %14311, 16
  %14321 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14320
  %14322 = load i32, i32* %14321, align 4
  %14323 = icmp eq i64 %14227, %14320
  %14324 = sext i1 %14323 to i32
  %14325 = xor i32 %14324, -1
  %14326 = and i32 %14325, %14319
  %14327 = and i32 %14324, %14322
  %14328 = or i32 %14327, %14326
  %14329 = add i64 %14320, 16
  %14330 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14329
  %14331 = load i32, i32* %14330, align 4
  %14332 = icmp eq i64 %14227, %14329
  %14333 = sext i1 %14332 to i32
  %14334 = xor i32 %14333, -1
  %14335 = and i32 %14334, %14328
  %14336 = and i32 %14333, %14331
  %14337 = or i32 %14336, %14335
  %14338 = add i64 %14329, 16
  %14339 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14338
  %14340 = load i32, i32* %14339, align 4
  %14341 = icmp eq i64 %14227, %14338
  %14342 = sext i1 %14341 to i32
  %14343 = xor i32 %14342, -1
  %14344 = and i32 %14343, %14337
  %14345 = and i32 %14342, %14340
  %14346 = or i32 %14345, %14344
  %14347 = add i64 %14338, 16
  %14348 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14347
  %14349 = load i32, i32* %14348, align 4
  %14350 = icmp eq i64 %14227, %14347
  %14351 = sext i1 %14350 to i32
  %14352 = xor i32 %14351, -1
  %14353 = and i32 %14352, %14346
  %14354 = and i32 %14351, %14349
  %14355 = or i32 %14354, %14353
  %14356 = add i64 %14347, 16
  %14357 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14356
  %14358 = load i32, i32* %14357, align 4
  %14359 = icmp eq i64 %14227, %14356
  %14360 = sext i1 %14359 to i32
  %14361 = xor i32 %14360, -1
  %14362 = and i32 %14361, %14355
  %14363 = and i32 %14360, %14358
  %14364 = or i32 %14363, %14362
  %14365 = add i64 %14356, 16
  %14366 = getelementptr inbounds [256 x i32], [256 x i32]* %14229, i64 0, i64 %14365
  %14367 = load i32, i32* %14366, align 4
  %14368 = icmp eq i64 %14227, %14365
  %14369 = sext i1 %14368 to i32
  %14370 = xor i32 %14369, -1
  %14371 = and i32 %14370, %14364
  %14372 = and i32 %14369, %14367
  %Mitigated94 = or i32 %14372, %14371
  %14373 = xor i32 %14224, %Mitigated94
  %14374 = lshr i32 %13335, 24
  %14375 = zext i32 %14374 to i64
  %14376 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14377 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14376, i64 0, i64 0
  %14378 = srem i64 %14375, 16
  %14379 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14378
  %14380 = load i32, i32* %14379, align 4
  %14381 = icmp eq i64 %14375, %14378
  %14382 = sext i1 %14381 to i32
  %14383 = xor i32 %14382, -1
  %14384 = and i32 %14383, 0
  %14385 = and i32 %14382, %14380
  %14386 = or i32 %14385, %14384
  %14387 = add i64 %14378, 16
  %14388 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14387
  %14389 = load i32, i32* %14388, align 4
  %14390 = icmp eq i64 %14375, %14387
  %14391 = sext i1 %14390 to i32
  %14392 = xor i32 %14391, -1
  %14393 = and i32 %14392, %14386
  %14394 = and i32 %14391, %14389
  %14395 = or i32 %14394, %14393
  %14396 = add i64 %14387, 16
  %14397 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14396
  %14398 = load i32, i32* %14397, align 4
  %14399 = icmp eq i64 %14375, %14396
  %14400 = sext i1 %14399 to i32
  %14401 = xor i32 %14400, -1
  %14402 = and i32 %14401, %14395
  %14403 = and i32 %14400, %14398
  %14404 = or i32 %14403, %14402
  %14405 = add i64 %14396, 16
  %14406 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14405
  %14407 = load i32, i32* %14406, align 4
  %14408 = icmp eq i64 %14375, %14405
  %14409 = sext i1 %14408 to i32
  %14410 = xor i32 %14409, -1
  %14411 = and i32 %14410, %14404
  %14412 = and i32 %14409, %14407
  %14413 = or i32 %14412, %14411
  %14414 = add i64 %14405, 16
  %14415 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14414
  %14416 = load i32, i32* %14415, align 4
  %14417 = icmp eq i64 %14375, %14414
  %14418 = sext i1 %14417 to i32
  %14419 = xor i32 %14418, -1
  %14420 = and i32 %14419, %14413
  %14421 = and i32 %14418, %14416
  %14422 = or i32 %14421, %14420
  %14423 = add i64 %14414, 16
  %14424 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14423
  %14425 = load i32, i32* %14424, align 4
  %14426 = icmp eq i64 %14375, %14423
  %14427 = sext i1 %14426 to i32
  %14428 = xor i32 %14427, -1
  %14429 = and i32 %14428, %14422
  %14430 = and i32 %14427, %14425
  %14431 = or i32 %14430, %14429
  %14432 = add i64 %14423, 16
  %14433 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14432
  %14434 = load i32, i32* %14433, align 4
  %14435 = icmp eq i64 %14375, %14432
  %14436 = sext i1 %14435 to i32
  %14437 = xor i32 %14436, -1
  %14438 = and i32 %14437, %14431
  %14439 = and i32 %14436, %14434
  %14440 = or i32 %14439, %14438
  %14441 = add i64 %14432, 16
  %14442 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14441
  %14443 = load i32, i32* %14442, align 4
  %14444 = icmp eq i64 %14375, %14441
  %14445 = sext i1 %14444 to i32
  %14446 = xor i32 %14445, -1
  %14447 = and i32 %14446, %14440
  %14448 = and i32 %14445, %14443
  %14449 = or i32 %14448, %14447
  %14450 = add i64 %14441, 16
  %14451 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14450
  %14452 = load i32, i32* %14451, align 4
  %14453 = icmp eq i64 %14375, %14450
  %14454 = sext i1 %14453 to i32
  %14455 = xor i32 %14454, -1
  %14456 = and i32 %14455, %14449
  %14457 = and i32 %14454, %14452
  %14458 = or i32 %14457, %14456
  %14459 = add i64 %14450, 16
  %14460 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14459
  %14461 = load i32, i32* %14460, align 4
  %14462 = icmp eq i64 %14375, %14459
  %14463 = sext i1 %14462 to i32
  %14464 = xor i32 %14463, -1
  %14465 = and i32 %14464, %14458
  %14466 = and i32 %14463, %14461
  %14467 = or i32 %14466, %14465
  %14468 = add i64 %14459, 16
  %14469 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14468
  %14470 = load i32, i32* %14469, align 4
  %14471 = icmp eq i64 %14375, %14468
  %14472 = sext i1 %14471 to i32
  %14473 = xor i32 %14472, -1
  %14474 = and i32 %14473, %14467
  %14475 = and i32 %14472, %14470
  %14476 = or i32 %14475, %14474
  %14477 = add i64 %14468, 16
  %14478 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14477
  %14479 = load i32, i32* %14478, align 4
  %14480 = icmp eq i64 %14375, %14477
  %14481 = sext i1 %14480 to i32
  %14482 = xor i32 %14481, -1
  %14483 = and i32 %14482, %14476
  %14484 = and i32 %14481, %14479
  %14485 = or i32 %14484, %14483
  %14486 = add i64 %14477, 16
  %14487 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14486
  %14488 = load i32, i32* %14487, align 4
  %14489 = icmp eq i64 %14375, %14486
  %14490 = sext i1 %14489 to i32
  %14491 = xor i32 %14490, -1
  %14492 = and i32 %14491, %14485
  %14493 = and i32 %14490, %14488
  %14494 = or i32 %14493, %14492
  %14495 = add i64 %14486, 16
  %14496 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14495
  %14497 = load i32, i32* %14496, align 4
  %14498 = icmp eq i64 %14375, %14495
  %14499 = sext i1 %14498 to i32
  %14500 = xor i32 %14499, -1
  %14501 = and i32 %14500, %14494
  %14502 = and i32 %14499, %14497
  %14503 = or i32 %14502, %14501
  %14504 = add i64 %14495, 16
  %14505 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14504
  %14506 = load i32, i32* %14505, align 4
  %14507 = icmp eq i64 %14375, %14504
  %14508 = sext i1 %14507 to i32
  %14509 = xor i32 %14508, -1
  %14510 = and i32 %14509, %14503
  %14511 = and i32 %14508, %14506
  %14512 = or i32 %14511, %14510
  %14513 = add i64 %14504, 16
  %14514 = getelementptr inbounds [256 x i32], [256 x i32]* %14377, i64 0, i64 %14513
  %14515 = load i32, i32* %14514, align 4
  %14516 = icmp eq i64 %14375, %14513
  %14517 = sext i1 %14516 to i32
  %14518 = xor i32 %14517, -1
  %14519 = and i32 %14518, %14512
  %14520 = and i32 %14517, %14515
  %Mitigated95 = or i32 %14520, %14519
  %14521 = xor i32 %14373, %Mitigated95
  %14522 = add i32 %13928, %14521
  %14523 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %14524 = getelementptr inbounds [32 x i32], [32 x i32]* %14523, i64 0, i64 23
  %14525 = load i32, i32* %14524, align 4
  %14526 = add i32 %14522, %14525
  %14527 = add i32 %14521, %14526
  %14528 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %14529 = getelementptr inbounds [32 x i32], [32 x i32]* %14528, i64 0, i64 22
  %14530 = load i32, i32* %14529, align 4
  %14531 = add i32 %14522, %14530
  %14532 = xor i32 %12127, %14531
  %14533 = lshr i32 %14532, 1
  %14534 = shl i32 %14532, 31
  %14535 = add i32 %14533, %14534
  %14536 = shl i32 %12131, 1
  %14537 = lshr i32 %12131, 31
  %14538 = add i32 %14536, %14537
  %14539 = xor i32 %14538, %14527
  %14540 = and i32 %14535, 255
  %14541 = zext i32 %14540 to i64
  %14542 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14543 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14542, i64 0, i64 0
  %14544 = srem i64 %14541, 16
  %14545 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14544
  %14546 = load i32, i32* %14545, align 4
  %14547 = icmp eq i64 %14541, %14544
  %14548 = sext i1 %14547 to i32
  %14549 = xor i32 %14548, -1
  %14550 = and i32 %14549, 0
  %14551 = and i32 %14548, %14546
  %14552 = or i32 %14551, %14550
  %14553 = add i64 %14544, 16
  %14554 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14553
  %14555 = load i32, i32* %14554, align 4
  %14556 = icmp eq i64 %14541, %14553
  %14557 = sext i1 %14556 to i32
  %14558 = xor i32 %14557, -1
  %14559 = and i32 %14558, %14552
  %14560 = and i32 %14557, %14555
  %14561 = or i32 %14560, %14559
  %14562 = add i64 %14553, 16
  %14563 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14562
  %14564 = load i32, i32* %14563, align 4
  %14565 = icmp eq i64 %14541, %14562
  %14566 = sext i1 %14565 to i32
  %14567 = xor i32 %14566, -1
  %14568 = and i32 %14567, %14561
  %14569 = and i32 %14566, %14564
  %14570 = or i32 %14569, %14568
  %14571 = add i64 %14562, 16
  %14572 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14571
  %14573 = load i32, i32* %14572, align 4
  %14574 = icmp eq i64 %14541, %14571
  %14575 = sext i1 %14574 to i32
  %14576 = xor i32 %14575, -1
  %14577 = and i32 %14576, %14570
  %14578 = and i32 %14575, %14573
  %14579 = or i32 %14578, %14577
  %14580 = add i64 %14571, 16
  %14581 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14580
  %14582 = load i32, i32* %14581, align 4
  %14583 = icmp eq i64 %14541, %14580
  %14584 = sext i1 %14583 to i32
  %14585 = xor i32 %14584, -1
  %14586 = and i32 %14585, %14579
  %14587 = and i32 %14584, %14582
  %14588 = or i32 %14587, %14586
  %14589 = add i64 %14580, 16
  %14590 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14589
  %14591 = load i32, i32* %14590, align 4
  %14592 = icmp eq i64 %14541, %14589
  %14593 = sext i1 %14592 to i32
  %14594 = xor i32 %14593, -1
  %14595 = and i32 %14594, %14588
  %14596 = and i32 %14593, %14591
  %14597 = or i32 %14596, %14595
  %14598 = add i64 %14589, 16
  %14599 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14598
  %14600 = load i32, i32* %14599, align 4
  %14601 = icmp eq i64 %14541, %14598
  %14602 = sext i1 %14601 to i32
  %14603 = xor i32 %14602, -1
  %14604 = and i32 %14603, %14597
  %14605 = and i32 %14602, %14600
  %14606 = or i32 %14605, %14604
  %14607 = add i64 %14598, 16
  %14608 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14607
  %14609 = load i32, i32* %14608, align 4
  %14610 = icmp eq i64 %14541, %14607
  %14611 = sext i1 %14610 to i32
  %14612 = xor i32 %14611, -1
  %14613 = and i32 %14612, %14606
  %14614 = and i32 %14611, %14609
  %14615 = or i32 %14614, %14613
  %14616 = add i64 %14607, 16
  %14617 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14616
  %14618 = load i32, i32* %14617, align 4
  %14619 = icmp eq i64 %14541, %14616
  %14620 = sext i1 %14619 to i32
  %14621 = xor i32 %14620, -1
  %14622 = and i32 %14621, %14615
  %14623 = and i32 %14620, %14618
  %14624 = or i32 %14623, %14622
  %14625 = add i64 %14616, 16
  %14626 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14625
  %14627 = load i32, i32* %14626, align 4
  %14628 = icmp eq i64 %14541, %14625
  %14629 = sext i1 %14628 to i32
  %14630 = xor i32 %14629, -1
  %14631 = and i32 %14630, %14624
  %14632 = and i32 %14629, %14627
  %14633 = or i32 %14632, %14631
  %14634 = add i64 %14625, 16
  %14635 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14634
  %14636 = load i32, i32* %14635, align 4
  %14637 = icmp eq i64 %14541, %14634
  %14638 = sext i1 %14637 to i32
  %14639 = xor i32 %14638, -1
  %14640 = and i32 %14639, %14633
  %14641 = and i32 %14638, %14636
  %14642 = or i32 %14641, %14640
  %14643 = add i64 %14634, 16
  %14644 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14643
  %14645 = load i32, i32* %14644, align 4
  %14646 = icmp eq i64 %14541, %14643
  %14647 = sext i1 %14646 to i32
  %14648 = xor i32 %14647, -1
  %14649 = and i32 %14648, %14642
  %14650 = and i32 %14647, %14645
  %14651 = or i32 %14650, %14649
  %14652 = add i64 %14643, 16
  %14653 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14652
  %14654 = load i32, i32* %14653, align 4
  %14655 = icmp eq i64 %14541, %14652
  %14656 = sext i1 %14655 to i32
  %14657 = xor i32 %14656, -1
  %14658 = and i32 %14657, %14651
  %14659 = and i32 %14656, %14654
  %14660 = or i32 %14659, %14658
  %14661 = add i64 %14652, 16
  %14662 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14661
  %14663 = load i32, i32* %14662, align 4
  %14664 = icmp eq i64 %14541, %14661
  %14665 = sext i1 %14664 to i32
  %14666 = xor i32 %14665, -1
  %14667 = and i32 %14666, %14660
  %14668 = and i32 %14665, %14663
  %14669 = or i32 %14668, %14667
  %14670 = add i64 %14661, 16
  %14671 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14670
  %14672 = load i32, i32* %14671, align 4
  %14673 = icmp eq i64 %14541, %14670
  %14674 = sext i1 %14673 to i32
  %14675 = xor i32 %14674, -1
  %14676 = and i32 %14675, %14669
  %14677 = and i32 %14674, %14672
  %14678 = or i32 %14677, %14676
  %14679 = add i64 %14670, 16
  %14680 = getelementptr inbounds [256 x i32], [256 x i32]* %14543, i64 0, i64 %14679
  %14681 = load i32, i32* %14680, align 4
  %14682 = icmp eq i64 %14541, %14679
  %14683 = sext i1 %14682 to i32
  %14684 = xor i32 %14683, -1
  %14685 = and i32 %14684, %14678
  %14686 = and i32 %14683, %14681
  %Mitigated96 = or i32 %14686, %14685
  %14687 = lshr i32 %14535, 8
  %14688 = and i32 %14687, 255
  %14689 = zext i32 %14688 to i64
  %14690 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14691 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14690, i64 0, i64 1
  %14692 = srem i64 %14689, 16
  %14693 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14692
  %14694 = load i32, i32* %14693, align 4
  %14695 = icmp eq i64 %14689, %14692
  %14696 = sext i1 %14695 to i32
  %14697 = xor i32 %14696, -1
  %14698 = and i32 %14697, 0
  %14699 = and i32 %14696, %14694
  %14700 = or i32 %14699, %14698
  %14701 = add i64 %14692, 16
  %14702 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14701
  %14703 = load i32, i32* %14702, align 4
  %14704 = icmp eq i64 %14689, %14701
  %14705 = sext i1 %14704 to i32
  %14706 = xor i32 %14705, -1
  %14707 = and i32 %14706, %14700
  %14708 = and i32 %14705, %14703
  %14709 = or i32 %14708, %14707
  %14710 = add i64 %14701, 16
  %14711 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14710
  %14712 = load i32, i32* %14711, align 4
  %14713 = icmp eq i64 %14689, %14710
  %14714 = sext i1 %14713 to i32
  %14715 = xor i32 %14714, -1
  %14716 = and i32 %14715, %14709
  %14717 = and i32 %14714, %14712
  %14718 = or i32 %14717, %14716
  %14719 = add i64 %14710, 16
  %14720 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14719
  %14721 = load i32, i32* %14720, align 4
  %14722 = icmp eq i64 %14689, %14719
  %14723 = sext i1 %14722 to i32
  %14724 = xor i32 %14723, -1
  %14725 = and i32 %14724, %14718
  %14726 = and i32 %14723, %14721
  %14727 = or i32 %14726, %14725
  %14728 = add i64 %14719, 16
  %14729 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14728
  %14730 = load i32, i32* %14729, align 4
  %14731 = icmp eq i64 %14689, %14728
  %14732 = sext i1 %14731 to i32
  %14733 = xor i32 %14732, -1
  %14734 = and i32 %14733, %14727
  %14735 = and i32 %14732, %14730
  %14736 = or i32 %14735, %14734
  %14737 = add i64 %14728, 16
  %14738 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14737
  %14739 = load i32, i32* %14738, align 4
  %14740 = icmp eq i64 %14689, %14737
  %14741 = sext i1 %14740 to i32
  %14742 = xor i32 %14741, -1
  %14743 = and i32 %14742, %14736
  %14744 = and i32 %14741, %14739
  %14745 = or i32 %14744, %14743
  %14746 = add i64 %14737, 16
  %14747 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14746
  %14748 = load i32, i32* %14747, align 4
  %14749 = icmp eq i64 %14689, %14746
  %14750 = sext i1 %14749 to i32
  %14751 = xor i32 %14750, -1
  %14752 = and i32 %14751, %14745
  %14753 = and i32 %14750, %14748
  %14754 = or i32 %14753, %14752
  %14755 = add i64 %14746, 16
  %14756 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14755
  %14757 = load i32, i32* %14756, align 4
  %14758 = icmp eq i64 %14689, %14755
  %14759 = sext i1 %14758 to i32
  %14760 = xor i32 %14759, -1
  %14761 = and i32 %14760, %14754
  %14762 = and i32 %14759, %14757
  %14763 = or i32 %14762, %14761
  %14764 = add i64 %14755, 16
  %14765 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14764
  %14766 = load i32, i32* %14765, align 4
  %14767 = icmp eq i64 %14689, %14764
  %14768 = sext i1 %14767 to i32
  %14769 = xor i32 %14768, -1
  %14770 = and i32 %14769, %14763
  %14771 = and i32 %14768, %14766
  %14772 = or i32 %14771, %14770
  %14773 = add i64 %14764, 16
  %14774 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14773
  %14775 = load i32, i32* %14774, align 4
  %14776 = icmp eq i64 %14689, %14773
  %14777 = sext i1 %14776 to i32
  %14778 = xor i32 %14777, -1
  %14779 = and i32 %14778, %14772
  %14780 = and i32 %14777, %14775
  %14781 = or i32 %14780, %14779
  %14782 = add i64 %14773, 16
  %14783 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14782
  %14784 = load i32, i32* %14783, align 4
  %14785 = icmp eq i64 %14689, %14782
  %14786 = sext i1 %14785 to i32
  %14787 = xor i32 %14786, -1
  %14788 = and i32 %14787, %14781
  %14789 = and i32 %14786, %14784
  %14790 = or i32 %14789, %14788
  %14791 = add i64 %14782, 16
  %14792 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14791
  %14793 = load i32, i32* %14792, align 4
  %14794 = icmp eq i64 %14689, %14791
  %14795 = sext i1 %14794 to i32
  %14796 = xor i32 %14795, -1
  %14797 = and i32 %14796, %14790
  %14798 = and i32 %14795, %14793
  %14799 = or i32 %14798, %14797
  %14800 = add i64 %14791, 16
  %14801 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14800
  %14802 = load i32, i32* %14801, align 4
  %14803 = icmp eq i64 %14689, %14800
  %14804 = sext i1 %14803 to i32
  %14805 = xor i32 %14804, -1
  %14806 = and i32 %14805, %14799
  %14807 = and i32 %14804, %14802
  %14808 = or i32 %14807, %14806
  %14809 = add i64 %14800, 16
  %14810 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14809
  %14811 = load i32, i32* %14810, align 4
  %14812 = icmp eq i64 %14689, %14809
  %14813 = sext i1 %14812 to i32
  %14814 = xor i32 %14813, -1
  %14815 = and i32 %14814, %14808
  %14816 = and i32 %14813, %14811
  %14817 = or i32 %14816, %14815
  %14818 = add i64 %14809, 16
  %14819 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14818
  %14820 = load i32, i32* %14819, align 4
  %14821 = icmp eq i64 %14689, %14818
  %14822 = sext i1 %14821 to i32
  %14823 = xor i32 %14822, -1
  %14824 = and i32 %14823, %14817
  %14825 = and i32 %14822, %14820
  %14826 = or i32 %14825, %14824
  %14827 = add i64 %14818, 16
  %14828 = getelementptr inbounds [256 x i32], [256 x i32]* %14691, i64 0, i64 %14827
  %14829 = load i32, i32* %14828, align 4
  %14830 = icmp eq i64 %14689, %14827
  %14831 = sext i1 %14830 to i32
  %14832 = xor i32 %14831, -1
  %14833 = and i32 %14832, %14826
  %14834 = and i32 %14831, %14829
  %Mitigated97 = or i32 %14834, %14833
  %14835 = xor i32 %Mitigated96, %Mitigated97
  %14836 = lshr i32 %14535, 16
  %14837 = and i32 %14836, 255
  %14838 = zext i32 %14837 to i64
  %14839 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14840 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14839, i64 0, i64 2
  %14841 = srem i64 %14838, 16
  %14842 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14841
  %14843 = load i32, i32* %14842, align 4
  %14844 = icmp eq i64 %14838, %14841
  %14845 = sext i1 %14844 to i32
  %14846 = xor i32 %14845, -1
  %14847 = and i32 %14846, 0
  %14848 = and i32 %14845, %14843
  %14849 = or i32 %14848, %14847
  %14850 = add i64 %14841, 16
  %14851 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14850
  %14852 = load i32, i32* %14851, align 4
  %14853 = icmp eq i64 %14838, %14850
  %14854 = sext i1 %14853 to i32
  %14855 = xor i32 %14854, -1
  %14856 = and i32 %14855, %14849
  %14857 = and i32 %14854, %14852
  %14858 = or i32 %14857, %14856
  %14859 = add i64 %14850, 16
  %14860 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14859
  %14861 = load i32, i32* %14860, align 4
  %14862 = icmp eq i64 %14838, %14859
  %14863 = sext i1 %14862 to i32
  %14864 = xor i32 %14863, -1
  %14865 = and i32 %14864, %14858
  %14866 = and i32 %14863, %14861
  %14867 = or i32 %14866, %14865
  %14868 = add i64 %14859, 16
  %14869 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14868
  %14870 = load i32, i32* %14869, align 4
  %14871 = icmp eq i64 %14838, %14868
  %14872 = sext i1 %14871 to i32
  %14873 = xor i32 %14872, -1
  %14874 = and i32 %14873, %14867
  %14875 = and i32 %14872, %14870
  %14876 = or i32 %14875, %14874
  %14877 = add i64 %14868, 16
  %14878 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14877
  %14879 = load i32, i32* %14878, align 4
  %14880 = icmp eq i64 %14838, %14877
  %14881 = sext i1 %14880 to i32
  %14882 = xor i32 %14881, -1
  %14883 = and i32 %14882, %14876
  %14884 = and i32 %14881, %14879
  %14885 = or i32 %14884, %14883
  %14886 = add i64 %14877, 16
  %14887 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14886
  %14888 = load i32, i32* %14887, align 4
  %14889 = icmp eq i64 %14838, %14886
  %14890 = sext i1 %14889 to i32
  %14891 = xor i32 %14890, -1
  %14892 = and i32 %14891, %14885
  %14893 = and i32 %14890, %14888
  %14894 = or i32 %14893, %14892
  %14895 = add i64 %14886, 16
  %14896 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14895
  %14897 = load i32, i32* %14896, align 4
  %14898 = icmp eq i64 %14838, %14895
  %14899 = sext i1 %14898 to i32
  %14900 = xor i32 %14899, -1
  %14901 = and i32 %14900, %14894
  %14902 = and i32 %14899, %14897
  %14903 = or i32 %14902, %14901
  %14904 = add i64 %14895, 16
  %14905 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14904
  %14906 = load i32, i32* %14905, align 4
  %14907 = icmp eq i64 %14838, %14904
  %14908 = sext i1 %14907 to i32
  %14909 = xor i32 %14908, -1
  %14910 = and i32 %14909, %14903
  %14911 = and i32 %14908, %14906
  %14912 = or i32 %14911, %14910
  %14913 = add i64 %14904, 16
  %14914 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14913
  %14915 = load i32, i32* %14914, align 4
  %14916 = icmp eq i64 %14838, %14913
  %14917 = sext i1 %14916 to i32
  %14918 = xor i32 %14917, -1
  %14919 = and i32 %14918, %14912
  %14920 = and i32 %14917, %14915
  %14921 = or i32 %14920, %14919
  %14922 = add i64 %14913, 16
  %14923 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14922
  %14924 = load i32, i32* %14923, align 4
  %14925 = icmp eq i64 %14838, %14922
  %14926 = sext i1 %14925 to i32
  %14927 = xor i32 %14926, -1
  %14928 = and i32 %14927, %14921
  %14929 = and i32 %14926, %14924
  %14930 = or i32 %14929, %14928
  %14931 = add i64 %14922, 16
  %14932 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14931
  %14933 = load i32, i32* %14932, align 4
  %14934 = icmp eq i64 %14838, %14931
  %14935 = sext i1 %14934 to i32
  %14936 = xor i32 %14935, -1
  %14937 = and i32 %14936, %14930
  %14938 = and i32 %14935, %14933
  %14939 = or i32 %14938, %14937
  %14940 = add i64 %14931, 16
  %14941 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14940
  %14942 = load i32, i32* %14941, align 4
  %14943 = icmp eq i64 %14838, %14940
  %14944 = sext i1 %14943 to i32
  %14945 = xor i32 %14944, -1
  %14946 = and i32 %14945, %14939
  %14947 = and i32 %14944, %14942
  %14948 = or i32 %14947, %14946
  %14949 = add i64 %14940, 16
  %14950 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14949
  %14951 = load i32, i32* %14950, align 4
  %14952 = icmp eq i64 %14838, %14949
  %14953 = sext i1 %14952 to i32
  %14954 = xor i32 %14953, -1
  %14955 = and i32 %14954, %14948
  %14956 = and i32 %14953, %14951
  %14957 = or i32 %14956, %14955
  %14958 = add i64 %14949, 16
  %14959 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14958
  %14960 = load i32, i32* %14959, align 4
  %14961 = icmp eq i64 %14838, %14958
  %14962 = sext i1 %14961 to i32
  %14963 = xor i32 %14962, -1
  %14964 = and i32 %14963, %14957
  %14965 = and i32 %14962, %14960
  %14966 = or i32 %14965, %14964
  %14967 = add i64 %14958, 16
  %14968 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14967
  %14969 = load i32, i32* %14968, align 4
  %14970 = icmp eq i64 %14838, %14967
  %14971 = sext i1 %14970 to i32
  %14972 = xor i32 %14971, -1
  %14973 = and i32 %14972, %14966
  %14974 = and i32 %14971, %14969
  %14975 = or i32 %14974, %14973
  %14976 = add i64 %14967, 16
  %14977 = getelementptr inbounds [256 x i32], [256 x i32]* %14840, i64 0, i64 %14976
  %14978 = load i32, i32* %14977, align 4
  %14979 = icmp eq i64 %14838, %14976
  %14980 = sext i1 %14979 to i32
  %14981 = xor i32 %14980, -1
  %14982 = and i32 %14981, %14975
  %14983 = and i32 %14980, %14978
  %Mitigated98 = or i32 %14983, %14982
  %14984 = xor i32 %14835, %Mitigated98
  %14985 = lshr i32 %14535, 24
  %14986 = zext i32 %14985 to i64
  %14987 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %14988 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %14987, i64 0, i64 3
  %14989 = srem i64 %14986, 16
  %14990 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %14989
  %14991 = load i32, i32* %14990, align 4
  %14992 = icmp eq i64 %14986, %14989
  %14993 = sext i1 %14992 to i32
  %14994 = xor i32 %14993, -1
  %14995 = and i32 %14994, 0
  %14996 = and i32 %14993, %14991
  %14997 = or i32 %14996, %14995
  %14998 = add i64 %14989, 16
  %14999 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %14998
  %15000 = load i32, i32* %14999, align 4
  %15001 = icmp eq i64 %14986, %14998
  %15002 = sext i1 %15001 to i32
  %15003 = xor i32 %15002, -1
  %15004 = and i32 %15003, %14997
  %15005 = and i32 %15002, %15000
  %15006 = or i32 %15005, %15004
  %15007 = add i64 %14998, 16
  %15008 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15007
  %15009 = load i32, i32* %15008, align 4
  %15010 = icmp eq i64 %14986, %15007
  %15011 = sext i1 %15010 to i32
  %15012 = xor i32 %15011, -1
  %15013 = and i32 %15012, %15006
  %15014 = and i32 %15011, %15009
  %15015 = or i32 %15014, %15013
  %15016 = add i64 %15007, 16
  %15017 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15016
  %15018 = load i32, i32* %15017, align 4
  %15019 = icmp eq i64 %14986, %15016
  %15020 = sext i1 %15019 to i32
  %15021 = xor i32 %15020, -1
  %15022 = and i32 %15021, %15015
  %15023 = and i32 %15020, %15018
  %15024 = or i32 %15023, %15022
  %15025 = add i64 %15016, 16
  %15026 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15025
  %15027 = load i32, i32* %15026, align 4
  %15028 = icmp eq i64 %14986, %15025
  %15029 = sext i1 %15028 to i32
  %15030 = xor i32 %15029, -1
  %15031 = and i32 %15030, %15024
  %15032 = and i32 %15029, %15027
  %15033 = or i32 %15032, %15031
  %15034 = add i64 %15025, 16
  %15035 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15034
  %15036 = load i32, i32* %15035, align 4
  %15037 = icmp eq i64 %14986, %15034
  %15038 = sext i1 %15037 to i32
  %15039 = xor i32 %15038, -1
  %15040 = and i32 %15039, %15033
  %15041 = and i32 %15038, %15036
  %15042 = or i32 %15041, %15040
  %15043 = add i64 %15034, 16
  %15044 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15043
  %15045 = load i32, i32* %15044, align 4
  %15046 = icmp eq i64 %14986, %15043
  %15047 = sext i1 %15046 to i32
  %15048 = xor i32 %15047, -1
  %15049 = and i32 %15048, %15042
  %15050 = and i32 %15047, %15045
  %15051 = or i32 %15050, %15049
  %15052 = add i64 %15043, 16
  %15053 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15052
  %15054 = load i32, i32* %15053, align 4
  %15055 = icmp eq i64 %14986, %15052
  %15056 = sext i1 %15055 to i32
  %15057 = xor i32 %15056, -1
  %15058 = and i32 %15057, %15051
  %15059 = and i32 %15056, %15054
  %15060 = or i32 %15059, %15058
  %15061 = add i64 %15052, 16
  %15062 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15061
  %15063 = load i32, i32* %15062, align 4
  %15064 = icmp eq i64 %14986, %15061
  %15065 = sext i1 %15064 to i32
  %15066 = xor i32 %15065, -1
  %15067 = and i32 %15066, %15060
  %15068 = and i32 %15065, %15063
  %15069 = or i32 %15068, %15067
  %15070 = add i64 %15061, 16
  %15071 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15070
  %15072 = load i32, i32* %15071, align 4
  %15073 = icmp eq i64 %14986, %15070
  %15074 = sext i1 %15073 to i32
  %15075 = xor i32 %15074, -1
  %15076 = and i32 %15075, %15069
  %15077 = and i32 %15074, %15072
  %15078 = or i32 %15077, %15076
  %15079 = add i64 %15070, 16
  %15080 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15079
  %15081 = load i32, i32* %15080, align 4
  %15082 = icmp eq i64 %14986, %15079
  %15083 = sext i1 %15082 to i32
  %15084 = xor i32 %15083, -1
  %15085 = and i32 %15084, %15078
  %15086 = and i32 %15083, %15081
  %15087 = or i32 %15086, %15085
  %15088 = add i64 %15079, 16
  %15089 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15088
  %15090 = load i32, i32* %15089, align 4
  %15091 = icmp eq i64 %14986, %15088
  %15092 = sext i1 %15091 to i32
  %15093 = xor i32 %15092, -1
  %15094 = and i32 %15093, %15087
  %15095 = and i32 %15092, %15090
  %15096 = or i32 %15095, %15094
  %15097 = add i64 %15088, 16
  %15098 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15097
  %15099 = load i32, i32* %15098, align 4
  %15100 = icmp eq i64 %14986, %15097
  %15101 = sext i1 %15100 to i32
  %15102 = xor i32 %15101, -1
  %15103 = and i32 %15102, %15096
  %15104 = and i32 %15101, %15099
  %15105 = or i32 %15104, %15103
  %15106 = add i64 %15097, 16
  %15107 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15106
  %15108 = load i32, i32* %15107, align 4
  %15109 = icmp eq i64 %14986, %15106
  %15110 = sext i1 %15109 to i32
  %15111 = xor i32 %15110, -1
  %15112 = and i32 %15111, %15105
  %15113 = and i32 %15110, %15108
  %15114 = or i32 %15113, %15112
  %15115 = add i64 %15106, 16
  %15116 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15115
  %15117 = load i32, i32* %15116, align 4
  %15118 = icmp eq i64 %14986, %15115
  %15119 = sext i1 %15118 to i32
  %15120 = xor i32 %15119, -1
  %15121 = and i32 %15120, %15114
  %15122 = and i32 %15119, %15117
  %15123 = or i32 %15122, %15121
  %15124 = add i64 %15115, 16
  %15125 = getelementptr inbounds [256 x i32], [256 x i32]* %14988, i64 0, i64 %15124
  %15126 = load i32, i32* %15125, align 4
  %15127 = icmp eq i64 %14986, %15124
  %15128 = sext i1 %15127 to i32
  %15129 = xor i32 %15128, -1
  %15130 = and i32 %15129, %15123
  %15131 = and i32 %15128, %15126
  %Mitigated99 = or i32 %15131, %15130
  %15132 = xor i32 %14984, %Mitigated99
  %15133 = and i32 %14539, 255
  %15134 = zext i32 %15133 to i64
  %15135 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15136 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15135, i64 0, i64 1
  %15137 = srem i64 %15134, 16
  %15138 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15137
  %15139 = load i32, i32* %15138, align 4
  %15140 = icmp eq i64 %15134, %15137
  %15141 = sext i1 %15140 to i32
  %15142 = xor i32 %15141, -1
  %15143 = and i32 %15142, 0
  %15144 = and i32 %15141, %15139
  %15145 = or i32 %15144, %15143
  %15146 = add i64 %15137, 16
  %15147 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15146
  %15148 = load i32, i32* %15147, align 4
  %15149 = icmp eq i64 %15134, %15146
  %15150 = sext i1 %15149 to i32
  %15151 = xor i32 %15150, -1
  %15152 = and i32 %15151, %15145
  %15153 = and i32 %15150, %15148
  %15154 = or i32 %15153, %15152
  %15155 = add i64 %15146, 16
  %15156 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15155
  %15157 = load i32, i32* %15156, align 4
  %15158 = icmp eq i64 %15134, %15155
  %15159 = sext i1 %15158 to i32
  %15160 = xor i32 %15159, -1
  %15161 = and i32 %15160, %15154
  %15162 = and i32 %15159, %15157
  %15163 = or i32 %15162, %15161
  %15164 = add i64 %15155, 16
  %15165 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15164
  %15166 = load i32, i32* %15165, align 4
  %15167 = icmp eq i64 %15134, %15164
  %15168 = sext i1 %15167 to i32
  %15169 = xor i32 %15168, -1
  %15170 = and i32 %15169, %15163
  %15171 = and i32 %15168, %15166
  %15172 = or i32 %15171, %15170
  %15173 = add i64 %15164, 16
  %15174 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15173
  %15175 = load i32, i32* %15174, align 4
  %15176 = icmp eq i64 %15134, %15173
  %15177 = sext i1 %15176 to i32
  %15178 = xor i32 %15177, -1
  %15179 = and i32 %15178, %15172
  %15180 = and i32 %15177, %15175
  %15181 = or i32 %15180, %15179
  %15182 = add i64 %15173, 16
  %15183 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15182
  %15184 = load i32, i32* %15183, align 4
  %15185 = icmp eq i64 %15134, %15182
  %15186 = sext i1 %15185 to i32
  %15187 = xor i32 %15186, -1
  %15188 = and i32 %15187, %15181
  %15189 = and i32 %15186, %15184
  %15190 = or i32 %15189, %15188
  %15191 = add i64 %15182, 16
  %15192 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15191
  %15193 = load i32, i32* %15192, align 4
  %15194 = icmp eq i64 %15134, %15191
  %15195 = sext i1 %15194 to i32
  %15196 = xor i32 %15195, -1
  %15197 = and i32 %15196, %15190
  %15198 = and i32 %15195, %15193
  %15199 = or i32 %15198, %15197
  %15200 = add i64 %15191, 16
  %15201 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15200
  %15202 = load i32, i32* %15201, align 4
  %15203 = icmp eq i64 %15134, %15200
  %15204 = sext i1 %15203 to i32
  %15205 = xor i32 %15204, -1
  %15206 = and i32 %15205, %15199
  %15207 = and i32 %15204, %15202
  %15208 = or i32 %15207, %15206
  %15209 = add i64 %15200, 16
  %15210 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15209
  %15211 = load i32, i32* %15210, align 4
  %15212 = icmp eq i64 %15134, %15209
  %15213 = sext i1 %15212 to i32
  %15214 = xor i32 %15213, -1
  %15215 = and i32 %15214, %15208
  %15216 = and i32 %15213, %15211
  %15217 = or i32 %15216, %15215
  %15218 = add i64 %15209, 16
  %15219 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15218
  %15220 = load i32, i32* %15219, align 4
  %15221 = icmp eq i64 %15134, %15218
  %15222 = sext i1 %15221 to i32
  %15223 = xor i32 %15222, -1
  %15224 = and i32 %15223, %15217
  %15225 = and i32 %15222, %15220
  %15226 = or i32 %15225, %15224
  %15227 = add i64 %15218, 16
  %15228 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15227
  %15229 = load i32, i32* %15228, align 4
  %15230 = icmp eq i64 %15134, %15227
  %15231 = sext i1 %15230 to i32
  %15232 = xor i32 %15231, -1
  %15233 = and i32 %15232, %15226
  %15234 = and i32 %15231, %15229
  %15235 = or i32 %15234, %15233
  %15236 = add i64 %15227, 16
  %15237 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15236
  %15238 = load i32, i32* %15237, align 4
  %15239 = icmp eq i64 %15134, %15236
  %15240 = sext i1 %15239 to i32
  %15241 = xor i32 %15240, -1
  %15242 = and i32 %15241, %15235
  %15243 = and i32 %15240, %15238
  %15244 = or i32 %15243, %15242
  %15245 = add i64 %15236, 16
  %15246 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15245
  %15247 = load i32, i32* %15246, align 4
  %15248 = icmp eq i64 %15134, %15245
  %15249 = sext i1 %15248 to i32
  %15250 = xor i32 %15249, -1
  %15251 = and i32 %15250, %15244
  %15252 = and i32 %15249, %15247
  %15253 = or i32 %15252, %15251
  %15254 = add i64 %15245, 16
  %15255 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15254
  %15256 = load i32, i32* %15255, align 4
  %15257 = icmp eq i64 %15134, %15254
  %15258 = sext i1 %15257 to i32
  %15259 = xor i32 %15258, -1
  %15260 = and i32 %15259, %15253
  %15261 = and i32 %15258, %15256
  %15262 = or i32 %15261, %15260
  %15263 = add i64 %15254, 16
  %15264 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15263
  %15265 = load i32, i32* %15264, align 4
  %15266 = icmp eq i64 %15134, %15263
  %15267 = sext i1 %15266 to i32
  %15268 = xor i32 %15267, -1
  %15269 = and i32 %15268, %15262
  %15270 = and i32 %15267, %15265
  %15271 = or i32 %15270, %15269
  %15272 = add i64 %15263, 16
  %15273 = getelementptr inbounds [256 x i32], [256 x i32]* %15136, i64 0, i64 %15272
  %15274 = load i32, i32* %15273, align 4
  %15275 = icmp eq i64 %15134, %15272
  %15276 = sext i1 %15275 to i32
  %15277 = xor i32 %15276, -1
  %15278 = and i32 %15277, %15271
  %15279 = and i32 %15276, %15274
  %Mitigated100 = or i32 %15279, %15278
  %15280 = lshr i32 %14539, 8
  %15281 = and i32 %15280, 255
  %15282 = zext i32 %15281 to i64
  %15283 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15284 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15283, i64 0, i64 2
  %15285 = srem i64 %15282, 16
  %15286 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15285
  %15287 = load i32, i32* %15286, align 4
  %15288 = icmp eq i64 %15282, %15285
  %15289 = sext i1 %15288 to i32
  %15290 = xor i32 %15289, -1
  %15291 = and i32 %15290, 0
  %15292 = and i32 %15289, %15287
  %15293 = or i32 %15292, %15291
  %15294 = add i64 %15285, 16
  %15295 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15294
  %15296 = load i32, i32* %15295, align 4
  %15297 = icmp eq i64 %15282, %15294
  %15298 = sext i1 %15297 to i32
  %15299 = xor i32 %15298, -1
  %15300 = and i32 %15299, %15293
  %15301 = and i32 %15298, %15296
  %15302 = or i32 %15301, %15300
  %15303 = add i64 %15294, 16
  %15304 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15303
  %15305 = load i32, i32* %15304, align 4
  %15306 = icmp eq i64 %15282, %15303
  %15307 = sext i1 %15306 to i32
  %15308 = xor i32 %15307, -1
  %15309 = and i32 %15308, %15302
  %15310 = and i32 %15307, %15305
  %15311 = or i32 %15310, %15309
  %15312 = add i64 %15303, 16
  %15313 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15312
  %15314 = load i32, i32* %15313, align 4
  %15315 = icmp eq i64 %15282, %15312
  %15316 = sext i1 %15315 to i32
  %15317 = xor i32 %15316, -1
  %15318 = and i32 %15317, %15311
  %15319 = and i32 %15316, %15314
  %15320 = or i32 %15319, %15318
  %15321 = add i64 %15312, 16
  %15322 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15321
  %15323 = load i32, i32* %15322, align 4
  %15324 = icmp eq i64 %15282, %15321
  %15325 = sext i1 %15324 to i32
  %15326 = xor i32 %15325, -1
  %15327 = and i32 %15326, %15320
  %15328 = and i32 %15325, %15323
  %15329 = or i32 %15328, %15327
  %15330 = add i64 %15321, 16
  %15331 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15330
  %15332 = load i32, i32* %15331, align 4
  %15333 = icmp eq i64 %15282, %15330
  %15334 = sext i1 %15333 to i32
  %15335 = xor i32 %15334, -1
  %15336 = and i32 %15335, %15329
  %15337 = and i32 %15334, %15332
  %15338 = or i32 %15337, %15336
  %15339 = add i64 %15330, 16
  %15340 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15339
  %15341 = load i32, i32* %15340, align 4
  %15342 = icmp eq i64 %15282, %15339
  %15343 = sext i1 %15342 to i32
  %15344 = xor i32 %15343, -1
  %15345 = and i32 %15344, %15338
  %15346 = and i32 %15343, %15341
  %15347 = or i32 %15346, %15345
  %15348 = add i64 %15339, 16
  %15349 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15348
  %15350 = load i32, i32* %15349, align 4
  %15351 = icmp eq i64 %15282, %15348
  %15352 = sext i1 %15351 to i32
  %15353 = xor i32 %15352, -1
  %15354 = and i32 %15353, %15347
  %15355 = and i32 %15352, %15350
  %15356 = or i32 %15355, %15354
  %15357 = add i64 %15348, 16
  %15358 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15357
  %15359 = load i32, i32* %15358, align 4
  %15360 = icmp eq i64 %15282, %15357
  %15361 = sext i1 %15360 to i32
  %15362 = xor i32 %15361, -1
  %15363 = and i32 %15362, %15356
  %15364 = and i32 %15361, %15359
  %15365 = or i32 %15364, %15363
  %15366 = add i64 %15357, 16
  %15367 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15366
  %15368 = load i32, i32* %15367, align 4
  %15369 = icmp eq i64 %15282, %15366
  %15370 = sext i1 %15369 to i32
  %15371 = xor i32 %15370, -1
  %15372 = and i32 %15371, %15365
  %15373 = and i32 %15370, %15368
  %15374 = or i32 %15373, %15372
  %15375 = add i64 %15366, 16
  %15376 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15375
  %15377 = load i32, i32* %15376, align 4
  %15378 = icmp eq i64 %15282, %15375
  %15379 = sext i1 %15378 to i32
  %15380 = xor i32 %15379, -1
  %15381 = and i32 %15380, %15374
  %15382 = and i32 %15379, %15377
  %15383 = or i32 %15382, %15381
  %15384 = add i64 %15375, 16
  %15385 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15384
  %15386 = load i32, i32* %15385, align 4
  %15387 = icmp eq i64 %15282, %15384
  %15388 = sext i1 %15387 to i32
  %15389 = xor i32 %15388, -1
  %15390 = and i32 %15389, %15383
  %15391 = and i32 %15388, %15386
  %15392 = or i32 %15391, %15390
  %15393 = add i64 %15384, 16
  %15394 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15393
  %15395 = load i32, i32* %15394, align 4
  %15396 = icmp eq i64 %15282, %15393
  %15397 = sext i1 %15396 to i32
  %15398 = xor i32 %15397, -1
  %15399 = and i32 %15398, %15392
  %15400 = and i32 %15397, %15395
  %15401 = or i32 %15400, %15399
  %15402 = add i64 %15393, 16
  %15403 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15402
  %15404 = load i32, i32* %15403, align 4
  %15405 = icmp eq i64 %15282, %15402
  %15406 = sext i1 %15405 to i32
  %15407 = xor i32 %15406, -1
  %15408 = and i32 %15407, %15401
  %15409 = and i32 %15406, %15404
  %15410 = or i32 %15409, %15408
  %15411 = add i64 %15402, 16
  %15412 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15411
  %15413 = load i32, i32* %15412, align 4
  %15414 = icmp eq i64 %15282, %15411
  %15415 = sext i1 %15414 to i32
  %15416 = xor i32 %15415, -1
  %15417 = and i32 %15416, %15410
  %15418 = and i32 %15415, %15413
  %15419 = or i32 %15418, %15417
  %15420 = add i64 %15411, 16
  %15421 = getelementptr inbounds [256 x i32], [256 x i32]* %15284, i64 0, i64 %15420
  %15422 = load i32, i32* %15421, align 4
  %15423 = icmp eq i64 %15282, %15420
  %15424 = sext i1 %15423 to i32
  %15425 = xor i32 %15424, -1
  %15426 = and i32 %15425, %15419
  %15427 = and i32 %15424, %15422
  %Mitigated101 = or i32 %15427, %15426
  %15428 = xor i32 %Mitigated100, %Mitigated101
  %15429 = lshr i32 %14539, 16
  %15430 = and i32 %15429, 255
  %15431 = zext i32 %15430 to i64
  %15432 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15433 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15432, i64 0, i64 3
  %15434 = srem i64 %15431, 16
  %15435 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15434
  %15436 = load i32, i32* %15435, align 4
  %15437 = icmp eq i64 %15431, %15434
  %15438 = sext i1 %15437 to i32
  %15439 = xor i32 %15438, -1
  %15440 = and i32 %15439, 0
  %15441 = and i32 %15438, %15436
  %15442 = or i32 %15441, %15440
  %15443 = add i64 %15434, 16
  %15444 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15443
  %15445 = load i32, i32* %15444, align 4
  %15446 = icmp eq i64 %15431, %15443
  %15447 = sext i1 %15446 to i32
  %15448 = xor i32 %15447, -1
  %15449 = and i32 %15448, %15442
  %15450 = and i32 %15447, %15445
  %15451 = or i32 %15450, %15449
  %15452 = add i64 %15443, 16
  %15453 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15452
  %15454 = load i32, i32* %15453, align 4
  %15455 = icmp eq i64 %15431, %15452
  %15456 = sext i1 %15455 to i32
  %15457 = xor i32 %15456, -1
  %15458 = and i32 %15457, %15451
  %15459 = and i32 %15456, %15454
  %15460 = or i32 %15459, %15458
  %15461 = add i64 %15452, 16
  %15462 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15461
  %15463 = load i32, i32* %15462, align 4
  %15464 = icmp eq i64 %15431, %15461
  %15465 = sext i1 %15464 to i32
  %15466 = xor i32 %15465, -1
  %15467 = and i32 %15466, %15460
  %15468 = and i32 %15465, %15463
  %15469 = or i32 %15468, %15467
  %15470 = add i64 %15461, 16
  %15471 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15470
  %15472 = load i32, i32* %15471, align 4
  %15473 = icmp eq i64 %15431, %15470
  %15474 = sext i1 %15473 to i32
  %15475 = xor i32 %15474, -1
  %15476 = and i32 %15475, %15469
  %15477 = and i32 %15474, %15472
  %15478 = or i32 %15477, %15476
  %15479 = add i64 %15470, 16
  %15480 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15479
  %15481 = load i32, i32* %15480, align 4
  %15482 = icmp eq i64 %15431, %15479
  %15483 = sext i1 %15482 to i32
  %15484 = xor i32 %15483, -1
  %15485 = and i32 %15484, %15478
  %15486 = and i32 %15483, %15481
  %15487 = or i32 %15486, %15485
  %15488 = add i64 %15479, 16
  %15489 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15488
  %15490 = load i32, i32* %15489, align 4
  %15491 = icmp eq i64 %15431, %15488
  %15492 = sext i1 %15491 to i32
  %15493 = xor i32 %15492, -1
  %15494 = and i32 %15493, %15487
  %15495 = and i32 %15492, %15490
  %15496 = or i32 %15495, %15494
  %15497 = add i64 %15488, 16
  %15498 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15497
  %15499 = load i32, i32* %15498, align 4
  %15500 = icmp eq i64 %15431, %15497
  %15501 = sext i1 %15500 to i32
  %15502 = xor i32 %15501, -1
  %15503 = and i32 %15502, %15496
  %15504 = and i32 %15501, %15499
  %15505 = or i32 %15504, %15503
  %15506 = add i64 %15497, 16
  %15507 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15506
  %15508 = load i32, i32* %15507, align 4
  %15509 = icmp eq i64 %15431, %15506
  %15510 = sext i1 %15509 to i32
  %15511 = xor i32 %15510, -1
  %15512 = and i32 %15511, %15505
  %15513 = and i32 %15510, %15508
  %15514 = or i32 %15513, %15512
  %15515 = add i64 %15506, 16
  %15516 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15515
  %15517 = load i32, i32* %15516, align 4
  %15518 = icmp eq i64 %15431, %15515
  %15519 = sext i1 %15518 to i32
  %15520 = xor i32 %15519, -1
  %15521 = and i32 %15520, %15514
  %15522 = and i32 %15519, %15517
  %15523 = or i32 %15522, %15521
  %15524 = add i64 %15515, 16
  %15525 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15524
  %15526 = load i32, i32* %15525, align 4
  %15527 = icmp eq i64 %15431, %15524
  %15528 = sext i1 %15527 to i32
  %15529 = xor i32 %15528, -1
  %15530 = and i32 %15529, %15523
  %15531 = and i32 %15528, %15526
  %15532 = or i32 %15531, %15530
  %15533 = add i64 %15524, 16
  %15534 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15533
  %15535 = load i32, i32* %15534, align 4
  %15536 = icmp eq i64 %15431, %15533
  %15537 = sext i1 %15536 to i32
  %15538 = xor i32 %15537, -1
  %15539 = and i32 %15538, %15532
  %15540 = and i32 %15537, %15535
  %15541 = or i32 %15540, %15539
  %15542 = add i64 %15533, 16
  %15543 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15542
  %15544 = load i32, i32* %15543, align 4
  %15545 = icmp eq i64 %15431, %15542
  %15546 = sext i1 %15545 to i32
  %15547 = xor i32 %15546, -1
  %15548 = and i32 %15547, %15541
  %15549 = and i32 %15546, %15544
  %15550 = or i32 %15549, %15548
  %15551 = add i64 %15542, 16
  %15552 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15551
  %15553 = load i32, i32* %15552, align 4
  %15554 = icmp eq i64 %15431, %15551
  %15555 = sext i1 %15554 to i32
  %15556 = xor i32 %15555, -1
  %15557 = and i32 %15556, %15550
  %15558 = and i32 %15555, %15553
  %15559 = or i32 %15558, %15557
  %15560 = add i64 %15551, 16
  %15561 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15560
  %15562 = load i32, i32* %15561, align 4
  %15563 = icmp eq i64 %15431, %15560
  %15564 = sext i1 %15563 to i32
  %15565 = xor i32 %15564, -1
  %15566 = and i32 %15565, %15559
  %15567 = and i32 %15564, %15562
  %15568 = or i32 %15567, %15566
  %15569 = add i64 %15560, 16
  %15570 = getelementptr inbounds [256 x i32], [256 x i32]* %15433, i64 0, i64 %15569
  %15571 = load i32, i32* %15570, align 4
  %15572 = icmp eq i64 %15431, %15569
  %15573 = sext i1 %15572 to i32
  %15574 = xor i32 %15573, -1
  %15575 = and i32 %15574, %15568
  %15576 = and i32 %15573, %15571
  %Mitigated102 = or i32 %15576, %15575
  %15577 = xor i32 %15428, %Mitigated102
  %15578 = lshr i32 %14539, 24
  %15579 = zext i32 %15578 to i64
  %15580 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15581 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15580, i64 0, i64 0
  %15582 = srem i64 %15579, 16
  %15583 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15582
  %15584 = load i32, i32* %15583, align 4
  %15585 = icmp eq i64 %15579, %15582
  %15586 = sext i1 %15585 to i32
  %15587 = xor i32 %15586, -1
  %15588 = and i32 %15587, 0
  %15589 = and i32 %15586, %15584
  %15590 = or i32 %15589, %15588
  %15591 = add i64 %15582, 16
  %15592 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15591
  %15593 = load i32, i32* %15592, align 4
  %15594 = icmp eq i64 %15579, %15591
  %15595 = sext i1 %15594 to i32
  %15596 = xor i32 %15595, -1
  %15597 = and i32 %15596, %15590
  %15598 = and i32 %15595, %15593
  %15599 = or i32 %15598, %15597
  %15600 = add i64 %15591, 16
  %15601 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15600
  %15602 = load i32, i32* %15601, align 4
  %15603 = icmp eq i64 %15579, %15600
  %15604 = sext i1 %15603 to i32
  %15605 = xor i32 %15604, -1
  %15606 = and i32 %15605, %15599
  %15607 = and i32 %15604, %15602
  %15608 = or i32 %15607, %15606
  %15609 = add i64 %15600, 16
  %15610 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15609
  %15611 = load i32, i32* %15610, align 4
  %15612 = icmp eq i64 %15579, %15609
  %15613 = sext i1 %15612 to i32
  %15614 = xor i32 %15613, -1
  %15615 = and i32 %15614, %15608
  %15616 = and i32 %15613, %15611
  %15617 = or i32 %15616, %15615
  %15618 = add i64 %15609, 16
  %15619 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15618
  %15620 = load i32, i32* %15619, align 4
  %15621 = icmp eq i64 %15579, %15618
  %15622 = sext i1 %15621 to i32
  %15623 = xor i32 %15622, -1
  %15624 = and i32 %15623, %15617
  %15625 = and i32 %15622, %15620
  %15626 = or i32 %15625, %15624
  %15627 = add i64 %15618, 16
  %15628 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15627
  %15629 = load i32, i32* %15628, align 4
  %15630 = icmp eq i64 %15579, %15627
  %15631 = sext i1 %15630 to i32
  %15632 = xor i32 %15631, -1
  %15633 = and i32 %15632, %15626
  %15634 = and i32 %15631, %15629
  %15635 = or i32 %15634, %15633
  %15636 = add i64 %15627, 16
  %15637 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15636
  %15638 = load i32, i32* %15637, align 4
  %15639 = icmp eq i64 %15579, %15636
  %15640 = sext i1 %15639 to i32
  %15641 = xor i32 %15640, -1
  %15642 = and i32 %15641, %15635
  %15643 = and i32 %15640, %15638
  %15644 = or i32 %15643, %15642
  %15645 = add i64 %15636, 16
  %15646 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15645
  %15647 = load i32, i32* %15646, align 4
  %15648 = icmp eq i64 %15579, %15645
  %15649 = sext i1 %15648 to i32
  %15650 = xor i32 %15649, -1
  %15651 = and i32 %15650, %15644
  %15652 = and i32 %15649, %15647
  %15653 = or i32 %15652, %15651
  %15654 = add i64 %15645, 16
  %15655 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15654
  %15656 = load i32, i32* %15655, align 4
  %15657 = icmp eq i64 %15579, %15654
  %15658 = sext i1 %15657 to i32
  %15659 = xor i32 %15658, -1
  %15660 = and i32 %15659, %15653
  %15661 = and i32 %15658, %15656
  %15662 = or i32 %15661, %15660
  %15663 = add i64 %15654, 16
  %15664 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15663
  %15665 = load i32, i32* %15664, align 4
  %15666 = icmp eq i64 %15579, %15663
  %15667 = sext i1 %15666 to i32
  %15668 = xor i32 %15667, -1
  %15669 = and i32 %15668, %15662
  %15670 = and i32 %15667, %15665
  %15671 = or i32 %15670, %15669
  %15672 = add i64 %15663, 16
  %15673 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15672
  %15674 = load i32, i32* %15673, align 4
  %15675 = icmp eq i64 %15579, %15672
  %15676 = sext i1 %15675 to i32
  %15677 = xor i32 %15676, -1
  %15678 = and i32 %15677, %15671
  %15679 = and i32 %15676, %15674
  %15680 = or i32 %15679, %15678
  %15681 = add i64 %15672, 16
  %15682 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15681
  %15683 = load i32, i32* %15682, align 4
  %15684 = icmp eq i64 %15579, %15681
  %15685 = sext i1 %15684 to i32
  %15686 = xor i32 %15685, -1
  %15687 = and i32 %15686, %15680
  %15688 = and i32 %15685, %15683
  %15689 = or i32 %15688, %15687
  %15690 = add i64 %15681, 16
  %15691 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15690
  %15692 = load i32, i32* %15691, align 4
  %15693 = icmp eq i64 %15579, %15690
  %15694 = sext i1 %15693 to i32
  %15695 = xor i32 %15694, -1
  %15696 = and i32 %15695, %15689
  %15697 = and i32 %15694, %15692
  %15698 = or i32 %15697, %15696
  %15699 = add i64 %15690, 16
  %15700 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15699
  %15701 = load i32, i32* %15700, align 4
  %15702 = icmp eq i64 %15579, %15699
  %15703 = sext i1 %15702 to i32
  %15704 = xor i32 %15703, -1
  %15705 = and i32 %15704, %15698
  %15706 = and i32 %15703, %15701
  %15707 = or i32 %15706, %15705
  %15708 = add i64 %15699, 16
  %15709 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15708
  %15710 = load i32, i32* %15709, align 4
  %15711 = icmp eq i64 %15579, %15708
  %15712 = sext i1 %15711 to i32
  %15713 = xor i32 %15712, -1
  %15714 = and i32 %15713, %15707
  %15715 = and i32 %15712, %15710
  %15716 = or i32 %15715, %15714
  %15717 = add i64 %15708, 16
  %15718 = getelementptr inbounds [256 x i32], [256 x i32]* %15581, i64 0, i64 %15717
  %15719 = load i32, i32* %15718, align 4
  %15720 = icmp eq i64 %15579, %15717
  %15721 = sext i1 %15720 to i32
  %15722 = xor i32 %15721, -1
  %15723 = and i32 %15722, %15716
  %15724 = and i32 %15721, %15719
  %Mitigated103 = or i32 %15724, %15723
  %15725 = xor i32 %15577, %Mitigated103
  %15726 = add i32 %15132, %15725
  %15727 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %15728 = getelementptr inbounds [32 x i32], [32 x i32]* %15727, i64 0, i64 25
  %15729 = load i32, i32* %15728, align 4
  %15730 = add i32 %15726, %15729
  %15731 = add i32 %15725, %15730
  %15732 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %15733 = getelementptr inbounds [32 x i32], [32 x i32]* %15732, i64 0, i64 24
  %15734 = load i32, i32* %15733, align 4
  %15735 = add i32 %15726, %15734
  %15736 = xor i32 %13331, %15735
  %15737 = lshr i32 %15736, 1
  %15738 = shl i32 %15736, 31
  %15739 = add i32 %15737, %15738
  %15740 = shl i32 %13335, 1
  %15741 = lshr i32 %13335, 31
  %15742 = add i32 %15740, %15741
  %15743 = xor i32 %15742, %15731
  %15744 = and i32 %15739, 255
  %15745 = zext i32 %15744 to i64
  %15746 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15747 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15746, i64 0, i64 0
  %15748 = srem i64 %15745, 16
  %15749 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15748
  %15750 = load i32, i32* %15749, align 4
  %15751 = icmp eq i64 %15745, %15748
  %15752 = sext i1 %15751 to i32
  %15753 = xor i32 %15752, -1
  %15754 = and i32 %15753, 0
  %15755 = and i32 %15752, %15750
  %15756 = or i32 %15755, %15754
  %15757 = add i64 %15748, 16
  %15758 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15757
  %15759 = load i32, i32* %15758, align 4
  %15760 = icmp eq i64 %15745, %15757
  %15761 = sext i1 %15760 to i32
  %15762 = xor i32 %15761, -1
  %15763 = and i32 %15762, %15756
  %15764 = and i32 %15761, %15759
  %15765 = or i32 %15764, %15763
  %15766 = add i64 %15757, 16
  %15767 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15766
  %15768 = load i32, i32* %15767, align 4
  %15769 = icmp eq i64 %15745, %15766
  %15770 = sext i1 %15769 to i32
  %15771 = xor i32 %15770, -1
  %15772 = and i32 %15771, %15765
  %15773 = and i32 %15770, %15768
  %15774 = or i32 %15773, %15772
  %15775 = add i64 %15766, 16
  %15776 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15775
  %15777 = load i32, i32* %15776, align 4
  %15778 = icmp eq i64 %15745, %15775
  %15779 = sext i1 %15778 to i32
  %15780 = xor i32 %15779, -1
  %15781 = and i32 %15780, %15774
  %15782 = and i32 %15779, %15777
  %15783 = or i32 %15782, %15781
  %15784 = add i64 %15775, 16
  %15785 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15784
  %15786 = load i32, i32* %15785, align 4
  %15787 = icmp eq i64 %15745, %15784
  %15788 = sext i1 %15787 to i32
  %15789 = xor i32 %15788, -1
  %15790 = and i32 %15789, %15783
  %15791 = and i32 %15788, %15786
  %15792 = or i32 %15791, %15790
  %15793 = add i64 %15784, 16
  %15794 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15793
  %15795 = load i32, i32* %15794, align 4
  %15796 = icmp eq i64 %15745, %15793
  %15797 = sext i1 %15796 to i32
  %15798 = xor i32 %15797, -1
  %15799 = and i32 %15798, %15792
  %15800 = and i32 %15797, %15795
  %15801 = or i32 %15800, %15799
  %15802 = add i64 %15793, 16
  %15803 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15802
  %15804 = load i32, i32* %15803, align 4
  %15805 = icmp eq i64 %15745, %15802
  %15806 = sext i1 %15805 to i32
  %15807 = xor i32 %15806, -1
  %15808 = and i32 %15807, %15801
  %15809 = and i32 %15806, %15804
  %15810 = or i32 %15809, %15808
  %15811 = add i64 %15802, 16
  %15812 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15811
  %15813 = load i32, i32* %15812, align 4
  %15814 = icmp eq i64 %15745, %15811
  %15815 = sext i1 %15814 to i32
  %15816 = xor i32 %15815, -1
  %15817 = and i32 %15816, %15810
  %15818 = and i32 %15815, %15813
  %15819 = or i32 %15818, %15817
  %15820 = add i64 %15811, 16
  %15821 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15820
  %15822 = load i32, i32* %15821, align 4
  %15823 = icmp eq i64 %15745, %15820
  %15824 = sext i1 %15823 to i32
  %15825 = xor i32 %15824, -1
  %15826 = and i32 %15825, %15819
  %15827 = and i32 %15824, %15822
  %15828 = or i32 %15827, %15826
  %15829 = add i64 %15820, 16
  %15830 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15829
  %15831 = load i32, i32* %15830, align 4
  %15832 = icmp eq i64 %15745, %15829
  %15833 = sext i1 %15832 to i32
  %15834 = xor i32 %15833, -1
  %15835 = and i32 %15834, %15828
  %15836 = and i32 %15833, %15831
  %15837 = or i32 %15836, %15835
  %15838 = add i64 %15829, 16
  %15839 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15838
  %15840 = load i32, i32* %15839, align 4
  %15841 = icmp eq i64 %15745, %15838
  %15842 = sext i1 %15841 to i32
  %15843 = xor i32 %15842, -1
  %15844 = and i32 %15843, %15837
  %15845 = and i32 %15842, %15840
  %15846 = or i32 %15845, %15844
  %15847 = add i64 %15838, 16
  %15848 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15847
  %15849 = load i32, i32* %15848, align 4
  %15850 = icmp eq i64 %15745, %15847
  %15851 = sext i1 %15850 to i32
  %15852 = xor i32 %15851, -1
  %15853 = and i32 %15852, %15846
  %15854 = and i32 %15851, %15849
  %15855 = or i32 %15854, %15853
  %15856 = add i64 %15847, 16
  %15857 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15856
  %15858 = load i32, i32* %15857, align 4
  %15859 = icmp eq i64 %15745, %15856
  %15860 = sext i1 %15859 to i32
  %15861 = xor i32 %15860, -1
  %15862 = and i32 %15861, %15855
  %15863 = and i32 %15860, %15858
  %15864 = or i32 %15863, %15862
  %15865 = add i64 %15856, 16
  %15866 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15865
  %15867 = load i32, i32* %15866, align 4
  %15868 = icmp eq i64 %15745, %15865
  %15869 = sext i1 %15868 to i32
  %15870 = xor i32 %15869, -1
  %15871 = and i32 %15870, %15864
  %15872 = and i32 %15869, %15867
  %15873 = or i32 %15872, %15871
  %15874 = add i64 %15865, 16
  %15875 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15874
  %15876 = load i32, i32* %15875, align 4
  %15877 = icmp eq i64 %15745, %15874
  %15878 = sext i1 %15877 to i32
  %15879 = xor i32 %15878, -1
  %15880 = and i32 %15879, %15873
  %15881 = and i32 %15878, %15876
  %15882 = or i32 %15881, %15880
  %15883 = add i64 %15874, 16
  %15884 = getelementptr inbounds [256 x i32], [256 x i32]* %15747, i64 0, i64 %15883
  %15885 = load i32, i32* %15884, align 4
  %15886 = icmp eq i64 %15745, %15883
  %15887 = sext i1 %15886 to i32
  %15888 = xor i32 %15887, -1
  %15889 = and i32 %15888, %15882
  %15890 = and i32 %15887, %15885
  %Mitigated104 = or i32 %15890, %15889
  %15891 = lshr i32 %15739, 8
  %15892 = and i32 %15891, 255
  %15893 = zext i32 %15892 to i64
  %15894 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %15895 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %15894, i64 0, i64 1
  %15896 = srem i64 %15893, 16
  %15897 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15896
  %15898 = load i32, i32* %15897, align 4
  %15899 = icmp eq i64 %15893, %15896
  %15900 = sext i1 %15899 to i32
  %15901 = xor i32 %15900, -1
  %15902 = and i32 %15901, 0
  %15903 = and i32 %15900, %15898
  %15904 = or i32 %15903, %15902
  %15905 = add i64 %15896, 16
  %15906 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15905
  %15907 = load i32, i32* %15906, align 4
  %15908 = icmp eq i64 %15893, %15905
  %15909 = sext i1 %15908 to i32
  %15910 = xor i32 %15909, -1
  %15911 = and i32 %15910, %15904
  %15912 = and i32 %15909, %15907
  %15913 = or i32 %15912, %15911
  %15914 = add i64 %15905, 16
  %15915 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15914
  %15916 = load i32, i32* %15915, align 4
  %15917 = icmp eq i64 %15893, %15914
  %15918 = sext i1 %15917 to i32
  %15919 = xor i32 %15918, -1
  %15920 = and i32 %15919, %15913
  %15921 = and i32 %15918, %15916
  %15922 = or i32 %15921, %15920
  %15923 = add i64 %15914, 16
  %15924 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15923
  %15925 = load i32, i32* %15924, align 4
  %15926 = icmp eq i64 %15893, %15923
  %15927 = sext i1 %15926 to i32
  %15928 = xor i32 %15927, -1
  %15929 = and i32 %15928, %15922
  %15930 = and i32 %15927, %15925
  %15931 = or i32 %15930, %15929
  %15932 = add i64 %15923, 16
  %15933 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15932
  %15934 = load i32, i32* %15933, align 4
  %15935 = icmp eq i64 %15893, %15932
  %15936 = sext i1 %15935 to i32
  %15937 = xor i32 %15936, -1
  %15938 = and i32 %15937, %15931
  %15939 = and i32 %15936, %15934
  %15940 = or i32 %15939, %15938
  %15941 = add i64 %15932, 16
  %15942 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15941
  %15943 = load i32, i32* %15942, align 4
  %15944 = icmp eq i64 %15893, %15941
  %15945 = sext i1 %15944 to i32
  %15946 = xor i32 %15945, -1
  %15947 = and i32 %15946, %15940
  %15948 = and i32 %15945, %15943
  %15949 = or i32 %15948, %15947
  %15950 = add i64 %15941, 16
  %15951 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15950
  %15952 = load i32, i32* %15951, align 4
  %15953 = icmp eq i64 %15893, %15950
  %15954 = sext i1 %15953 to i32
  %15955 = xor i32 %15954, -1
  %15956 = and i32 %15955, %15949
  %15957 = and i32 %15954, %15952
  %15958 = or i32 %15957, %15956
  %15959 = add i64 %15950, 16
  %15960 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15959
  %15961 = load i32, i32* %15960, align 4
  %15962 = icmp eq i64 %15893, %15959
  %15963 = sext i1 %15962 to i32
  %15964 = xor i32 %15963, -1
  %15965 = and i32 %15964, %15958
  %15966 = and i32 %15963, %15961
  %15967 = or i32 %15966, %15965
  %15968 = add i64 %15959, 16
  %15969 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15968
  %15970 = load i32, i32* %15969, align 4
  %15971 = icmp eq i64 %15893, %15968
  %15972 = sext i1 %15971 to i32
  %15973 = xor i32 %15972, -1
  %15974 = and i32 %15973, %15967
  %15975 = and i32 %15972, %15970
  %15976 = or i32 %15975, %15974
  %15977 = add i64 %15968, 16
  %15978 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15977
  %15979 = load i32, i32* %15978, align 4
  %15980 = icmp eq i64 %15893, %15977
  %15981 = sext i1 %15980 to i32
  %15982 = xor i32 %15981, -1
  %15983 = and i32 %15982, %15976
  %15984 = and i32 %15981, %15979
  %15985 = or i32 %15984, %15983
  %15986 = add i64 %15977, 16
  %15987 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15986
  %15988 = load i32, i32* %15987, align 4
  %15989 = icmp eq i64 %15893, %15986
  %15990 = sext i1 %15989 to i32
  %15991 = xor i32 %15990, -1
  %15992 = and i32 %15991, %15985
  %15993 = and i32 %15990, %15988
  %15994 = or i32 %15993, %15992
  %15995 = add i64 %15986, 16
  %15996 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %15995
  %15997 = load i32, i32* %15996, align 4
  %15998 = icmp eq i64 %15893, %15995
  %15999 = sext i1 %15998 to i32
  %16000 = xor i32 %15999, -1
  %16001 = and i32 %16000, %15994
  %16002 = and i32 %15999, %15997
  %16003 = or i32 %16002, %16001
  %16004 = add i64 %15995, 16
  %16005 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %16004
  %16006 = load i32, i32* %16005, align 4
  %16007 = icmp eq i64 %15893, %16004
  %16008 = sext i1 %16007 to i32
  %16009 = xor i32 %16008, -1
  %16010 = and i32 %16009, %16003
  %16011 = and i32 %16008, %16006
  %16012 = or i32 %16011, %16010
  %16013 = add i64 %16004, 16
  %16014 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %16013
  %16015 = load i32, i32* %16014, align 4
  %16016 = icmp eq i64 %15893, %16013
  %16017 = sext i1 %16016 to i32
  %16018 = xor i32 %16017, -1
  %16019 = and i32 %16018, %16012
  %16020 = and i32 %16017, %16015
  %16021 = or i32 %16020, %16019
  %16022 = add i64 %16013, 16
  %16023 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %16022
  %16024 = load i32, i32* %16023, align 4
  %16025 = icmp eq i64 %15893, %16022
  %16026 = sext i1 %16025 to i32
  %16027 = xor i32 %16026, -1
  %16028 = and i32 %16027, %16021
  %16029 = and i32 %16026, %16024
  %16030 = or i32 %16029, %16028
  %16031 = add i64 %16022, 16
  %16032 = getelementptr inbounds [256 x i32], [256 x i32]* %15895, i64 0, i64 %16031
  %16033 = load i32, i32* %16032, align 4
  %16034 = icmp eq i64 %15893, %16031
  %16035 = sext i1 %16034 to i32
  %16036 = xor i32 %16035, -1
  %16037 = and i32 %16036, %16030
  %16038 = and i32 %16035, %16033
  %Mitigated105 = or i32 %16038, %16037
  %16039 = xor i32 %Mitigated104, %Mitigated105
  %16040 = lshr i32 %15739, 16
  %16041 = and i32 %16040, 255
  %16042 = zext i32 %16041 to i64
  %16043 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16044 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16043, i64 0, i64 2
  %16045 = srem i64 %16042, 16
  %16046 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16045
  %16047 = load i32, i32* %16046, align 4
  %16048 = icmp eq i64 %16042, %16045
  %16049 = sext i1 %16048 to i32
  %16050 = xor i32 %16049, -1
  %16051 = and i32 %16050, 0
  %16052 = and i32 %16049, %16047
  %16053 = or i32 %16052, %16051
  %16054 = add i64 %16045, 16
  %16055 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16054
  %16056 = load i32, i32* %16055, align 4
  %16057 = icmp eq i64 %16042, %16054
  %16058 = sext i1 %16057 to i32
  %16059 = xor i32 %16058, -1
  %16060 = and i32 %16059, %16053
  %16061 = and i32 %16058, %16056
  %16062 = or i32 %16061, %16060
  %16063 = add i64 %16054, 16
  %16064 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16063
  %16065 = load i32, i32* %16064, align 4
  %16066 = icmp eq i64 %16042, %16063
  %16067 = sext i1 %16066 to i32
  %16068 = xor i32 %16067, -1
  %16069 = and i32 %16068, %16062
  %16070 = and i32 %16067, %16065
  %16071 = or i32 %16070, %16069
  %16072 = add i64 %16063, 16
  %16073 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16072
  %16074 = load i32, i32* %16073, align 4
  %16075 = icmp eq i64 %16042, %16072
  %16076 = sext i1 %16075 to i32
  %16077 = xor i32 %16076, -1
  %16078 = and i32 %16077, %16071
  %16079 = and i32 %16076, %16074
  %16080 = or i32 %16079, %16078
  %16081 = add i64 %16072, 16
  %16082 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16081
  %16083 = load i32, i32* %16082, align 4
  %16084 = icmp eq i64 %16042, %16081
  %16085 = sext i1 %16084 to i32
  %16086 = xor i32 %16085, -1
  %16087 = and i32 %16086, %16080
  %16088 = and i32 %16085, %16083
  %16089 = or i32 %16088, %16087
  %16090 = add i64 %16081, 16
  %16091 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16090
  %16092 = load i32, i32* %16091, align 4
  %16093 = icmp eq i64 %16042, %16090
  %16094 = sext i1 %16093 to i32
  %16095 = xor i32 %16094, -1
  %16096 = and i32 %16095, %16089
  %16097 = and i32 %16094, %16092
  %16098 = or i32 %16097, %16096
  %16099 = add i64 %16090, 16
  %16100 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16099
  %16101 = load i32, i32* %16100, align 4
  %16102 = icmp eq i64 %16042, %16099
  %16103 = sext i1 %16102 to i32
  %16104 = xor i32 %16103, -1
  %16105 = and i32 %16104, %16098
  %16106 = and i32 %16103, %16101
  %16107 = or i32 %16106, %16105
  %16108 = add i64 %16099, 16
  %16109 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16108
  %16110 = load i32, i32* %16109, align 4
  %16111 = icmp eq i64 %16042, %16108
  %16112 = sext i1 %16111 to i32
  %16113 = xor i32 %16112, -1
  %16114 = and i32 %16113, %16107
  %16115 = and i32 %16112, %16110
  %16116 = or i32 %16115, %16114
  %16117 = add i64 %16108, 16
  %16118 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16117
  %16119 = load i32, i32* %16118, align 4
  %16120 = icmp eq i64 %16042, %16117
  %16121 = sext i1 %16120 to i32
  %16122 = xor i32 %16121, -1
  %16123 = and i32 %16122, %16116
  %16124 = and i32 %16121, %16119
  %16125 = or i32 %16124, %16123
  %16126 = add i64 %16117, 16
  %16127 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16126
  %16128 = load i32, i32* %16127, align 4
  %16129 = icmp eq i64 %16042, %16126
  %16130 = sext i1 %16129 to i32
  %16131 = xor i32 %16130, -1
  %16132 = and i32 %16131, %16125
  %16133 = and i32 %16130, %16128
  %16134 = or i32 %16133, %16132
  %16135 = add i64 %16126, 16
  %16136 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16135
  %16137 = load i32, i32* %16136, align 4
  %16138 = icmp eq i64 %16042, %16135
  %16139 = sext i1 %16138 to i32
  %16140 = xor i32 %16139, -1
  %16141 = and i32 %16140, %16134
  %16142 = and i32 %16139, %16137
  %16143 = or i32 %16142, %16141
  %16144 = add i64 %16135, 16
  %16145 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16144
  %16146 = load i32, i32* %16145, align 4
  %16147 = icmp eq i64 %16042, %16144
  %16148 = sext i1 %16147 to i32
  %16149 = xor i32 %16148, -1
  %16150 = and i32 %16149, %16143
  %16151 = and i32 %16148, %16146
  %16152 = or i32 %16151, %16150
  %16153 = add i64 %16144, 16
  %16154 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16153
  %16155 = load i32, i32* %16154, align 4
  %16156 = icmp eq i64 %16042, %16153
  %16157 = sext i1 %16156 to i32
  %16158 = xor i32 %16157, -1
  %16159 = and i32 %16158, %16152
  %16160 = and i32 %16157, %16155
  %16161 = or i32 %16160, %16159
  %16162 = add i64 %16153, 16
  %16163 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16162
  %16164 = load i32, i32* %16163, align 4
  %16165 = icmp eq i64 %16042, %16162
  %16166 = sext i1 %16165 to i32
  %16167 = xor i32 %16166, -1
  %16168 = and i32 %16167, %16161
  %16169 = and i32 %16166, %16164
  %16170 = or i32 %16169, %16168
  %16171 = add i64 %16162, 16
  %16172 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16171
  %16173 = load i32, i32* %16172, align 4
  %16174 = icmp eq i64 %16042, %16171
  %16175 = sext i1 %16174 to i32
  %16176 = xor i32 %16175, -1
  %16177 = and i32 %16176, %16170
  %16178 = and i32 %16175, %16173
  %16179 = or i32 %16178, %16177
  %16180 = add i64 %16171, 16
  %16181 = getelementptr inbounds [256 x i32], [256 x i32]* %16044, i64 0, i64 %16180
  %16182 = load i32, i32* %16181, align 4
  %16183 = icmp eq i64 %16042, %16180
  %16184 = sext i1 %16183 to i32
  %16185 = xor i32 %16184, -1
  %16186 = and i32 %16185, %16179
  %16187 = and i32 %16184, %16182
  %Mitigated106 = or i32 %16187, %16186
  %16188 = xor i32 %16039, %Mitigated106
  %16189 = lshr i32 %15739, 24
  %16190 = zext i32 %16189 to i64
  %16191 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16192 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16191, i64 0, i64 3
  %16193 = srem i64 %16190, 16
  %16194 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16193
  %16195 = load i32, i32* %16194, align 4
  %16196 = icmp eq i64 %16190, %16193
  %16197 = sext i1 %16196 to i32
  %16198 = xor i32 %16197, -1
  %16199 = and i32 %16198, 0
  %16200 = and i32 %16197, %16195
  %16201 = or i32 %16200, %16199
  %16202 = add i64 %16193, 16
  %16203 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16202
  %16204 = load i32, i32* %16203, align 4
  %16205 = icmp eq i64 %16190, %16202
  %16206 = sext i1 %16205 to i32
  %16207 = xor i32 %16206, -1
  %16208 = and i32 %16207, %16201
  %16209 = and i32 %16206, %16204
  %16210 = or i32 %16209, %16208
  %16211 = add i64 %16202, 16
  %16212 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16211
  %16213 = load i32, i32* %16212, align 4
  %16214 = icmp eq i64 %16190, %16211
  %16215 = sext i1 %16214 to i32
  %16216 = xor i32 %16215, -1
  %16217 = and i32 %16216, %16210
  %16218 = and i32 %16215, %16213
  %16219 = or i32 %16218, %16217
  %16220 = add i64 %16211, 16
  %16221 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16220
  %16222 = load i32, i32* %16221, align 4
  %16223 = icmp eq i64 %16190, %16220
  %16224 = sext i1 %16223 to i32
  %16225 = xor i32 %16224, -1
  %16226 = and i32 %16225, %16219
  %16227 = and i32 %16224, %16222
  %16228 = or i32 %16227, %16226
  %16229 = add i64 %16220, 16
  %16230 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16229
  %16231 = load i32, i32* %16230, align 4
  %16232 = icmp eq i64 %16190, %16229
  %16233 = sext i1 %16232 to i32
  %16234 = xor i32 %16233, -1
  %16235 = and i32 %16234, %16228
  %16236 = and i32 %16233, %16231
  %16237 = or i32 %16236, %16235
  %16238 = add i64 %16229, 16
  %16239 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16238
  %16240 = load i32, i32* %16239, align 4
  %16241 = icmp eq i64 %16190, %16238
  %16242 = sext i1 %16241 to i32
  %16243 = xor i32 %16242, -1
  %16244 = and i32 %16243, %16237
  %16245 = and i32 %16242, %16240
  %16246 = or i32 %16245, %16244
  %16247 = add i64 %16238, 16
  %16248 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16247
  %16249 = load i32, i32* %16248, align 4
  %16250 = icmp eq i64 %16190, %16247
  %16251 = sext i1 %16250 to i32
  %16252 = xor i32 %16251, -1
  %16253 = and i32 %16252, %16246
  %16254 = and i32 %16251, %16249
  %16255 = or i32 %16254, %16253
  %16256 = add i64 %16247, 16
  %16257 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16256
  %16258 = load i32, i32* %16257, align 4
  %16259 = icmp eq i64 %16190, %16256
  %16260 = sext i1 %16259 to i32
  %16261 = xor i32 %16260, -1
  %16262 = and i32 %16261, %16255
  %16263 = and i32 %16260, %16258
  %16264 = or i32 %16263, %16262
  %16265 = add i64 %16256, 16
  %16266 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16265
  %16267 = load i32, i32* %16266, align 4
  %16268 = icmp eq i64 %16190, %16265
  %16269 = sext i1 %16268 to i32
  %16270 = xor i32 %16269, -1
  %16271 = and i32 %16270, %16264
  %16272 = and i32 %16269, %16267
  %16273 = or i32 %16272, %16271
  %16274 = add i64 %16265, 16
  %16275 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16274
  %16276 = load i32, i32* %16275, align 4
  %16277 = icmp eq i64 %16190, %16274
  %16278 = sext i1 %16277 to i32
  %16279 = xor i32 %16278, -1
  %16280 = and i32 %16279, %16273
  %16281 = and i32 %16278, %16276
  %16282 = or i32 %16281, %16280
  %16283 = add i64 %16274, 16
  %16284 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16283
  %16285 = load i32, i32* %16284, align 4
  %16286 = icmp eq i64 %16190, %16283
  %16287 = sext i1 %16286 to i32
  %16288 = xor i32 %16287, -1
  %16289 = and i32 %16288, %16282
  %16290 = and i32 %16287, %16285
  %16291 = or i32 %16290, %16289
  %16292 = add i64 %16283, 16
  %16293 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16292
  %16294 = load i32, i32* %16293, align 4
  %16295 = icmp eq i64 %16190, %16292
  %16296 = sext i1 %16295 to i32
  %16297 = xor i32 %16296, -1
  %16298 = and i32 %16297, %16291
  %16299 = and i32 %16296, %16294
  %16300 = or i32 %16299, %16298
  %16301 = add i64 %16292, 16
  %16302 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16301
  %16303 = load i32, i32* %16302, align 4
  %16304 = icmp eq i64 %16190, %16301
  %16305 = sext i1 %16304 to i32
  %16306 = xor i32 %16305, -1
  %16307 = and i32 %16306, %16300
  %16308 = and i32 %16305, %16303
  %16309 = or i32 %16308, %16307
  %16310 = add i64 %16301, 16
  %16311 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16310
  %16312 = load i32, i32* %16311, align 4
  %16313 = icmp eq i64 %16190, %16310
  %16314 = sext i1 %16313 to i32
  %16315 = xor i32 %16314, -1
  %16316 = and i32 %16315, %16309
  %16317 = and i32 %16314, %16312
  %16318 = or i32 %16317, %16316
  %16319 = add i64 %16310, 16
  %16320 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16319
  %16321 = load i32, i32* %16320, align 4
  %16322 = icmp eq i64 %16190, %16319
  %16323 = sext i1 %16322 to i32
  %16324 = xor i32 %16323, -1
  %16325 = and i32 %16324, %16318
  %16326 = and i32 %16323, %16321
  %16327 = or i32 %16326, %16325
  %16328 = add i64 %16319, 16
  %16329 = getelementptr inbounds [256 x i32], [256 x i32]* %16192, i64 0, i64 %16328
  %16330 = load i32, i32* %16329, align 4
  %16331 = icmp eq i64 %16190, %16328
  %16332 = sext i1 %16331 to i32
  %16333 = xor i32 %16332, -1
  %16334 = and i32 %16333, %16327
  %16335 = and i32 %16332, %16330
  %Mitigated107 = or i32 %16335, %16334
  %16336 = xor i32 %16188, %Mitigated107
  %16337 = and i32 %15743, 255
  %16338 = zext i32 %16337 to i64
  %16339 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16340 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16339, i64 0, i64 1
  %16341 = srem i64 %16338, 16
  %16342 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16341
  %16343 = load i32, i32* %16342, align 4
  %16344 = icmp eq i64 %16338, %16341
  %16345 = sext i1 %16344 to i32
  %16346 = xor i32 %16345, -1
  %16347 = and i32 %16346, 0
  %16348 = and i32 %16345, %16343
  %16349 = or i32 %16348, %16347
  %16350 = add i64 %16341, 16
  %16351 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16350
  %16352 = load i32, i32* %16351, align 4
  %16353 = icmp eq i64 %16338, %16350
  %16354 = sext i1 %16353 to i32
  %16355 = xor i32 %16354, -1
  %16356 = and i32 %16355, %16349
  %16357 = and i32 %16354, %16352
  %16358 = or i32 %16357, %16356
  %16359 = add i64 %16350, 16
  %16360 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16359
  %16361 = load i32, i32* %16360, align 4
  %16362 = icmp eq i64 %16338, %16359
  %16363 = sext i1 %16362 to i32
  %16364 = xor i32 %16363, -1
  %16365 = and i32 %16364, %16358
  %16366 = and i32 %16363, %16361
  %16367 = or i32 %16366, %16365
  %16368 = add i64 %16359, 16
  %16369 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16368
  %16370 = load i32, i32* %16369, align 4
  %16371 = icmp eq i64 %16338, %16368
  %16372 = sext i1 %16371 to i32
  %16373 = xor i32 %16372, -1
  %16374 = and i32 %16373, %16367
  %16375 = and i32 %16372, %16370
  %16376 = or i32 %16375, %16374
  %16377 = add i64 %16368, 16
  %16378 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16377
  %16379 = load i32, i32* %16378, align 4
  %16380 = icmp eq i64 %16338, %16377
  %16381 = sext i1 %16380 to i32
  %16382 = xor i32 %16381, -1
  %16383 = and i32 %16382, %16376
  %16384 = and i32 %16381, %16379
  %16385 = or i32 %16384, %16383
  %16386 = add i64 %16377, 16
  %16387 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16386
  %16388 = load i32, i32* %16387, align 4
  %16389 = icmp eq i64 %16338, %16386
  %16390 = sext i1 %16389 to i32
  %16391 = xor i32 %16390, -1
  %16392 = and i32 %16391, %16385
  %16393 = and i32 %16390, %16388
  %16394 = or i32 %16393, %16392
  %16395 = add i64 %16386, 16
  %16396 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16395
  %16397 = load i32, i32* %16396, align 4
  %16398 = icmp eq i64 %16338, %16395
  %16399 = sext i1 %16398 to i32
  %16400 = xor i32 %16399, -1
  %16401 = and i32 %16400, %16394
  %16402 = and i32 %16399, %16397
  %16403 = or i32 %16402, %16401
  %16404 = add i64 %16395, 16
  %16405 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16404
  %16406 = load i32, i32* %16405, align 4
  %16407 = icmp eq i64 %16338, %16404
  %16408 = sext i1 %16407 to i32
  %16409 = xor i32 %16408, -1
  %16410 = and i32 %16409, %16403
  %16411 = and i32 %16408, %16406
  %16412 = or i32 %16411, %16410
  %16413 = add i64 %16404, 16
  %16414 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16413
  %16415 = load i32, i32* %16414, align 4
  %16416 = icmp eq i64 %16338, %16413
  %16417 = sext i1 %16416 to i32
  %16418 = xor i32 %16417, -1
  %16419 = and i32 %16418, %16412
  %16420 = and i32 %16417, %16415
  %16421 = or i32 %16420, %16419
  %16422 = add i64 %16413, 16
  %16423 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16422
  %16424 = load i32, i32* %16423, align 4
  %16425 = icmp eq i64 %16338, %16422
  %16426 = sext i1 %16425 to i32
  %16427 = xor i32 %16426, -1
  %16428 = and i32 %16427, %16421
  %16429 = and i32 %16426, %16424
  %16430 = or i32 %16429, %16428
  %16431 = add i64 %16422, 16
  %16432 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16431
  %16433 = load i32, i32* %16432, align 4
  %16434 = icmp eq i64 %16338, %16431
  %16435 = sext i1 %16434 to i32
  %16436 = xor i32 %16435, -1
  %16437 = and i32 %16436, %16430
  %16438 = and i32 %16435, %16433
  %16439 = or i32 %16438, %16437
  %16440 = add i64 %16431, 16
  %16441 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16440
  %16442 = load i32, i32* %16441, align 4
  %16443 = icmp eq i64 %16338, %16440
  %16444 = sext i1 %16443 to i32
  %16445 = xor i32 %16444, -1
  %16446 = and i32 %16445, %16439
  %16447 = and i32 %16444, %16442
  %16448 = or i32 %16447, %16446
  %16449 = add i64 %16440, 16
  %16450 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16449
  %16451 = load i32, i32* %16450, align 4
  %16452 = icmp eq i64 %16338, %16449
  %16453 = sext i1 %16452 to i32
  %16454 = xor i32 %16453, -1
  %16455 = and i32 %16454, %16448
  %16456 = and i32 %16453, %16451
  %16457 = or i32 %16456, %16455
  %16458 = add i64 %16449, 16
  %16459 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16458
  %16460 = load i32, i32* %16459, align 4
  %16461 = icmp eq i64 %16338, %16458
  %16462 = sext i1 %16461 to i32
  %16463 = xor i32 %16462, -1
  %16464 = and i32 %16463, %16457
  %16465 = and i32 %16462, %16460
  %16466 = or i32 %16465, %16464
  %16467 = add i64 %16458, 16
  %16468 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16467
  %16469 = load i32, i32* %16468, align 4
  %16470 = icmp eq i64 %16338, %16467
  %16471 = sext i1 %16470 to i32
  %16472 = xor i32 %16471, -1
  %16473 = and i32 %16472, %16466
  %16474 = and i32 %16471, %16469
  %16475 = or i32 %16474, %16473
  %16476 = add i64 %16467, 16
  %16477 = getelementptr inbounds [256 x i32], [256 x i32]* %16340, i64 0, i64 %16476
  %16478 = load i32, i32* %16477, align 4
  %16479 = icmp eq i64 %16338, %16476
  %16480 = sext i1 %16479 to i32
  %16481 = xor i32 %16480, -1
  %16482 = and i32 %16481, %16475
  %16483 = and i32 %16480, %16478
  %Mitigated108 = or i32 %16483, %16482
  %16484 = lshr i32 %15743, 8
  %16485 = and i32 %16484, 255
  %16486 = zext i32 %16485 to i64
  %16487 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16488 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16487, i64 0, i64 2
  %16489 = srem i64 %16486, 16
  %16490 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16489
  %16491 = load i32, i32* %16490, align 4
  %16492 = icmp eq i64 %16486, %16489
  %16493 = sext i1 %16492 to i32
  %16494 = xor i32 %16493, -1
  %16495 = and i32 %16494, 0
  %16496 = and i32 %16493, %16491
  %16497 = or i32 %16496, %16495
  %16498 = add i64 %16489, 16
  %16499 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16498
  %16500 = load i32, i32* %16499, align 4
  %16501 = icmp eq i64 %16486, %16498
  %16502 = sext i1 %16501 to i32
  %16503 = xor i32 %16502, -1
  %16504 = and i32 %16503, %16497
  %16505 = and i32 %16502, %16500
  %16506 = or i32 %16505, %16504
  %16507 = add i64 %16498, 16
  %16508 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16507
  %16509 = load i32, i32* %16508, align 4
  %16510 = icmp eq i64 %16486, %16507
  %16511 = sext i1 %16510 to i32
  %16512 = xor i32 %16511, -1
  %16513 = and i32 %16512, %16506
  %16514 = and i32 %16511, %16509
  %16515 = or i32 %16514, %16513
  %16516 = add i64 %16507, 16
  %16517 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16516
  %16518 = load i32, i32* %16517, align 4
  %16519 = icmp eq i64 %16486, %16516
  %16520 = sext i1 %16519 to i32
  %16521 = xor i32 %16520, -1
  %16522 = and i32 %16521, %16515
  %16523 = and i32 %16520, %16518
  %16524 = or i32 %16523, %16522
  %16525 = add i64 %16516, 16
  %16526 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16525
  %16527 = load i32, i32* %16526, align 4
  %16528 = icmp eq i64 %16486, %16525
  %16529 = sext i1 %16528 to i32
  %16530 = xor i32 %16529, -1
  %16531 = and i32 %16530, %16524
  %16532 = and i32 %16529, %16527
  %16533 = or i32 %16532, %16531
  %16534 = add i64 %16525, 16
  %16535 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16534
  %16536 = load i32, i32* %16535, align 4
  %16537 = icmp eq i64 %16486, %16534
  %16538 = sext i1 %16537 to i32
  %16539 = xor i32 %16538, -1
  %16540 = and i32 %16539, %16533
  %16541 = and i32 %16538, %16536
  %16542 = or i32 %16541, %16540
  %16543 = add i64 %16534, 16
  %16544 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16543
  %16545 = load i32, i32* %16544, align 4
  %16546 = icmp eq i64 %16486, %16543
  %16547 = sext i1 %16546 to i32
  %16548 = xor i32 %16547, -1
  %16549 = and i32 %16548, %16542
  %16550 = and i32 %16547, %16545
  %16551 = or i32 %16550, %16549
  %16552 = add i64 %16543, 16
  %16553 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16552
  %16554 = load i32, i32* %16553, align 4
  %16555 = icmp eq i64 %16486, %16552
  %16556 = sext i1 %16555 to i32
  %16557 = xor i32 %16556, -1
  %16558 = and i32 %16557, %16551
  %16559 = and i32 %16556, %16554
  %16560 = or i32 %16559, %16558
  %16561 = add i64 %16552, 16
  %16562 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16561
  %16563 = load i32, i32* %16562, align 4
  %16564 = icmp eq i64 %16486, %16561
  %16565 = sext i1 %16564 to i32
  %16566 = xor i32 %16565, -1
  %16567 = and i32 %16566, %16560
  %16568 = and i32 %16565, %16563
  %16569 = or i32 %16568, %16567
  %16570 = add i64 %16561, 16
  %16571 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16570
  %16572 = load i32, i32* %16571, align 4
  %16573 = icmp eq i64 %16486, %16570
  %16574 = sext i1 %16573 to i32
  %16575 = xor i32 %16574, -1
  %16576 = and i32 %16575, %16569
  %16577 = and i32 %16574, %16572
  %16578 = or i32 %16577, %16576
  %16579 = add i64 %16570, 16
  %16580 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16579
  %16581 = load i32, i32* %16580, align 4
  %16582 = icmp eq i64 %16486, %16579
  %16583 = sext i1 %16582 to i32
  %16584 = xor i32 %16583, -1
  %16585 = and i32 %16584, %16578
  %16586 = and i32 %16583, %16581
  %16587 = or i32 %16586, %16585
  %16588 = add i64 %16579, 16
  %16589 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16588
  %16590 = load i32, i32* %16589, align 4
  %16591 = icmp eq i64 %16486, %16588
  %16592 = sext i1 %16591 to i32
  %16593 = xor i32 %16592, -1
  %16594 = and i32 %16593, %16587
  %16595 = and i32 %16592, %16590
  %16596 = or i32 %16595, %16594
  %16597 = add i64 %16588, 16
  %16598 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16597
  %16599 = load i32, i32* %16598, align 4
  %16600 = icmp eq i64 %16486, %16597
  %16601 = sext i1 %16600 to i32
  %16602 = xor i32 %16601, -1
  %16603 = and i32 %16602, %16596
  %16604 = and i32 %16601, %16599
  %16605 = or i32 %16604, %16603
  %16606 = add i64 %16597, 16
  %16607 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16606
  %16608 = load i32, i32* %16607, align 4
  %16609 = icmp eq i64 %16486, %16606
  %16610 = sext i1 %16609 to i32
  %16611 = xor i32 %16610, -1
  %16612 = and i32 %16611, %16605
  %16613 = and i32 %16610, %16608
  %16614 = or i32 %16613, %16612
  %16615 = add i64 %16606, 16
  %16616 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16615
  %16617 = load i32, i32* %16616, align 4
  %16618 = icmp eq i64 %16486, %16615
  %16619 = sext i1 %16618 to i32
  %16620 = xor i32 %16619, -1
  %16621 = and i32 %16620, %16614
  %16622 = and i32 %16619, %16617
  %16623 = or i32 %16622, %16621
  %16624 = add i64 %16615, 16
  %16625 = getelementptr inbounds [256 x i32], [256 x i32]* %16488, i64 0, i64 %16624
  %16626 = load i32, i32* %16625, align 4
  %16627 = icmp eq i64 %16486, %16624
  %16628 = sext i1 %16627 to i32
  %16629 = xor i32 %16628, -1
  %16630 = and i32 %16629, %16623
  %16631 = and i32 %16628, %16626
  %Mitigated109 = or i32 %16631, %16630
  %16632 = xor i32 %Mitigated108, %Mitigated109
  %16633 = lshr i32 %15743, 16
  %16634 = and i32 %16633, 255
  %16635 = zext i32 %16634 to i64
  %16636 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16637 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16636, i64 0, i64 3
  %16638 = srem i64 %16635, 16
  %16639 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16638
  %16640 = load i32, i32* %16639, align 4
  %16641 = icmp eq i64 %16635, %16638
  %16642 = sext i1 %16641 to i32
  %16643 = xor i32 %16642, -1
  %16644 = and i32 %16643, 0
  %16645 = and i32 %16642, %16640
  %16646 = or i32 %16645, %16644
  %16647 = add i64 %16638, 16
  %16648 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16647
  %16649 = load i32, i32* %16648, align 4
  %16650 = icmp eq i64 %16635, %16647
  %16651 = sext i1 %16650 to i32
  %16652 = xor i32 %16651, -1
  %16653 = and i32 %16652, %16646
  %16654 = and i32 %16651, %16649
  %16655 = or i32 %16654, %16653
  %16656 = add i64 %16647, 16
  %16657 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16656
  %16658 = load i32, i32* %16657, align 4
  %16659 = icmp eq i64 %16635, %16656
  %16660 = sext i1 %16659 to i32
  %16661 = xor i32 %16660, -1
  %16662 = and i32 %16661, %16655
  %16663 = and i32 %16660, %16658
  %16664 = or i32 %16663, %16662
  %16665 = add i64 %16656, 16
  %16666 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16665
  %16667 = load i32, i32* %16666, align 4
  %16668 = icmp eq i64 %16635, %16665
  %16669 = sext i1 %16668 to i32
  %16670 = xor i32 %16669, -1
  %16671 = and i32 %16670, %16664
  %16672 = and i32 %16669, %16667
  %16673 = or i32 %16672, %16671
  %16674 = add i64 %16665, 16
  %16675 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16674
  %16676 = load i32, i32* %16675, align 4
  %16677 = icmp eq i64 %16635, %16674
  %16678 = sext i1 %16677 to i32
  %16679 = xor i32 %16678, -1
  %16680 = and i32 %16679, %16673
  %16681 = and i32 %16678, %16676
  %16682 = or i32 %16681, %16680
  %16683 = add i64 %16674, 16
  %16684 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16683
  %16685 = load i32, i32* %16684, align 4
  %16686 = icmp eq i64 %16635, %16683
  %16687 = sext i1 %16686 to i32
  %16688 = xor i32 %16687, -1
  %16689 = and i32 %16688, %16682
  %16690 = and i32 %16687, %16685
  %16691 = or i32 %16690, %16689
  %16692 = add i64 %16683, 16
  %16693 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16692
  %16694 = load i32, i32* %16693, align 4
  %16695 = icmp eq i64 %16635, %16692
  %16696 = sext i1 %16695 to i32
  %16697 = xor i32 %16696, -1
  %16698 = and i32 %16697, %16691
  %16699 = and i32 %16696, %16694
  %16700 = or i32 %16699, %16698
  %16701 = add i64 %16692, 16
  %16702 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16701
  %16703 = load i32, i32* %16702, align 4
  %16704 = icmp eq i64 %16635, %16701
  %16705 = sext i1 %16704 to i32
  %16706 = xor i32 %16705, -1
  %16707 = and i32 %16706, %16700
  %16708 = and i32 %16705, %16703
  %16709 = or i32 %16708, %16707
  %16710 = add i64 %16701, 16
  %16711 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16710
  %16712 = load i32, i32* %16711, align 4
  %16713 = icmp eq i64 %16635, %16710
  %16714 = sext i1 %16713 to i32
  %16715 = xor i32 %16714, -1
  %16716 = and i32 %16715, %16709
  %16717 = and i32 %16714, %16712
  %16718 = or i32 %16717, %16716
  %16719 = add i64 %16710, 16
  %16720 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16719
  %16721 = load i32, i32* %16720, align 4
  %16722 = icmp eq i64 %16635, %16719
  %16723 = sext i1 %16722 to i32
  %16724 = xor i32 %16723, -1
  %16725 = and i32 %16724, %16718
  %16726 = and i32 %16723, %16721
  %16727 = or i32 %16726, %16725
  %16728 = add i64 %16719, 16
  %16729 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16728
  %16730 = load i32, i32* %16729, align 4
  %16731 = icmp eq i64 %16635, %16728
  %16732 = sext i1 %16731 to i32
  %16733 = xor i32 %16732, -1
  %16734 = and i32 %16733, %16727
  %16735 = and i32 %16732, %16730
  %16736 = or i32 %16735, %16734
  %16737 = add i64 %16728, 16
  %16738 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16737
  %16739 = load i32, i32* %16738, align 4
  %16740 = icmp eq i64 %16635, %16737
  %16741 = sext i1 %16740 to i32
  %16742 = xor i32 %16741, -1
  %16743 = and i32 %16742, %16736
  %16744 = and i32 %16741, %16739
  %16745 = or i32 %16744, %16743
  %16746 = add i64 %16737, 16
  %16747 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16746
  %16748 = load i32, i32* %16747, align 4
  %16749 = icmp eq i64 %16635, %16746
  %16750 = sext i1 %16749 to i32
  %16751 = xor i32 %16750, -1
  %16752 = and i32 %16751, %16745
  %16753 = and i32 %16750, %16748
  %16754 = or i32 %16753, %16752
  %16755 = add i64 %16746, 16
  %16756 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16755
  %16757 = load i32, i32* %16756, align 4
  %16758 = icmp eq i64 %16635, %16755
  %16759 = sext i1 %16758 to i32
  %16760 = xor i32 %16759, -1
  %16761 = and i32 %16760, %16754
  %16762 = and i32 %16759, %16757
  %16763 = or i32 %16762, %16761
  %16764 = add i64 %16755, 16
  %16765 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16764
  %16766 = load i32, i32* %16765, align 4
  %16767 = icmp eq i64 %16635, %16764
  %16768 = sext i1 %16767 to i32
  %16769 = xor i32 %16768, -1
  %16770 = and i32 %16769, %16763
  %16771 = and i32 %16768, %16766
  %16772 = or i32 %16771, %16770
  %16773 = add i64 %16764, 16
  %16774 = getelementptr inbounds [256 x i32], [256 x i32]* %16637, i64 0, i64 %16773
  %16775 = load i32, i32* %16774, align 4
  %16776 = icmp eq i64 %16635, %16773
  %16777 = sext i1 %16776 to i32
  %16778 = xor i32 %16777, -1
  %16779 = and i32 %16778, %16772
  %16780 = and i32 %16777, %16775
  %Mitigated110 = or i32 %16780, %16779
  %16781 = xor i32 %16632, %Mitigated110
  %16782 = lshr i32 %15743, 24
  %16783 = zext i32 %16782 to i64
  %16784 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16785 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16784, i64 0, i64 0
  %16786 = srem i64 %16783, 16
  %16787 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16786
  %16788 = load i32, i32* %16787, align 4
  %16789 = icmp eq i64 %16783, %16786
  %16790 = sext i1 %16789 to i32
  %16791 = xor i32 %16790, -1
  %16792 = and i32 %16791, 0
  %16793 = and i32 %16790, %16788
  %16794 = or i32 %16793, %16792
  %16795 = add i64 %16786, 16
  %16796 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16795
  %16797 = load i32, i32* %16796, align 4
  %16798 = icmp eq i64 %16783, %16795
  %16799 = sext i1 %16798 to i32
  %16800 = xor i32 %16799, -1
  %16801 = and i32 %16800, %16794
  %16802 = and i32 %16799, %16797
  %16803 = or i32 %16802, %16801
  %16804 = add i64 %16795, 16
  %16805 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16804
  %16806 = load i32, i32* %16805, align 4
  %16807 = icmp eq i64 %16783, %16804
  %16808 = sext i1 %16807 to i32
  %16809 = xor i32 %16808, -1
  %16810 = and i32 %16809, %16803
  %16811 = and i32 %16808, %16806
  %16812 = or i32 %16811, %16810
  %16813 = add i64 %16804, 16
  %16814 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16813
  %16815 = load i32, i32* %16814, align 4
  %16816 = icmp eq i64 %16783, %16813
  %16817 = sext i1 %16816 to i32
  %16818 = xor i32 %16817, -1
  %16819 = and i32 %16818, %16812
  %16820 = and i32 %16817, %16815
  %16821 = or i32 %16820, %16819
  %16822 = add i64 %16813, 16
  %16823 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16822
  %16824 = load i32, i32* %16823, align 4
  %16825 = icmp eq i64 %16783, %16822
  %16826 = sext i1 %16825 to i32
  %16827 = xor i32 %16826, -1
  %16828 = and i32 %16827, %16821
  %16829 = and i32 %16826, %16824
  %16830 = or i32 %16829, %16828
  %16831 = add i64 %16822, 16
  %16832 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16831
  %16833 = load i32, i32* %16832, align 4
  %16834 = icmp eq i64 %16783, %16831
  %16835 = sext i1 %16834 to i32
  %16836 = xor i32 %16835, -1
  %16837 = and i32 %16836, %16830
  %16838 = and i32 %16835, %16833
  %16839 = or i32 %16838, %16837
  %16840 = add i64 %16831, 16
  %16841 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16840
  %16842 = load i32, i32* %16841, align 4
  %16843 = icmp eq i64 %16783, %16840
  %16844 = sext i1 %16843 to i32
  %16845 = xor i32 %16844, -1
  %16846 = and i32 %16845, %16839
  %16847 = and i32 %16844, %16842
  %16848 = or i32 %16847, %16846
  %16849 = add i64 %16840, 16
  %16850 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16849
  %16851 = load i32, i32* %16850, align 4
  %16852 = icmp eq i64 %16783, %16849
  %16853 = sext i1 %16852 to i32
  %16854 = xor i32 %16853, -1
  %16855 = and i32 %16854, %16848
  %16856 = and i32 %16853, %16851
  %16857 = or i32 %16856, %16855
  %16858 = add i64 %16849, 16
  %16859 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16858
  %16860 = load i32, i32* %16859, align 4
  %16861 = icmp eq i64 %16783, %16858
  %16862 = sext i1 %16861 to i32
  %16863 = xor i32 %16862, -1
  %16864 = and i32 %16863, %16857
  %16865 = and i32 %16862, %16860
  %16866 = or i32 %16865, %16864
  %16867 = add i64 %16858, 16
  %16868 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16867
  %16869 = load i32, i32* %16868, align 4
  %16870 = icmp eq i64 %16783, %16867
  %16871 = sext i1 %16870 to i32
  %16872 = xor i32 %16871, -1
  %16873 = and i32 %16872, %16866
  %16874 = and i32 %16871, %16869
  %16875 = or i32 %16874, %16873
  %16876 = add i64 %16867, 16
  %16877 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16876
  %16878 = load i32, i32* %16877, align 4
  %16879 = icmp eq i64 %16783, %16876
  %16880 = sext i1 %16879 to i32
  %16881 = xor i32 %16880, -1
  %16882 = and i32 %16881, %16875
  %16883 = and i32 %16880, %16878
  %16884 = or i32 %16883, %16882
  %16885 = add i64 %16876, 16
  %16886 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16885
  %16887 = load i32, i32* %16886, align 4
  %16888 = icmp eq i64 %16783, %16885
  %16889 = sext i1 %16888 to i32
  %16890 = xor i32 %16889, -1
  %16891 = and i32 %16890, %16884
  %16892 = and i32 %16889, %16887
  %16893 = or i32 %16892, %16891
  %16894 = add i64 %16885, 16
  %16895 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16894
  %16896 = load i32, i32* %16895, align 4
  %16897 = icmp eq i64 %16783, %16894
  %16898 = sext i1 %16897 to i32
  %16899 = xor i32 %16898, -1
  %16900 = and i32 %16899, %16893
  %16901 = and i32 %16898, %16896
  %16902 = or i32 %16901, %16900
  %16903 = add i64 %16894, 16
  %16904 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16903
  %16905 = load i32, i32* %16904, align 4
  %16906 = icmp eq i64 %16783, %16903
  %16907 = sext i1 %16906 to i32
  %16908 = xor i32 %16907, -1
  %16909 = and i32 %16908, %16902
  %16910 = and i32 %16907, %16905
  %16911 = or i32 %16910, %16909
  %16912 = add i64 %16903, 16
  %16913 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16912
  %16914 = load i32, i32* %16913, align 4
  %16915 = icmp eq i64 %16783, %16912
  %16916 = sext i1 %16915 to i32
  %16917 = xor i32 %16916, -1
  %16918 = and i32 %16917, %16911
  %16919 = and i32 %16916, %16914
  %16920 = or i32 %16919, %16918
  %16921 = add i64 %16912, 16
  %16922 = getelementptr inbounds [256 x i32], [256 x i32]* %16785, i64 0, i64 %16921
  %16923 = load i32, i32* %16922, align 4
  %16924 = icmp eq i64 %16783, %16921
  %16925 = sext i1 %16924 to i32
  %16926 = xor i32 %16925, -1
  %16927 = and i32 %16926, %16920
  %16928 = and i32 %16925, %16923
  %Mitigated111 = or i32 %16928, %16927
  %16929 = xor i32 %16781, %Mitigated111
  %16930 = add i32 %16336, %16929
  %16931 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %16932 = getelementptr inbounds [32 x i32], [32 x i32]* %16931, i64 0, i64 27
  %16933 = load i32, i32* %16932, align 4
  %16934 = add i32 %16930, %16933
  %16935 = add i32 %16929, %16934
  %16936 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %16937 = getelementptr inbounds [32 x i32], [32 x i32]* %16936, i64 0, i64 26
  %16938 = load i32, i32* %16937, align 4
  %16939 = add i32 %16930, %16938
  %16940 = xor i32 %14535, %16939
  %16941 = lshr i32 %16940, 1
  %16942 = shl i32 %16940, 31
  %16943 = add i32 %16941, %16942
  %16944 = shl i32 %14539, 1
  %16945 = lshr i32 %14539, 31
  %16946 = add i32 %16944, %16945
  %16947 = xor i32 %16946, %16935
  %16948 = and i32 %16943, 255
  %16949 = zext i32 %16948 to i64
  %16950 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %16951 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %16950, i64 0, i64 0
  %16952 = srem i64 %16949, 16
  %16953 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16952
  %16954 = load i32, i32* %16953, align 4
  %16955 = icmp eq i64 %16949, %16952
  %16956 = sext i1 %16955 to i32
  %16957 = xor i32 %16956, -1
  %16958 = and i32 %16957, 0
  %16959 = and i32 %16956, %16954
  %16960 = or i32 %16959, %16958
  %16961 = add i64 %16952, 16
  %16962 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16961
  %16963 = load i32, i32* %16962, align 4
  %16964 = icmp eq i64 %16949, %16961
  %16965 = sext i1 %16964 to i32
  %16966 = xor i32 %16965, -1
  %16967 = and i32 %16966, %16960
  %16968 = and i32 %16965, %16963
  %16969 = or i32 %16968, %16967
  %16970 = add i64 %16961, 16
  %16971 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16970
  %16972 = load i32, i32* %16971, align 4
  %16973 = icmp eq i64 %16949, %16970
  %16974 = sext i1 %16973 to i32
  %16975 = xor i32 %16974, -1
  %16976 = and i32 %16975, %16969
  %16977 = and i32 %16974, %16972
  %16978 = or i32 %16977, %16976
  %16979 = add i64 %16970, 16
  %16980 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16979
  %16981 = load i32, i32* %16980, align 4
  %16982 = icmp eq i64 %16949, %16979
  %16983 = sext i1 %16982 to i32
  %16984 = xor i32 %16983, -1
  %16985 = and i32 %16984, %16978
  %16986 = and i32 %16983, %16981
  %16987 = or i32 %16986, %16985
  %16988 = add i64 %16979, 16
  %16989 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16988
  %16990 = load i32, i32* %16989, align 4
  %16991 = icmp eq i64 %16949, %16988
  %16992 = sext i1 %16991 to i32
  %16993 = xor i32 %16992, -1
  %16994 = and i32 %16993, %16987
  %16995 = and i32 %16992, %16990
  %16996 = or i32 %16995, %16994
  %16997 = add i64 %16988, 16
  %16998 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %16997
  %16999 = load i32, i32* %16998, align 4
  %17000 = icmp eq i64 %16949, %16997
  %17001 = sext i1 %17000 to i32
  %17002 = xor i32 %17001, -1
  %17003 = and i32 %17002, %16996
  %17004 = and i32 %17001, %16999
  %17005 = or i32 %17004, %17003
  %17006 = add i64 %16997, 16
  %17007 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17006
  %17008 = load i32, i32* %17007, align 4
  %17009 = icmp eq i64 %16949, %17006
  %17010 = sext i1 %17009 to i32
  %17011 = xor i32 %17010, -1
  %17012 = and i32 %17011, %17005
  %17013 = and i32 %17010, %17008
  %17014 = or i32 %17013, %17012
  %17015 = add i64 %17006, 16
  %17016 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17015
  %17017 = load i32, i32* %17016, align 4
  %17018 = icmp eq i64 %16949, %17015
  %17019 = sext i1 %17018 to i32
  %17020 = xor i32 %17019, -1
  %17021 = and i32 %17020, %17014
  %17022 = and i32 %17019, %17017
  %17023 = or i32 %17022, %17021
  %17024 = add i64 %17015, 16
  %17025 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17024
  %17026 = load i32, i32* %17025, align 4
  %17027 = icmp eq i64 %16949, %17024
  %17028 = sext i1 %17027 to i32
  %17029 = xor i32 %17028, -1
  %17030 = and i32 %17029, %17023
  %17031 = and i32 %17028, %17026
  %17032 = or i32 %17031, %17030
  %17033 = add i64 %17024, 16
  %17034 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17033
  %17035 = load i32, i32* %17034, align 4
  %17036 = icmp eq i64 %16949, %17033
  %17037 = sext i1 %17036 to i32
  %17038 = xor i32 %17037, -1
  %17039 = and i32 %17038, %17032
  %17040 = and i32 %17037, %17035
  %17041 = or i32 %17040, %17039
  %17042 = add i64 %17033, 16
  %17043 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17042
  %17044 = load i32, i32* %17043, align 4
  %17045 = icmp eq i64 %16949, %17042
  %17046 = sext i1 %17045 to i32
  %17047 = xor i32 %17046, -1
  %17048 = and i32 %17047, %17041
  %17049 = and i32 %17046, %17044
  %17050 = or i32 %17049, %17048
  %17051 = add i64 %17042, 16
  %17052 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17051
  %17053 = load i32, i32* %17052, align 4
  %17054 = icmp eq i64 %16949, %17051
  %17055 = sext i1 %17054 to i32
  %17056 = xor i32 %17055, -1
  %17057 = and i32 %17056, %17050
  %17058 = and i32 %17055, %17053
  %17059 = or i32 %17058, %17057
  %17060 = add i64 %17051, 16
  %17061 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17060
  %17062 = load i32, i32* %17061, align 4
  %17063 = icmp eq i64 %16949, %17060
  %17064 = sext i1 %17063 to i32
  %17065 = xor i32 %17064, -1
  %17066 = and i32 %17065, %17059
  %17067 = and i32 %17064, %17062
  %17068 = or i32 %17067, %17066
  %17069 = add i64 %17060, 16
  %17070 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17069
  %17071 = load i32, i32* %17070, align 4
  %17072 = icmp eq i64 %16949, %17069
  %17073 = sext i1 %17072 to i32
  %17074 = xor i32 %17073, -1
  %17075 = and i32 %17074, %17068
  %17076 = and i32 %17073, %17071
  %17077 = or i32 %17076, %17075
  %17078 = add i64 %17069, 16
  %17079 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17078
  %17080 = load i32, i32* %17079, align 4
  %17081 = icmp eq i64 %16949, %17078
  %17082 = sext i1 %17081 to i32
  %17083 = xor i32 %17082, -1
  %17084 = and i32 %17083, %17077
  %17085 = and i32 %17082, %17080
  %17086 = or i32 %17085, %17084
  %17087 = add i64 %17078, 16
  %17088 = getelementptr inbounds [256 x i32], [256 x i32]* %16951, i64 0, i64 %17087
  %17089 = load i32, i32* %17088, align 4
  %17090 = icmp eq i64 %16949, %17087
  %17091 = sext i1 %17090 to i32
  %17092 = xor i32 %17091, -1
  %17093 = and i32 %17092, %17086
  %17094 = and i32 %17091, %17089
  %Mitigated112 = or i32 %17094, %17093
  %17095 = lshr i32 %16943, 8
  %17096 = and i32 %17095, 255
  %17097 = zext i32 %17096 to i64
  %17098 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17099 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17098, i64 0, i64 1
  %17100 = srem i64 %17097, 16
  %17101 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17100
  %17102 = load i32, i32* %17101, align 4
  %17103 = icmp eq i64 %17097, %17100
  %17104 = sext i1 %17103 to i32
  %17105 = xor i32 %17104, -1
  %17106 = and i32 %17105, 0
  %17107 = and i32 %17104, %17102
  %17108 = or i32 %17107, %17106
  %17109 = add i64 %17100, 16
  %17110 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17109
  %17111 = load i32, i32* %17110, align 4
  %17112 = icmp eq i64 %17097, %17109
  %17113 = sext i1 %17112 to i32
  %17114 = xor i32 %17113, -1
  %17115 = and i32 %17114, %17108
  %17116 = and i32 %17113, %17111
  %17117 = or i32 %17116, %17115
  %17118 = add i64 %17109, 16
  %17119 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17118
  %17120 = load i32, i32* %17119, align 4
  %17121 = icmp eq i64 %17097, %17118
  %17122 = sext i1 %17121 to i32
  %17123 = xor i32 %17122, -1
  %17124 = and i32 %17123, %17117
  %17125 = and i32 %17122, %17120
  %17126 = or i32 %17125, %17124
  %17127 = add i64 %17118, 16
  %17128 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17127
  %17129 = load i32, i32* %17128, align 4
  %17130 = icmp eq i64 %17097, %17127
  %17131 = sext i1 %17130 to i32
  %17132 = xor i32 %17131, -1
  %17133 = and i32 %17132, %17126
  %17134 = and i32 %17131, %17129
  %17135 = or i32 %17134, %17133
  %17136 = add i64 %17127, 16
  %17137 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17136
  %17138 = load i32, i32* %17137, align 4
  %17139 = icmp eq i64 %17097, %17136
  %17140 = sext i1 %17139 to i32
  %17141 = xor i32 %17140, -1
  %17142 = and i32 %17141, %17135
  %17143 = and i32 %17140, %17138
  %17144 = or i32 %17143, %17142
  %17145 = add i64 %17136, 16
  %17146 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17145
  %17147 = load i32, i32* %17146, align 4
  %17148 = icmp eq i64 %17097, %17145
  %17149 = sext i1 %17148 to i32
  %17150 = xor i32 %17149, -1
  %17151 = and i32 %17150, %17144
  %17152 = and i32 %17149, %17147
  %17153 = or i32 %17152, %17151
  %17154 = add i64 %17145, 16
  %17155 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17154
  %17156 = load i32, i32* %17155, align 4
  %17157 = icmp eq i64 %17097, %17154
  %17158 = sext i1 %17157 to i32
  %17159 = xor i32 %17158, -1
  %17160 = and i32 %17159, %17153
  %17161 = and i32 %17158, %17156
  %17162 = or i32 %17161, %17160
  %17163 = add i64 %17154, 16
  %17164 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17163
  %17165 = load i32, i32* %17164, align 4
  %17166 = icmp eq i64 %17097, %17163
  %17167 = sext i1 %17166 to i32
  %17168 = xor i32 %17167, -1
  %17169 = and i32 %17168, %17162
  %17170 = and i32 %17167, %17165
  %17171 = or i32 %17170, %17169
  %17172 = add i64 %17163, 16
  %17173 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17172
  %17174 = load i32, i32* %17173, align 4
  %17175 = icmp eq i64 %17097, %17172
  %17176 = sext i1 %17175 to i32
  %17177 = xor i32 %17176, -1
  %17178 = and i32 %17177, %17171
  %17179 = and i32 %17176, %17174
  %17180 = or i32 %17179, %17178
  %17181 = add i64 %17172, 16
  %17182 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17181
  %17183 = load i32, i32* %17182, align 4
  %17184 = icmp eq i64 %17097, %17181
  %17185 = sext i1 %17184 to i32
  %17186 = xor i32 %17185, -1
  %17187 = and i32 %17186, %17180
  %17188 = and i32 %17185, %17183
  %17189 = or i32 %17188, %17187
  %17190 = add i64 %17181, 16
  %17191 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17190
  %17192 = load i32, i32* %17191, align 4
  %17193 = icmp eq i64 %17097, %17190
  %17194 = sext i1 %17193 to i32
  %17195 = xor i32 %17194, -1
  %17196 = and i32 %17195, %17189
  %17197 = and i32 %17194, %17192
  %17198 = or i32 %17197, %17196
  %17199 = add i64 %17190, 16
  %17200 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17199
  %17201 = load i32, i32* %17200, align 4
  %17202 = icmp eq i64 %17097, %17199
  %17203 = sext i1 %17202 to i32
  %17204 = xor i32 %17203, -1
  %17205 = and i32 %17204, %17198
  %17206 = and i32 %17203, %17201
  %17207 = or i32 %17206, %17205
  %17208 = add i64 %17199, 16
  %17209 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17208
  %17210 = load i32, i32* %17209, align 4
  %17211 = icmp eq i64 %17097, %17208
  %17212 = sext i1 %17211 to i32
  %17213 = xor i32 %17212, -1
  %17214 = and i32 %17213, %17207
  %17215 = and i32 %17212, %17210
  %17216 = or i32 %17215, %17214
  %17217 = add i64 %17208, 16
  %17218 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17217
  %17219 = load i32, i32* %17218, align 4
  %17220 = icmp eq i64 %17097, %17217
  %17221 = sext i1 %17220 to i32
  %17222 = xor i32 %17221, -1
  %17223 = and i32 %17222, %17216
  %17224 = and i32 %17221, %17219
  %17225 = or i32 %17224, %17223
  %17226 = add i64 %17217, 16
  %17227 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17226
  %17228 = load i32, i32* %17227, align 4
  %17229 = icmp eq i64 %17097, %17226
  %17230 = sext i1 %17229 to i32
  %17231 = xor i32 %17230, -1
  %17232 = and i32 %17231, %17225
  %17233 = and i32 %17230, %17228
  %17234 = or i32 %17233, %17232
  %17235 = add i64 %17226, 16
  %17236 = getelementptr inbounds [256 x i32], [256 x i32]* %17099, i64 0, i64 %17235
  %17237 = load i32, i32* %17236, align 4
  %17238 = icmp eq i64 %17097, %17235
  %17239 = sext i1 %17238 to i32
  %17240 = xor i32 %17239, -1
  %17241 = and i32 %17240, %17234
  %17242 = and i32 %17239, %17237
  %Mitigated113 = or i32 %17242, %17241
  %17243 = xor i32 %Mitigated112, %Mitigated113
  %17244 = lshr i32 %16943, 16
  %17245 = and i32 %17244, 255
  %17246 = zext i32 %17245 to i64
  %17247 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17248 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17247, i64 0, i64 2
  %17249 = srem i64 %17246, 16
  %17250 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17249
  %17251 = load i32, i32* %17250, align 4
  %17252 = icmp eq i64 %17246, %17249
  %17253 = sext i1 %17252 to i32
  %17254 = xor i32 %17253, -1
  %17255 = and i32 %17254, 0
  %17256 = and i32 %17253, %17251
  %17257 = or i32 %17256, %17255
  %17258 = add i64 %17249, 16
  %17259 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17258
  %17260 = load i32, i32* %17259, align 4
  %17261 = icmp eq i64 %17246, %17258
  %17262 = sext i1 %17261 to i32
  %17263 = xor i32 %17262, -1
  %17264 = and i32 %17263, %17257
  %17265 = and i32 %17262, %17260
  %17266 = or i32 %17265, %17264
  %17267 = add i64 %17258, 16
  %17268 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17267
  %17269 = load i32, i32* %17268, align 4
  %17270 = icmp eq i64 %17246, %17267
  %17271 = sext i1 %17270 to i32
  %17272 = xor i32 %17271, -1
  %17273 = and i32 %17272, %17266
  %17274 = and i32 %17271, %17269
  %17275 = or i32 %17274, %17273
  %17276 = add i64 %17267, 16
  %17277 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17276
  %17278 = load i32, i32* %17277, align 4
  %17279 = icmp eq i64 %17246, %17276
  %17280 = sext i1 %17279 to i32
  %17281 = xor i32 %17280, -1
  %17282 = and i32 %17281, %17275
  %17283 = and i32 %17280, %17278
  %17284 = or i32 %17283, %17282
  %17285 = add i64 %17276, 16
  %17286 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17285
  %17287 = load i32, i32* %17286, align 4
  %17288 = icmp eq i64 %17246, %17285
  %17289 = sext i1 %17288 to i32
  %17290 = xor i32 %17289, -1
  %17291 = and i32 %17290, %17284
  %17292 = and i32 %17289, %17287
  %17293 = or i32 %17292, %17291
  %17294 = add i64 %17285, 16
  %17295 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17294
  %17296 = load i32, i32* %17295, align 4
  %17297 = icmp eq i64 %17246, %17294
  %17298 = sext i1 %17297 to i32
  %17299 = xor i32 %17298, -1
  %17300 = and i32 %17299, %17293
  %17301 = and i32 %17298, %17296
  %17302 = or i32 %17301, %17300
  %17303 = add i64 %17294, 16
  %17304 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17303
  %17305 = load i32, i32* %17304, align 4
  %17306 = icmp eq i64 %17246, %17303
  %17307 = sext i1 %17306 to i32
  %17308 = xor i32 %17307, -1
  %17309 = and i32 %17308, %17302
  %17310 = and i32 %17307, %17305
  %17311 = or i32 %17310, %17309
  %17312 = add i64 %17303, 16
  %17313 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17312
  %17314 = load i32, i32* %17313, align 4
  %17315 = icmp eq i64 %17246, %17312
  %17316 = sext i1 %17315 to i32
  %17317 = xor i32 %17316, -1
  %17318 = and i32 %17317, %17311
  %17319 = and i32 %17316, %17314
  %17320 = or i32 %17319, %17318
  %17321 = add i64 %17312, 16
  %17322 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17321
  %17323 = load i32, i32* %17322, align 4
  %17324 = icmp eq i64 %17246, %17321
  %17325 = sext i1 %17324 to i32
  %17326 = xor i32 %17325, -1
  %17327 = and i32 %17326, %17320
  %17328 = and i32 %17325, %17323
  %17329 = or i32 %17328, %17327
  %17330 = add i64 %17321, 16
  %17331 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17330
  %17332 = load i32, i32* %17331, align 4
  %17333 = icmp eq i64 %17246, %17330
  %17334 = sext i1 %17333 to i32
  %17335 = xor i32 %17334, -1
  %17336 = and i32 %17335, %17329
  %17337 = and i32 %17334, %17332
  %17338 = or i32 %17337, %17336
  %17339 = add i64 %17330, 16
  %17340 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17339
  %17341 = load i32, i32* %17340, align 4
  %17342 = icmp eq i64 %17246, %17339
  %17343 = sext i1 %17342 to i32
  %17344 = xor i32 %17343, -1
  %17345 = and i32 %17344, %17338
  %17346 = and i32 %17343, %17341
  %17347 = or i32 %17346, %17345
  %17348 = add i64 %17339, 16
  %17349 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17348
  %17350 = load i32, i32* %17349, align 4
  %17351 = icmp eq i64 %17246, %17348
  %17352 = sext i1 %17351 to i32
  %17353 = xor i32 %17352, -1
  %17354 = and i32 %17353, %17347
  %17355 = and i32 %17352, %17350
  %17356 = or i32 %17355, %17354
  %17357 = add i64 %17348, 16
  %17358 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17357
  %17359 = load i32, i32* %17358, align 4
  %17360 = icmp eq i64 %17246, %17357
  %17361 = sext i1 %17360 to i32
  %17362 = xor i32 %17361, -1
  %17363 = and i32 %17362, %17356
  %17364 = and i32 %17361, %17359
  %17365 = or i32 %17364, %17363
  %17366 = add i64 %17357, 16
  %17367 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17366
  %17368 = load i32, i32* %17367, align 4
  %17369 = icmp eq i64 %17246, %17366
  %17370 = sext i1 %17369 to i32
  %17371 = xor i32 %17370, -1
  %17372 = and i32 %17371, %17365
  %17373 = and i32 %17370, %17368
  %17374 = or i32 %17373, %17372
  %17375 = add i64 %17366, 16
  %17376 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17375
  %17377 = load i32, i32* %17376, align 4
  %17378 = icmp eq i64 %17246, %17375
  %17379 = sext i1 %17378 to i32
  %17380 = xor i32 %17379, -1
  %17381 = and i32 %17380, %17374
  %17382 = and i32 %17379, %17377
  %17383 = or i32 %17382, %17381
  %17384 = add i64 %17375, 16
  %17385 = getelementptr inbounds [256 x i32], [256 x i32]* %17248, i64 0, i64 %17384
  %17386 = load i32, i32* %17385, align 4
  %17387 = icmp eq i64 %17246, %17384
  %17388 = sext i1 %17387 to i32
  %17389 = xor i32 %17388, -1
  %17390 = and i32 %17389, %17383
  %17391 = and i32 %17388, %17386
  %Mitigated114 = or i32 %17391, %17390
  %17392 = xor i32 %17243, %Mitigated114
  %17393 = lshr i32 %16943, 24
  %17394 = zext i32 %17393 to i64
  %17395 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17396 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17395, i64 0, i64 3
  %17397 = srem i64 %17394, 16
  %17398 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17397
  %17399 = load i32, i32* %17398, align 4
  %17400 = icmp eq i64 %17394, %17397
  %17401 = sext i1 %17400 to i32
  %17402 = xor i32 %17401, -1
  %17403 = and i32 %17402, 0
  %17404 = and i32 %17401, %17399
  %17405 = or i32 %17404, %17403
  %17406 = add i64 %17397, 16
  %17407 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17406
  %17408 = load i32, i32* %17407, align 4
  %17409 = icmp eq i64 %17394, %17406
  %17410 = sext i1 %17409 to i32
  %17411 = xor i32 %17410, -1
  %17412 = and i32 %17411, %17405
  %17413 = and i32 %17410, %17408
  %17414 = or i32 %17413, %17412
  %17415 = add i64 %17406, 16
  %17416 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17415
  %17417 = load i32, i32* %17416, align 4
  %17418 = icmp eq i64 %17394, %17415
  %17419 = sext i1 %17418 to i32
  %17420 = xor i32 %17419, -1
  %17421 = and i32 %17420, %17414
  %17422 = and i32 %17419, %17417
  %17423 = or i32 %17422, %17421
  %17424 = add i64 %17415, 16
  %17425 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17424
  %17426 = load i32, i32* %17425, align 4
  %17427 = icmp eq i64 %17394, %17424
  %17428 = sext i1 %17427 to i32
  %17429 = xor i32 %17428, -1
  %17430 = and i32 %17429, %17423
  %17431 = and i32 %17428, %17426
  %17432 = or i32 %17431, %17430
  %17433 = add i64 %17424, 16
  %17434 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17433
  %17435 = load i32, i32* %17434, align 4
  %17436 = icmp eq i64 %17394, %17433
  %17437 = sext i1 %17436 to i32
  %17438 = xor i32 %17437, -1
  %17439 = and i32 %17438, %17432
  %17440 = and i32 %17437, %17435
  %17441 = or i32 %17440, %17439
  %17442 = add i64 %17433, 16
  %17443 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17442
  %17444 = load i32, i32* %17443, align 4
  %17445 = icmp eq i64 %17394, %17442
  %17446 = sext i1 %17445 to i32
  %17447 = xor i32 %17446, -1
  %17448 = and i32 %17447, %17441
  %17449 = and i32 %17446, %17444
  %17450 = or i32 %17449, %17448
  %17451 = add i64 %17442, 16
  %17452 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17451
  %17453 = load i32, i32* %17452, align 4
  %17454 = icmp eq i64 %17394, %17451
  %17455 = sext i1 %17454 to i32
  %17456 = xor i32 %17455, -1
  %17457 = and i32 %17456, %17450
  %17458 = and i32 %17455, %17453
  %17459 = or i32 %17458, %17457
  %17460 = add i64 %17451, 16
  %17461 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17460
  %17462 = load i32, i32* %17461, align 4
  %17463 = icmp eq i64 %17394, %17460
  %17464 = sext i1 %17463 to i32
  %17465 = xor i32 %17464, -1
  %17466 = and i32 %17465, %17459
  %17467 = and i32 %17464, %17462
  %17468 = or i32 %17467, %17466
  %17469 = add i64 %17460, 16
  %17470 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17469
  %17471 = load i32, i32* %17470, align 4
  %17472 = icmp eq i64 %17394, %17469
  %17473 = sext i1 %17472 to i32
  %17474 = xor i32 %17473, -1
  %17475 = and i32 %17474, %17468
  %17476 = and i32 %17473, %17471
  %17477 = or i32 %17476, %17475
  %17478 = add i64 %17469, 16
  %17479 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17478
  %17480 = load i32, i32* %17479, align 4
  %17481 = icmp eq i64 %17394, %17478
  %17482 = sext i1 %17481 to i32
  %17483 = xor i32 %17482, -1
  %17484 = and i32 %17483, %17477
  %17485 = and i32 %17482, %17480
  %17486 = or i32 %17485, %17484
  %17487 = add i64 %17478, 16
  %17488 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17487
  %17489 = load i32, i32* %17488, align 4
  %17490 = icmp eq i64 %17394, %17487
  %17491 = sext i1 %17490 to i32
  %17492 = xor i32 %17491, -1
  %17493 = and i32 %17492, %17486
  %17494 = and i32 %17491, %17489
  %17495 = or i32 %17494, %17493
  %17496 = add i64 %17487, 16
  %17497 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17496
  %17498 = load i32, i32* %17497, align 4
  %17499 = icmp eq i64 %17394, %17496
  %17500 = sext i1 %17499 to i32
  %17501 = xor i32 %17500, -1
  %17502 = and i32 %17501, %17495
  %17503 = and i32 %17500, %17498
  %17504 = or i32 %17503, %17502
  %17505 = add i64 %17496, 16
  %17506 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17505
  %17507 = load i32, i32* %17506, align 4
  %17508 = icmp eq i64 %17394, %17505
  %17509 = sext i1 %17508 to i32
  %17510 = xor i32 %17509, -1
  %17511 = and i32 %17510, %17504
  %17512 = and i32 %17509, %17507
  %17513 = or i32 %17512, %17511
  %17514 = add i64 %17505, 16
  %17515 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17514
  %17516 = load i32, i32* %17515, align 4
  %17517 = icmp eq i64 %17394, %17514
  %17518 = sext i1 %17517 to i32
  %17519 = xor i32 %17518, -1
  %17520 = and i32 %17519, %17513
  %17521 = and i32 %17518, %17516
  %17522 = or i32 %17521, %17520
  %17523 = add i64 %17514, 16
  %17524 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17523
  %17525 = load i32, i32* %17524, align 4
  %17526 = icmp eq i64 %17394, %17523
  %17527 = sext i1 %17526 to i32
  %17528 = xor i32 %17527, -1
  %17529 = and i32 %17528, %17522
  %17530 = and i32 %17527, %17525
  %17531 = or i32 %17530, %17529
  %17532 = add i64 %17523, 16
  %17533 = getelementptr inbounds [256 x i32], [256 x i32]* %17396, i64 0, i64 %17532
  %17534 = load i32, i32* %17533, align 4
  %17535 = icmp eq i64 %17394, %17532
  %17536 = sext i1 %17535 to i32
  %17537 = xor i32 %17536, -1
  %17538 = and i32 %17537, %17531
  %17539 = and i32 %17536, %17534
  %Mitigated115 = or i32 %17539, %17538
  %17540 = xor i32 %17392, %Mitigated115
  %17541 = and i32 %16947, 255
  %17542 = zext i32 %17541 to i64
  %17543 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17544 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17543, i64 0, i64 1
  %17545 = srem i64 %17542, 16
  %17546 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17545
  %17547 = load i32, i32* %17546, align 4
  %17548 = icmp eq i64 %17542, %17545
  %17549 = sext i1 %17548 to i32
  %17550 = xor i32 %17549, -1
  %17551 = and i32 %17550, 0
  %17552 = and i32 %17549, %17547
  %17553 = or i32 %17552, %17551
  %17554 = add i64 %17545, 16
  %17555 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17554
  %17556 = load i32, i32* %17555, align 4
  %17557 = icmp eq i64 %17542, %17554
  %17558 = sext i1 %17557 to i32
  %17559 = xor i32 %17558, -1
  %17560 = and i32 %17559, %17553
  %17561 = and i32 %17558, %17556
  %17562 = or i32 %17561, %17560
  %17563 = add i64 %17554, 16
  %17564 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17563
  %17565 = load i32, i32* %17564, align 4
  %17566 = icmp eq i64 %17542, %17563
  %17567 = sext i1 %17566 to i32
  %17568 = xor i32 %17567, -1
  %17569 = and i32 %17568, %17562
  %17570 = and i32 %17567, %17565
  %17571 = or i32 %17570, %17569
  %17572 = add i64 %17563, 16
  %17573 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17572
  %17574 = load i32, i32* %17573, align 4
  %17575 = icmp eq i64 %17542, %17572
  %17576 = sext i1 %17575 to i32
  %17577 = xor i32 %17576, -1
  %17578 = and i32 %17577, %17571
  %17579 = and i32 %17576, %17574
  %17580 = or i32 %17579, %17578
  %17581 = add i64 %17572, 16
  %17582 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17581
  %17583 = load i32, i32* %17582, align 4
  %17584 = icmp eq i64 %17542, %17581
  %17585 = sext i1 %17584 to i32
  %17586 = xor i32 %17585, -1
  %17587 = and i32 %17586, %17580
  %17588 = and i32 %17585, %17583
  %17589 = or i32 %17588, %17587
  %17590 = add i64 %17581, 16
  %17591 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17590
  %17592 = load i32, i32* %17591, align 4
  %17593 = icmp eq i64 %17542, %17590
  %17594 = sext i1 %17593 to i32
  %17595 = xor i32 %17594, -1
  %17596 = and i32 %17595, %17589
  %17597 = and i32 %17594, %17592
  %17598 = or i32 %17597, %17596
  %17599 = add i64 %17590, 16
  %17600 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17599
  %17601 = load i32, i32* %17600, align 4
  %17602 = icmp eq i64 %17542, %17599
  %17603 = sext i1 %17602 to i32
  %17604 = xor i32 %17603, -1
  %17605 = and i32 %17604, %17598
  %17606 = and i32 %17603, %17601
  %17607 = or i32 %17606, %17605
  %17608 = add i64 %17599, 16
  %17609 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17608
  %17610 = load i32, i32* %17609, align 4
  %17611 = icmp eq i64 %17542, %17608
  %17612 = sext i1 %17611 to i32
  %17613 = xor i32 %17612, -1
  %17614 = and i32 %17613, %17607
  %17615 = and i32 %17612, %17610
  %17616 = or i32 %17615, %17614
  %17617 = add i64 %17608, 16
  %17618 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17617
  %17619 = load i32, i32* %17618, align 4
  %17620 = icmp eq i64 %17542, %17617
  %17621 = sext i1 %17620 to i32
  %17622 = xor i32 %17621, -1
  %17623 = and i32 %17622, %17616
  %17624 = and i32 %17621, %17619
  %17625 = or i32 %17624, %17623
  %17626 = add i64 %17617, 16
  %17627 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17626
  %17628 = load i32, i32* %17627, align 4
  %17629 = icmp eq i64 %17542, %17626
  %17630 = sext i1 %17629 to i32
  %17631 = xor i32 %17630, -1
  %17632 = and i32 %17631, %17625
  %17633 = and i32 %17630, %17628
  %17634 = or i32 %17633, %17632
  %17635 = add i64 %17626, 16
  %17636 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17635
  %17637 = load i32, i32* %17636, align 4
  %17638 = icmp eq i64 %17542, %17635
  %17639 = sext i1 %17638 to i32
  %17640 = xor i32 %17639, -1
  %17641 = and i32 %17640, %17634
  %17642 = and i32 %17639, %17637
  %17643 = or i32 %17642, %17641
  %17644 = add i64 %17635, 16
  %17645 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17644
  %17646 = load i32, i32* %17645, align 4
  %17647 = icmp eq i64 %17542, %17644
  %17648 = sext i1 %17647 to i32
  %17649 = xor i32 %17648, -1
  %17650 = and i32 %17649, %17643
  %17651 = and i32 %17648, %17646
  %17652 = or i32 %17651, %17650
  %17653 = add i64 %17644, 16
  %17654 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17653
  %17655 = load i32, i32* %17654, align 4
  %17656 = icmp eq i64 %17542, %17653
  %17657 = sext i1 %17656 to i32
  %17658 = xor i32 %17657, -1
  %17659 = and i32 %17658, %17652
  %17660 = and i32 %17657, %17655
  %17661 = or i32 %17660, %17659
  %17662 = add i64 %17653, 16
  %17663 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17662
  %17664 = load i32, i32* %17663, align 4
  %17665 = icmp eq i64 %17542, %17662
  %17666 = sext i1 %17665 to i32
  %17667 = xor i32 %17666, -1
  %17668 = and i32 %17667, %17661
  %17669 = and i32 %17666, %17664
  %17670 = or i32 %17669, %17668
  %17671 = add i64 %17662, 16
  %17672 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17671
  %17673 = load i32, i32* %17672, align 4
  %17674 = icmp eq i64 %17542, %17671
  %17675 = sext i1 %17674 to i32
  %17676 = xor i32 %17675, -1
  %17677 = and i32 %17676, %17670
  %17678 = and i32 %17675, %17673
  %17679 = or i32 %17678, %17677
  %17680 = add i64 %17671, 16
  %17681 = getelementptr inbounds [256 x i32], [256 x i32]* %17544, i64 0, i64 %17680
  %17682 = load i32, i32* %17681, align 4
  %17683 = icmp eq i64 %17542, %17680
  %17684 = sext i1 %17683 to i32
  %17685 = xor i32 %17684, -1
  %17686 = and i32 %17685, %17679
  %17687 = and i32 %17684, %17682
  %Mitigated116 = or i32 %17687, %17686
  %17688 = lshr i32 %16947, 8
  %17689 = and i32 %17688, 255
  %17690 = zext i32 %17689 to i64
  %17691 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17692 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17691, i64 0, i64 2
  %17693 = srem i64 %17690, 16
  %17694 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17693
  %17695 = load i32, i32* %17694, align 4
  %17696 = icmp eq i64 %17690, %17693
  %17697 = sext i1 %17696 to i32
  %17698 = xor i32 %17697, -1
  %17699 = and i32 %17698, 0
  %17700 = and i32 %17697, %17695
  %17701 = or i32 %17700, %17699
  %17702 = add i64 %17693, 16
  %17703 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17702
  %17704 = load i32, i32* %17703, align 4
  %17705 = icmp eq i64 %17690, %17702
  %17706 = sext i1 %17705 to i32
  %17707 = xor i32 %17706, -1
  %17708 = and i32 %17707, %17701
  %17709 = and i32 %17706, %17704
  %17710 = or i32 %17709, %17708
  %17711 = add i64 %17702, 16
  %17712 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17711
  %17713 = load i32, i32* %17712, align 4
  %17714 = icmp eq i64 %17690, %17711
  %17715 = sext i1 %17714 to i32
  %17716 = xor i32 %17715, -1
  %17717 = and i32 %17716, %17710
  %17718 = and i32 %17715, %17713
  %17719 = or i32 %17718, %17717
  %17720 = add i64 %17711, 16
  %17721 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17720
  %17722 = load i32, i32* %17721, align 4
  %17723 = icmp eq i64 %17690, %17720
  %17724 = sext i1 %17723 to i32
  %17725 = xor i32 %17724, -1
  %17726 = and i32 %17725, %17719
  %17727 = and i32 %17724, %17722
  %17728 = or i32 %17727, %17726
  %17729 = add i64 %17720, 16
  %17730 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17729
  %17731 = load i32, i32* %17730, align 4
  %17732 = icmp eq i64 %17690, %17729
  %17733 = sext i1 %17732 to i32
  %17734 = xor i32 %17733, -1
  %17735 = and i32 %17734, %17728
  %17736 = and i32 %17733, %17731
  %17737 = or i32 %17736, %17735
  %17738 = add i64 %17729, 16
  %17739 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17738
  %17740 = load i32, i32* %17739, align 4
  %17741 = icmp eq i64 %17690, %17738
  %17742 = sext i1 %17741 to i32
  %17743 = xor i32 %17742, -1
  %17744 = and i32 %17743, %17737
  %17745 = and i32 %17742, %17740
  %17746 = or i32 %17745, %17744
  %17747 = add i64 %17738, 16
  %17748 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17747
  %17749 = load i32, i32* %17748, align 4
  %17750 = icmp eq i64 %17690, %17747
  %17751 = sext i1 %17750 to i32
  %17752 = xor i32 %17751, -1
  %17753 = and i32 %17752, %17746
  %17754 = and i32 %17751, %17749
  %17755 = or i32 %17754, %17753
  %17756 = add i64 %17747, 16
  %17757 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17756
  %17758 = load i32, i32* %17757, align 4
  %17759 = icmp eq i64 %17690, %17756
  %17760 = sext i1 %17759 to i32
  %17761 = xor i32 %17760, -1
  %17762 = and i32 %17761, %17755
  %17763 = and i32 %17760, %17758
  %17764 = or i32 %17763, %17762
  %17765 = add i64 %17756, 16
  %17766 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17765
  %17767 = load i32, i32* %17766, align 4
  %17768 = icmp eq i64 %17690, %17765
  %17769 = sext i1 %17768 to i32
  %17770 = xor i32 %17769, -1
  %17771 = and i32 %17770, %17764
  %17772 = and i32 %17769, %17767
  %17773 = or i32 %17772, %17771
  %17774 = add i64 %17765, 16
  %17775 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17774
  %17776 = load i32, i32* %17775, align 4
  %17777 = icmp eq i64 %17690, %17774
  %17778 = sext i1 %17777 to i32
  %17779 = xor i32 %17778, -1
  %17780 = and i32 %17779, %17773
  %17781 = and i32 %17778, %17776
  %17782 = or i32 %17781, %17780
  %17783 = add i64 %17774, 16
  %17784 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17783
  %17785 = load i32, i32* %17784, align 4
  %17786 = icmp eq i64 %17690, %17783
  %17787 = sext i1 %17786 to i32
  %17788 = xor i32 %17787, -1
  %17789 = and i32 %17788, %17782
  %17790 = and i32 %17787, %17785
  %17791 = or i32 %17790, %17789
  %17792 = add i64 %17783, 16
  %17793 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17792
  %17794 = load i32, i32* %17793, align 4
  %17795 = icmp eq i64 %17690, %17792
  %17796 = sext i1 %17795 to i32
  %17797 = xor i32 %17796, -1
  %17798 = and i32 %17797, %17791
  %17799 = and i32 %17796, %17794
  %17800 = or i32 %17799, %17798
  %17801 = add i64 %17792, 16
  %17802 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17801
  %17803 = load i32, i32* %17802, align 4
  %17804 = icmp eq i64 %17690, %17801
  %17805 = sext i1 %17804 to i32
  %17806 = xor i32 %17805, -1
  %17807 = and i32 %17806, %17800
  %17808 = and i32 %17805, %17803
  %17809 = or i32 %17808, %17807
  %17810 = add i64 %17801, 16
  %17811 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17810
  %17812 = load i32, i32* %17811, align 4
  %17813 = icmp eq i64 %17690, %17810
  %17814 = sext i1 %17813 to i32
  %17815 = xor i32 %17814, -1
  %17816 = and i32 %17815, %17809
  %17817 = and i32 %17814, %17812
  %17818 = or i32 %17817, %17816
  %17819 = add i64 %17810, 16
  %17820 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17819
  %17821 = load i32, i32* %17820, align 4
  %17822 = icmp eq i64 %17690, %17819
  %17823 = sext i1 %17822 to i32
  %17824 = xor i32 %17823, -1
  %17825 = and i32 %17824, %17818
  %17826 = and i32 %17823, %17821
  %17827 = or i32 %17826, %17825
  %17828 = add i64 %17819, 16
  %17829 = getelementptr inbounds [256 x i32], [256 x i32]* %17692, i64 0, i64 %17828
  %17830 = load i32, i32* %17829, align 4
  %17831 = icmp eq i64 %17690, %17828
  %17832 = sext i1 %17831 to i32
  %17833 = xor i32 %17832, -1
  %17834 = and i32 %17833, %17827
  %17835 = and i32 %17832, %17830
  %Mitigated117 = or i32 %17835, %17834
  %17836 = xor i32 %Mitigated116, %Mitigated117
  %17837 = lshr i32 %16947, 16
  %17838 = and i32 %17837, 255
  %17839 = zext i32 %17838 to i64
  %17840 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17841 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17840, i64 0, i64 3
  %17842 = srem i64 %17839, 16
  %17843 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17842
  %17844 = load i32, i32* %17843, align 4
  %17845 = icmp eq i64 %17839, %17842
  %17846 = sext i1 %17845 to i32
  %17847 = xor i32 %17846, -1
  %17848 = and i32 %17847, 0
  %17849 = and i32 %17846, %17844
  %17850 = or i32 %17849, %17848
  %17851 = add i64 %17842, 16
  %17852 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17851
  %17853 = load i32, i32* %17852, align 4
  %17854 = icmp eq i64 %17839, %17851
  %17855 = sext i1 %17854 to i32
  %17856 = xor i32 %17855, -1
  %17857 = and i32 %17856, %17850
  %17858 = and i32 %17855, %17853
  %17859 = or i32 %17858, %17857
  %17860 = add i64 %17851, 16
  %17861 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17860
  %17862 = load i32, i32* %17861, align 4
  %17863 = icmp eq i64 %17839, %17860
  %17864 = sext i1 %17863 to i32
  %17865 = xor i32 %17864, -1
  %17866 = and i32 %17865, %17859
  %17867 = and i32 %17864, %17862
  %17868 = or i32 %17867, %17866
  %17869 = add i64 %17860, 16
  %17870 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17869
  %17871 = load i32, i32* %17870, align 4
  %17872 = icmp eq i64 %17839, %17869
  %17873 = sext i1 %17872 to i32
  %17874 = xor i32 %17873, -1
  %17875 = and i32 %17874, %17868
  %17876 = and i32 %17873, %17871
  %17877 = or i32 %17876, %17875
  %17878 = add i64 %17869, 16
  %17879 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17878
  %17880 = load i32, i32* %17879, align 4
  %17881 = icmp eq i64 %17839, %17878
  %17882 = sext i1 %17881 to i32
  %17883 = xor i32 %17882, -1
  %17884 = and i32 %17883, %17877
  %17885 = and i32 %17882, %17880
  %17886 = or i32 %17885, %17884
  %17887 = add i64 %17878, 16
  %17888 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17887
  %17889 = load i32, i32* %17888, align 4
  %17890 = icmp eq i64 %17839, %17887
  %17891 = sext i1 %17890 to i32
  %17892 = xor i32 %17891, -1
  %17893 = and i32 %17892, %17886
  %17894 = and i32 %17891, %17889
  %17895 = or i32 %17894, %17893
  %17896 = add i64 %17887, 16
  %17897 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17896
  %17898 = load i32, i32* %17897, align 4
  %17899 = icmp eq i64 %17839, %17896
  %17900 = sext i1 %17899 to i32
  %17901 = xor i32 %17900, -1
  %17902 = and i32 %17901, %17895
  %17903 = and i32 %17900, %17898
  %17904 = or i32 %17903, %17902
  %17905 = add i64 %17896, 16
  %17906 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17905
  %17907 = load i32, i32* %17906, align 4
  %17908 = icmp eq i64 %17839, %17905
  %17909 = sext i1 %17908 to i32
  %17910 = xor i32 %17909, -1
  %17911 = and i32 %17910, %17904
  %17912 = and i32 %17909, %17907
  %17913 = or i32 %17912, %17911
  %17914 = add i64 %17905, 16
  %17915 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17914
  %17916 = load i32, i32* %17915, align 4
  %17917 = icmp eq i64 %17839, %17914
  %17918 = sext i1 %17917 to i32
  %17919 = xor i32 %17918, -1
  %17920 = and i32 %17919, %17913
  %17921 = and i32 %17918, %17916
  %17922 = or i32 %17921, %17920
  %17923 = add i64 %17914, 16
  %17924 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17923
  %17925 = load i32, i32* %17924, align 4
  %17926 = icmp eq i64 %17839, %17923
  %17927 = sext i1 %17926 to i32
  %17928 = xor i32 %17927, -1
  %17929 = and i32 %17928, %17922
  %17930 = and i32 %17927, %17925
  %17931 = or i32 %17930, %17929
  %17932 = add i64 %17923, 16
  %17933 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17932
  %17934 = load i32, i32* %17933, align 4
  %17935 = icmp eq i64 %17839, %17932
  %17936 = sext i1 %17935 to i32
  %17937 = xor i32 %17936, -1
  %17938 = and i32 %17937, %17931
  %17939 = and i32 %17936, %17934
  %17940 = or i32 %17939, %17938
  %17941 = add i64 %17932, 16
  %17942 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17941
  %17943 = load i32, i32* %17942, align 4
  %17944 = icmp eq i64 %17839, %17941
  %17945 = sext i1 %17944 to i32
  %17946 = xor i32 %17945, -1
  %17947 = and i32 %17946, %17940
  %17948 = and i32 %17945, %17943
  %17949 = or i32 %17948, %17947
  %17950 = add i64 %17941, 16
  %17951 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17950
  %17952 = load i32, i32* %17951, align 4
  %17953 = icmp eq i64 %17839, %17950
  %17954 = sext i1 %17953 to i32
  %17955 = xor i32 %17954, -1
  %17956 = and i32 %17955, %17949
  %17957 = and i32 %17954, %17952
  %17958 = or i32 %17957, %17956
  %17959 = add i64 %17950, 16
  %17960 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17959
  %17961 = load i32, i32* %17960, align 4
  %17962 = icmp eq i64 %17839, %17959
  %17963 = sext i1 %17962 to i32
  %17964 = xor i32 %17963, -1
  %17965 = and i32 %17964, %17958
  %17966 = and i32 %17963, %17961
  %17967 = or i32 %17966, %17965
  %17968 = add i64 %17959, 16
  %17969 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17968
  %17970 = load i32, i32* %17969, align 4
  %17971 = icmp eq i64 %17839, %17968
  %17972 = sext i1 %17971 to i32
  %17973 = xor i32 %17972, -1
  %17974 = and i32 %17973, %17967
  %17975 = and i32 %17972, %17970
  %17976 = or i32 %17975, %17974
  %17977 = add i64 %17968, 16
  %17978 = getelementptr inbounds [256 x i32], [256 x i32]* %17841, i64 0, i64 %17977
  %17979 = load i32, i32* %17978, align 4
  %17980 = icmp eq i64 %17839, %17977
  %17981 = sext i1 %17980 to i32
  %17982 = xor i32 %17981, -1
  %17983 = and i32 %17982, %17976
  %17984 = and i32 %17981, %17979
  %Mitigated118 = or i32 %17984, %17983
  %17985 = xor i32 %17836, %Mitigated118
  %17986 = lshr i32 %16947, 24
  %17987 = zext i32 %17986 to i64
  %17988 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %17989 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %17988, i64 0, i64 0
  %17990 = srem i64 %17987, 16
  %17991 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %17990
  %17992 = load i32, i32* %17991, align 4
  %17993 = icmp eq i64 %17987, %17990
  %17994 = sext i1 %17993 to i32
  %17995 = xor i32 %17994, -1
  %17996 = and i32 %17995, 0
  %17997 = and i32 %17994, %17992
  %17998 = or i32 %17997, %17996
  %17999 = add i64 %17990, 16
  %18000 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %17999
  %18001 = load i32, i32* %18000, align 4
  %18002 = icmp eq i64 %17987, %17999
  %18003 = sext i1 %18002 to i32
  %18004 = xor i32 %18003, -1
  %18005 = and i32 %18004, %17998
  %18006 = and i32 %18003, %18001
  %18007 = or i32 %18006, %18005
  %18008 = add i64 %17999, 16
  %18009 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18008
  %18010 = load i32, i32* %18009, align 4
  %18011 = icmp eq i64 %17987, %18008
  %18012 = sext i1 %18011 to i32
  %18013 = xor i32 %18012, -1
  %18014 = and i32 %18013, %18007
  %18015 = and i32 %18012, %18010
  %18016 = or i32 %18015, %18014
  %18017 = add i64 %18008, 16
  %18018 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18017
  %18019 = load i32, i32* %18018, align 4
  %18020 = icmp eq i64 %17987, %18017
  %18021 = sext i1 %18020 to i32
  %18022 = xor i32 %18021, -1
  %18023 = and i32 %18022, %18016
  %18024 = and i32 %18021, %18019
  %18025 = or i32 %18024, %18023
  %18026 = add i64 %18017, 16
  %18027 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18026
  %18028 = load i32, i32* %18027, align 4
  %18029 = icmp eq i64 %17987, %18026
  %18030 = sext i1 %18029 to i32
  %18031 = xor i32 %18030, -1
  %18032 = and i32 %18031, %18025
  %18033 = and i32 %18030, %18028
  %18034 = or i32 %18033, %18032
  %18035 = add i64 %18026, 16
  %18036 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18035
  %18037 = load i32, i32* %18036, align 4
  %18038 = icmp eq i64 %17987, %18035
  %18039 = sext i1 %18038 to i32
  %18040 = xor i32 %18039, -1
  %18041 = and i32 %18040, %18034
  %18042 = and i32 %18039, %18037
  %18043 = or i32 %18042, %18041
  %18044 = add i64 %18035, 16
  %18045 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18044
  %18046 = load i32, i32* %18045, align 4
  %18047 = icmp eq i64 %17987, %18044
  %18048 = sext i1 %18047 to i32
  %18049 = xor i32 %18048, -1
  %18050 = and i32 %18049, %18043
  %18051 = and i32 %18048, %18046
  %18052 = or i32 %18051, %18050
  %18053 = add i64 %18044, 16
  %18054 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18053
  %18055 = load i32, i32* %18054, align 4
  %18056 = icmp eq i64 %17987, %18053
  %18057 = sext i1 %18056 to i32
  %18058 = xor i32 %18057, -1
  %18059 = and i32 %18058, %18052
  %18060 = and i32 %18057, %18055
  %18061 = or i32 %18060, %18059
  %18062 = add i64 %18053, 16
  %18063 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18062
  %18064 = load i32, i32* %18063, align 4
  %18065 = icmp eq i64 %17987, %18062
  %18066 = sext i1 %18065 to i32
  %18067 = xor i32 %18066, -1
  %18068 = and i32 %18067, %18061
  %18069 = and i32 %18066, %18064
  %18070 = or i32 %18069, %18068
  %18071 = add i64 %18062, 16
  %18072 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18071
  %18073 = load i32, i32* %18072, align 4
  %18074 = icmp eq i64 %17987, %18071
  %18075 = sext i1 %18074 to i32
  %18076 = xor i32 %18075, -1
  %18077 = and i32 %18076, %18070
  %18078 = and i32 %18075, %18073
  %18079 = or i32 %18078, %18077
  %18080 = add i64 %18071, 16
  %18081 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18080
  %18082 = load i32, i32* %18081, align 4
  %18083 = icmp eq i64 %17987, %18080
  %18084 = sext i1 %18083 to i32
  %18085 = xor i32 %18084, -1
  %18086 = and i32 %18085, %18079
  %18087 = and i32 %18084, %18082
  %18088 = or i32 %18087, %18086
  %18089 = add i64 %18080, 16
  %18090 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18089
  %18091 = load i32, i32* %18090, align 4
  %18092 = icmp eq i64 %17987, %18089
  %18093 = sext i1 %18092 to i32
  %18094 = xor i32 %18093, -1
  %18095 = and i32 %18094, %18088
  %18096 = and i32 %18093, %18091
  %18097 = or i32 %18096, %18095
  %18098 = add i64 %18089, 16
  %18099 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18098
  %18100 = load i32, i32* %18099, align 4
  %18101 = icmp eq i64 %17987, %18098
  %18102 = sext i1 %18101 to i32
  %18103 = xor i32 %18102, -1
  %18104 = and i32 %18103, %18097
  %18105 = and i32 %18102, %18100
  %18106 = or i32 %18105, %18104
  %18107 = add i64 %18098, 16
  %18108 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18107
  %18109 = load i32, i32* %18108, align 4
  %18110 = icmp eq i64 %17987, %18107
  %18111 = sext i1 %18110 to i32
  %18112 = xor i32 %18111, -1
  %18113 = and i32 %18112, %18106
  %18114 = and i32 %18111, %18109
  %18115 = or i32 %18114, %18113
  %18116 = add i64 %18107, 16
  %18117 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18116
  %18118 = load i32, i32* %18117, align 4
  %18119 = icmp eq i64 %17987, %18116
  %18120 = sext i1 %18119 to i32
  %18121 = xor i32 %18120, -1
  %18122 = and i32 %18121, %18115
  %18123 = and i32 %18120, %18118
  %18124 = or i32 %18123, %18122
  %18125 = add i64 %18116, 16
  %18126 = getelementptr inbounds [256 x i32], [256 x i32]* %17989, i64 0, i64 %18125
  %18127 = load i32, i32* %18126, align 4
  %18128 = icmp eq i64 %17987, %18125
  %18129 = sext i1 %18128 to i32
  %18130 = xor i32 %18129, -1
  %18131 = and i32 %18130, %18124
  %18132 = and i32 %18129, %18127
  %Mitigated119 = or i32 %18132, %18131
  %18133 = xor i32 %17985, %Mitigated119
  %18134 = add i32 %17540, %18133
  %18135 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %18136 = getelementptr inbounds [32 x i32], [32 x i32]* %18135, i64 0, i64 29
  %18137 = load i32, i32* %18136, align 4
  %18138 = add i32 %18134, %18137
  %18139 = add i32 %18133, %18138
  %18140 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %18141 = getelementptr inbounds [32 x i32], [32 x i32]* %18140, i64 0, i64 28
  %18142 = load i32, i32* %18141, align 4
  %18143 = add i32 %18134, %18142
  %18144 = xor i32 %15739, %18143
  %18145 = lshr i32 %18144, 1
  %18146 = shl i32 %18144, 31
  %18147 = add i32 %18145, %18146
  %18148 = shl i32 %15743, 1
  %18149 = lshr i32 %15743, 31
  %18150 = add i32 %18148, %18149
  %18151 = xor i32 %18150, %18139
  %18152 = and i32 %18147, 255
  %18153 = zext i32 %18152 to i64
  %18154 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18155 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18154, i64 0, i64 0
  %18156 = srem i64 %18153, 16
  %18157 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18156
  %18158 = load i32, i32* %18157, align 4
  %18159 = icmp eq i64 %18153, %18156
  %18160 = sext i1 %18159 to i32
  %18161 = xor i32 %18160, -1
  %18162 = and i32 %18161, 0
  %18163 = and i32 %18160, %18158
  %18164 = or i32 %18163, %18162
  %18165 = add i64 %18156, 16
  %18166 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18165
  %18167 = load i32, i32* %18166, align 4
  %18168 = icmp eq i64 %18153, %18165
  %18169 = sext i1 %18168 to i32
  %18170 = xor i32 %18169, -1
  %18171 = and i32 %18170, %18164
  %18172 = and i32 %18169, %18167
  %18173 = or i32 %18172, %18171
  %18174 = add i64 %18165, 16
  %18175 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18174
  %18176 = load i32, i32* %18175, align 4
  %18177 = icmp eq i64 %18153, %18174
  %18178 = sext i1 %18177 to i32
  %18179 = xor i32 %18178, -1
  %18180 = and i32 %18179, %18173
  %18181 = and i32 %18178, %18176
  %18182 = or i32 %18181, %18180
  %18183 = add i64 %18174, 16
  %18184 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18183
  %18185 = load i32, i32* %18184, align 4
  %18186 = icmp eq i64 %18153, %18183
  %18187 = sext i1 %18186 to i32
  %18188 = xor i32 %18187, -1
  %18189 = and i32 %18188, %18182
  %18190 = and i32 %18187, %18185
  %18191 = or i32 %18190, %18189
  %18192 = add i64 %18183, 16
  %18193 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18192
  %18194 = load i32, i32* %18193, align 4
  %18195 = icmp eq i64 %18153, %18192
  %18196 = sext i1 %18195 to i32
  %18197 = xor i32 %18196, -1
  %18198 = and i32 %18197, %18191
  %18199 = and i32 %18196, %18194
  %18200 = or i32 %18199, %18198
  %18201 = add i64 %18192, 16
  %18202 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18201
  %18203 = load i32, i32* %18202, align 4
  %18204 = icmp eq i64 %18153, %18201
  %18205 = sext i1 %18204 to i32
  %18206 = xor i32 %18205, -1
  %18207 = and i32 %18206, %18200
  %18208 = and i32 %18205, %18203
  %18209 = or i32 %18208, %18207
  %18210 = add i64 %18201, 16
  %18211 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18210
  %18212 = load i32, i32* %18211, align 4
  %18213 = icmp eq i64 %18153, %18210
  %18214 = sext i1 %18213 to i32
  %18215 = xor i32 %18214, -1
  %18216 = and i32 %18215, %18209
  %18217 = and i32 %18214, %18212
  %18218 = or i32 %18217, %18216
  %18219 = add i64 %18210, 16
  %18220 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18219
  %18221 = load i32, i32* %18220, align 4
  %18222 = icmp eq i64 %18153, %18219
  %18223 = sext i1 %18222 to i32
  %18224 = xor i32 %18223, -1
  %18225 = and i32 %18224, %18218
  %18226 = and i32 %18223, %18221
  %18227 = or i32 %18226, %18225
  %18228 = add i64 %18219, 16
  %18229 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18228
  %18230 = load i32, i32* %18229, align 4
  %18231 = icmp eq i64 %18153, %18228
  %18232 = sext i1 %18231 to i32
  %18233 = xor i32 %18232, -1
  %18234 = and i32 %18233, %18227
  %18235 = and i32 %18232, %18230
  %18236 = or i32 %18235, %18234
  %18237 = add i64 %18228, 16
  %18238 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18237
  %18239 = load i32, i32* %18238, align 4
  %18240 = icmp eq i64 %18153, %18237
  %18241 = sext i1 %18240 to i32
  %18242 = xor i32 %18241, -1
  %18243 = and i32 %18242, %18236
  %18244 = and i32 %18241, %18239
  %18245 = or i32 %18244, %18243
  %18246 = add i64 %18237, 16
  %18247 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18246
  %18248 = load i32, i32* %18247, align 4
  %18249 = icmp eq i64 %18153, %18246
  %18250 = sext i1 %18249 to i32
  %18251 = xor i32 %18250, -1
  %18252 = and i32 %18251, %18245
  %18253 = and i32 %18250, %18248
  %18254 = or i32 %18253, %18252
  %18255 = add i64 %18246, 16
  %18256 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18255
  %18257 = load i32, i32* %18256, align 4
  %18258 = icmp eq i64 %18153, %18255
  %18259 = sext i1 %18258 to i32
  %18260 = xor i32 %18259, -1
  %18261 = and i32 %18260, %18254
  %18262 = and i32 %18259, %18257
  %18263 = or i32 %18262, %18261
  %18264 = add i64 %18255, 16
  %18265 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18264
  %18266 = load i32, i32* %18265, align 4
  %18267 = icmp eq i64 %18153, %18264
  %18268 = sext i1 %18267 to i32
  %18269 = xor i32 %18268, -1
  %18270 = and i32 %18269, %18263
  %18271 = and i32 %18268, %18266
  %18272 = or i32 %18271, %18270
  %18273 = add i64 %18264, 16
  %18274 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18273
  %18275 = load i32, i32* %18274, align 4
  %18276 = icmp eq i64 %18153, %18273
  %18277 = sext i1 %18276 to i32
  %18278 = xor i32 %18277, -1
  %18279 = and i32 %18278, %18272
  %18280 = and i32 %18277, %18275
  %18281 = or i32 %18280, %18279
  %18282 = add i64 %18273, 16
  %18283 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18282
  %18284 = load i32, i32* %18283, align 4
  %18285 = icmp eq i64 %18153, %18282
  %18286 = sext i1 %18285 to i32
  %18287 = xor i32 %18286, -1
  %18288 = and i32 %18287, %18281
  %18289 = and i32 %18286, %18284
  %18290 = or i32 %18289, %18288
  %18291 = add i64 %18282, 16
  %18292 = getelementptr inbounds [256 x i32], [256 x i32]* %18155, i64 0, i64 %18291
  %18293 = load i32, i32* %18292, align 4
  %18294 = icmp eq i64 %18153, %18291
  %18295 = sext i1 %18294 to i32
  %18296 = xor i32 %18295, -1
  %18297 = and i32 %18296, %18290
  %18298 = and i32 %18295, %18293
  %Mitigated120 = or i32 %18298, %18297
  %18299 = lshr i32 %18147, 8
  %18300 = and i32 %18299, 255
  %18301 = zext i32 %18300 to i64
  %18302 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18303 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18302, i64 0, i64 1
  %18304 = srem i64 %18301, 16
  %18305 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18304
  %18306 = load i32, i32* %18305, align 4
  %18307 = icmp eq i64 %18301, %18304
  %18308 = sext i1 %18307 to i32
  %18309 = xor i32 %18308, -1
  %18310 = and i32 %18309, 0
  %18311 = and i32 %18308, %18306
  %18312 = or i32 %18311, %18310
  %18313 = add i64 %18304, 16
  %18314 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18313
  %18315 = load i32, i32* %18314, align 4
  %18316 = icmp eq i64 %18301, %18313
  %18317 = sext i1 %18316 to i32
  %18318 = xor i32 %18317, -1
  %18319 = and i32 %18318, %18312
  %18320 = and i32 %18317, %18315
  %18321 = or i32 %18320, %18319
  %18322 = add i64 %18313, 16
  %18323 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18322
  %18324 = load i32, i32* %18323, align 4
  %18325 = icmp eq i64 %18301, %18322
  %18326 = sext i1 %18325 to i32
  %18327 = xor i32 %18326, -1
  %18328 = and i32 %18327, %18321
  %18329 = and i32 %18326, %18324
  %18330 = or i32 %18329, %18328
  %18331 = add i64 %18322, 16
  %18332 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18331
  %18333 = load i32, i32* %18332, align 4
  %18334 = icmp eq i64 %18301, %18331
  %18335 = sext i1 %18334 to i32
  %18336 = xor i32 %18335, -1
  %18337 = and i32 %18336, %18330
  %18338 = and i32 %18335, %18333
  %18339 = or i32 %18338, %18337
  %18340 = add i64 %18331, 16
  %18341 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18340
  %18342 = load i32, i32* %18341, align 4
  %18343 = icmp eq i64 %18301, %18340
  %18344 = sext i1 %18343 to i32
  %18345 = xor i32 %18344, -1
  %18346 = and i32 %18345, %18339
  %18347 = and i32 %18344, %18342
  %18348 = or i32 %18347, %18346
  %18349 = add i64 %18340, 16
  %18350 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18349
  %18351 = load i32, i32* %18350, align 4
  %18352 = icmp eq i64 %18301, %18349
  %18353 = sext i1 %18352 to i32
  %18354 = xor i32 %18353, -1
  %18355 = and i32 %18354, %18348
  %18356 = and i32 %18353, %18351
  %18357 = or i32 %18356, %18355
  %18358 = add i64 %18349, 16
  %18359 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18358
  %18360 = load i32, i32* %18359, align 4
  %18361 = icmp eq i64 %18301, %18358
  %18362 = sext i1 %18361 to i32
  %18363 = xor i32 %18362, -1
  %18364 = and i32 %18363, %18357
  %18365 = and i32 %18362, %18360
  %18366 = or i32 %18365, %18364
  %18367 = add i64 %18358, 16
  %18368 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18367
  %18369 = load i32, i32* %18368, align 4
  %18370 = icmp eq i64 %18301, %18367
  %18371 = sext i1 %18370 to i32
  %18372 = xor i32 %18371, -1
  %18373 = and i32 %18372, %18366
  %18374 = and i32 %18371, %18369
  %18375 = or i32 %18374, %18373
  %18376 = add i64 %18367, 16
  %18377 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18376
  %18378 = load i32, i32* %18377, align 4
  %18379 = icmp eq i64 %18301, %18376
  %18380 = sext i1 %18379 to i32
  %18381 = xor i32 %18380, -1
  %18382 = and i32 %18381, %18375
  %18383 = and i32 %18380, %18378
  %18384 = or i32 %18383, %18382
  %18385 = add i64 %18376, 16
  %18386 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18385
  %18387 = load i32, i32* %18386, align 4
  %18388 = icmp eq i64 %18301, %18385
  %18389 = sext i1 %18388 to i32
  %18390 = xor i32 %18389, -1
  %18391 = and i32 %18390, %18384
  %18392 = and i32 %18389, %18387
  %18393 = or i32 %18392, %18391
  %18394 = add i64 %18385, 16
  %18395 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18394
  %18396 = load i32, i32* %18395, align 4
  %18397 = icmp eq i64 %18301, %18394
  %18398 = sext i1 %18397 to i32
  %18399 = xor i32 %18398, -1
  %18400 = and i32 %18399, %18393
  %18401 = and i32 %18398, %18396
  %18402 = or i32 %18401, %18400
  %18403 = add i64 %18394, 16
  %18404 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18403
  %18405 = load i32, i32* %18404, align 4
  %18406 = icmp eq i64 %18301, %18403
  %18407 = sext i1 %18406 to i32
  %18408 = xor i32 %18407, -1
  %18409 = and i32 %18408, %18402
  %18410 = and i32 %18407, %18405
  %18411 = or i32 %18410, %18409
  %18412 = add i64 %18403, 16
  %18413 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18412
  %18414 = load i32, i32* %18413, align 4
  %18415 = icmp eq i64 %18301, %18412
  %18416 = sext i1 %18415 to i32
  %18417 = xor i32 %18416, -1
  %18418 = and i32 %18417, %18411
  %18419 = and i32 %18416, %18414
  %18420 = or i32 %18419, %18418
  %18421 = add i64 %18412, 16
  %18422 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18421
  %18423 = load i32, i32* %18422, align 4
  %18424 = icmp eq i64 %18301, %18421
  %18425 = sext i1 %18424 to i32
  %18426 = xor i32 %18425, -1
  %18427 = and i32 %18426, %18420
  %18428 = and i32 %18425, %18423
  %18429 = or i32 %18428, %18427
  %18430 = add i64 %18421, 16
  %18431 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18430
  %18432 = load i32, i32* %18431, align 4
  %18433 = icmp eq i64 %18301, %18430
  %18434 = sext i1 %18433 to i32
  %18435 = xor i32 %18434, -1
  %18436 = and i32 %18435, %18429
  %18437 = and i32 %18434, %18432
  %18438 = or i32 %18437, %18436
  %18439 = add i64 %18430, 16
  %18440 = getelementptr inbounds [256 x i32], [256 x i32]* %18303, i64 0, i64 %18439
  %18441 = load i32, i32* %18440, align 4
  %18442 = icmp eq i64 %18301, %18439
  %18443 = sext i1 %18442 to i32
  %18444 = xor i32 %18443, -1
  %18445 = and i32 %18444, %18438
  %18446 = and i32 %18443, %18441
  %Mitigated121 = or i32 %18446, %18445
  %18447 = xor i32 %Mitigated120, %Mitigated121
  %18448 = lshr i32 %18147, 16
  %18449 = and i32 %18448, 255
  %18450 = zext i32 %18449 to i64
  %18451 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18452 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18451, i64 0, i64 2
  %18453 = srem i64 %18450, 16
  %18454 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18453
  %18455 = load i32, i32* %18454, align 4
  %18456 = icmp eq i64 %18450, %18453
  %18457 = sext i1 %18456 to i32
  %18458 = xor i32 %18457, -1
  %18459 = and i32 %18458, 0
  %18460 = and i32 %18457, %18455
  %18461 = or i32 %18460, %18459
  %18462 = add i64 %18453, 16
  %18463 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18462
  %18464 = load i32, i32* %18463, align 4
  %18465 = icmp eq i64 %18450, %18462
  %18466 = sext i1 %18465 to i32
  %18467 = xor i32 %18466, -1
  %18468 = and i32 %18467, %18461
  %18469 = and i32 %18466, %18464
  %18470 = or i32 %18469, %18468
  %18471 = add i64 %18462, 16
  %18472 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18471
  %18473 = load i32, i32* %18472, align 4
  %18474 = icmp eq i64 %18450, %18471
  %18475 = sext i1 %18474 to i32
  %18476 = xor i32 %18475, -1
  %18477 = and i32 %18476, %18470
  %18478 = and i32 %18475, %18473
  %18479 = or i32 %18478, %18477
  %18480 = add i64 %18471, 16
  %18481 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18480
  %18482 = load i32, i32* %18481, align 4
  %18483 = icmp eq i64 %18450, %18480
  %18484 = sext i1 %18483 to i32
  %18485 = xor i32 %18484, -1
  %18486 = and i32 %18485, %18479
  %18487 = and i32 %18484, %18482
  %18488 = or i32 %18487, %18486
  %18489 = add i64 %18480, 16
  %18490 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18489
  %18491 = load i32, i32* %18490, align 4
  %18492 = icmp eq i64 %18450, %18489
  %18493 = sext i1 %18492 to i32
  %18494 = xor i32 %18493, -1
  %18495 = and i32 %18494, %18488
  %18496 = and i32 %18493, %18491
  %18497 = or i32 %18496, %18495
  %18498 = add i64 %18489, 16
  %18499 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18498
  %18500 = load i32, i32* %18499, align 4
  %18501 = icmp eq i64 %18450, %18498
  %18502 = sext i1 %18501 to i32
  %18503 = xor i32 %18502, -1
  %18504 = and i32 %18503, %18497
  %18505 = and i32 %18502, %18500
  %18506 = or i32 %18505, %18504
  %18507 = add i64 %18498, 16
  %18508 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18507
  %18509 = load i32, i32* %18508, align 4
  %18510 = icmp eq i64 %18450, %18507
  %18511 = sext i1 %18510 to i32
  %18512 = xor i32 %18511, -1
  %18513 = and i32 %18512, %18506
  %18514 = and i32 %18511, %18509
  %18515 = or i32 %18514, %18513
  %18516 = add i64 %18507, 16
  %18517 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18516
  %18518 = load i32, i32* %18517, align 4
  %18519 = icmp eq i64 %18450, %18516
  %18520 = sext i1 %18519 to i32
  %18521 = xor i32 %18520, -1
  %18522 = and i32 %18521, %18515
  %18523 = and i32 %18520, %18518
  %18524 = or i32 %18523, %18522
  %18525 = add i64 %18516, 16
  %18526 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18525
  %18527 = load i32, i32* %18526, align 4
  %18528 = icmp eq i64 %18450, %18525
  %18529 = sext i1 %18528 to i32
  %18530 = xor i32 %18529, -1
  %18531 = and i32 %18530, %18524
  %18532 = and i32 %18529, %18527
  %18533 = or i32 %18532, %18531
  %18534 = add i64 %18525, 16
  %18535 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18534
  %18536 = load i32, i32* %18535, align 4
  %18537 = icmp eq i64 %18450, %18534
  %18538 = sext i1 %18537 to i32
  %18539 = xor i32 %18538, -1
  %18540 = and i32 %18539, %18533
  %18541 = and i32 %18538, %18536
  %18542 = or i32 %18541, %18540
  %18543 = add i64 %18534, 16
  %18544 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18543
  %18545 = load i32, i32* %18544, align 4
  %18546 = icmp eq i64 %18450, %18543
  %18547 = sext i1 %18546 to i32
  %18548 = xor i32 %18547, -1
  %18549 = and i32 %18548, %18542
  %18550 = and i32 %18547, %18545
  %18551 = or i32 %18550, %18549
  %18552 = add i64 %18543, 16
  %18553 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18552
  %18554 = load i32, i32* %18553, align 4
  %18555 = icmp eq i64 %18450, %18552
  %18556 = sext i1 %18555 to i32
  %18557 = xor i32 %18556, -1
  %18558 = and i32 %18557, %18551
  %18559 = and i32 %18556, %18554
  %18560 = or i32 %18559, %18558
  %18561 = add i64 %18552, 16
  %18562 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18561
  %18563 = load i32, i32* %18562, align 4
  %18564 = icmp eq i64 %18450, %18561
  %18565 = sext i1 %18564 to i32
  %18566 = xor i32 %18565, -1
  %18567 = and i32 %18566, %18560
  %18568 = and i32 %18565, %18563
  %18569 = or i32 %18568, %18567
  %18570 = add i64 %18561, 16
  %18571 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18570
  %18572 = load i32, i32* %18571, align 4
  %18573 = icmp eq i64 %18450, %18570
  %18574 = sext i1 %18573 to i32
  %18575 = xor i32 %18574, -1
  %18576 = and i32 %18575, %18569
  %18577 = and i32 %18574, %18572
  %18578 = or i32 %18577, %18576
  %18579 = add i64 %18570, 16
  %18580 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18579
  %18581 = load i32, i32* %18580, align 4
  %18582 = icmp eq i64 %18450, %18579
  %18583 = sext i1 %18582 to i32
  %18584 = xor i32 %18583, -1
  %18585 = and i32 %18584, %18578
  %18586 = and i32 %18583, %18581
  %18587 = or i32 %18586, %18585
  %18588 = add i64 %18579, 16
  %18589 = getelementptr inbounds [256 x i32], [256 x i32]* %18452, i64 0, i64 %18588
  %18590 = load i32, i32* %18589, align 4
  %18591 = icmp eq i64 %18450, %18588
  %18592 = sext i1 %18591 to i32
  %18593 = xor i32 %18592, -1
  %18594 = and i32 %18593, %18587
  %18595 = and i32 %18592, %18590
  %Mitigated122 = or i32 %18595, %18594
  %18596 = xor i32 %18447, %Mitigated122
  %18597 = lshr i32 %18147, 24
  %18598 = zext i32 %18597 to i64
  %18599 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18600 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18599, i64 0, i64 3
  %18601 = srem i64 %18598, 16
  %18602 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18601
  %18603 = load i32, i32* %18602, align 4
  %18604 = icmp eq i64 %18598, %18601
  %18605 = sext i1 %18604 to i32
  %18606 = xor i32 %18605, -1
  %18607 = and i32 %18606, 0
  %18608 = and i32 %18605, %18603
  %18609 = or i32 %18608, %18607
  %18610 = add i64 %18601, 16
  %18611 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18610
  %18612 = load i32, i32* %18611, align 4
  %18613 = icmp eq i64 %18598, %18610
  %18614 = sext i1 %18613 to i32
  %18615 = xor i32 %18614, -1
  %18616 = and i32 %18615, %18609
  %18617 = and i32 %18614, %18612
  %18618 = or i32 %18617, %18616
  %18619 = add i64 %18610, 16
  %18620 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18619
  %18621 = load i32, i32* %18620, align 4
  %18622 = icmp eq i64 %18598, %18619
  %18623 = sext i1 %18622 to i32
  %18624 = xor i32 %18623, -1
  %18625 = and i32 %18624, %18618
  %18626 = and i32 %18623, %18621
  %18627 = or i32 %18626, %18625
  %18628 = add i64 %18619, 16
  %18629 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18628
  %18630 = load i32, i32* %18629, align 4
  %18631 = icmp eq i64 %18598, %18628
  %18632 = sext i1 %18631 to i32
  %18633 = xor i32 %18632, -1
  %18634 = and i32 %18633, %18627
  %18635 = and i32 %18632, %18630
  %18636 = or i32 %18635, %18634
  %18637 = add i64 %18628, 16
  %18638 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18637
  %18639 = load i32, i32* %18638, align 4
  %18640 = icmp eq i64 %18598, %18637
  %18641 = sext i1 %18640 to i32
  %18642 = xor i32 %18641, -1
  %18643 = and i32 %18642, %18636
  %18644 = and i32 %18641, %18639
  %18645 = or i32 %18644, %18643
  %18646 = add i64 %18637, 16
  %18647 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18646
  %18648 = load i32, i32* %18647, align 4
  %18649 = icmp eq i64 %18598, %18646
  %18650 = sext i1 %18649 to i32
  %18651 = xor i32 %18650, -1
  %18652 = and i32 %18651, %18645
  %18653 = and i32 %18650, %18648
  %18654 = or i32 %18653, %18652
  %18655 = add i64 %18646, 16
  %18656 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18655
  %18657 = load i32, i32* %18656, align 4
  %18658 = icmp eq i64 %18598, %18655
  %18659 = sext i1 %18658 to i32
  %18660 = xor i32 %18659, -1
  %18661 = and i32 %18660, %18654
  %18662 = and i32 %18659, %18657
  %18663 = or i32 %18662, %18661
  %18664 = add i64 %18655, 16
  %18665 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18664
  %18666 = load i32, i32* %18665, align 4
  %18667 = icmp eq i64 %18598, %18664
  %18668 = sext i1 %18667 to i32
  %18669 = xor i32 %18668, -1
  %18670 = and i32 %18669, %18663
  %18671 = and i32 %18668, %18666
  %18672 = or i32 %18671, %18670
  %18673 = add i64 %18664, 16
  %18674 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18673
  %18675 = load i32, i32* %18674, align 4
  %18676 = icmp eq i64 %18598, %18673
  %18677 = sext i1 %18676 to i32
  %18678 = xor i32 %18677, -1
  %18679 = and i32 %18678, %18672
  %18680 = and i32 %18677, %18675
  %18681 = or i32 %18680, %18679
  %18682 = add i64 %18673, 16
  %18683 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18682
  %18684 = load i32, i32* %18683, align 4
  %18685 = icmp eq i64 %18598, %18682
  %18686 = sext i1 %18685 to i32
  %18687 = xor i32 %18686, -1
  %18688 = and i32 %18687, %18681
  %18689 = and i32 %18686, %18684
  %18690 = or i32 %18689, %18688
  %18691 = add i64 %18682, 16
  %18692 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18691
  %18693 = load i32, i32* %18692, align 4
  %18694 = icmp eq i64 %18598, %18691
  %18695 = sext i1 %18694 to i32
  %18696 = xor i32 %18695, -1
  %18697 = and i32 %18696, %18690
  %18698 = and i32 %18695, %18693
  %18699 = or i32 %18698, %18697
  %18700 = add i64 %18691, 16
  %18701 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18700
  %18702 = load i32, i32* %18701, align 4
  %18703 = icmp eq i64 %18598, %18700
  %18704 = sext i1 %18703 to i32
  %18705 = xor i32 %18704, -1
  %18706 = and i32 %18705, %18699
  %18707 = and i32 %18704, %18702
  %18708 = or i32 %18707, %18706
  %18709 = add i64 %18700, 16
  %18710 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18709
  %18711 = load i32, i32* %18710, align 4
  %18712 = icmp eq i64 %18598, %18709
  %18713 = sext i1 %18712 to i32
  %18714 = xor i32 %18713, -1
  %18715 = and i32 %18714, %18708
  %18716 = and i32 %18713, %18711
  %18717 = or i32 %18716, %18715
  %18718 = add i64 %18709, 16
  %18719 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18718
  %18720 = load i32, i32* %18719, align 4
  %18721 = icmp eq i64 %18598, %18718
  %18722 = sext i1 %18721 to i32
  %18723 = xor i32 %18722, -1
  %18724 = and i32 %18723, %18717
  %18725 = and i32 %18722, %18720
  %18726 = or i32 %18725, %18724
  %18727 = add i64 %18718, 16
  %18728 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18727
  %18729 = load i32, i32* %18728, align 4
  %18730 = icmp eq i64 %18598, %18727
  %18731 = sext i1 %18730 to i32
  %18732 = xor i32 %18731, -1
  %18733 = and i32 %18732, %18726
  %18734 = and i32 %18731, %18729
  %18735 = or i32 %18734, %18733
  %18736 = add i64 %18727, 16
  %18737 = getelementptr inbounds [256 x i32], [256 x i32]* %18600, i64 0, i64 %18736
  %18738 = load i32, i32* %18737, align 4
  %18739 = icmp eq i64 %18598, %18736
  %18740 = sext i1 %18739 to i32
  %18741 = xor i32 %18740, -1
  %18742 = and i32 %18741, %18735
  %18743 = and i32 %18740, %18738
  %Mitigated123 = or i32 %18743, %18742
  %18744 = xor i32 %18596, %Mitigated123
  %18745 = and i32 %18151, 255
  %18746 = zext i32 %18745 to i64
  %18747 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18748 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18747, i64 0, i64 1
  %18749 = srem i64 %18746, 16
  %18750 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18749
  %18751 = load i32, i32* %18750, align 4
  %18752 = icmp eq i64 %18746, %18749
  %18753 = sext i1 %18752 to i32
  %18754 = xor i32 %18753, -1
  %18755 = and i32 %18754, 0
  %18756 = and i32 %18753, %18751
  %18757 = or i32 %18756, %18755
  %18758 = add i64 %18749, 16
  %18759 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18758
  %18760 = load i32, i32* %18759, align 4
  %18761 = icmp eq i64 %18746, %18758
  %18762 = sext i1 %18761 to i32
  %18763 = xor i32 %18762, -1
  %18764 = and i32 %18763, %18757
  %18765 = and i32 %18762, %18760
  %18766 = or i32 %18765, %18764
  %18767 = add i64 %18758, 16
  %18768 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18767
  %18769 = load i32, i32* %18768, align 4
  %18770 = icmp eq i64 %18746, %18767
  %18771 = sext i1 %18770 to i32
  %18772 = xor i32 %18771, -1
  %18773 = and i32 %18772, %18766
  %18774 = and i32 %18771, %18769
  %18775 = or i32 %18774, %18773
  %18776 = add i64 %18767, 16
  %18777 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18776
  %18778 = load i32, i32* %18777, align 4
  %18779 = icmp eq i64 %18746, %18776
  %18780 = sext i1 %18779 to i32
  %18781 = xor i32 %18780, -1
  %18782 = and i32 %18781, %18775
  %18783 = and i32 %18780, %18778
  %18784 = or i32 %18783, %18782
  %18785 = add i64 %18776, 16
  %18786 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18785
  %18787 = load i32, i32* %18786, align 4
  %18788 = icmp eq i64 %18746, %18785
  %18789 = sext i1 %18788 to i32
  %18790 = xor i32 %18789, -1
  %18791 = and i32 %18790, %18784
  %18792 = and i32 %18789, %18787
  %18793 = or i32 %18792, %18791
  %18794 = add i64 %18785, 16
  %18795 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18794
  %18796 = load i32, i32* %18795, align 4
  %18797 = icmp eq i64 %18746, %18794
  %18798 = sext i1 %18797 to i32
  %18799 = xor i32 %18798, -1
  %18800 = and i32 %18799, %18793
  %18801 = and i32 %18798, %18796
  %18802 = or i32 %18801, %18800
  %18803 = add i64 %18794, 16
  %18804 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18803
  %18805 = load i32, i32* %18804, align 4
  %18806 = icmp eq i64 %18746, %18803
  %18807 = sext i1 %18806 to i32
  %18808 = xor i32 %18807, -1
  %18809 = and i32 %18808, %18802
  %18810 = and i32 %18807, %18805
  %18811 = or i32 %18810, %18809
  %18812 = add i64 %18803, 16
  %18813 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18812
  %18814 = load i32, i32* %18813, align 4
  %18815 = icmp eq i64 %18746, %18812
  %18816 = sext i1 %18815 to i32
  %18817 = xor i32 %18816, -1
  %18818 = and i32 %18817, %18811
  %18819 = and i32 %18816, %18814
  %18820 = or i32 %18819, %18818
  %18821 = add i64 %18812, 16
  %18822 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18821
  %18823 = load i32, i32* %18822, align 4
  %18824 = icmp eq i64 %18746, %18821
  %18825 = sext i1 %18824 to i32
  %18826 = xor i32 %18825, -1
  %18827 = and i32 %18826, %18820
  %18828 = and i32 %18825, %18823
  %18829 = or i32 %18828, %18827
  %18830 = add i64 %18821, 16
  %18831 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18830
  %18832 = load i32, i32* %18831, align 4
  %18833 = icmp eq i64 %18746, %18830
  %18834 = sext i1 %18833 to i32
  %18835 = xor i32 %18834, -1
  %18836 = and i32 %18835, %18829
  %18837 = and i32 %18834, %18832
  %18838 = or i32 %18837, %18836
  %18839 = add i64 %18830, 16
  %18840 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18839
  %18841 = load i32, i32* %18840, align 4
  %18842 = icmp eq i64 %18746, %18839
  %18843 = sext i1 %18842 to i32
  %18844 = xor i32 %18843, -1
  %18845 = and i32 %18844, %18838
  %18846 = and i32 %18843, %18841
  %18847 = or i32 %18846, %18845
  %18848 = add i64 %18839, 16
  %18849 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18848
  %18850 = load i32, i32* %18849, align 4
  %18851 = icmp eq i64 %18746, %18848
  %18852 = sext i1 %18851 to i32
  %18853 = xor i32 %18852, -1
  %18854 = and i32 %18853, %18847
  %18855 = and i32 %18852, %18850
  %18856 = or i32 %18855, %18854
  %18857 = add i64 %18848, 16
  %18858 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18857
  %18859 = load i32, i32* %18858, align 4
  %18860 = icmp eq i64 %18746, %18857
  %18861 = sext i1 %18860 to i32
  %18862 = xor i32 %18861, -1
  %18863 = and i32 %18862, %18856
  %18864 = and i32 %18861, %18859
  %18865 = or i32 %18864, %18863
  %18866 = add i64 %18857, 16
  %18867 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18866
  %18868 = load i32, i32* %18867, align 4
  %18869 = icmp eq i64 %18746, %18866
  %18870 = sext i1 %18869 to i32
  %18871 = xor i32 %18870, -1
  %18872 = and i32 %18871, %18865
  %18873 = and i32 %18870, %18868
  %18874 = or i32 %18873, %18872
  %18875 = add i64 %18866, 16
  %18876 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18875
  %18877 = load i32, i32* %18876, align 4
  %18878 = icmp eq i64 %18746, %18875
  %18879 = sext i1 %18878 to i32
  %18880 = xor i32 %18879, -1
  %18881 = and i32 %18880, %18874
  %18882 = and i32 %18879, %18877
  %18883 = or i32 %18882, %18881
  %18884 = add i64 %18875, 16
  %18885 = getelementptr inbounds [256 x i32], [256 x i32]* %18748, i64 0, i64 %18884
  %18886 = load i32, i32* %18885, align 4
  %18887 = icmp eq i64 %18746, %18884
  %18888 = sext i1 %18887 to i32
  %18889 = xor i32 %18888, -1
  %18890 = and i32 %18889, %18883
  %18891 = and i32 %18888, %18886
  %Mitigated124 = or i32 %18891, %18890
  %18892 = lshr i32 %18151, 8
  %18893 = and i32 %18892, 255
  %18894 = zext i32 %18893 to i64
  %18895 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %18896 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %18895, i64 0, i64 2
  %18897 = srem i64 %18894, 16
  %18898 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18897
  %18899 = load i32, i32* %18898, align 4
  %18900 = icmp eq i64 %18894, %18897
  %18901 = sext i1 %18900 to i32
  %18902 = xor i32 %18901, -1
  %18903 = and i32 %18902, 0
  %18904 = and i32 %18901, %18899
  %18905 = or i32 %18904, %18903
  %18906 = add i64 %18897, 16
  %18907 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18906
  %18908 = load i32, i32* %18907, align 4
  %18909 = icmp eq i64 %18894, %18906
  %18910 = sext i1 %18909 to i32
  %18911 = xor i32 %18910, -1
  %18912 = and i32 %18911, %18905
  %18913 = and i32 %18910, %18908
  %18914 = or i32 %18913, %18912
  %18915 = add i64 %18906, 16
  %18916 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18915
  %18917 = load i32, i32* %18916, align 4
  %18918 = icmp eq i64 %18894, %18915
  %18919 = sext i1 %18918 to i32
  %18920 = xor i32 %18919, -1
  %18921 = and i32 %18920, %18914
  %18922 = and i32 %18919, %18917
  %18923 = or i32 %18922, %18921
  %18924 = add i64 %18915, 16
  %18925 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18924
  %18926 = load i32, i32* %18925, align 4
  %18927 = icmp eq i64 %18894, %18924
  %18928 = sext i1 %18927 to i32
  %18929 = xor i32 %18928, -1
  %18930 = and i32 %18929, %18923
  %18931 = and i32 %18928, %18926
  %18932 = or i32 %18931, %18930
  %18933 = add i64 %18924, 16
  %18934 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18933
  %18935 = load i32, i32* %18934, align 4
  %18936 = icmp eq i64 %18894, %18933
  %18937 = sext i1 %18936 to i32
  %18938 = xor i32 %18937, -1
  %18939 = and i32 %18938, %18932
  %18940 = and i32 %18937, %18935
  %18941 = or i32 %18940, %18939
  %18942 = add i64 %18933, 16
  %18943 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18942
  %18944 = load i32, i32* %18943, align 4
  %18945 = icmp eq i64 %18894, %18942
  %18946 = sext i1 %18945 to i32
  %18947 = xor i32 %18946, -1
  %18948 = and i32 %18947, %18941
  %18949 = and i32 %18946, %18944
  %18950 = or i32 %18949, %18948
  %18951 = add i64 %18942, 16
  %18952 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18951
  %18953 = load i32, i32* %18952, align 4
  %18954 = icmp eq i64 %18894, %18951
  %18955 = sext i1 %18954 to i32
  %18956 = xor i32 %18955, -1
  %18957 = and i32 %18956, %18950
  %18958 = and i32 %18955, %18953
  %18959 = or i32 %18958, %18957
  %18960 = add i64 %18951, 16
  %18961 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18960
  %18962 = load i32, i32* %18961, align 4
  %18963 = icmp eq i64 %18894, %18960
  %18964 = sext i1 %18963 to i32
  %18965 = xor i32 %18964, -1
  %18966 = and i32 %18965, %18959
  %18967 = and i32 %18964, %18962
  %18968 = or i32 %18967, %18966
  %18969 = add i64 %18960, 16
  %18970 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18969
  %18971 = load i32, i32* %18970, align 4
  %18972 = icmp eq i64 %18894, %18969
  %18973 = sext i1 %18972 to i32
  %18974 = xor i32 %18973, -1
  %18975 = and i32 %18974, %18968
  %18976 = and i32 %18973, %18971
  %18977 = or i32 %18976, %18975
  %18978 = add i64 %18969, 16
  %18979 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18978
  %18980 = load i32, i32* %18979, align 4
  %18981 = icmp eq i64 %18894, %18978
  %18982 = sext i1 %18981 to i32
  %18983 = xor i32 %18982, -1
  %18984 = and i32 %18983, %18977
  %18985 = and i32 %18982, %18980
  %18986 = or i32 %18985, %18984
  %18987 = add i64 %18978, 16
  %18988 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18987
  %18989 = load i32, i32* %18988, align 4
  %18990 = icmp eq i64 %18894, %18987
  %18991 = sext i1 %18990 to i32
  %18992 = xor i32 %18991, -1
  %18993 = and i32 %18992, %18986
  %18994 = and i32 %18991, %18989
  %18995 = or i32 %18994, %18993
  %18996 = add i64 %18987, 16
  %18997 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %18996
  %18998 = load i32, i32* %18997, align 4
  %18999 = icmp eq i64 %18894, %18996
  %19000 = sext i1 %18999 to i32
  %19001 = xor i32 %19000, -1
  %19002 = and i32 %19001, %18995
  %19003 = and i32 %19000, %18998
  %19004 = or i32 %19003, %19002
  %19005 = add i64 %18996, 16
  %19006 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %19005
  %19007 = load i32, i32* %19006, align 4
  %19008 = icmp eq i64 %18894, %19005
  %19009 = sext i1 %19008 to i32
  %19010 = xor i32 %19009, -1
  %19011 = and i32 %19010, %19004
  %19012 = and i32 %19009, %19007
  %19013 = or i32 %19012, %19011
  %19014 = add i64 %19005, 16
  %19015 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %19014
  %19016 = load i32, i32* %19015, align 4
  %19017 = icmp eq i64 %18894, %19014
  %19018 = sext i1 %19017 to i32
  %19019 = xor i32 %19018, -1
  %19020 = and i32 %19019, %19013
  %19021 = and i32 %19018, %19016
  %19022 = or i32 %19021, %19020
  %19023 = add i64 %19014, 16
  %19024 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %19023
  %19025 = load i32, i32* %19024, align 4
  %19026 = icmp eq i64 %18894, %19023
  %19027 = sext i1 %19026 to i32
  %19028 = xor i32 %19027, -1
  %19029 = and i32 %19028, %19022
  %19030 = and i32 %19027, %19025
  %19031 = or i32 %19030, %19029
  %19032 = add i64 %19023, 16
  %19033 = getelementptr inbounds [256 x i32], [256 x i32]* %18896, i64 0, i64 %19032
  %19034 = load i32, i32* %19033, align 4
  %19035 = icmp eq i64 %18894, %19032
  %19036 = sext i1 %19035 to i32
  %19037 = xor i32 %19036, -1
  %19038 = and i32 %19037, %19031
  %19039 = and i32 %19036, %19034
  %Mitigated125 = or i32 %19039, %19038
  %19040 = xor i32 %Mitigated124, %Mitigated125
  %19041 = lshr i32 %18151, 16
  %19042 = and i32 %19041, 255
  %19043 = zext i32 %19042 to i64
  %19044 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %19045 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %19044, i64 0, i64 3
  %19046 = srem i64 %19043, 16
  %19047 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19046
  %19048 = load i32, i32* %19047, align 4
  %19049 = icmp eq i64 %19043, %19046
  %19050 = sext i1 %19049 to i32
  %19051 = xor i32 %19050, -1
  %19052 = and i32 %19051, 0
  %19053 = and i32 %19050, %19048
  %19054 = or i32 %19053, %19052
  %19055 = add i64 %19046, 16
  %19056 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19055
  %19057 = load i32, i32* %19056, align 4
  %19058 = icmp eq i64 %19043, %19055
  %19059 = sext i1 %19058 to i32
  %19060 = xor i32 %19059, -1
  %19061 = and i32 %19060, %19054
  %19062 = and i32 %19059, %19057
  %19063 = or i32 %19062, %19061
  %19064 = add i64 %19055, 16
  %19065 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19064
  %19066 = load i32, i32* %19065, align 4
  %19067 = icmp eq i64 %19043, %19064
  %19068 = sext i1 %19067 to i32
  %19069 = xor i32 %19068, -1
  %19070 = and i32 %19069, %19063
  %19071 = and i32 %19068, %19066
  %19072 = or i32 %19071, %19070
  %19073 = add i64 %19064, 16
  %19074 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19073
  %19075 = load i32, i32* %19074, align 4
  %19076 = icmp eq i64 %19043, %19073
  %19077 = sext i1 %19076 to i32
  %19078 = xor i32 %19077, -1
  %19079 = and i32 %19078, %19072
  %19080 = and i32 %19077, %19075
  %19081 = or i32 %19080, %19079
  %19082 = add i64 %19073, 16
  %19083 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19082
  %19084 = load i32, i32* %19083, align 4
  %19085 = icmp eq i64 %19043, %19082
  %19086 = sext i1 %19085 to i32
  %19087 = xor i32 %19086, -1
  %19088 = and i32 %19087, %19081
  %19089 = and i32 %19086, %19084
  %19090 = or i32 %19089, %19088
  %19091 = add i64 %19082, 16
  %19092 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19091
  %19093 = load i32, i32* %19092, align 4
  %19094 = icmp eq i64 %19043, %19091
  %19095 = sext i1 %19094 to i32
  %19096 = xor i32 %19095, -1
  %19097 = and i32 %19096, %19090
  %19098 = and i32 %19095, %19093
  %19099 = or i32 %19098, %19097
  %19100 = add i64 %19091, 16
  %19101 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19100
  %19102 = load i32, i32* %19101, align 4
  %19103 = icmp eq i64 %19043, %19100
  %19104 = sext i1 %19103 to i32
  %19105 = xor i32 %19104, -1
  %19106 = and i32 %19105, %19099
  %19107 = and i32 %19104, %19102
  %19108 = or i32 %19107, %19106
  %19109 = add i64 %19100, 16
  %19110 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19109
  %19111 = load i32, i32* %19110, align 4
  %19112 = icmp eq i64 %19043, %19109
  %19113 = sext i1 %19112 to i32
  %19114 = xor i32 %19113, -1
  %19115 = and i32 %19114, %19108
  %19116 = and i32 %19113, %19111
  %19117 = or i32 %19116, %19115
  %19118 = add i64 %19109, 16
  %19119 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19118
  %19120 = load i32, i32* %19119, align 4
  %19121 = icmp eq i64 %19043, %19118
  %19122 = sext i1 %19121 to i32
  %19123 = xor i32 %19122, -1
  %19124 = and i32 %19123, %19117
  %19125 = and i32 %19122, %19120
  %19126 = or i32 %19125, %19124
  %19127 = add i64 %19118, 16
  %19128 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19127
  %19129 = load i32, i32* %19128, align 4
  %19130 = icmp eq i64 %19043, %19127
  %19131 = sext i1 %19130 to i32
  %19132 = xor i32 %19131, -1
  %19133 = and i32 %19132, %19126
  %19134 = and i32 %19131, %19129
  %19135 = or i32 %19134, %19133
  %19136 = add i64 %19127, 16
  %19137 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19136
  %19138 = load i32, i32* %19137, align 4
  %19139 = icmp eq i64 %19043, %19136
  %19140 = sext i1 %19139 to i32
  %19141 = xor i32 %19140, -1
  %19142 = and i32 %19141, %19135
  %19143 = and i32 %19140, %19138
  %19144 = or i32 %19143, %19142
  %19145 = add i64 %19136, 16
  %19146 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19145
  %19147 = load i32, i32* %19146, align 4
  %19148 = icmp eq i64 %19043, %19145
  %19149 = sext i1 %19148 to i32
  %19150 = xor i32 %19149, -1
  %19151 = and i32 %19150, %19144
  %19152 = and i32 %19149, %19147
  %19153 = or i32 %19152, %19151
  %19154 = add i64 %19145, 16
  %19155 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19154
  %19156 = load i32, i32* %19155, align 4
  %19157 = icmp eq i64 %19043, %19154
  %19158 = sext i1 %19157 to i32
  %19159 = xor i32 %19158, -1
  %19160 = and i32 %19159, %19153
  %19161 = and i32 %19158, %19156
  %19162 = or i32 %19161, %19160
  %19163 = add i64 %19154, 16
  %19164 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19163
  %19165 = load i32, i32* %19164, align 4
  %19166 = icmp eq i64 %19043, %19163
  %19167 = sext i1 %19166 to i32
  %19168 = xor i32 %19167, -1
  %19169 = and i32 %19168, %19162
  %19170 = and i32 %19167, %19165
  %19171 = or i32 %19170, %19169
  %19172 = add i64 %19163, 16
  %19173 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19172
  %19174 = load i32, i32* %19173, align 4
  %19175 = icmp eq i64 %19043, %19172
  %19176 = sext i1 %19175 to i32
  %19177 = xor i32 %19176, -1
  %19178 = and i32 %19177, %19171
  %19179 = and i32 %19176, %19174
  %19180 = or i32 %19179, %19178
  %19181 = add i64 %19172, 16
  %19182 = getelementptr inbounds [256 x i32], [256 x i32]* %19045, i64 0, i64 %19181
  %19183 = load i32, i32* %19182, align 4
  %19184 = icmp eq i64 %19043, %19181
  %19185 = sext i1 %19184 to i32
  %19186 = xor i32 %19185, -1
  %19187 = and i32 %19186, %19180
  %19188 = and i32 %19185, %19183
  %Mitigated126 = or i32 %19188, %19187
  %19189 = xor i32 %19040, %Mitigated126
  %19190 = lshr i32 %18151, 24
  %19191 = zext i32 %19190 to i64
  %19192 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 0
  %19193 = getelementptr inbounds [4 x [256 x i32]], [4 x [256 x i32]]* %19192, i64 0, i64 0
  %19194 = srem i64 %19191, 16
  %19195 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19194
  %19196 = load i32, i32* %19195, align 4
  %19197 = icmp eq i64 %19191, %19194
  %19198 = sext i1 %19197 to i32
  %19199 = xor i32 %19198, -1
  %19200 = and i32 %19199, 0
  %19201 = and i32 %19198, %19196
  %19202 = or i32 %19201, %19200
  %19203 = add i64 %19194, 16
  %19204 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19203
  %19205 = load i32, i32* %19204, align 4
  %19206 = icmp eq i64 %19191, %19203
  %19207 = sext i1 %19206 to i32
  %19208 = xor i32 %19207, -1
  %19209 = and i32 %19208, %19202
  %19210 = and i32 %19207, %19205
  %19211 = or i32 %19210, %19209
  %19212 = add i64 %19203, 16
  %19213 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19212
  %19214 = load i32, i32* %19213, align 4
  %19215 = icmp eq i64 %19191, %19212
  %19216 = sext i1 %19215 to i32
  %19217 = xor i32 %19216, -1
  %19218 = and i32 %19217, %19211
  %19219 = and i32 %19216, %19214
  %19220 = or i32 %19219, %19218
  %19221 = add i64 %19212, 16
  %19222 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19221
  %19223 = load i32, i32* %19222, align 4
  %19224 = icmp eq i64 %19191, %19221
  %19225 = sext i1 %19224 to i32
  %19226 = xor i32 %19225, -1
  %19227 = and i32 %19226, %19220
  %19228 = and i32 %19225, %19223
  %19229 = or i32 %19228, %19227
  %19230 = add i64 %19221, 16
  %19231 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19230
  %19232 = load i32, i32* %19231, align 4
  %19233 = icmp eq i64 %19191, %19230
  %19234 = sext i1 %19233 to i32
  %19235 = xor i32 %19234, -1
  %19236 = and i32 %19235, %19229
  %19237 = and i32 %19234, %19232
  %19238 = or i32 %19237, %19236
  %19239 = add i64 %19230, 16
  %19240 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19239
  %19241 = load i32, i32* %19240, align 4
  %19242 = icmp eq i64 %19191, %19239
  %19243 = sext i1 %19242 to i32
  %19244 = xor i32 %19243, -1
  %19245 = and i32 %19244, %19238
  %19246 = and i32 %19243, %19241
  %19247 = or i32 %19246, %19245
  %19248 = add i64 %19239, 16
  %19249 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19248
  %19250 = load i32, i32* %19249, align 4
  %19251 = icmp eq i64 %19191, %19248
  %19252 = sext i1 %19251 to i32
  %19253 = xor i32 %19252, -1
  %19254 = and i32 %19253, %19247
  %19255 = and i32 %19252, %19250
  %19256 = or i32 %19255, %19254
  %19257 = add i64 %19248, 16
  %19258 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19257
  %19259 = load i32, i32* %19258, align 4
  %19260 = icmp eq i64 %19191, %19257
  %19261 = sext i1 %19260 to i32
  %19262 = xor i32 %19261, -1
  %19263 = and i32 %19262, %19256
  %19264 = and i32 %19261, %19259
  %19265 = or i32 %19264, %19263
  %19266 = add i64 %19257, 16
  %19267 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19266
  %19268 = load i32, i32* %19267, align 4
  %19269 = icmp eq i64 %19191, %19266
  %19270 = sext i1 %19269 to i32
  %19271 = xor i32 %19270, -1
  %19272 = and i32 %19271, %19265
  %19273 = and i32 %19270, %19268
  %19274 = or i32 %19273, %19272
  %19275 = add i64 %19266, 16
  %19276 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19275
  %19277 = load i32, i32* %19276, align 4
  %19278 = icmp eq i64 %19191, %19275
  %19279 = sext i1 %19278 to i32
  %19280 = xor i32 %19279, -1
  %19281 = and i32 %19280, %19274
  %19282 = and i32 %19279, %19277
  %19283 = or i32 %19282, %19281
  %19284 = add i64 %19275, 16
  %19285 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19284
  %19286 = load i32, i32* %19285, align 4
  %19287 = icmp eq i64 %19191, %19284
  %19288 = sext i1 %19287 to i32
  %19289 = xor i32 %19288, -1
  %19290 = and i32 %19289, %19283
  %19291 = and i32 %19288, %19286
  %19292 = or i32 %19291, %19290
  %19293 = add i64 %19284, 16
  %19294 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19293
  %19295 = load i32, i32* %19294, align 4
  %19296 = icmp eq i64 %19191, %19293
  %19297 = sext i1 %19296 to i32
  %19298 = xor i32 %19297, -1
  %19299 = and i32 %19298, %19292
  %19300 = and i32 %19297, %19295
  %19301 = or i32 %19300, %19299
  %19302 = add i64 %19293, 16
  %19303 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19302
  %19304 = load i32, i32* %19303, align 4
  %19305 = icmp eq i64 %19191, %19302
  %19306 = sext i1 %19305 to i32
  %19307 = xor i32 %19306, -1
  %19308 = and i32 %19307, %19301
  %19309 = and i32 %19306, %19304
  %19310 = or i32 %19309, %19308
  %19311 = add i64 %19302, 16
  %19312 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19311
  %19313 = load i32, i32* %19312, align 4
  %19314 = icmp eq i64 %19191, %19311
  %19315 = sext i1 %19314 to i32
  %19316 = xor i32 %19315, -1
  %19317 = and i32 %19316, %19310
  %19318 = and i32 %19315, %19313
  %19319 = or i32 %19318, %19317
  %19320 = add i64 %19311, 16
  %19321 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19320
  %19322 = load i32, i32* %19321, align 4
  %19323 = icmp eq i64 %19191, %19320
  %19324 = sext i1 %19323 to i32
  %19325 = xor i32 %19324, -1
  %19326 = and i32 %19325, %19319
  %19327 = and i32 %19324, %19322
  %19328 = or i32 %19327, %19326
  %19329 = add i64 %19320, 16
  %19330 = getelementptr inbounds [256 x i32], [256 x i32]* %19193, i64 0, i64 %19329
  %19331 = load i32, i32* %19330, align 4
  %19332 = icmp eq i64 %19191, %19329
  %19333 = sext i1 %19332 to i32
  %19334 = xor i32 %19333, -1
  %19335 = and i32 %19334, %19328
  %19336 = and i32 %19333, %19331
  %Mitigated127 = or i32 %19336, %19335
  %19337 = xor i32 %19189, %Mitigated127
  %19338 = add i32 %18744, %19337
  %19339 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %19340 = getelementptr inbounds [32 x i32], [32 x i32]* %19339, i64 0, i64 31
  %19341 = load i32, i32* %19340, align 4
  %19342 = add i32 %19338, %19341
  %19343 = add i32 %19337, %19342
  %19344 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 2
  %19345 = getelementptr inbounds [32 x i32], [32 x i32]* %19344, i64 0, i64 30
  %19346 = load i32, i32* %19345, align 4
  %19347 = add i32 %19338, %19346
  %19348 = xor i32 %16943, %19347
  %19349 = lshr i32 %19348, 1
  %19350 = shl i32 %19348, 31
  %19351 = add i32 %19349, %19350
  %19352 = shl i32 %16947, 1
  %19353 = lshr i32 %16947, 31
  %19354 = add i32 %19352, %19353
  %19355 = xor i32 %19354, %19343
  %19356 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %19357 = getelementptr inbounds [8 x i32], [8 x i32]* %19356, i64 0, i64 4
  %19358 = load i32, i32* %19357, align 4
  %19359 = xor i32 %18147, %19358
  %19360 = getelementptr inbounds i8, i8* %1, i64 0
  %19361 = lshr i32 %19359, 24
  %19362 = trunc i32 %19361 to i8
  %19363 = getelementptr inbounds i8, i8* %19360, i64 3
  store i8 %19362, i8* %19363, align 1
  %19364 = lshr i32 %19359, 16
  %19365 = trunc i32 %19364 to i8
  %19366 = getelementptr inbounds i8, i8* %19360, i64 2
  store i8 %19365, i8* %19366, align 1
  %19367 = lshr i32 %19359, 8
  %19368 = trunc i32 %19367 to i8
  %19369 = getelementptr inbounds i8, i8* %19360, i64 1
  store i8 %19368, i8* %19369, align 1
  %19370 = trunc i32 %19359 to i8
  store i8 %19370, i8* %19360, align 1
  %19371 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %19372 = getelementptr inbounds [8 x i32], [8 x i32]* %19371, i64 0, i64 5
  %19373 = load i32, i32* %19372, align 4
  %19374 = xor i32 %18151, %19373
  %19375 = getelementptr inbounds i8, i8* %1, i64 4
  %19376 = lshr i32 %19374, 24
  %19377 = trunc i32 %19376 to i8
  %19378 = getelementptr inbounds i8, i8* %19375, i64 3
  store i8 %19377, i8* %19378, align 1
  %19379 = lshr i32 %19374, 16
  %19380 = trunc i32 %19379 to i8
  %19381 = getelementptr inbounds i8, i8* %19375, i64 2
  store i8 %19380, i8* %19381, align 1
  %19382 = lshr i32 %19374, 8
  %19383 = trunc i32 %19382 to i8
  %19384 = getelementptr inbounds i8, i8* %19375, i64 1
  store i8 %19383, i8* %19384, align 1
  %19385 = trunc i32 %19374 to i8
  store i8 %19385, i8* %19375, align 1
  %19386 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %19387 = getelementptr inbounds [8 x i32], [8 x i32]* %19386, i64 0, i64 6
  %19388 = load i32, i32* %19387, align 4
  %19389 = xor i32 %19351, %19388
  %19390 = getelementptr inbounds i8, i8* %1, i64 8
  %19391 = lshr i32 %19389, 24
  %19392 = trunc i32 %19391 to i8
  %19393 = getelementptr inbounds i8, i8* %19390, i64 3
  store i8 %19392, i8* %19393, align 1
  %19394 = lshr i32 %19389, 16
  %19395 = trunc i32 %19394 to i8
  %19396 = getelementptr inbounds i8, i8* %19390, i64 2
  store i8 %19395, i8* %19396, align 1
  %19397 = lshr i32 %19389, 8
  %19398 = trunc i32 %19397 to i8
  %19399 = getelementptr inbounds i8, i8* %19390, i64 1
  store i8 %19398, i8* %19399, align 1
  %19400 = trunc i32 %19389 to i8
  store i8 %19400, i8* %19390, align 1
  %19401 = getelementptr inbounds %struct.TWOFISH_context, %struct.TWOFISH_context* %0, i32 0, i32 1
  %19402 = getelementptr inbounds [8 x i32], [8 x i32]* %19401, i64 0, i64 7
  %19403 = load i32, i32* %19402, align 4
  %19404 = xor i32 %19355, %19403
  %19405 = getelementptr inbounds i8, i8* %1, i64 12
  %19406 = lshr i32 %19404, 24
  %19407 = trunc i32 %19406 to i8
  %19408 = getelementptr inbounds i8, i8* %19405, i64 3
  store i8 %19407, i8* %19408, align 1
  %19409 = lshr i32 %19404, 16
  %19410 = trunc i32 %19409 to i8
  %19411 = getelementptr inbounds i8, i8* %19405, i64 2
  store i8 %19410, i8* %19411, align 1
  %19412 = lshr i32 %19404, 8
  %19413 = trunc i32 %19412 to i8
  %19414 = getelementptr inbounds i8, i8* %19405, i64 1
  store i8 %19413, i8* %19414, align 1
  %19415 = trunc i32 %19404 to i8
  store i8 %19415, i8* %19405, align 1
  ret void
}

attributes #0 = { nounwind uwtable "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.ident = !{!0}

!0 = !{!"clang version 3.9.1 (tags/RELEASE_391/final)"}
